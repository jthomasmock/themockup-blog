[
  {
    "objectID": "posts/2021-03-07-custom-gt-functions-and-testing/index.html",
    "href": "posts/2021-03-07-custom-gt-functions-and-testing/index.html",
    "title": "Creating a custom gt function for aligning first-row text and testing it with testthat",
    "section": "",
    "text": "It’s no secret, but I love the gt package and tables in general. I’ve been on a big table kick for almost a year at this point!\nWhile I love all the amazing features built into gt, sometimes I also want to create my own functions to wrap or extend features.\nFor example, I’ve done:\n\nCustom gt-themes and functions Blogpost\n\nEmbedding custom HTML Blogpost\n\nCreated repeatable beautiful table reporting Gist and Gist\n\nUsing patchwork to combine ggplot2 + gt Gist\n\n\nThis blogpost will cover how to solve a fairly common ask, how to add a symbol/character to the end of ONLY the first row of a column and maintain the alignment of the entire column. We’ll walk through how to accomplish this with gt only, creating our own function to do it more succinctly, and then how to further test our gt outputs with testthat!"
  },
  {
    "objectID": "posts/2021-03-07-custom-gt-functions-and-testing/index.html#no-repeats",
    "href": "posts/2021-03-07-custom-gt-functions-and-testing/index.html#no-repeats",
    "title": "Creating a custom gt function for aligning first-row text and testing it with testthat",
    "section": "No repeats",
    "text": "No repeats\nI’ve always been a fan of not having to repeat symbols/prefixes/suffixes inside tables. There’s some ongoing work here in gt to add this as a feature, but in the meantime I wanted to play around with a few ways to accomplish this with gt as it is, and/or a custom function as of today.\nYou can imagine a situation like below, where we want to label cells within a column as a percent, and want to indicate that it’s a percent ONLY on the first row.\n\nhead(gtcars) %>%\n  mutate(hp_pct = (hp/max(hp) * 100)) %>% \n  dplyr::select(mfr, model, year, trim, hp, hp_pct) %>%\n  gt() %>% \n  fmt_percent(columns = vars(hp_pct), rows = 1, scale_values = FALSE) %>% \n  fmt_number(columns = vars(hp_pct), rows = 2:6) %>% \n  tab_style(\n    style = cell_text(color = \"red\"), \n    locations = cells_body(vars(hp_pct), rows = 1)\n    )\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\nmfr\n      model\n      year\n      trim\n      hp\n      hp_pct\n    \n\n\nFord\nGT\n2017\nBase Coupe\n647\n97.88%\n\n\nFerrari\n458 Speciale\n2015\nBase Coupe\n597\n90.32\n\n\nFerrari\n458 Spider\n2015\nBase\n562\n85.02\n\n\nFerrari\n458 Italia\n2014\nBase Coupe\n562\n85.02\n\n\nFerrari\n488 GTB\n2016\nBase Coupe\n661\n100.00\n\n\nFerrari\nCalifornia\n2015\nBase Convertible\n553\n83.66\n\n\n\n\n\n\nHowever, you can quickly see that this misaligned the first row from the remaining rows.\n\n\nNo repeats in gt\n\nAn alternative would be to convert those rows to text and apply specific changes.\nThere’s quite a bit going on here:\n\n\nMust use a mono space font for the column of interest\n\nMust be mono-spaced so that everything aligns properly\n\n\nAlign the now text column to be right-aligned\n\nAlign to right, so again the decimal places align (text default aligns to left otherwise)\n\n\nUse gt::text_transform() to add percent to the first row\n\nuse base::format() to round and “force” a specific number of decimal places\n\n\nUse gt::text_transform() to add non-breaking space \"&nbsp\" to remaining rows\n\nMust use \"&nbsp\", which is the HTML code for nonbreaking space, as a raw space (eg \" \") will not work\n\n\n\nI want to pause here and say with the code below, we have officially accomplished our goal. However, this was fairly manual and can be repetitive for adding several of these transformations in a single table.\n\nhead(gtcars) %>%\n  mutate(hp_pct = (hp/max(hp) * 100)) %>% \n  dplyr::select(mfr, model, year, trim, hp, hp_pct) %>%\n  gt() %>%\n  # use a mono-spaced font\n  tab_style(\n    style = cell_text(font = google_font(\"Fira Mono\")),\n    locations = cells_body(columns = vars(hp_pct))\n    ) %>% \n  # align the column of interst to right\n  cols_align(align = \"right\", columns = vars(hp_pct)) %>% \n  # round and transform the first row to percent\n  text_transform(\n    locations = cells_body(vars(hp_pct), rows = 1),\n    fn = function(x){ \n      fmt_val <- format(as.double(x), nsmall = 1, digits = 1)\n      paste0(fmt_val, \"%\") %>% gt::html()}\n  ) %>% \n  text_transform(\n    locations = cells_body(vars(hp_pct), rows = 2:6),\n    fn = function(x){ \n      # round remaining rows, add a non-breaking space\n     fmt_val <- format(as.double(x), nsmall = 1, digits = 1)\n     lapply(fmt_val, function(x) paste0(x, '&nbsp') %>% gt::html())\n  })\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\nmfr\n      model\n      year\n      trim\n      hp\n      hp_pct\n    \n\n\nFord\nGT\n2017\nBase Coupe\n647\n97.9%\n\n\nFerrari\n458 Speciale\n2015\nBase Coupe\n597\n 90.3&nbsp\n\n\nFerrari\n458 Spider\n2015\nBase\n562\n 85.0&nbsp\n\n\nFerrari\n458 Italia\n2014\nBase Coupe\n562\n 85.0&nbsp\n\n\nFerrari\n488 GTB\n2016\nBase Coupe\n661\n100.0&nbsp\n\n\nFerrari\nCalifornia\n2015\nBase Convertible\n553\n 83.7&nbsp"
  },
  {
    "objectID": "posts/2021-03-07-custom-gt-functions-and-testing/index.html#format-symbol-first-function",
    "href": "posts/2021-03-07-custom-gt-functions-and-testing/index.html#format-symbol-first-function",
    "title": "Creating a custom gt function for aligning first-row text and testing it with testthat",
    "section": "Format symbol first Function",
    "text": "Format symbol first Function\nWe can try to wrap some of the gt code into a function and apply these transformations in bulk at the location of our choosing! This is especially important for making it generally apply to other types of inputs instead of JUST %. The function of interest is actually two custom functions, some gt functions, and a good chunk of logic.\nI’ve commented the individual sections as to their purpose, and included quite a bit of error-handling or protecting against various user inputs.\n\nfmt_symbol_first <- function(\n  gt_data,\n  column = NULL,        # column of interest to apply to\n  symbol = NULL,        # symbol to add, optionally\n  suffix = \"\",          # suffix to add, optionally\n  decimals = NULL,      # number of decimal places to round to\n  last_row_n,           # what's the last row in data?\n  symbol_first = FALSE  # symbol before or after suffix?\n) {\n  \n  # Test and error out if mandatory columns are missing\n  stopifnot(\"`symbol_first` argument must be a logical\" = is.logical(symbol_first))\n  stopifnot(\"`last_row_n` argument must be specified and numeric\" = is.numeric(last_row_n))\n  stopifnot(\"Input must be a gt table\" = class(gt_data)[[1]] == \"gt_tbl\")\n\n  # needs to type convert to double to play nicely with decimals and rounding\n  # as it's converted to character by gt::text_transform\n  add_to_first <- function(x, suff = suffix, symb = symbol) {\n    if (!is.null(decimals)) {\n      x <- suppressWarnings(as.double(x))\n      fmt_val <- format(x = x, nsmall = decimals, digits = decimals)\n    } else {\n      fmt_val <- x\n    }\n\n    # combine the value, passed suffix, symbol -> html\n    if (isTRUE(symbol_first)) {\n      paste0(fmt_val, symb, suff) %>% gt::html()\n    } else {\n      paste0(fmt_val, suff, symb) %>% gt::html()\n    }\n  }\n\n  # repeat non-breaking space for combined length of suffix + symbol\n  # logic is based on is a NULL passed or not\n  if (!is.null(symbol) | !identical(as.character(symbol), character(0))) {\n    suffix <- ifelse(identical(as.character(suffix), character(0)), \"\", suffix)\n    length_nbsp <- c(\"&nbsp\", rep(\"&nbsp\", nchar(suffix))) %>%\n      paste0(collapse = \"\")\n  } else {\n    suffix <- ifelse(identical(as.character(suffix), character(0)), \"\", suffix)\n    length_nbsp <- rep(\"&nbsp\", nchar(suffix)) %>%\n      paste0(collapse = \"\")\n  }\n\n  # affect rows OTHER than the first row\n  add_to_remainder <- function(x, length = length_nbsp) {\n    if (!is.null(decimals)) {\n      # if decimal not null, convert to double\n      x <- suppressWarnings(as.double(x))\n      # then round and format ALL to force specific decimals\n      fmt_val <- format(x = x, nsmall = decimals, digits = decimals)\n    } else {\n      fmt_val <- x\n    }\n    paste0(fmt_val, length) %>% lapply(FUN = gt::html)\n  }\n\n  # pass gt object\n  # align right to make sure the spacing is meaningful\n  gt_data %>%\n    cols_align(align = \"right\", columns = vars({{ column }})) %>%\n    # convert to mono-font for column of interest\n    tab_style(\n      style = cell_text(font = google_font(\"Fira Mono\")),\n      locations = cells_body(columns = vars({{ column }}))\n    ) %>%\n    # transform first rows\n    text_transform(\n      locations = cells_body(vars({{ column }}), rows = 1),\n      fn = add_to_first\n    ) %>%\n    # transform remaining rows\n    text_transform(\n      locations = cells_body(vars({{ column }}), rows = 2:last_row_n),\n      fn = add_to_remainder\n    )\n}\n\nUse the function\nWe can now use that fmt_symbol_first() function, note that I’m testing a few different combinations of suffix/symbols, decimals, etc that may be a bit nonsensical in the table itself but are interactively testing that the results are what I expect. Specifically, I’m making sure that symbols/suffixes are added, and that the spacing is correct. While this is useful for sanity checking quickly, we can also take another step to apply some proper unit-testing in the next section.\n\ngtcars %>% \n  head() %>% \n  dplyr::select(mfr, year, bdy_style, mpg_h, hp) %>% \n  dplyr::mutate(mpg_h = rnorm(n = dplyr::n(), mean = 22, sd = 1)) %>% \n  gt() %>% \n  opt_table_lines() %>% \n  fmt_symbol_first(column = mfr, symbol = \"&#x24;\", suffix = \" \", last_row_n = 6) %>%\n  fmt_symbol_first(column = year, symbol = NULL, suffix = \"%\", last_row_n = 6) %>%\n  fmt_symbol_first(column = mpg_h, symbol = \"&#37;\", suffix = NULL, last_row_n = 6, decimals = 1) %>% \n  fmt_symbol_first(column = hp, symbol = \"&#176;\", suffix = \"F\", last_row_n = 6, decimals = NULL, symbol_first = TRUE)\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\nmfr\n      year\n      bdy_style\n      mpg_h\n      hp\n    \n\n\nFord $\n2017%\ncoupe\n23.4%\n647°F\n\n\nFerrari&nbsp&nbsp\n2015&nbsp\ncoupe\n22.1&nbsp\n597&nbsp&nbsp\n\n\nFerrari&nbsp&nbsp\n2015&nbsp\nconvertible\n21.4&nbsp\n562&nbsp&nbsp\n\n\nFerrari&nbsp&nbsp\n2014&nbsp\ncoupe\n23.7&nbsp\n562&nbsp&nbsp\n\n\nFerrari&nbsp&nbsp\n2016&nbsp\ncoupe\n23.1&nbsp\n661&nbsp&nbsp\n\n\nFerrari&nbsp&nbsp\n2015&nbsp\nconvertible\n22.3&nbsp\n553&nbsp&nbsp"
  },
  {
    "objectID": "posts/2021-03-07-custom-gt-functions-and-testing/index.html#unit-testing",
    "href": "posts/2021-03-07-custom-gt-functions-and-testing/index.html#unit-testing",
    "title": "Creating a custom gt function for aligning first-row text and testing it with testthat",
    "section": "Unit testing",
    "text": "Unit testing\nAt this point, we’ve created a custom gt wrapper function, added some relatively robust checks into the function, but are still manually checking the output confirms to our expectations. We can perform proper unit testing with the {testthat} package.\n\nTesting your code can be painful and tedious, but it greatly increases the quality of your code. testthat tries to make testing as fun as possible, so that you get a visceral satisfaction from writing tests.\n\nWhile an in-depth run through of testhat is beyond the scope of this post, I have included an expandable section with a minimal example below, expanded from the “R Packages” book chapter on testing:\ntestthat Example\n\nlibrary(stringr)\nlibrary(testthat)\n\nstr_length(\"a\")   # 1 \n\n[1] 1\n\nstr_length(\"ab\")  # 2\n\n[1] 2\n\nstr_length(\"abc\") # 3\n\n[1] 3\n\n\nSo str_length() counts the length of a string, fairly straightforward!\nWe can convert this to a logical confirmation, which means that a computer can understand if the output was as expected, rather than just printing and reading which is mainly for our interactive use. I have included one FALSE output just as an example.\n\nstr_length(\"a\")   == 1 # 1 TRUE\n\n[1] TRUE\n\nstr_length(\"ab\")  == 2 # 2 TRUE\n\n[1] TRUE\n\nstr_length(\"abc\") == 3 # 3 TRUE\n\n[1] TRUE\n\nstr_length(\"abc\") == 1 # 3 FALSE\n\n[1] FALSE\n\n\nWhile this testing is useful, we can make it even easier with testhat, by using expect_equal(). Now, these functions will not return anything if they pass. If they fail, then they will print an error, and a helpful statement saying what the failure was.\n\n### All TRUE\ntestthat::expect_equal(str_length(\"a\"),   1) # TRUE\ntestthat::expect_equal(str_length(\"ab\"),  2) # TRUE\ntestthat::expect_equal(str_length(\"abc\"), 3) # TRUE\n\nJust to show you, here’s one where we get a FALSE, the match is off by 2.\n\ntestthat::expect_equal(str_length(\"a\"),  3) # FALSE\n\nError: str_length(\"a\") not equal to 3.\n1/1 mismatches\n[1] 1 - 3 == -2\n\n\nThe last step, is wrapping our various tests into test_that structure. Here, while the individual tests return no visible output, we can get a friendly message saying they have all passed!\n\ntest_that(\n  desc = \"str_length is number of characters\",\n  code = {\n    expect_equal(str_length(\"a\"), 1)\n    expect_equal(str_length(\"ab\"), 2)\n    expect_equal(str_length(\"abc\"), 3)\n  }\n)\n\nTest passed 🥳\n\n\nWe can also see what happens if there is a failure (abcd is not 3 characters, but 4).\n\ntest_that(\n  desc = \"str_length is number of characters\",\n  code = {\n    expect_equal(str_length(\"a\"), 1)\n    expect_equal(str_length(\"ab\"), 2)\n    expect_equal(str_length(\"abc\"), 3)\n    expect_equal(str_length(\"abcd\"), 3)\n  }\n)\n\n── Failure (<text>:7:5): str_length is number of characters ────────────────────\nstr_length(\"abcd\") not equal to 3.\n1/1 mismatches\n[1] 4 - 3 == 1\n\n\nError:\n! Test failed\n\n\nThese tests can be used interactively, but ultimately are even more useful when rolled into an R package. For that next step, I recommend reading through the “R Packages” book, specifically the Packages Chapter.\nTesting gt\n\nNow you may say, well those minimal example tests were easy, it’s just counting?! How do I test gt? We can treat gt exactly like what it is, a HTML table. Quick example below using our custom function (fmt_symbol_first()).\n\nex_gt <- gtcars %>% \n  head() %>% \n  dplyr::select(mfr, year, bdy_style, mpg_h, hp) %>% \n  dplyr::mutate(mpg_h = c(20.2, 22.0, 20.8, 21.2, 22.8, 22.7)) %>% \n  gt() %>% \n  opt_table_font(font = google_font(\"Roboto Mono\")) %>%\n  opt_table_lines() %>% \n  fmt_symbol_first(column = mfr, symbol = \"&#x24;\", suffix = \" \", last_row_n = 6) %>%\n  fmt_symbol_first(column = year, symbol = NULL, suffix = \"%\", last_row_n = 6) %>%\n  fmt_symbol_first(column = mpg_h, symbol = \"&#37;\", suffix = NULL, last_row_n = 6, decimals = 1) %>% \n  fmt_symbol_first(column = hp, symbol = \"&#176;\", suffix = \"F\", last_row_n = 6, decimals = NULL, symbol_first = TRUE)\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n# example table\nex_gt\n\n\n\n\n\n\nmfr\n      year\n      bdy_style\n      mpg_h\n      hp\n    \n\n\nFord $\n2017%\ncoupe\n20.2%\n647°F\n\n\nFerrari&nbsp&nbsp\n2015&nbsp\ncoupe\n22.0&nbsp\n597&nbsp&nbsp\n\n\nFerrari&nbsp&nbsp\n2015&nbsp\nconvertible\n20.8&nbsp\n562&nbsp&nbsp\n\n\nFerrari&nbsp&nbsp\n2014&nbsp\ncoupe\n21.2&nbsp\n562&nbsp&nbsp\n\n\nFerrari&nbsp&nbsp\n2016&nbsp\ncoupe\n22.8&nbsp\n661&nbsp&nbsp\n\n\nFerrari&nbsp&nbsp\n2015&nbsp\nconvertible\n22.7&nbsp\n553&nbsp&nbsp\n\n\n\n\n\n# what is it?\nex_gt %>% \n  as_raw_html() %>%  \n  str(max.level = 1)\n\n 'html' chr \"<table style=\\\"font-family: 'Roboto Mono', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubunt\"| __truncated__\n - attr(*, \"html\")= logi TRUE\n\n\nrvest\nThat’s a relatively basic table, but if used interactively it will just print out the output. We can “capture” the raw HTML via gt::as_raw_html(), and then just treat it like another table to “webscrape” with rvest.\n\nlibrary(rvest)\n\n\nAttaching package: 'rvest'\n\n\nThe following object is masked from 'package:readr':\n\n    guess_encoding\n\n# create object as RAW html\nex_gt_raw <- ex_gt %>% \n  as_raw_html()\n\n# read into rvest, and grab the table body\nex_html_tab <- read_html(ex_gt_raw) %>% \n  html_node(\"table > tbody\") \n\n# 6 row table!\nex_html_tab\n\n{html_node}\n<tbody style=\"border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3;\">\n[1] <tr>\\n<td style=\"padding-top: 8px; padding-bottom: 8px; padding-left: 5px ...\n[2] <tr>\\n<td style=\"padding-top: 8px; padding-bottom: 8px; padding-left: 5px ...\n[3] <tr>\\n<td style=\"padding-top: 8px; padding-bottom: 8px; padding-left: 5px ...\n[4] <tr>\\n<td style=\"padding-top: 8px; padding-bottom: 8px; padding-left: 5px ...\n[5] <tr>\\n<td style=\"padding-top: 8px; padding-bottom: 8px; padding-left: 5px ...\n[6] <tr>\\n<td style=\"padding-top: 8px; padding-bottom: 8px; padding-left: 5px ...\n\n\nTest HTML\nNow that it’s saved as HTML, we can extract a column, and we’re back to raw strings!\n\ncol1_extract <- ex_html_tab %>% \n    html_nodes(paste0(\"td:nth-child(\",1 , \")\")) %>% \n    html_text() \n\ncol1_extract\n\n[1] \"Ford $\"            \"Ferrari&nbsp&nbsp\" \"Ferrari&nbsp&nbsp\"\n[4] \"Ferrari&nbsp&nbsp\" \"Ferrari&nbsp&nbsp\" \"Ferrari&nbsp&nbsp\"\n\n\nNow, rather than using the whole string, I’m going to focus on testing the 1st row and then the remainder. Mainly because our function should do different things to the first row versus the remaining rows!\n\ncol1_extract[1] \n\n[1] \"Ford $\"\n\n\nSo this should be relatively straightforward, we want to do an exact match expecting \"Ford $\".\n\ntestthat::expect_match(col1_extract[1], \"Ford $\")\n\nError: col1_extract\\[1\\] does not match \"Ford $\".\nActual value: \"Ford \\$\"\n\n\nBUT oh no we get a failure??? This is because the $ is a special character in regex, so we need to “escape” it with \\\\. This tells regex to parse it as a literal “dollar sign”. After passing the escape, we now get a silent pass!\n\ntestthat::expect_match(col1_extract[1], \"Ford \\\\$\")\n\nWe can run it with test_that() as well, and since it passes we get our friendly little message!\n\ntest_that(\n  desc = \"First word is Ford $\",\n  code = testthat::expect_match(col1_extract[1], \"Ford \\\\$\")\n)\n\nTest passed 🥇\n\n\nTesting function\nNow, I want to test the individual columns for different things, so I’m going to write a test expectation function.\nI’m interested in:\n\nThe column number\n\nThe row number (ie first or remaining)\n\nA specific expectation\n\nAll using the same HTML input\n\ntest_gt_by_col <- function(col_n, row_first = TRUE, expectation){\n  \n  # if row_first = TRUE, then just get the 1st row\n  # otherwise select the remainder\n  if(isTRUE(row_first)){\n    row_sel <- 1\n  } else {\n    row_sel <- 2:6\n  }\n  \n  # use our example html\n  # grab the column by number\n  # get the rows by selection\n  # test the expectation\n  ex_html_tab %>% \n    html_nodes(paste0(\"td:nth-child(\",col_n , \")\")) %>% \n    html_text() %>% \n    .[row_sel] %>% \n    testthat::expect_match(expectation)\n}\n\nWe can then use our function and avoid having to copy-paste much at all!\n\ntest_that(\n  desc = \"First word is Ford $\",\n  code = test_gt_by_col(1, row_first = TRUE, expectation = \"Ford \\\\$\")\n)\n\nTest passed 🎊\n\n\nJust a quick reminder, if it fails (I’m intentionally failing). We can see that the expectation doesn’t match the remainder.\n\ntest_that(\n  desc = \"First word is Ford $\",\n  code = test_gt_by_col(1, row_first = FALSE, expectation = \"Ford \\\\$\")\n)\n\n── Failure (<text>:15:3): First word is Ford $ ─────────────────────────────────\n`\\.` does not match \"Ford \\\\$\".\nActual values:\n* Ferrari&nbsp&nbsp\n* Ferrari&nbsp&nbsp\n* Ferrari&nbsp&nbsp\n* Ferrari&nbsp&nbsp\n* Ferrari&nbsp&nbsp\nBacktrace:\n 1. global test_gt_by_col(1, row_first = FALSE, expectation = \"Ford \\\\$\")\n 3. testthat::expect_match(., expectation)\n 4. testthat:::expect_match_(...)\n\n\nError:\n! Test failed\n\n\nPut it all together\nWe can put it all together now, and test all of our columns of interest, with testthat using our custom testing function ON the output of the custom function we wrote earlier.\n\nCreate HTML table, extract w/ rvest, define test function\n\nex_gt <- gtcars %>% \n  head() %>% \n  dplyr::select(mfr, year, bdy_style, mpg_h, hp) %>% \n  dplyr::mutate(mpg_h = c(20.2, 22.0, 20.8, 21.2, 22.8, 22.7)) %>% \n  gt() %>% \n  opt_table_font(font = google_font(\"Roboto Mono\")) %>%\n  opt_table_lines() %>% \n  fmt_symbol_first(column = mfr, symbol = \"&#x24;\", suffix = \" \", last_row_n = 6) %>%\n  fmt_symbol_first(column = year, symbol = NULL, suffix = \"%\", last_row_n = 6) %>%\n  fmt_symbol_first(column = mpg_h, symbol = \"&#37;\", suffix = NULL, last_row_n = 6, decimals = 1) %>% \n  fmt_symbol_first(column = hp, symbol = \"&#176;\", suffix = \"F\", last_row_n = 6, decimals = NULL, symbol_first = TRUE)\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nex_gt_raw <- ex_gt %>% \n  as_raw_html()\n\n# read into rvest, and grab the table body\nex_html_tab <- read_html(ex_gt_raw) %>% \n  html_node(\"table > tbody\") \n\ntest_gt_by_col <- function(col_n, row_first = TRUE, expectation){\n  \n  # if row_first = TRUE, then just get the 1st row\n  # otherwise select the remainder\n  if(isTRUE(row_first)){\n    row_sel <- 1\n  } else {\n    row_sel <- 2:6\n  }\n  \n  # use our example html\n  # grab the column by number\n  # get the rows by selection\n  # test the expectation\n  ex_html_tab %>% \n    html_nodes(paste0(\"td:nth-child(\",col_n , \")\")) %>% \n    html_text() %>% \n    .[row_sel] %>% \n    testthat::expect_match(expectation)\n}\n\nNow we can run our tests on the specific columns and get a lot of “praise”! That’s it for now, but maybe we’ll explore putting these tests into a package down the line.\n\n# Test for escaped characters ---------------------------------------------\n# check that a suffix + symbol worked, and that escaped characters can be tested\ntestthat::test_that(\n  \"Escaped characters work\",\n  {\n    test_gt_by_col(1, expectation = \"Ford \\\\$\")\n    test_gt_by_col(1, row_first = FALSE, expectation = \"Ferrari&nbsp&nbsp\")\n  }\n  )\n\nTest passed 😀\n\n# Test for raw percent ----------------------------------------------------\n# on this column we used the literal string of %\ntestthat::test_that(\n  \"Raw percent character works\",\n  {\n    test_gt_by_col(2, expectation = \"2017%\")\n    test_gt_by_col(2, row_first = FALSE, expectation = \"201[4-7]&nbsp\")\n  }\n  )\n\nTest passed 🎉\n\n# Test for symbolic percent -----------------------------------------------\n# on this column we used the HTML code for percent\ntestthat::test_that(\n  \"HTML symbol for percent works\",\n  {\n    test_gt_by_col(4, expectation = \"20.2%\")\n    test_gt_by_col(4, row_first = FALSE, expectation = \"[0-9]+&nbsp\")\n  }\n  )\n\nTest passed 🥇\n\n# Test for suffix + symbol ------------------------------------------------\n# test for case where the symbol is in front of suffix\ntestthat::test_that(\n  \"A combined suffix + symbol work\",\n  {\n    test_gt_by_col(5, expectation = \"647°F\")\n    test_gt_by_col(5, row_first = FALSE, expectation = \"[0-9]+&nbsp&nbsp\")\n  }\n  )\n\nTest passed 🎊\n\n\n\n\n\n\n\n\nExpand for Session Info\n\n\n\n\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.0 (2022-04-22)\n os       macOS Monterey 12.2.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       America/Chicago\n date     2022-04-28\n pandoc   2.18 @ /Applications/RStudio.app/Contents/MacOS/quarto/bin/tools/ (via rmarkdown)\n quarto   0.9.294 @ /usr/local/bin/quarto\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version    date (UTC) lib source\n dplyr       * 1.0.8      2022-02-08 [1] CRAN (R 4.2.0)\n forcats     * 0.5.1      2021-01-27 [1] CRAN (R 4.2.0)\n ggplot2     * 3.3.5      2021-06-25 [1] CRAN (R 4.2.0)\n gt          * 0.5.0.9000 2022-04-27 [1] Github (rstudio/gt@0d4c83d)\n purrr       * 0.3.4      2020-04-17 [1] CRAN (R 4.2.0)\n readr       * 2.1.2      2022-01-30 [1] CRAN (R 4.2.0)\n rvest       * 1.0.2      2021-10-16 [1] CRAN (R 4.2.0)\n scales      * 1.2.0      2022-04-13 [1] CRAN (R 4.2.0)\n sessioninfo * 1.2.2      2021-12-06 [1] CRAN (R 4.2.0)\n stringr     * 1.4.0      2019-02-10 [1] CRAN (R 4.2.0)\n testthat    * 3.1.4      2022-04-26 [1] CRAN (R 4.2.0)\n tibble      * 3.1.6      2021-11-07 [1] CRAN (R 4.2.0)\n tidyr       * 1.2.0      2022-02-01 [1] CRAN (R 4.2.0)\n tidyverse   * 1.3.1      2021-04-15 [1] CRAN (R 4.2.0)\n\n [1] /Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/library\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "posts/2020-12-31-2020-in-review/index.html",
    "href": "posts/2020-12-31-2020-in-review/index.html",
    "title": "2020 in Review",
    "section": "",
    "text": "2020 was absolutely difficult in a lot of ways, both for the world and for me personally. Rather than focusing on some of the difficulties, I’d rather focus on some of the successes for 2020.\nI feel very blessed that my family has stayed happy and healthy, that I have the change to continue being able to grow into expanded roles at RStudio, that I have had a lot of time with my wife Maria and our dog Howard, and that 2020 is now over. Here’s to hopefully efficient vaccine delivery in 2021, and a safer new year to all!"
  },
  {
    "objectID": "posts/2020-12-31-2020-in-review/index.html#user-2020",
    "href": "posts/2020-12-31-2020-in-review/index.html#user-2020",
    "title": "2020 in Review",
    "section": "useR 2020",
    "text": "useR 2020\nI was lucky enough to both attend (virtually) and present at my first ever useR! I focused on the #TidyTuesday project, what it’s all about, and how the community has built around it.\n\n\nSo excited to be sharing what the community has built around #TidyTuesday for #useR2020 !\"TidyTuesday: Scaffolding for a Community of Practice\"https://t.co/NK3PKMACdeSlides: https://t.co/PAs1uruopZ#rstats\n\n— Tom Mock (@thomas_mock) July 8, 2020"
  },
  {
    "objectID": "posts/2020-12-31-2020-in-review/index.html#nyc-r",
    "href": "posts/2020-12-31-2020-in-review/index.html#nyc-r",
    "title": "2020 in Review",
    "section": "NYC R",
    "text": "NYC R\nGot to attend and present at my first NYC R conference, focused on doing more with RMarkdown!\n\nRecording\n\n\n\nReally excited to talk about #rstats + RMarkdown for #rstatsnyc in about an hr! Slides at: https://t.co/AYSprYoK9d if you want to follow along or maybe live tweet!Companion blog post: https://t.co/a6DbT0AA6c pic.twitter.com/5SQfrHjFim\n\n— Tom Mock (@thomas_mock) August 15, 2020"
  },
  {
    "objectID": "posts/2020-12-31-2020-in-review/index.html#hockey-analytics-night-in-canada-nfl-edition",
    "href": "posts/2020-12-31-2020-in-review/index.html#hockey-analytics-night-in-canada-nfl-edition",
    "title": "2020 in Review",
    "section": "Hockey Analytics Night in Canada: NFL Edition",
    "text": "Hockey Analytics Night in Canada: NFL Edition\nI was honored to be invited to and present at HANICx NFL, and after running a poll decided to present on the most requested topic: tidymodels!\n\n\nSlides: A short intro presentation on using tidymodels to predict whether the opposing team will run or pass\n\nRecording"
  },
  {
    "objectID": "posts/2020-12-31-2020-in-review/index.html#nhs-r-conference",
    "href": "posts/2020-12-31-2020-in-review/index.html#nhs-r-conference",
    "title": "2020 in Review",
    "section": "NHS R Conference",
    "text": "NHS R Conference\nGave an adapted version of my RMarkdown presentation for the NHS R community, enjoyed the chatter in the live groups there!\n\n\nReally enjoyed giving my presentation on Marvelous RMarkdown for the #NHSRconf2020 w/ #RStats !Slides: https://t.co/AYSprYoK9dCompanion Blogpost: https://t.co/a6DbT0AA6cRMarkdown Cookbook: https://t.co/Ce43CUlPBg\n\n— Tom Mock (@thomas_mock) November 12, 2020"
  },
  {
    "objectID": "posts/2020-12-31-2020-in-review/index.html#carnegie-mellon-sports-analytics-conference",
    "href": "posts/2020-12-31-2020-in-review/index.html#carnegie-mellon-sports-analytics-conference",
    "title": "2020 in Review",
    "section": "Carnegie Mellon Sports Analytics Conference",
    "text": "Carnegie Mellon Sports Analytics Conference\nGave my first public workshop for the CMSAC team, big thanks to Ron Yorko for the invite! I’ve always wanted to attend this conference and was deeply honored to join as a workshop presenter.\n\nSlides"
  },
  {
    "objectID": "posts/2020-12-31-2020-in-review/index.html#tables-presentation",
    "href": "posts/2020-12-31-2020-in-review/index.html#tables-presentation",
    "title": "2020 in Review",
    "section": "Tables Presentation",
    "text": "Tables Presentation\nGave a 60 min presentation on “Beautiful Tables in R”\n\nSlides"
  },
  {
    "objectID": "posts/2020-07-25-meta-rmarkdown/index.html",
    "href": "posts/2020-07-25-meta-rmarkdown/index.html",
    "title": "Meta RMarkdown - Taxonomy and Use cases",
    "section": "",
    "text": "Set of tools layed flat"
  },
  {
    "objectID": "posts/2020-07-25-meta-rmarkdown/index.html#nyr-presentation",
    "href": "posts/2020-07-25-meta-rmarkdown/index.html#nyr-presentation",
    "title": "Meta RMarkdown - Taxonomy and Use cases",
    "section": "NYR Presentation",
    "text": "NYR Presentation\n\nMy slides on this topic for the NYC R Conference are at bit.ly/marvelRMD.\nPDF Version for folks who want to try out the code-chunks."
  },
  {
    "objectID": "posts/2020-07-25-meta-rmarkdown/index.html#how-alison-hill-teaches-r-markdown",
    "href": "posts/2020-07-25-meta-rmarkdown/index.html#how-alison-hill-teaches-r-markdown",
    "title": "Meta RMarkdown - Taxonomy and Use cases",
    "section": "How Alison Hill teaches R Markdown",
    "text": "How Alison Hill teaches R Markdown\nIf you haven’t read it already make sure to read Dr. Alison Hill’s fantastic blogpost:How I teach R Markdown\nAlison is a RMarkdown superstar on the RStudio Education team. Her blogpost covers her guide on her well-informed approach for teaching R Markdown.\nShe has taught:\n- College students as a professor across a semester\n- In person professional learners at RStudio::conf in 1-2 day workshops\n- Digital Learners in Pharma/Finance/etc via shorter online workshops\nTo summarize her post:\n\n\nMake it. Make it again. - Show how knitting works throughout the process.\n\n\nMake it pretty - Engage your learners with visuals, tables, etc - motivation is key!\n\n\nMake it snappy - Get a shareable link the first 20 min (usually via Netlify Drop).\n\n\nMake it real - “Teach folks what they need to know to actually use the tool productively in real life.”\n\n\nMake it easy - “People will only keep using R Markdown if they see it making their life easier. So show them how. For example, the RStudio IDE has some very nice built-in features that make it much easier to be an R Markdown user.”\n\nAgain - GO READ her blogpost for additional links and guides she links to.\nMy blogpost below is meant to be a sister article to hers, framed with a similar approach we use in Customer Success but different in that we’re not doing as much long-form education. Alison’s approach is well-informed and very useful in the context of direct teaching activity, which is why I wanted to share it as well!"
  },
  {
    "objectID": "posts/2020-07-25-meta-rmarkdown/index.html#how-i-share-knowledge-around-r-markdown",
    "href": "posts/2020-07-25-meta-rmarkdown/index.html#how-i-share-knowledge-around-r-markdown",
    "title": "Meta RMarkdown - Taxonomy and Use cases",
    "section": "How I share knowledge around R Markdown",
    "text": "How I share knowledge around R Markdown\nI work on a different team than Alison at RStudio, specifically I’m a Customer Success Manager. This means that I work with existing RStudio Pro Product customers, most often people who have RStudio Connect. I work exclusively with High Tech/Software customers, meaning that they are typically already doing very sophisticated work with R in production, and I’m helping them further eliminate friction or empower their data science teams to do more with R.\nA core part of my job is knowledge sharing around how to use open-source software like R Markdown with or without our Pro Products. Thus most of my work is Strategic in nature, although I do often give shorter 30-60 min training sessions that are Tactical.\n\nA strategy is a set of guidelines used to achieve an overall objective, whereas tactics are the specific actions aimed at adhering to those guidelines. Source: Wikipedia\n\nThus my usual framing is covering topics that inform the learner of new strategies (ways of solving a problem) without necessary having to teach all the tactics (nuts and bolts of how it all works).\nThis post will focus on 4 core strategies of why R Markdown is SO useful and absolutely worth learning with links to external tactics/guides/write-ups of how to accomplish the various tasks.\n\n\n\nCat reading a military strategy book"
  },
  {
    "objectID": "posts/2020-07-25-meta-rmarkdown/index.html#r-markdown-for-literate-programming",
    "href": "posts/2020-07-25-meta-rmarkdown/index.html#r-markdown-for-literate-programming",
    "title": "Meta RMarkdown - Taxonomy and Use cases",
    "section": "R Markdown for Literate Programming",
    "text": "R Markdown for Literate Programming\nGoal: Capture code, text/comments, and output in a single document\nThis is the most common use of R Markdown, and is often how it is taught in University coursework. R Markdown is a tool for Literate Programming, and in summary is:\n\nA programming paradigm introduced by Donald Knuth in which a computer program is given an explanation of its logic in a natural language, such as English, interspersed with snippets of macros and traditional source code, from which compilable source code can be generated.\n\nNot just for R\nR Markdown obviously has rich support for R-based code and data products, but did you know it also supports:\n- Native Python or calling Python from R via reticulate\n- SQL - Blog post by Irene Steves\n- CSS or JavaScript for all sorts of customization\n- As well as Bash, Rcpp, Stan, and other formats\n- All together there are 52(!) possible language engines coming from knitr\nMVP of Reproducibility\n\nWhether you talk about Minimum Viable Product or Most Valuable Player, it works! Since R Markdown is a form of Literate Programming, you can write all of your comments, notes, and execute your code within it.\n\nR Markdown HAS to run successfully to save/knit the output\n\nR Markdown is self-documenting (the code is embedded)\n\nThe code is diffable and easily human readable in version control\n\nSelf-contained workspace\nExploratory Data Analysis\nAn example here is for Dave Robinson’s #TidyTuesday screencasts + code\n\nDave uses R Markdown to explore a brand new dataset each week, capturing his comments and train of thought as he tests the data, performs basic analyses, and moves towards a modeling or deliverable data product\n\n\n\n\nMan plotting an upward curve"
  },
  {
    "objectID": "posts/2020-07-25-meta-rmarkdown/index.html#r-markdown-as-a-data-product",
    "href": "posts/2020-07-25-meta-rmarkdown/index.html#r-markdown-as-a-data-product",
    "title": "Meta RMarkdown - Taxonomy and Use cases",
    "section": "R Markdown as a Data Product",
    "text": "R Markdown as a Data Product\nGoal: Generate output natively in R for consumption\nThis is typically the second most common use of R Markdown. Since R Markdown can knit to all sorts of different formats, it is a powerful tool for creating data products like:\nPresentations\n\nPowerpoint\n\nWeb-formats - xaringan (remark.js)\n\nLateX formats - Beamer\n\nDashboards with flexashboard\n\n\nLets you quickly build beautiful dashboards with either static or reactive components\nReports\n\nSupports HTML Documents, PDF, Word and many others\nEntire Websites\n\n\nblogdown for easily extensible custom websites or blogs\n\n\ndistill for scientific writing, native to the web (this website is built in distill)\n\nMost importantly these formats are created with code, so you get the benefit of reproducibility, automation, etc while still generating data products in the format your non-coder colleagues expect.\n\n\n\nChild operating mission control"
  },
  {
    "objectID": "posts/2020-07-25-meta-rmarkdown/index.html#r-markdown-as-a-control-document",
    "href": "posts/2020-07-25-meta-rmarkdown/index.html#r-markdown-as-a-control-document",
    "title": "Meta RMarkdown - Taxonomy and Use cases",
    "section": "R Markdown as a Control Document",
    "text": "R Markdown as a Control Document\nGoal: Scale data science tasks, automate the boring stuff, create robust pipelines\nLess widely known, but just as important is the idea of R Markdown as a meta-document that lets you bring in other code or automate processes.\nAs it’s much larger in scope than a single bullet point I’d recommend going to read Emily Riederer’s blog post on Rmarkdown Driven Development. It’s “an approach of using R Markdown within the larger scope of the analysis engineering concept” presented by Hilary Parker.\nA brief summary of her blogpost:\n\nI tend to think of each RMarkdown as having a “data product” (an analytical engine calibrated to answer some specific question) nestled within it. Surfacing this tool just requires a touch of forethought before beginning an analysis and a bit of clean-up afterwards.\nIn this post, I describe RMarkdown Driven Development: a progression of stages between a single ad-hoc RMarkdown script and more advanced and reusable data products like R projects and packages. This approach has numerous benefits.\n\nAutomation w/ parameters\n\nParameters are data passed to the R Markdown document to generate new outputs from the same code.\n\nAn example here is generating a report for all 50 US states.\n\nRather than writing 50 reports manually, you can pass a parameter of state to the R Markdown report and render 50x reports at once!\n\nThe input R Markdown is always the same, but you pass each state as a parameter programatically to generate a new report for EACH state with it’s data.\n\n\n\n\nParamaterized reports\n\n\nParameterized report cookbook\n\nParameterized Reports site\nChild Documents\n\nChild documents allow you to bring in OTHER RMarkdown code/documents into a parent, meaning you can use the parent document as a meta-document referencing code/outputs in other documents.\n\nThis can greatly help with the flow/size of a single document and you can essentially modularize portions of the document.\nIt’s worth noting that you should read Emily’s post above on building up a robust R Markdown workflow.\n\nChild Documents\n\nChild Documents - Yihui’s Blog\n\n\n\nRMarkdown for Emails w/ blastula\n\n\nWhile this is technically a data-product, because it is generating an email I’m putting it as a Control Document. The short of this is that blastula provides a framework to generate HMTL emails from R Markdown, which are then sent by an email server or RStudio Connect.\n\nThis Blastula Webinar covers a lot of the use cases, all with code and real-life applications\n\n\nR Markdown + RStudio Connect as an execution engine\n\nR Markdown is a first-class citizen on RStudio Connect, and you can interactively generate new reports based on parameters, or schedule R Markdown documents to re-execute documents on a schedule.\nCode for ETL - an example of an ETL process through an automated R Markdown report, this could query against a SQL database or a spark cluster to process ETL jobs, all on a schedule down to the minute or up to a year.\nScheduled reporting - maybe your boss needs a report built every Monday? You can do that too - pulling in new data and re-generating a report on a specific time-schedule all with no need for human intervention.\nEmailing w/ blastula - maybe your boss is too busy to consume a full report every day - send a conditional email directly to them if a specific number is hit or missed all with code in R! This email could is built with R Markdown, and could contain plots, tables, raw data, or attach ANY R Markdown-based document (so… basically anything).\n\n\n\n\nGif of a machine creating jelly rolls"
  },
  {
    "objectID": "posts/2020-07-25-meta-rmarkdown/index.html#rmarkdown-for-templating",
    "href": "posts/2020-07-25-meta-rmarkdown/index.html#rmarkdown-for-templating",
    "title": "Meta RMarkdown - Taxonomy and Use cases",
    "section": "RMarkdown for Templating",
    "text": "RMarkdown for Templating\nGoal: Don’t repeat yourself, generate input templates or output documents from code.\nUsing R Markdown for templating is normally thought of for knitr::render() + parameters, but there’s additional techniques to solve specific problems that don’t fit neatly into paramaterized reports as well.\nKnitting w/ knit::render()\n\nThis is the first step towards using a template, and lets you generate R Markdown outputs programatically with code. It can be coupled with parameters or with other arguments for outputs locations, etc.\nLooping outputs\n\nThis is really still focused at data products, but programmatically building up portions WITHIN a document.\n\nIn this example, I’m taking a single function and using purrr::walk() to generate new outputs from a template within the R Markdown report.\nNote that for the chunk that outputs the repeated portions, you have to set results=\"asis\" in the chunk option.\n\n\n\nMinimal example below with the palmerpenguins dataset. Full copy-pastable code at: https://git.io/JJBcC.\nNote that I’m writing one function and calling it n times, it would loop across all the data based on the different inputs.\n---\noutput: html_document\n---\n  \n  \n```{r penguin function, echo=FALSE, message=FALSE}\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(palmerpenguins)\nlibrary(glue)\npenguins <- palmerpenguins::penguins\nmultiplot <- function(penguin_name){\n  cat(glue::glue(\"  \\n### {penguin_name}  \\n  \\n\"))\n  df_pen <- penguins %>% \n    filter(as.character(species) == penguin_name) %>% \n    na.omit()\n  \n  flipper_len <- df_pen %>% \n    summarize(mean = mean(flipper_length_mm)) %>% \n    pull(mean) %>% \n    round(digits = 1)\n  \n  bill_len <- df_pen %>% \n    summarize(mean = mean(bill_length_mm)) %>% \n    pull(mean) %>% \n    round(digits = 1)\n  \n  cat(\n    glue::glue(\"There are {nrow(df_pen)} observations of {penguin_name} penguins. The average flipper length is {flipper_len} and the average bill length is {bill_len}.  \\n\")\n  )\n  \n  plot_out <- df_pen %>% \n    ggplot(aes(x = bill_length_mm, y = flipper_length_mm)) +\n    geom_point() +\n    labs(x = \"Bill Length\", y = \"Flipper Length\", title = penguin_name)\n  \n  print(plot_out)\n  \n  cat(\"  \\n  \\n\")\n}\n```\n\n```{r loop output,fig.width=6,echo=FALSE,message=FALSE,results=\"asis\"}\npurrr::walk(unique(as.character(penguins$species)), multiplot)\n```\n\n<!-- https://git.io/JJBcC -->\nWhich generates the following document:\n\n\nLoop Output in RMD\n\n\nwhisker\n\n\nwhisker is a templating engine for R conforming to the Mustache specification.\n\nIt uses glue style syntax to add data to templates either in memory or to an output file, where my mental model is it is glue for documents rather than strings.\n\nYou can include templates from all sorts of inputs, like R files, R Markdown, markdown or plain text.\n\nThese templates can be local directories, or stored in the inst directory of an R package.\n\nLastly, these can also generate outputs in the same format, eg you can create templates/outputs for R, R Markdown or other plain-text formats!\n\nMinimal whisker example below:\nFirst, some input data:\ndata <- list(\n  name = \"Chris\", \n  value = 10000, \n  taxed_value = 10000 - (10000 * 0.4), \n  in_ca = TRUE\n)\n\nThen a template:\ntemplate <-\n'Hello {{name}}\nYou have just won ${{value}}!\n{{#in_ca}}\nWell, ${{taxed_value}}, after taxes.\n{{/in_ca}}'\nNow, fill the template!\ntext <- whisker.render(template, data)\ncat(text)\n# Output\nHello Chris\nYou have just won $10000!\nWell, $6000, after taxes.\nI use whisker natively to generate the readme files for each week’s #TidyTuesday submission. Separate blog-post to come for that!\nusethis::use_template()\n\nAlternatively to natively using whisker usethis::use_template() provides a more ready to use function, and uses whisker internally.\n\n\nuse_template() Used as the engine for a templating function in other packages.\n\n\n\nSharla Gelfand, the “Queen of Reproducible Reporting”, put together lots of material using the usethis::use_template() workflow in their work.\n\n\nSharla Gelfand’s use_template() blogpost\n\nIn short, they turned an annual report from a mess of copy-pasting and manual work into a fast, streamlined, reproducible, and easily repeatable workflow using R, R Markdown, and usethis::use_template().\n\n\nRecording of their presentation on the same topic\n\n\nSlides for that presentation.\n\n\nFin\nSo that’s an overview of my approach to sharing knowledge around R Markdown, and like Alison said:\n\nBut remember: there is no one way to learn R Markdown, and no one way to teach it either. I love seeing the creativity of the community when introducing the R Markdown family - so keep them coming!\n\n\n\n\n\n\n\nExpand for Session Info\n\n\n\n\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.0 (2022-04-22)\n os       macOS Monterey 12.2.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       America/Chicago\n date     2022-04-28\n pandoc   2.18 @ /Applications/RStudio.app/Contents/MacOS/quarto/bin/tools/ (via rmarkdown)\n quarto   0.9.294 @ /usr/local/bin/quarto\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version date (UTC) lib source\n sessioninfo * 1.2.2   2021-12-06 [1] CRAN (R 4.2.0)\n\n [1] /Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/library\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "posts/2021-01-18-reading-tables-from-images-with-magick/index.html",
    "href": "posts/2021-01-18-reading-tables-from-images-with-magick/index.html",
    "title": "Reading tables from images with magick",
    "section": "",
    "text": "ImageMagick is a robust and comprehensive open-source image processing library, and per the official docs:\n\nUse ImageMagick® to create, edit, compose, or convert bitmap images. It can read and write images in a variety of formats (over 200) including PNG, JPEG, GIF, HEIC, TIFF, DPX, EXR, WebP, Postscript, PDF, and SVG. ImageMagick can resize, flip, mirror, rotate, distort, shear and transform images, adjust image colors, apply various special effects, or draw text, lines, polygons, ellipses and Bézier curves.\n\nWhile you can use it from various APIs, tools or CLIs, one of the easiest ways for R users to get started is with the R wrapper by ROpenSci’s Jeroen Ooms called magick. This package provides a large set of pipe-friendly functions allowing for interactive editing and testing.\nI’ve written briefly about magick before, specifically in using it to add logos to final ggplot2 images, but today will be a different use-case, namely using magick to read data embedded in images.\nAnother note is that while the docs for ImageMagick proper and the magick R wrapper are very good, ImageMagick is an entire piece of software. This means that there is an amazing breadth of applications, knowledge, and tricks to apply. I think of it a lot like regex, where it’s very useful but for many applications we only scratch the surface. For a nice “cookbook” for using ImageMagick, check out this resource. It’s a “legacy” guide, but many of the examples can be converted to magick in R or from the CLI itself."
  },
  {
    "objectID": "posts/2021-01-18-reading-tables-from-images-with-magick/index.html#remove-the-background-and-grid",
    "href": "posts/2021-01-18-reading-tables-from-images-with-magick/index.html#remove-the-background-and-grid",
    "title": "Reading tables from images with magick",
    "section": "Remove the background and grid",
    "text": "Remove the background and grid\nWe’ll first start by converting the color image to greyscale via image_quantize().\n\nraw_img %>% \n  image_quantize(colorspace = \"gray\") %>% \n  image_ggplot()\n\n\n\n\nWe can remove the grid by converting “white” colors to transparent, and allowing for some “fuzzy” approximation of colors that are close to white or “touching”. There’s a lot more to fuzz in that it’s the “relative color distance (value between 0 and 100) to be considered similar in the filling algorithm”, but I’m not a color space expert by any means.\nBelow we have an example of fuzz = 0, fuzz = 20, fuzz = 40, fuzz = 60. Each increase does remove a bit of “noise”, but is also reducing the quality of the “signal”.\n\nCode for Combo\n\nfuzz_fun <- function(fuzz){\n  raw_img %>% \n    image_quantize(colorspace = \"gray\") %>% \n    image_transparent(color = \"white\", fuzz=fuzz) %>% \n    image_background(\"white\") %>% \n    image_crop(geometry_area(0, 150,110, 45))\n}\n\nfuzz_fun(20)\n\n\n\ncombo_fuzz <- c(\n  fuzz_fun(0),\n  fuzz_fun(20),\n  fuzz_fun(40),\n  fuzz_fun(60)\n) %>% \n  image_append(stack = TRUE) \n\n\nimage_ggplot(combo_fuzz)\n\n\n\n\nIn practical terms, we are balancing increase fuzz to remove unnecessary components (eg grid lines) while leaving the actual characters there. Increasing fuzz will remove more “noise” but will eventually start to eat away at the actual “signal” as well.\n\nno_grid <- raw_img %>% \n  image_quantize(colorspace = \"gray\") %>% \n   image_transparent(color = \"white\", fuzz=20) %>% \n   image_background(\"white\") \n\nimage_ggplot(no_grid)\n\n\n\n\nSo we’ve taken white and converted it to transparent, and then set the image background back to “white”.\nYou can also remove continuous lines with a “thinning” method. We can use image_morphology() coupled with a rectangular kernel to remove straight horizontal lines for the most part. You can read Rectangle:20x1 as finding rectangles about 20 pixels wide x 1 pixel high. We couple this with image_negate() as otherwise it will focus on the characters.\nSo we’ll negate > thin > negate to get back to our white background sans grid-lines. While this works pretty well, it’s not always necessary for the OCR. I did want to show it as it can be helpful in some situations.\n\nno_grid %>% \n  image_negate() %>% \n  image_ggplot()\n\n\n\n\n\nno_grid %>%\n  image_negate() %>% # negate\n  image_morphology(method = \"Thinning\", kernel = \"Rectangle:20x1\") %>%\n  image_negate() %>% # back to white\n  image_ggplot()\n\n\n\n\nThis worked pretty well! However, remember that we don’t always have to do this. We’ll also still need to crop the image to remove the team logos as they can’t be parsed as text."
  },
  {
    "objectID": "posts/2021-01-18-reading-tables-from-images-with-magick/index.html#crop-the-image",
    "href": "posts/2021-01-18-reading-tables-from-images-with-magick/index.html#crop-the-image",
    "title": "Reading tables from images with magick",
    "section": "Crop the image",
    "text": "Crop the image\ngeometry_area() is used in various functions to indicate the starting width/heights and then the offset, all in pixels.\n\ngeometry_area(width = NULL, height = NULL, x_off = 0, y_off = 0)\n\nNote that you’re always “starting” from the top and left sides, and we’re passing the geometry_area() to image_crop to crop the image itself.\n\n# remove the top 20 pixels\nno_grid %>% \n  image_crop(geometry_area(0, 0,110, 45)) %>% \n  image_ggplot()\n\n\n\n\nSo this techniques can be used to cut out specific portions of an image, which is another useful technique for tricky columns. For now, let’s hope we can use ALL the data together.\n\nno_grid_crop <- no_grid %>% \n  image_crop(geometry_area(0, 0,110, 45))\n\nno_grid_crop %>% \n  image_ggplot()"
  },
  {
    "objectID": "posts/2021-01-18-reading-tables-from-images-with-magick/index.html#try-ocr",
    "href": "posts/2021-01-18-reading-tables-from-images-with-magick/index.html#try-ocr",
    "title": "Reading tables from images with magick",
    "section": "Try OCR",
    "text": "Try OCR\nWe can try our first OCR now! Note that image_ocr() is just calling tesseract behind the scenes.\n\nno_grid_crop %>% \n  image_ocr()\n\n[1] \"Aaron Donald (DE - LA) 19.0\\nMyles Garrett (DE - CLE) 16.5\\nT.J. Watt (OLB - PIT) 14.5\\nKhalil Mack (OLB - CHI) 13.0\\nJustin Houston (DE - IND) 12.0\\nEmmanuel Ogbah (DE - MIA) 11.0\\nCarl Lawson (DE - CIN) 10.5\\nBrandon Graham (DE - PHI) 10.0\\nDeMarcus Lawrence (DE - DAL) 10.0\\nYannick Ngakoue (DE - BAL) 10.0\\nMontez Sweat (DE - WAS) 10.0\\nCarlos Dunlap (DE - SEA) 9.0\\nCameron Jordan (DE - NO) 9.0\\nKerry Hyder (DE - SF) 9.0\\nShaquil Barrett (OLB - TB) 9.0\\nStephon Tuitt (DE - PIT) 9.0\\nRomeo Okwara (DE - DET) 9.0\\n\"\n\n\nThis did a great job, but what about this raw text string we ended up with? Also note that image_ocr() is just a wrapper around tesseract::ocr().\nLet’s go into tesseract proper to try some robust things out!\nI’m going to focus on one numeric “column” first to keep things relatively simpler. We’ll use image_crop to grab the column of interest, then we’ll call tesseract::ocr() on it. We can provide some options to the engine, namely that we’re expecting only spaces, numbers, or a decimal. This will explicitly prevent 5 being converted to S for example. It does really well here!\n\nnum_only <- tesseract::tesseract(\n  options = list(tessedit_char_whitelist = c(\".0123456789 \"))\n  )\n\nno_grid %>% \n  image_quantize(colorspace = 'gray') %>% \n  image_threshold() %>% \n  image_crop(geometry_area(100, 0, 600, 40)) %>% \n  ocr(engine = num_only) \n\n[1] \"19.0\\n16.5\\n14.5\\n13.0\\n12.0\\n11.0\\n10.5\\n10.0\\n10.0\\n10.0\\n10.0\\n9.0\\n9.0\\n9.0\\n9.0\\n9.0\\n9.0\\n\"\n\n\nBut we have text, numbers, and some symbols like (.\nSo let’s pass those as limitations to the engine, and then we can take the raw text and turn it into a dataframe/tibble.\n\ncombo <- tesseract::tesseract(\n    options = list(\n      tessedit_char_whitelist = paste0(\n        c(letters, LETTERS, \" \", \".0123456789 (-)\"), collapse = \"\")\n      )\n  )\n\nraw_text <- no_grid %>%\n  image_quantize(colorspace = \"gray\") %>%\n  image_transparent(\"white\", fuzz = 22) %>%\n  image_background(\"white\") %>%\n  image_threshold() %>%\n  image_crop(geometry_area(0, 0, 110, 45)) %>%  \n  ocr(engine = combo)"
  },
  {
    "objectID": "posts/2021-01-18-reading-tables-from-images-with-magick/index.html#make-a-tibble",
    "href": "posts/2021-01-18-reading-tables-from-images-with-magick/index.html#make-a-tibble",
    "title": "Reading tables from images with magick",
    "section": "Make a Tibble",
    "text": "Make a Tibble\n\nraw_text\n\n[1] \"Aaron Donald (DE - LA) 19.0\\nMyles Garrett (DE - CLE) 16.5\\nT.J. Watt (OLB - PIT) 14.5\\nKhalil Mack (OLB - CHI) 13.0\\nJustin Houston (DE - IND) 12.0\\nEmmanuel Ogbah (DE - MIA) 11.0\\nCarl Lawson (DE - CIN) 10.5\\nBrandon Graham (DE - PHI) 10.0\\nDeMarcus Lawrence (DE - DAL) 10.0\\nYannick Ngakoue (DE - BAL) 10.0\\nMontez Sweat (DE - WAS) 10.0\\nCarlos Dunlap (DE - SEA) 9.0\\nCameron Jordan (DE - NO) 9.0\\nKerry Hyder (DE - SF) 9.0\\nShaquil Barrett (OLB - TB) 9.0\\nStephon Tuitt (DE - PIT) 9.0\\nRomeo Okwara (DE - DET) 9.0\\n\"\n\n\nThis looks pretty much perfect! We just now need to get it into a dataframe. We can accomplish this by splitting on each new row (\\n) and then adding that as a column in a tibble.\n\nraw_tibble <- raw_text %>% \n  str_split(pattern = \"\\n\") %>% \n  unlist() %>%\n  tibble(data = .) \n\nraw_tibble\n\n# A tibble: 18 × 1\n   data                               \n   <chr>                              \n 1 \"Aaron Donald (DE - LA) 19.0\"      \n 2 \"Myles Garrett (DE - CLE) 16.5\"    \n 3 \"T.J. Watt (OLB - PIT) 14.5\"       \n 4 \"Khalil Mack (OLB - CHI) 13.0\"     \n 5 \"Justin Houston (DE - IND) 12.0\"   \n 6 \"Emmanuel Ogbah (DE - MIA) 11.0\"   \n 7 \"Carl Lawson (DE - CIN) 10.5\"      \n 8 \"Brandon Graham (DE - PHI) 10.0\"   \n 9 \"DeMarcus Lawrence (DE - DAL) 10.0\"\n10 \"Yannick Ngakoue (DE - BAL) 10.0\"  \n11 \"Montez Sweat (DE - WAS) 10.0\"     \n12 \"Carlos Dunlap (DE - SEA) 9.0\"     \n13 \"Cameron Jordan (DE - NO) 9.0\"     \n14 \"Kerry Hyder (DE - SF) 9.0\"        \n15 \"Shaquil Barrett (OLB - TB) 9.0\"   \n16 \"Stephon Tuitt (DE - PIT) 9.0\"     \n17 \"Romeo Okwara (DE - DET) 9.0\"      \n18 \"\"                                 \n\n\nNow we have essentially perfect data at this point, we just need to separate out our columns and drop the row without any data."
  },
  {
    "objectID": "posts/2021-01-18-reading-tables-from-images-with-magick/index.html#tidy-the-tibble",
    "href": "posts/2021-01-18-reading-tables-from-images-with-magick/index.html#tidy-the-tibble",
    "title": "Reading tables from images with magick",
    "section": "Tidy the Tibble",
    "text": "Tidy the Tibble\nWe’ll first drop any rows where the character string is < 2. We can then use tidyr::separate() to separate one column into 4 new columns as player, position, team, and sacks. There are multiple separators, which for the example seen T.J. Watt (OLB - PIT) 14.5 are:\n\n\nT.J.Watt then ( represented as “\\\\(”\n\n\nOLB then - represented as “-”\n\n\nPIT then ) represented as “\\\\)”\n\nwhich leaves us with 14.5 at the end\n\nWe have to “escape” the parentheses with \\\\ so that regex can understand them. The | inside the sep arguments tell the regex to separate at a match of a white-space + parentheses OR white-space + dash OR parentheses + white-space.\nAs our last step, we’ll convert sacks to a double column, and then BOOM!\n\nraw_tibble %>% \n  filter(str_length(data) >= 2)  %>%\n  separate(\n    data, \n    into = c(\"player\", \"position\", \"team\", \"sacks\"), \n    sep = c(\" \\\\(| - |\\\\) \")\n    ) %>% \n  mutate(sacks = as.double(sacks))\n\n# A tibble: 17 × 4\n   player            position team  sacks\n   <chr>             <chr>    <chr> <dbl>\n 1 Aaron Donald      DE       LA     19  \n 2 Myles Garrett     DE       CLE    16.5\n 3 T.J. Watt         OLB      PIT    14.5\n 4 Khalil Mack       OLB      CHI    13  \n 5 Justin Houston    DE       IND    12  \n 6 Emmanuel Ogbah    DE       MIA    11  \n 7 Carl Lawson       DE       CIN    10.5\n 8 Brandon Graham    DE       PHI    10  \n 9 DeMarcus Lawrence DE       DAL    10  \n10 Yannick Ngakoue   DE       BAL    10  \n11 Montez Sweat      DE       WAS    10  \n12 Carlos Dunlap     DE       SEA     9  \n13 Cameron Jordan    DE       NO      9  \n14 Kerry Hyder       DE       SF      9  \n15 Shaquil Barrett   OLB      TB      9  \n16 Stephon Tuitt     DE       PIT     9  \n17 Romeo Okwara      DE       DET     9"
  },
  {
    "objectID": "posts/2021-01-18-reading-tables-from-images-with-magick/index.html#write-it-as-a-function",
    "href": "posts/2021-01-18-reading-tables-from-images-with-magick/index.html#write-it-as-a-function",
    "title": "Reading tables from images with magick",
    "section": "Write it as a Function",
    "text": "Write it as a Function\nWe can wrap this process into a reusable function, and then call it on our 3 images of interest!\n\nscrape_fun <- function(url_in, crop_left, crop_top){\n  raw_img <- image_read(url_in) %>% \n    image_quantize(colorspace = 'gray') %>%\n    image_transparent(\"white\", fuzz=22) %>% \n    image_background(\"white\") %>%\n    image_threshold() %>% \n    image_crop(geometry_area(0, 0, crop_left, crop_top)) \n  \n  image_ocr(raw_img) %>% \n    str_c() %>% \n    str_split(pattern = \"\\n\") %>% \n    unlist() %>%\n    tibble(data = .) %>% \n    filter(str_length(data) >= 2) %>% \n    separate(\n      data, \n      into = c(\"player\", \"position\", \"team\", \"sacks\"), \n      sep = c(\" \\\\(| - |\\\\) \")\n      ) %>% \n    mutate(sacks = as.double(sacks)) %>% \n    mutate(sacks = if_else(sacks >= 20, sacks/10, sacks))\n}\n\nWe can then call our new function! You may notice that I added a mutate above which protects against missing decimal places. Trey Hendrickson’s decimal place is apparently hard for the parser to “capture”.\n\n# output to tibble\ncr_sacks <- tibble(\n  url_in = c(\n    \"https://pbs.twimg.com/media/ErtmQ1PXYAEUQoY?format=jpg&name=900x900\",\n    \"https://pbs.twimg.com/media/ErtmSLlXMAAvylA?format=jpg&name=900x900\",\n    \"https://pbs.twimg.com/media/ErtmTUGW8AEZ6Cy?format=jpg&name=900x900\"\n    ),\n  crop_left = c(110, 95, 95),\n  crop_top = c(45, 5, 5)\n) %>% \n  pmap_df(scrape_fun)\n\ncr_sacks\n\n# A tibble: 46 × 4\n   player            position team  sacks\n   <chr>             <chr>    <chr> <dbl>\n 1 Aaron Donald      DE       LA     19  \n 2 Myles Garrett     DE       CLE    16.5\n 3 T.J. Watt         OLB      PIT    14.5\n 4 Khalil Mack       OLB      CHI    13  \n 5 Justin Houston    DE       IND    12  \n 6 Emmanuel Ogbah    DE       MIA    11  \n 7 Carl Lawson       DE       CIN    10.5\n 8 Brandon Graham    DE       PHI    10  \n 9 DeMarcus Lawrence DE       DAL    10  \n10 Yannick Ngakoue   DE       BAL    10  \n# … with 36 more rows\n\n\nWe can plot it just to be safe, and to see if everything “checks out”! We get a range we expected, and see that T.J. Watt and Aaron Donald create many more of their own sacks relative to their positions.\n\ncr_sacks %>% \n  mutate(position = if_else(position == \"LB\", \"OLB\", position)) %>% \n  ggplot(aes(x = sacks, y = position)) +\n  ggridges::geom_density_ridges(quantile_lines = TRUE, quantiles = 2) +\n  geom_point(\n    data = filter(cr_sacks, player %in% c(\"Aaron Donald\", \"T.J. Watt\")),\n    size = 3\n    ) +\n  ggridges::theme_ridges() +\n  theme(\n    axis.text = element_text(size = 10),\n    axis.title = element_text(size = 14),\n    plot.title = element_text(size = 16),\n    plot.caption = element_text(size = 10),\n    panel.grid.minor = element_blank(),\n    axis.title.x = element_text(hjust = 0)\n    ) +\n  labs(\n    x = \"\\nCreated Sacks\", y = \"\",\n    title = \"T.J. Watt and A. Donald are both outliers amongst their positions\",\n    subtitle = \"Created Sacks by position\",\n    caption = \"Data: ESPN | Plot: @thomas_mock\"\n    )\n\nPicking joint bandwidth of 1.05"
  },
  {
    "objectID": "posts/2021-01-18-reading-tables-from-images-with-magick/index.html#get-the-raw-img",
    "href": "posts/2021-01-18-reading-tables-from-images-with-magick/index.html#get-the-raw-img",
    "title": "Reading tables from images with magick",
    "section": "Get the raw img",
    "text": "Get the raw img\n\nburke <- \"https://pbs.twimg.com/media/EpdF4fzW4AEeOvF?format=png&name=small\"\nraw_img <- image_read(burke)\n\nNow, again while interactively you can just “print” the magick object and it will show up in the RStudio viewer pane, for this blog-post I’ll need to explicitly “show” it. I’ll call magick::image_ggplot(<img object>) to print it throughout the post.\n\nimage_ggplot(raw_img)\n\n\n\n\nThis looks like a relatively clean image, the only major problems as mentioned above are that it’s very low-quality along with not ideal fonts, and it cuts off some of the data for team."
  },
  {
    "objectID": "posts/2021-01-18-reading-tables-from-images-with-magick/index.html#clean-it-up",
    "href": "posts/2021-01-18-reading-tables-from-images-with-magick/index.html#clean-it-up",
    "title": "Reading tables from images with magick",
    "section": "Clean it up",
    "text": "Clean it up\nWe can remove the grid by converting “white” colors to transparent, and allowing for some “fuzzy” approximation of colors that are close to white or “touching”. There’s a lot more to fuzz in that it’s the “relative color distance (value between 0 and 100) to be considered similar in the filling algorithm”, but I’m not a color space expert by any means.\nIn practical terms, we are balancing increase fuzz to remove unnecessary components (eg grid lines) while leaving the actual characters there. Increasing fuzz will remove more “noise” but will eventually start to eat away at the actual “signal” as well.\nBelow we have an example of fuzz = 0, fuzz = 20, fuzz = 50, fuzz = 70.\nSo we’ve taken white and converted it to transparent, and then set the image background back to “white”.\n\nno_grid <- raw_img %>% \n   image_transparent(color = \"white\", fuzz=20) %>% \n   image_background(\"white\") \n\nimage_ggplot(no_grid)\n\n\n\n\nYou can also remove continuous lines with a “thinning” method. We can use image_morphology() coupled with a rectangular kernel to remove straight horizontal lines for the most part. You can read Rectangle:20x1 as finding rectangles about 20 pixels wide x 1 pixel high. We couple this with image_negate() as otherwise it will focus on the characters.\nSo we’ll negate > thin > negate to get back to our white background sans grid-lines.\n\nno_grid %>% \n  image_negate() %>% \n  image_ggplot()\n\n\n\n\nWe can apply the thinning morph as seen below, flipping back and forth with image_negate().\n\nno_grid %>% \n  image_negate() %>%\n  image_morphology(method = \"Thinning\", kernel = \"Rectangle:20x1\") %>% \n  image_negate() %>% \n  image_ggplot()\n\n\n\n\nThis worked pretty well! However, because of the mis-alignment of the column labels and the columns themselves, I’m just going to trim the top off."
  },
  {
    "objectID": "posts/2021-01-18-reading-tables-from-images-with-magick/index.html#crop-the-image-1",
    "href": "posts/2021-01-18-reading-tables-from-images-with-magick/index.html#crop-the-image-1",
    "title": "Reading tables from images with magick",
    "section": "Crop the image",
    "text": "Crop the image\ngeometry_area() is used in various functions to indicate the starting width/heights and then the offset, all in pixels.\n\ngeometry_area(width = NULL, height = NULL, x_off = 0, y_off = 0)\n\nNote that you’re always “starting” from the top and left sides, and we’re passing the geometry_area() to image_crop to crop the image itself.\n\n# remove the top 20 pixels\nno_grid %>% \n  image_crop(geometry_area(0, 0, 0, 20)) %>% \n  image_ggplot()\n\n\n\n\nSo this techniques can be used to cut out specific portions of an image, which is another useful technique for tricky columns. For now, let’s hope we can use ALL the data together.\n\nno_grid_crop <- no_grid %>% \n  image_crop(geometry_area(0, 0, 0, 20))\n\nno_grid_crop %>% \n  image_ggplot()"
  },
  {
    "objectID": "posts/2021-01-18-reading-tables-from-images-with-magick/index.html#try-ocr-1",
    "href": "posts/2021-01-18-reading-tables-from-images-with-magick/index.html#try-ocr-1",
    "title": "Reading tables from images with magick",
    "section": "Try OCR",
    "text": "Try OCR\nWe can try our first OCR now! Note that image_ocr() is just calling tesseract behind the scenes.\n\nno_grid_crop %>% \n  image_ocr()\n\n[1] \"Bills 100 99.3 07\\nPackers 100 100 0\\nRams 100989 11\\nChiefs 100 100 0\\nSaints 100 100 0\\nSeahawks 100 (97.7 23\\nSteelers 100 100 0\\nBuccaneer 99.5 92.6 69\\nTitans 97.6 787 18.9\\nColts 949 664 028.5,\\nBrowns 946 0 «675 TA\\nRavens 90.1 S18 38.3\\nFootballT 88.6 583 303\\nCardinals 65.7 (25.7 40\\nDolphins 43.7 24 353\\nGiants 413 100313\\nBears 35.3 18 335\\nVikings. 317 430 278\\nRaiders 29.1 45 246\\nEagles 18.3 340-149\\n49ers 145 os 14\\nPatriots 58 0 58\\nCowboys 23 0 23\\nLions 19 0 19\\nPanthers oO. oO O41\\n\"\n\n\nThis did a decent job, but I can already see some “problems”.\nThe Rams row is “squished” together, the Browns have some letters instead of numbers, and the Ravens have a “S” instead of a 5.\nLet’s go into tesseract proper to try some robust things out!\nI’m going to focus on one “column” first to keep things relatively simpler. We’ll use image_crop to grab the column of interest, then we’ll call tesseract::ocr() on it. We can provide some options to the engine, namely that we’re expecting only spaces, numbers, or a decimal. This will explicitly prevent 5 being converted to S for example.\n\nnum_only <- tesseract::tesseract(\n  options = list(tessedit_char_whitelist = c(\".0123456789 \"))\n  )\nno_grid %>% \n  image_quantize(colorspace = 'gray') %>% \n  image_threshold() %>% \n  image_crop(geometry_area(80, 0, 80, 20)) %>% \n  ocr(engine = num_only) \n\n[1] \"100\\n100\\n100\\n100\\n100\\n100\\n100\\n99.5\\n97.6\\n4.9\\n94.6\\n90.1\\n88.6\\n657\\n48.7\\n41.3\\n35.3\\n317\\n29.1\\n18.3\\n14.5\\n5.8\\n2.3\\n1.9\\n01\\n\"\n\n\nI’m going to “plot” the data to show some areas where mistakes were still made. We know that 100 is the max, and that the values are ranked, and thus should be always decreasing. We have at least 5 examples where the data is missing a period which causes it to be scaled improperly (10x larger than reality).\n\nocr_col1 <- no_grid %>%\n  image_crop(geometry_area(80, 0, 80, 20)) %>%\n  ocr(engine = num_only) %>%\n  str_split(pattern = \"\\n\") %>%\n  unlist() %>%\n  enframe() %>%\n  mutate(value = as.double(value)) %>%\n  filter(!is.na(value))\n\nocr_col1 %>%\n  mutate(color = case_when(\n    value > 100 ~ \"red\",\n    value > lag(value) ~ \"red\",\n    value > lag(value, n = 3) ~ \"red\",\n    TRUE ~ \"black\"\n  )) %>%\n  ggplot(aes(x = name, y = value, color = color)) +\n  geom_point(size = 3) +\n  scale_color_identity()\n\n\n\n\nAgain, due to the VERY low image quality (the original image is 72 DPI and only ~500 pixels high) we’re basically stuck with some of these manual steps. Regardless, we’ve got “better” data now that we’ve added our conversion logic. Those same 5 points now fall “accurately” into the appropriate range.\n\nocr_col1 %>% \n  mutate(color = case_when(\n    value > 100 ~ \"red\",\n    value > lag(value) ~ \"red\",\n    value > lag(value, n = 3) ~ \"red\",\n    TRUE ~ \"black\"\n  )) %>% \n  mutate(\n    value = if_else(value > 100, value/10, value),\n    value = if_else(name >= 22, value/10, value)\n    ) %>% \n  ggplot(aes(x = name, y = value, color = color)) +\n  geom_point(size = 3) +\n  scale_color_identity()\n\n\n\n\nSo we’ve apparently “fixed” this column!"
  },
  {
    "objectID": "posts/2021-01-18-reading-tables-from-images-with-magick/index.html#create-a-function",
    "href": "posts/2021-01-18-reading-tables-from-images-with-magick/index.html#create-a-function",
    "title": "Reading tables from images with magick",
    "section": "Create a function",
    "text": "Create a function\nWe’ll create a function so that we can split out each column, apply optimal characters or numeric to each and then recombine.\n\nimg_ocr_fun <- function(trim_width, trim_start, char_num = TRUE) {\n  \n  num_only <- tesseract::tesseract(\n    options = list(tessedit_char_whitelist = c(\".0123456789 \"))\n  )\n\n  combo <- tesseract::tesseract(\n    options = list(\n      tessedit_char_whitelist = paste0(\n        c(letters, LETTERS, \" \", \".0123456789 \"), collapse = \"\")\n      )\n  )\n\n\n  input_char <- if (isTRUE(char_num)) {\n    num_only\n  } else {\n    combo\n  }\n\n  no_grid %>%\n    image_crop(geometry_area(trim_width, 0, trim_start, 20)) %>%\n    ocr(engine = input_char) %>%\n    str_split(pattern = \"\\n\") %>%\n    unlist() %>%\n    enframe() %>%\n    select(-name) %>%\n    filter(!is.na(value), str_length(value) > 0)\n}\n\nWe can “find” the columns by cropping specific areas. Note that I’ve “recombined” all of them with image_append() so that you can see that each section together completes the table.\n\nc(\n  no_grid %>%\n    image_crop(geometry_area(80, 0, 0, 20)),\n  no_grid %>%\n    image_crop(geometry_area(50, 0, 80, 20)),\n  no_grid %>%\n    image_crop(geometry_area(50, 0, 140, 20)),\n  no_grid %>%\n    image_crop(geometry_area(50, 0, 210, 20))\n) %>%\n  image_append() %>%\n  image_ggplot()"
  },
  {
    "objectID": "posts/2021-01-18-reading-tables-from-images-with-magick/index.html#apply-the-function",
    "href": "posts/2021-01-18-reading-tables-from-images-with-magick/index.html#apply-the-function",
    "title": "Reading tables from images with magick",
    "section": "Apply the function",
    "text": "Apply the function\nWe can use purrr::pmap() to apply the functions with each of our parameters, and then use bind_cols to create our actual dataset.\n\nall_ocr <- list(trim_width = c(80, 50, 50, 50),\n     trim_start = c(0, 80, 140, 210),\n     char_num = c(FALSE, TRUE, FALSE, TRUE)) %>% \n  pmap(img_ocr_fun)\n\n# it fails on one row\nall_ocr[[4]] <- append(all_ocr[[4]]$value, 271, after = 10)\n\ndata_df <- all_ocr %>% \n  bind_cols() %>% \n  set_names(nm = \"team\", \"win\", \"lose\", \"leverage\") \n\nNew names:\n• `value` -> `value...1`\n• `value` -> `value...2`\n• `value` -> `value...3`\n• `` -> `...4`\n\ndata_df\n\n# A tibble: 25 × 4\n   team      win   lose  leverage\n   <chr>     <chr> <chr> <chr>   \n 1 Bills     100   99.3  07      \n 2 Packers   100   100   0       \n 3 Rams      100   98.9  11      \n 4 Chiefs    100   100   0       \n 5 Saints    100   100   0       \n 6 Seahawks  100   977   23      \n 7 Steelers  100   100   0       \n 8 Buccaneer 99.5  92.6  69      \n 9 Titans    97.6  78.7  18.9    \n10 Colts     94.9  66.4  285     \n# … with 15 more rows"
  },
  {
    "objectID": "posts/2021-01-18-reading-tables-from-images-with-magick/index.html#clean-it-up-1",
    "href": "posts/2021-01-18-reading-tables-from-images-with-magick/index.html#clean-it-up-1",
    "title": "Reading tables from images with magick",
    "section": "Clean it up",
    "text": "Clean it up\nWe can convert some of the letters to their proper numeric. I intentionally used characters vs numeric on some columns as it “guesses” better in our really low quality image. I then add some logic to convert our numbers if decimal places are missing, and it gets VERY close, but is not perfect.\n\ndata_df %>% \n  mutate(across(win:leverage, ~str_replace(tolower(.x), \"s\", \"5\"))) %>% \n  mutate(across(win:leverage, ~str_replace(tolower(.x), \"o|a\", \"0\"))) %>% \n  mutate(across(win:leverage, as.double)) %>% \n  mutate(across(win:leverage, ~if_else(.x > 100, .x/10, .x))) %>% \n  mutate(lose = if_else(lose > win, lose/10, lose)) %>% \n  mutate(leverage = win - lose) %>% \n  print(n = 25)\n\n# A tibble: 25 × 4\n   team         win  lose leverage\n   <chr>      <dbl> <dbl>    <dbl>\n 1 Bills      100    99.3    0.700\n 2 Packers    100   100      0    \n 3 Rams       100    98.9    1.10 \n 4 Chiefs     100   100      0    \n 5 Saints     100   100      0    \n 6 Seahawks   100    97.7    2.30 \n 7 Steelers   100   100      0    \n 8 Buccaneer   99.5  92.6    6.90 \n 9 Titans      97.6  78.7   18.9  \n10 Colts       94.9  66.4   28.5  \n11 Browns      94.6  67.5   27.1  \n12 Ravens      90.1  51.8   38.3  \n13 Football T  88.6  38.3   50.3  \n14 Cardinals   65.7  28.7   37    \n15 Dolphins    48.7  13.4   35.3  \n16 Giants      41.3  10     31.3  \n17 Bears       35.3  18     17.3  \n18 Vikings     31.7   4.3   27.4  \n19 Raiders     29.1   4.5   24.6  \n20 Eagles      18.3   3.4   14.9  \n21 49ers       14.5   5      9.5  \n22 Patriots    58     0     58    \n23 Cowboys     23     0     23    \n24 Lions       19     0     19    \n25 Panthers     1     0      1    \n\n\nIt looks really good, and it really only messed up a few rows, which we could fix manually, but you can see that while these techniques are robust you are still at the mercy of image quality!\n\n\n\n\n\n\nExpand for Session Info\n\n\n\n\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.0 (2022-04-22)\n os       macOS Monterey 12.2.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       America/Chicago\n date     2022-04-28\n pandoc   2.18 @ /Applications/RStudio.app/Contents/MacOS/quarto/bin/tools/ (via rmarkdown)\n quarto   0.9.294 @ /usr/local/bin/quarto\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version date (UTC) lib source\n dplyr       * 1.0.8   2022-02-08 [1] CRAN (R 4.2.0)\n forcats     * 0.5.1   2021-01-27 [1] CRAN (R 4.2.0)\n ggplot2     * 3.3.5   2021-06-25 [1] CRAN (R 4.2.0)\n magick      * 2.7.3   2021-08-18 [1] CRAN (R 4.2.0)\n purrr       * 0.3.4   2020-04-17 [1] CRAN (R 4.2.0)\n readr       * 2.1.2   2022-01-30 [1] CRAN (R 4.2.0)\n sessioninfo * 1.2.2   2021-12-06 [1] CRAN (R 4.2.0)\n stringr     * 1.4.0   2019-02-10 [1] CRAN (R 4.2.0)\n tesseract   * 5.0.0   2022-01-10 [1] CRAN (R 4.2.0)\n tibble      * 3.1.6   2021-11-07 [1] CRAN (R 4.2.0)\n tidyr       * 1.2.0   2022-02-01 [1] CRAN (R 4.2.0)\n tidyverse   * 1.3.1   2021-04-15 [1] CRAN (R 4.2.0)\n\n [1] /Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/library\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "posts/2020-05-16-gt-a-grammar-of-tables/index.html",
    "href": "posts/2020-05-16-gt-a-grammar-of-tables/index.html",
    "title": "gt - a (G)rammar of (T)ables",
    "section": "",
    "text": "Preview of the table to come"
  },
  {
    "objectID": "posts/2020-05-16-gt-a-grammar-of-tables/index.html#gt-package---a-grammar-of-tables",
    "href": "posts/2020-05-16-gt-a-grammar-of-tables/index.html#gt-package---a-grammar-of-tables",
    "title": "gt - a (G)rammar of (T)ables",
    "section": "\ngt package - a (g)rammar of (t)ables",
    "text": "gt package - a (g)rammar of (t)ables\ngt is an R package for generating formatted tables from dataframes in R with a Grammar of Tables.\nIf you want to go deeper than this basic guide, check out the gt site, which has lots of examples!\nRaw data comes from: Pro Football Reference & Over the Cap\n\n\nComponent parts of a gt table\n\n\nPer the package website, gt has the following component parts:\n\nThe parts (roughly from top to bottom) are:\n\nthe Table Header (optional; with a title and possibly a subtitle)\nthe Stub and the Stub Head (optional; contains row labels, optionally within row groups having row group labels and possibly summary labels when a summary is present)\nthe Column Labels (contains column labels, optionally under spanner column labels)\nthe Table Body (contains columns and rows of cells)\nthe Table Footer (optional; possibly with footnotes and source notes)\n\n\nAs you can see it is fleshing out the idea of formatting or adding various parts of the table in a robust way."
  },
  {
    "objectID": "posts/2020-05-16-gt-a-grammar-of-tables/index.html#read-in-the-data",
    "href": "posts/2020-05-16-gt-a-grammar-of-tables/index.html#read-in-the-data",
    "title": "gt - a (G)rammar of (T)ables",
    "section": "Read in the Data",
    "text": "Read in the Data\nI’ve gone through collecting the data and have put into a non-tidy wide format for Salary Rank, playoff week and appearances, Total appearances, and finally salary from 2014-2019. The raw CSV is available on GitHub\n\nlibrary(gt) # for static tables\nlibrary(tidyverse) # all the things\nlibrary(paletteer) # for all the palettes\n\nplayoff_salary <- read_csv(\"playoff_salary.csv\")\n\nRows: 36 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): player\ndbl (6): Wildcard, Division, Conference, Superbowl, Total, salary\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nglimpse(playoff_salary)\n\nRows: 36\nColumns: 7\n$ player     <chr> \"Tom Brady\", \"Aaron Rodgers\", \"Russell Wilson\", \"Ben Roethl…\n$ Wildcard   <dbl> 1, 2, 4, 3, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 0, 0, 1, 1, 1, 1,…\n$ Division   <dbl> 5, 4, 4, 3, 2, 2, 2, 2, 1, 2, 1, 1, 2, 0, 2, 2, 0, 1, 0, 1,…\n$ Conference <dbl> 5, 3, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 2, 1, 0, 1, 0, 0,…\n$ Superbowl  <dbl> 4, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,…\n$ Total      <dbl> 15, 9, 10, 7, 4, 5, 6, 3, 3, 5, 3, 3, 5, 2, 5, 4, 1, 3, 1, …\n$ salary     <dbl> 100.065, 125.602, 91.114, 127.690, 93.700, 75.264, 104.374,…"
  },
  {
    "objectID": "posts/2020-05-16-gt-a-grammar-of-tables/index.html#basics-of-gt",
    "href": "posts/2020-05-16-gt-a-grammar-of-tables/index.html#basics-of-gt",
    "title": "gt - a (G)rammar of (T)ables",
    "section": "Basics of gt",
    "text": "Basics of gt\nA very basic gt table can be created as so:\n\nplayoff_salary %>%\n  head() %>%\n  gt()\n\n\n\n\n\n\nplayer\n      Wildcard\n      Division\n      Conference\n      Superbowl\n      Total\n      salary\n    \n\n\nTom Brady\n1\n5\n5\n4\n15\n100.065\n\n\nAaron Rodgers\n2\n4\n3\n0\n9\n125.602\n\n\nRussell Wilson\n4\n4\n1\n1\n10\n91.114\n\n\nBen Roethlisberger\n3\n3\n1\n0\n7\n127.690\n\n\nAlex Smith\n2\n2\n0\n0\n4\n93.700\n\n\nAndrew Luck\n2\n2\n1\n0\n5\n75.264\n\n\n\n\n\n\nImmediately we have a basic table with minimal formatting.\nThe core parts we want to change are:\n- Conditional color formatting for Total Appearances and Salary\n- Change the fonts\n- Add borders"
  },
  {
    "objectID": "posts/2020-05-16-gt-a-grammar-of-tables/index.html#format-currency",
    "href": "posts/2020-05-16-gt-a-grammar-of-tables/index.html#format-currency",
    "title": "gt - a (G)rammar of (T)ables",
    "section": "Format Currency",
    "text": "Format Currency\nFormatting numbers all together now, with both the color function and gt::fmt_currency() to add dollar + M to our cells. Notice that gt takes glue style string parsing, so you can use the pattern argument to add trailing or leading text input as you like.\nFor example pattern = \"{x} MIL\" would convert 125.1 to $125.1 MIL. We’ll use \"{x} M\" to indicate we want to add a space + M to each value in the salary column. We also indicate decimals = 1 to provide built in rounding!\n\nplayoff_salary %>%\n  head() %>%\n  gt() %>%\n  data_color(\n    columns = vars(salary),\n    colors = scales::col_numeric(\n      palette = c(\"#ffffff\", \"#f2fbd2\", \"#c9ecb4\", \"#93d3ab\", \"#35b0ab\"),\n      domain = NULL\n    )\n  ) %>%\n  data_color(\n    columns = vars(Total),\n    colors = scales::col_numeric(\n      palette = c(\"#ffffff\", \"#f2fbd2\", \"#c9ecb4\", \"#93d3ab\", \"#35b0ab\"),\n      domain = NULL\n    )\n  ) %>%\n  ##########################\n  ### This section changed\n  ##########################\n  fmt_currency(\n    # Define the columns to change\n    columns = vars(salary),\n    # How many decimals to round to\n    decimals = 1,\n    # glue style pattern match & string conversion\n    pattern = \"{x} M\"\n  ) %>%\n  # Align the now character column to be right-aligned\n  cols_align(\n    align = \"right\",\n    columns = vars(salary)\n  )\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\nplayer\n      Wildcard\n      Division\n      Conference\n      Superbowl\n      Total\n      salary\n    \n\n\nTom Brady\n1\n5\n5\n4\n15\n$100.1 M\n\n\nAaron Rodgers\n2\n4\n3\n0\n9\n$125.6 M\n\n\nRussell Wilson\n4\n4\n1\n1\n10\n$91.1 M\n\n\nBen Roethlisberger\n3\n3\n1\n0\n7\n$127.7 M\n\n\nAlex Smith\n2\n2\n0\n0\n4\n$93.7 M\n\n\nAndrew Luck\n2\n2\n1\n0\n5\n$75.3 M"
  },
  {
    "objectID": "posts/2020-05-16-gt-a-grammar-of-tables/index.html#add-borders",
    "href": "posts/2020-05-16-gt-a-grammar-of-tables/index.html#add-borders",
    "title": "gt - a (G)rammar of (T)ables",
    "section": "Add Borders",
    "text": "Add Borders\nNow we can add our border to the left of the Total column. We’ll use tab_style() to accomplish this, and gt has a cell_borders() function to control formatting of:\n- Location & Side\n- Color & Weight\nSo we tell gt to style the cell borders to black, attach to the left side of the cell, make it “heavier” at 3 pixels (px(3)), with the location in the cell body of the Total column. See below for the code that accomplishes this. We do a separate call to add a black border below the column labels.\n\nplayoff_salary %>%\n  head() %>%\n  gt() %>%\n  data_color(\n    columns = vars(salary),\n    colors = scales::col_numeric(\n      palette = c(\"#ffffff\", \"#f2fbd2\", \"#c9ecb4\", \"#93d3ab\", \"#35b0ab\"),\n      domain = NULL\n    )\n  ) %>%\n  data_color(\n    columns = vars(Total),\n    colors = scales::col_numeric(\n      palette = c(\"#ffffff\", \"#f2fbd2\", \"#c9ecb4\", \"#93d3ab\", \"#35b0ab\"),\n      domain = NULL\n    )\n  ) %>%\n  fmt_currency(\n    columns = vars(salary),\n    decimals = 1,\n    pattern = \"{x} M\"\n  ) %>%\n  cols_align(\n    align = \"right\",\n    columns = vars(salary)\n  ) %>% \n  ##########################\n  ### This section changed\n  ##########################\n  # We use tab_style() to change style of cells\n  # cell_borders() provides the formatting\n  # locations tells it where\n  # add a border to left of the Total column\n  tab_style(\n    style = list(\n      cell_borders(\n        sides = \"left\",\n        color = \"black\",\n        weight = px(3)\n      )\n    ),\n    locations = list(\n      cells_body(\n        columns = vars(Total)\n      )\n    )\n  ) %>%\n  # We use tab_style() to change style of cells\n  # cell_borders() provides the formatting\n  # locations tells it where\n  # Add black borders to the bottom of all the column labels\n  tab_style(\n    style = list(\n      cell_borders(\n        sides = \"bottom\",\n        color = \"black\",\n        weight = px(3)\n      )\n    ),\n    locations = list(\n      cells_column_labels(\n        columns = gt::everything()\n      )\n    )\n  )\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\nplayer\n      Wildcard\n      Division\n      Conference\n      Superbowl\n      Total\n      salary\n    \n\n\nTom Brady\n1\n5\n5\n4\n15\n$100.1 M\n\n\nAaron Rodgers\n2\n4\n3\n0\n9\n$125.6 M\n\n\nRussell Wilson\n4\n4\n1\n1\n10\n$91.1 M\n\n\nBen Roethlisberger\n3\n3\n1\n0\n7\n$127.7 M\n\n\nAlex Smith\n2\n2\n0\n0\n4\n$93.7 M\n\n\nAndrew Luck\n2\n2\n1\n0\n5\n$75.3 M"
  },
  {
    "objectID": "posts/2020-05-16-gt-a-grammar-of-tables/index.html#add-titles",
    "href": "posts/2020-05-16-gt-a-grammar-of-tables/index.html#add-titles",
    "title": "gt - a (G)rammar of (T)ables",
    "section": "Add titles",
    "text": "Add titles\nWe can now finalize the table by correcting some column labels, adding a source note to honor the data sources, and adding a header w/ title and subtitle.\ngt::cols_label() allows us to change the title of specific columns ad hoc, similar to dplyr::rename(), while tab_source_note() adds a source note at the bottom of the table, and tab_header() adds an optional title and subtitle. Notice that we can use md() to parse markdown syntax within these text strings. I can make things bold with this markdown syntax like: md(\"**text**\").\nNote that at this point, I’m essentially done with the table so I have removed the head() call to show the full table. Our data_color() formatting expands to match the new colors, and all of our formatting thus far is good to go!\n\ncomplete_table <- playoff_salary %>%\n  # REMOVED head() %>%\n  gt() %>%\n  data_color(\n    columns = vars(salary),\n    colors = scales::col_numeric(\n      palette = c(\"#ffffff\", \"#f2fbd2\", \"#c9ecb4\", \"#93d3ab\", \"#35b0ab\"),\n      domain = NULL\n    )\n  ) %>%\n  data_color(\n    columns = vars(Total),\n    colors = scales::col_numeric(\n      palette = c(\"#ffffff\", \"#f2fbd2\", \"#c9ecb4\", \"#93d3ab\", \"#35b0ab\"),\n      domain = NULL\n    )\n  ) %>%\n  fmt_currency(\n    columns = vars(salary),\n    decimals = 1,\n    pattern = \"{x} M\"\n  ) %>%\n  cols_align(\n    align = \"right\",\n    columns = vars(salary)\n  ) %>% \n  tab_style(\n    style = list(\n      cell_borders(\n        sides = \"left\",\n        color = \"black\",\n        weight = px(3)\n      )\n    ),\n    locations = list(\n      cells_body(\n        columns = vars(Total)\n      )\n    )\n  ) %>%\n  tab_style(\n    style = list(\n      cell_borders(\n        sides = \"bottom\",\n        color = \"black\",\n        weight = px(3)\n      )\n    ),\n    locations = list(\n      cells_column_labels(\n        columns = gt::everything()\n      )\n    )\n  ) %>%\n  ##########################\n  ### This section changed\n  ##########################\n  cols_label(\n    player = \"Player\",\n    salary = \"Salary\"\n  ) %>%\n  tab_source_note(\"TABLE: @THOMAS_MOCK | DATA: PRO FOOTBALL REFERENCE & OVER THE CAP\") %>%\n  tab_header(\n    title = md(\"**2014 - 2019 Salary and Playoff Appearances**\"),\n    subtitle = \"QBS limited to playoff games where they threw a pass\"\n  )\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\ncomplete_table\n\n\n\n\n\n\n\n2014 - 2019 Salary and Playoff Appearances\n    \n\nQBS limited to playoff games where they threw a pass\n    \n\n\nPlayer\n      Wildcard\n      Division\n      Conference\n      Superbowl\n      Total\n      Salary\n    \n\n\nTom Brady\n1\n5\n5\n4\n15\n$100.1 M\n\n\nAaron Rodgers\n2\n4\n3\n0\n9\n$125.6 M\n\n\nRussell Wilson\n4\n4\n1\n1\n10\n$91.1 M\n\n\nBen Roethlisberger\n3\n3\n1\n0\n7\n$127.7 M\n\n\nAlex Smith\n2\n2\n0\n0\n4\n$93.7 M\n\n\nAndrew Luck\n2\n2\n1\n0\n5\n$75.3 M\n\n\nCam Newton\n2\n2\n1\n1\n6\n$104.4 M\n\n\nDak Prescott\n1\n2\n0\n0\n3\n$4.0 M\n\n\nDeshaun Watson\n2\n1\n0\n0\n3\n$9.4 M\n\n\nDrew Brees\n2\n2\n1\n0\n5\n$125.2 M\n\n\nKirk Cousins\n2\n1\n0\n0\n3\n$98.4 M\n\n\nMarcus Mariota\n2\n1\n0\n0\n3\n$45.1 M\n\n\nMatt Ryan\n1\n2\n1\n1\n5\n$118.0 M\n\n\nMatt Stafford\n2\n0\n0\n0\n2\n$129.7 M\n\n\nPatrick Mahomes\n0\n2\n2\n1\n5\n$11.2 M\n\n\nPeyton Manning\n0\n2\n1\n1\n4\n$35.0 M\n\n\nAndy Dalton\n1\n0\n0\n0\n1\n$80.0 M\n\n\nBlake Bortles\n1\n1\n1\n0\n3\n$31.7 M\n\n\nBrian Hoyer\n1\n0\n0\n0\n1\n$12.9 M\n\n\nBrock Osweiler\n1\n1\n0\n0\n2\n$15.6 M\n\n\nCarson Palmer\n0\n1\n1\n0\n2\n$62.9 M\n\n\nCarson Wentz\n1\n0\n0\n0\n1\n$26.6 M\n\n\nCase Keenum\n0\n1\n1\n0\n2\n$24.7 M\n\n\nEli Manning\n1\n0\n0\n0\n1\n$124.2 M\n\n\nJared Goff\n1\n1\n1\n1\n4\n$29.7 M\n\n\nJimmy Garoppolo\n0\n1\n1\n1\n3\n$59.8 M\n\n\nJoe Flacco\n1\n1\n0\n0\n2\n$106.1 M\n\n\nJosh Allen\n1\n0\n0\n0\n1\n$8.7 M\n\n\nLamar Jackson\n1\n1\n0\n0\n2\n$3.9 M\n\n\nMitchell Trubisky\n1\n0\n0\n0\n1\n$19.8 M\n\n\nNick Foles\n1\n1\n0\n0\n2\n$33.8 M\n\n\nPhilip Rivers\n1\n1\n0\n0\n2\n$117.3 M\n\n\nRyan Tannehill\n1\n1\n1\n0\n3\n$51.2 M\n\n\nTeddy Bridgewater\n1\n0\n0\n0\n1\n$12.4 M\n\n\nTony Romo\n1\n1\n0\n0\n2\n$47.6 M\n\n\nTyrod Taylor\n1\n0\n0\n0\n1\n$37.7 M\n\n\n\nTABLE: @THOMAS_MOCK | DATA: PRO FOOTBALL REFERENCE & OVER THE CAP"
  },
  {
    "objectID": "posts/2020-05-16-gt-a-grammar-of-tables/index.html#import-google-font",
    "href": "posts/2020-05-16-gt-a-grammar-of-tables/index.html#import-google-font",
    "title": "gt - a (G)rammar of (T)ables",
    "section": "Import Google Font",
    "text": "Import Google Font\nI want to use a Google font (Karla + Fira Mono).\nYou can see all the Google Fonts here. At fonts.google.com you’ll:\n- Search for specific fonts\n- Select the Style you want (+ button)\n- Open the sidebar to download the fonts locally\n- Import the fonts into your system (varies by Mac, Windows, Linux) – I use extrafont for this, but there are numerous ways, packages like gfonts allow you to use Google fonts in RMD or Shiny for example\nI’m on a Mac, so I import the fonts to my Font Book (guide here) and then use extrafont::font_import(pattern = \"Karla\") to import them to R and register them for things like ggplot2 or gt. Hopefully in the future the systemfonts package will take care of this but for now that’s my workflow.\n\n# not run (I already have them locally)\nextrafont::font_import(pattern = \"Karla\")\nextrafont::font_import(pattern = \"Fira Mono\")\n\n\nextra_tab <- complete_table %>%\n  # Adjust numeric font\n  tab_style(\n    style = list(\n      cell_text(\n        font = \"Fira Mono\",\n        align = \"center\"\n      )\n    ),\n    locations = list(\n      cells_body(columns = vars(Wildcard, Division, Conference, Superbowl, Total, salary))\n    )\n  ) %>%\n  # Style header font\n  gt::tab_style(\n    style = list(\n      cell_text(font = \"Karla\", weight = \"bold\")\n    ),\n    locations = list(\n      cells_column_labels(gt::everything())\n    )\n  ) %>%\n  # Adjust font of Player Column\n  tab_style(\n    style = list(\n      cell_text(font = \"Karla\")\n    ),\n    location = list(\n      cells_body(columns = vars(player))\n    )\n  ) %>%\n  # Adjust title font\n  tab_style(\n    style = list(\n      cell_text(\n        font = \"Fira Mono\",\n        align = \"left\"\n      )\n    ),\n    locations = list(\n      cells_title(groups = \"title\")\n    )\n  ) %>%\n  # Adjust sub-title font\n  tab_style(\n    style = list(\n      cell_text(\n        font = \"Fira Mono\",\n        align = \"left\"\n      )\n    ),\n    locations = list(\n      cells_title(groups = \"subtitle\")\n    )\n  )\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nextra_tab\n\n\n\n\n\n\n\n2014 - 2019 Salary and Playoff Appearances\n    \n\nQBS limited to playoff games where they threw a pass\n    \n\n\nPlayer\n      Wildcard\n      Division\n      Conference\n      Superbowl\n      Total\n      Salary\n    \n\n\nTom Brady\n1\n5\n5\n4\n15\n$100.1 M\n\n\nAaron Rodgers\n2\n4\n3\n0\n9\n$125.6 M\n\n\nRussell Wilson\n4\n4\n1\n1\n10\n$91.1 M\n\n\nBen Roethlisberger\n3\n3\n1\n0\n7\n$127.7 M\n\n\nAlex Smith\n2\n2\n0\n0\n4\n$93.7 M\n\n\nAndrew Luck\n2\n2\n1\n0\n5\n$75.3 M\n\n\nCam Newton\n2\n2\n1\n1\n6\n$104.4 M\n\n\nDak Prescott\n1\n2\n0\n0\n3\n$4.0 M\n\n\nDeshaun Watson\n2\n1\n0\n0\n3\n$9.4 M\n\n\nDrew Brees\n2\n2\n1\n0\n5\n$125.2 M\n\n\nKirk Cousins\n2\n1\n0\n0\n3\n$98.4 M\n\n\nMarcus Mariota\n2\n1\n0\n0\n3\n$45.1 M\n\n\nMatt Ryan\n1\n2\n1\n1\n5\n$118.0 M\n\n\nMatt Stafford\n2\n0\n0\n0\n2\n$129.7 M\n\n\nPatrick Mahomes\n0\n2\n2\n1\n5\n$11.2 M\n\n\nPeyton Manning\n0\n2\n1\n1\n4\n$35.0 M\n\n\nAndy Dalton\n1\n0\n0\n0\n1\n$80.0 M\n\n\nBlake Bortles\n1\n1\n1\n0\n3\n$31.7 M\n\n\nBrian Hoyer\n1\n0\n0\n0\n1\n$12.9 M\n\n\nBrock Osweiler\n1\n1\n0\n0\n2\n$15.6 M\n\n\nCarson Palmer\n0\n1\n1\n0\n2\n$62.9 M\n\n\nCarson Wentz\n1\n0\n0\n0\n1\n$26.6 M\n\n\nCase Keenum\n0\n1\n1\n0\n2\n$24.7 M\n\n\nEli Manning\n1\n0\n0\n0\n1\n$124.2 M\n\n\nJared Goff\n1\n1\n1\n1\n4\n$29.7 M\n\n\nJimmy Garoppolo\n0\n1\n1\n1\n3\n$59.8 M\n\n\nJoe Flacco\n1\n1\n0\n0\n2\n$106.1 M\n\n\nJosh Allen\n1\n0\n0\n0\n1\n$8.7 M\n\n\nLamar Jackson\n1\n1\n0\n0\n2\n$3.9 M\n\n\nMitchell Trubisky\n1\n0\n0\n0\n1\n$19.8 M\n\n\nNick Foles\n1\n1\n0\n0\n2\n$33.8 M\n\n\nPhilip Rivers\n1\n1\n0\n0\n2\n$117.3 M\n\n\nRyan Tannehill\n1\n1\n1\n0\n3\n$51.2 M\n\n\nTeddy Bridgewater\n1\n0\n0\n0\n1\n$12.4 M\n\n\nTony Romo\n1\n1\n0\n0\n2\n$47.6 M\n\n\nTyrod Taylor\n1\n0\n0\n0\n1\n$37.7 M\n\n\n\nTABLE: @THOMAS_MOCK | DATA: PRO FOOTBALL REFERENCE & OVER THE CAP\n    \n\n\n\n# Save it as png\n# gtsave(extra_tab, \"extra_tab.png\")"
  },
  {
    "objectID": "posts/2020-05-22-parsing-json-in-r-with-jsonlite/index.html",
    "href": "posts/2020-05-22-parsing-json-in-r-with-jsonlite/index.html",
    "title": "Easily parsing JSON in R with jsonlite and purrr",
    "section": "",
    "text": "It’s turtles all the way down, source: https://en.wikipedia.org/wiki/Turtles_all_the_way_down"
  },
  {
    "objectID": "posts/2020-05-22-parsing-json-in-r-with-jsonlite/index.html#rstudio-viewer",
    "href": "posts/2020-05-22-parsing-json-in-r-with-jsonlite/index.html#rstudio-viewer",
    "title": "Easily parsing JSON in R with jsonlite and purrr",
    "section": "RStudio Viewer",
    "text": "RStudio Viewer\n\n\nThe RStudio viewer is also super useful for navigating, once you have the data in R\n\n— Hadley Wickham (@hadleywickham) May 25, 2020\n\nAdditionally, the RStudio IDE itself has a lovely way of parsing through JSON files, including the ability to output the code to access specific parts of JSON objects!\nFirst - open the raw_json with the RStudio viewer.\n\nView(raw_json)\n\n\n\nYou get a list-viewer type experience with RStudio itself, and it still has search!\n\n\nOnce it is open you can search for specific object names or navigate similarly to listviewer.\n\n\nWe can see our same athlete object as a list!\n\n\nOnce you search and find something of interest (for example athletes object), you can click on the scroll to open it as a temp object in the viewer, or just click the table-arrow button to copy the code to access this level of the object to the console."
  },
  {
    "objectID": "posts/2020-05-22-parsing-json-in-r-with-jsonlite/index.html#listviewer",
    "href": "posts/2020-05-22-parsing-json-in-r-with-jsonlite/index.html#listviewer",
    "title": "Easily parsing JSON in R with jsonlite and purrr",
    "section": "listviewer",
    "text": "listviewer\nSecondly, the listviewer package is also fantastic! It lets you explore JSON interactively in a similar way to the RStudio Viewer. We can use this to interactively explore the data before we start coding away.\nBecause we’re looking at the 2019 season, I know that Lamar Jackson is the top QB in the dataset, and we can guess at some of the other columns by going to the actual webpage this API is building. From that we can assume there are columns for player name, team name, QBR, PAA, PLAYS, etc.\n\n\nExample of the website\n\n\nI’ll let you do this interactively because that’s how’d you use in RStudio, and try searching for:\n- Lamar Jackson – important for finding the QB names\n- 83 – this one is important as a data point\nIn the interactive jsonedit() viewer below:\n\n# interactive list or JSON viewer\n# note that you can change the view to raw JSON or the more \n# interactive `View` option\nlistviewer::jsonedit(raw_json, height = \"800px\", mode = \"view\")\n\n\n\n\n\nNow as you’re searching notice that it provides the depth/level you’re in. The only awkward part is like JavaScript it indexes from 0… so as usual note that index == 0 is index == 1 in R. The listviewer author does have a little helper function in this regard.\nFor example:\nIf you search for 83 and click on the 83 cell, you’ll get the following location:\nobject > athletes > 0 > categories > 0 > totals > 0\nwhich is equivalent to the following in R:\nraw_json$athletes[[1]]$categories[[1]]$totals[[1]][[1]]\nThe listviewer strategy can allow you to explore interactively, while the code below is more of moving through the JSON object in R.\nLet’s get into the code itself to extract and work with the JSON data."
  },
  {
    "objectID": "posts/2020-05-22-parsing-json-in-r-with-jsonlite/index.html#the-code",
    "href": "posts/2020-05-22-parsing-json-in-r-with-jsonlite/index.html#the-code",
    "title": "Easily parsing JSON in R with jsonlite and purrr",
    "section": "The code",
    "text": "The code\nThis utilizes purrr to get at the various components, but I’ll also show how to do this with mostly base R.\n\nlibrary(tidyverse)\nlibrary(jsonlite)\nlibrary(httr)\n\n# link to the API output as a JSON file\nurl_json <- \"https://site.web.api.espn.com/apis/fitt/v3/sports/football/nfl/qbr?region=us&lang=en&qbrType=seasons&seasontype=2&isqualified=true&sort=schedAdjQBR%3Adesc&season=2019\"\n\n# get the raw json into R\nraw_json <- httr::GET(url_json) %>% \n  httr::content()\n\n# get names of the QBR categories\ncategory_names <- pluck(raw_json, \"categories\", 1, \"labels\") %>% tolower()\n\n\n# create the dataframe and tidy it up\nex_output <- pluck(raw_json, \"athletes\") %>%\n  enframe() %>%\n  unnest_wider(value) %>% \n  unnest_wider(athlete) %>% \n  select(displayName, teamName:teamShortName, headshot, categories) %>% \n  hoist(categories, \n    data = list(1, \"totals\")) %>%\n  mutate(data = map(data, ~set_names(.x, nm = category_names))) %>% \n  select(-categories) %>% \n  unnest_wider(data) %>% \n  mutate(headshot = pluck(headshot, \"href\"))\n\nglimpse(ex_output)\n\nRows: 30\nColumns: 13\n$ displayName   <chr> \"Lamar Jackson\", \"Patrick Mahomes\", \"Drew Brees\", \"Dak P…\n$ teamName      <chr> \"Ravens\", \"Chiefs\", \"Saints\", \"Cowboys\", \"Seahawks\", \"Li…\n$ teamShortName <chr> \"BAL\", \"KC\", \"NO\", \"DAL\", \"SEA\", \"DET\", \"HOU\", \"MIA\", \"T…\n$ tqbr          <chr> \"83.0\", \"77.7\", \"73.3\", \"71.9\", \"71.5\", \"71.3\", \"70.5\", …\n$ pa            <chr> \"66.7\", \"55.8\", \"33.7\", \"48.1\", \"43.0\", \"27.0\", \"42.3\", …\n$ qbp           <chr> \"613\", \"585\", \"419\", \"690\", \"674\", \"353\", \"662\", \"620\", …\n$ tot           <chr> \"103.7\", \"97.3\", \"62.6\", \"93.1\", \"90.9\", \"56.1\", \"91.6\",…\n$ pas           <chr> \"55.0\", \"71.6\", \"53.1\", \"70.7\", \"58.3\", \"44.5\", \"52.0\", …\n$ run           <chr> \"39.1\", \"14.3\", \"1.6\", \"10.0\", \"10.6\", \"1.6\", \"19.8\", \"6…\n$ exp           <chr> \"0.0\", \"0.0\", \"0.0\", \"0.0\", \"0.0\", \"0.0\", \"0.0\", \"0.0\", …\n$ pen           <chr> \"2.2\", \"5.0\", \"1.9\", \"2.6\", \"1.5\", \"1.9\", \"1.4\", \"3.7\", …\n$ qbr           <chr> \"82.3\", \"79.4\", \"75.7\", \"72.8\", \"71.2\", \"74.7\", \"71.2\", …\n$ sac           <chr> \"-7.4\", \"-6.5\", \"-6.0\", \"-9.7\", \"-20.6\", \"-8.0\", \"-18.5\"…\n\n\nNow that you have explored the raw data via jsonedit and you see where we are going with this, we can actually try playing around with it in R."
  },
  {
    "objectID": "posts/2020-05-22-parsing-json-in-r-with-jsonlite/index.html#level-1",
    "href": "posts/2020-05-22-parsing-json-in-r-with-jsonlite/index.html#level-1",
    "title": "Easily parsing JSON in R with jsonlite and purrr",
    "section": "Level 1",
    "text": "Level 1\n\nstr(raw_json, max.level = 1)\n\nList of 7\n $ pagination     :List of 6\n $ athletes       :List of 30\n $ currentSeason  :List of 5\n $ requestedSeason:List of 5\n $ glossary       :List of 10\n $ categories     :List of 1\n $ currentValues  :List of 13\n\n\nWe can see that the JSON file at depth 1 has info about the pages returned, athletes in our dataset, what season it is, glossary of terms, categories, and current values.\nHowever some of those lists are actually reporting as lists of lists and lists of dataframes, so let’s try one level deeper."
  },
  {
    "objectID": "posts/2020-05-22-parsing-json-in-r-with-jsonlite/index.html#level-2",
    "href": "posts/2020-05-22-parsing-json-in-r-with-jsonlite/index.html#level-2",
    "title": "Easily parsing JSON in R with jsonlite and purrr",
    "section": "Level 2",
    "text": "Level 2\nNow we can see that pagination is just character strings of length 1 after two levels, however athletes has: two objects, a dataframe called athlete with 30 rows, and a list called categories is a list of length 30 (which aligns with the length of the athlete dataframe).\nThis is probably the most interesting data to us, as we’re looking for about 30-32 QBs from this API endpoint. Now, how do we actually get at these list objects?\n\nstr(raw_json, max.level = 2)\n\nList of 7\n $ pagination     :List of 6\n  ..$ count: int 30\n  ..$ limit: int 50\n  ..$ page : int 1\n  ..$ pages: int 1\n  ..$ first: chr \"http://site.api.espn.com:80/apis/fitt/v3/sports/football/nfl/qbr?isqualified=true&lang=en&qbrtype=seasons&regio\"| __truncated__\n  ..$ last : chr \"http://site.api.espn.com:80/apis/fitt/v3/sports/football/nfl/qbr?isqualified=true&lang=en&qbrtype=seasons&regio\"| __truncated__\n $ athletes       :List of 30\n  ..$ :List of 2\n  ..$ :List of 2\n  ..$ :List of 2\n  ..$ :List of 2\n  ..$ :List of 2\n  ..$ :List of 2\n  ..$ :List of 2\n  ..$ :List of 2\n  ..$ :List of 2\n  ..$ :List of 2\n  ..$ :List of 2\n  ..$ :List of 2\n  ..$ :List of 2\n  ..$ :List of 2\n  ..$ :List of 2\n  ..$ :List of 2\n  ..$ :List of 2\n  ..$ :List of 2\n  ..$ :List of 2\n  ..$ :List of 2\n  ..$ :List of 2\n  ..$ :List of 2\n  ..$ :List of 2\n  ..$ :List of 2\n  ..$ :List of 2\n  ..$ :List of 2\n  ..$ :List of 2\n  ..$ :List of 2\n  ..$ :List of 2\n  ..$ :List of 2\n $ currentSeason  :List of 5\n  ..$ year       : int 2021\n  ..$ displayName: chr \"2021\"\n  ..$ startDate  : chr \"2021-07-17T07:00:00.000+0000\"\n  ..$ endDate    : chr \"2022-02-16T07:59:00.000+0000\"\n  ..$ type       :List of 6\n $ requestedSeason:List of 5\n  ..$ year       : int 2019\n  ..$ displayName: chr \"2019\"\n  ..$ startDate  : chr \"2019-07-31T07:00:00.000+0000\"\n  ..$ endDate    : chr \"2020-02-06T07:59:00.000+0000\"\n  ..$ type       :List of 6\n $ glossary       :List of 10\n  ..$ :List of 2\n  ..$ :List of 2\n  ..$ :List of 2\n  ..$ :List of 2\n  ..$ :List of 2\n  ..$ :List of 2\n  ..$ :List of 2\n  ..$ :List of 2\n  ..$ :List of 2\n  ..$ :List of 2\n $ categories     :List of 1\n  ..$ :List of 6\n $ currentValues  :List of 13\n  ..$ qbrType    : chr \"seasons\"\n  ..$ sport      : chr \"football\"\n  ..$ league     : chr \"nfl\"\n  ..$ season     : int 2019\n  ..$ seasontype : int 2\n  ..$ week       : NULL\n  ..$ conference : int 9\n  ..$ isQualified: logi TRUE\n  ..$ limit      : int 50\n  ..$ page       : int 1\n  ..$ lang       : chr \"en\"\n  ..$ sort       :List of 2\n  ..$ region     : chr \"us\""
  },
  {
    "objectID": "posts/2020-05-22-parsing-json-in-r-with-jsonlite/index.html#get-at-the-list",
    "href": "posts/2020-05-22-parsing-json-in-r-with-jsonlite/index.html#get-at-the-list",
    "title": "Easily parsing JSON in R with jsonlite and purrr",
    "section": "Get at the list",
    "text": "Get at the list\nBecause the JSON file is parsed into R as nested lists, we can access various parts of it through base R with either the $ or with [[ + name. Full details around subsetting lists and vectors are available in Advanced R.\nLet’s try these out by trying to access:\n- raw_json to athletes (raw_json[[\"athletes\"]]) - Looking at it’s structure, again using the max.level argument to prevent extra printing.\nI’d like to note that I’ll be switching back and forth a bit between $ and [[ subsetting, as both accomplish the same thing, where $ is faster to type, but [[ is a bit more strict. Also to access by numerical position, you HAVE to use [[.\nAgain, full details around subsetting lists and vectors are available in Advanced R. This is definitely worth reading for edge cases, pitfalls, and lots of nice examples that go beyond the scope of this blog post.\n\nraw_json$athletes %>% str(max.level = 1)\n\nList of 30\n $ :List of 2\n $ :List of 2\n $ :List of 2\n $ :List of 2\n $ :List of 2\n $ :List of 2\n $ :List of 2\n $ :List of 2\n $ :List of 2\n $ :List of 2\n $ :List of 2\n $ :List of 2\n $ :List of 2\n $ :List of 2\n $ :List of 2\n $ :List of 2\n $ :List of 2\n $ :List of 2\n $ :List of 2\n $ :List of 2\n $ :List of 2\n $ :List of 2\n $ :List of 2\n $ :List of 2\n $ :List of 2\n $ :List of 2\n $ :List of 2\n $ :List of 2\n $ :List of 2\n $ :List of 2\n\n# this does the same thing!\nraw_json[[\"athletes\"]] %>% str(max.level = 1)\n\nList of 30\n $ :List of 2\n $ :List of 2\n $ :List of 2\n $ :List of 2\n $ :List of 2\n $ :List of 2\n $ :List of 2\n $ :List of 2\n $ :List of 2\n $ :List of 2\n $ :List of 2\n $ :List of 2\n $ :List of 2\n $ :List of 2\n $ :List of 2\n $ :List of 2\n $ :List of 2\n $ :List of 2\n $ :List of 2\n $ :List of 2\n $ :List of 2\n $ :List of 2\n $ :List of 2\n $ :List of 2\n $ :List of 2\n $ :List of 2\n $ :List of 2\n $ :List of 2\n $ :List of 2\n $ :List of 2\n\n\nAccess the dataframe\nWe can get to the raw values for a specific player by going one list deeper and we now see an output of str() that looks pretty close to a dataframe!\n\n# json -> list --> named elements of a list \nraw_json$athletes[[1]]$athlete %>% str(max.level = 1)\n\nList of 20\n $ id           : chr \"3916387\"\n $ uid          : chr \"s:20~l:28~a:3916387\"\n $ guid         : chr \"7d76fbb11c5ed9f4954fcad43f720ae2\"\n $ type         : chr \"football\"\n $ firstName    : chr \"Lamar\"\n $ lastName     : chr \"Jackson\"\n $ displayName  : chr \"Lamar Jackson\"\n $ shortName    : chr \"L. Jackson\"\n $ debutYear    : int 2018\n $ links        :List of 7\n $ headshot     :List of 2\n $ position     :List of 7\n $ status       :List of 4\n $ age          : int 25\n $ teamName     : chr \"Ravens\"\n $ teamShortName: chr \"BAL\"\n $ teams        :List of 1\n $ slug         : chr \"lamar-jackson\"\n $ teamId       : chr \"33\"\n $ teamUId      : chr \"s:20~l:28~t:33\"\n\n\nNow there’s still some sticky situations here, namely that some of the future columns are still lists. We’ll deal with that a little bit later.\nAccess the lists\nWe can change our 3rd call to categories instead of athlete to check out the other object with the player values. We see that we can get at the raw values for each of the categories here. Note that the code raw_json$athletes[[1]] is only giving us 1 of the 30 total players. Changing the [[1]] to [[2]] or [[3]] would give us the 2nd/3rd players in the list respectively.\n\n# json -> list --> vector of player values\nraw_json$athletes[[1]]$categories[[1]]$totals %>% unlist()\n\n [1] \"83.0\"  \"66.7\"  \"613\"   \"103.7\" \"55.0\"  \"39.1\"  \"0.0\"   \"2.2\"   \"82.3\" \n[10] \"-7.4\" \n\n\nWe could check out the other items in categories like so, but we see that the name/display elements are not very helpful at length of 1. I’m much more interested in the totals and ranks columns as they have length 10.\n\n# json -> list -> dataframe -> dataframe w/ list columns!\nraw_json$athletes[[1]]$categories[[1]] %>% str(max.level = 1)\n\nList of 4\n $ name       : chr \"general\"\n $ displayName: chr \"General \"\n $ totals     :List of 10\n $ ranks      :List of 10\n\n\nSo let’s check out the 3rd list and what is in it. Now if you’re like me, this is starting to feel a bit hairy! We’re 7 levels deep into one object and this is just 1 output of a total of 30!\nStick with me for one more example and then we’ll get into purrr!\n\nraw_json$athletes[[1]]$categories[[1]][3][[1]] %>% unlist()\n\n [1] \"83.0\"  \"66.7\"  \"613\"   \"103.7\" \"55.0\"  \"39.1\"  \"0.0\"   \"2.2\"   \"82.3\" \n[10] \"-7.4\" \n\n\nSo we know:\n- The QB names and teams (raw_json$athletes[[ROW_NUMBER]]$athlete)\n- Their stats are in a different part of the JSON file (aw_json$athletes[[ROW_NUMBER]]$categories)\nIf you wanted to you could combine the athlete dataframe with their stats with a for loop. There are additional way of optimizing this (potentially convert to matrix and then to data.frame), but I just want to show that it’s possible and fairly readable! An example with lapply is below as well. Note that since we’re not pre-allocating our data.frame, this is likely the slowest method. It’s ok for our 30 iteration example, but is likely not the best strategy for large JSON files.\n\nlength_df <- length(raw_json[[\"athletes\"]])\n\npbp_out <- data.frame()\n\ncategory_names <- raw_json[[\"categories\"]][[1]][[\"labels\"]] %>% unlist()\n\nvar_select <- c(\"displayName\", \"teamName\", \"teamShortName\")\n\nfor (i in 1:length_df){\n  \n  athlete_vec <- raw_json[[\"athletes\"]][[i]][[\"athlete\"]][var_select]\n  \n  # grab each QBs stats and convert to a vector of type double\n  raw_vec <- as.double(raw_json[[\"athletes\"]][[i]][[\"categories\"]][[1]][[\"totals\"]])\n  \n  # split each stat into it's own list with the proper name\n  split_vec <- split(raw_vec, category_names)\n  \n  combine_vec <- c(athlete_vec, split_vec)\n  \n  # convert the list into a dataframe \n  pbp_df_loop <- cbind.data.frame(combine_vec)\n  \n  # combine the 30 QB's stats into the empty data.frame\n  pbp_out <- rbind(pbp_out, pbp_df_loop)\n}\n\n\n# take a peek at the result!\nglimpse(pbp_out)\n\nRows: 30\nColumns: 13\n$ displayName   <chr> \"Lamar Jackson\", \"Patrick Mahomes\", \"Drew Brees\", \"Dak P…\n$ teamName      <chr> \"Ravens\", \"Chiefs\", \"Saints\", \"Cowboys\", \"Seahawks\", \"Li…\n$ teamShortName <chr> \"BAL\", \"KC\", \"NO\", \"DAL\", \"SEA\", \"DET\", \"HOU\", \"MIA\", \"T…\n$ EXP           <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ PA            <dbl> 66.7, 55.8, 33.7, 48.1, 43.0, 27.0, 42.3, 30.2, 19.0, 27…\n$ PAS           <dbl> 55.0, 71.6, 53.1, 70.7, 58.3, 44.5, 52.0, 47.6, 18.1, 54…\n$ PEN           <dbl> 2.2, 5.0, 1.9, 2.6, 1.5, 1.9, 1.4, 3.7, 2.3, 1.1, 5.8, 5…\n$ QBP           <dbl> 613, 585, 419, 690, 674, 353, 662, 620, 374, 598, 745, 5…\n$ QBR           <dbl> 82.3, 79.4, 75.7, 72.8, 71.2, 74.7, 71.2, 66.6, 67.2, 65…\n$ RUN           <dbl> 39.1, 14.3, 1.6, 10.0, 10.6, 1.6, 19.8, 6.3, 11.7, 2.7, …\n$ SAC           <dbl> -7.4, -6.5, -6.0, -9.7, -20.6, -8.0, -18.5, -13.1, -13.7…\n$ TOT           <dbl> 103.7, 97.3, 62.6, 93.1, 90.9, 56.1, 91.6, 70.7, 45.8, 7…\n$ TQBR          <dbl> 83.0, 77.7, 73.3, 71.9, 71.5, 71.3, 70.5, 68.3, 64.2, 64…\n\n\nLet’s try this again, but with a function and iterating that function with lapply.\n\nvar_select <- c(\"displayName\", \"teamName\", \"teamShortName\")\n# how many rows?\nlength_df <- length(raw_json[[\"athletes\"]])\n\n# category names again\ncategory_names <- raw_json[[\"categories\"]][[1]][[\"labels\"]] %>% unlist()\n\n# create a function to apply\nqbr_stat_fun <- function(qb_num){\n  \n  # get each QB name/team\n  athlete_vec <- raw_json[[\"athletes\"]][[qb_num]][[\"athlete\"]][var_select]\n  \n  # grab each QBs stats and convert to a vector of type double\n  raw_vec <- as.double(raw_json[[\"athletes\"]][[qb_num]][[\"categories\"]][[1]][[\"totals\"]])\n  \n  # split each stat into it's own list with the proper name\n  split_vec <- split(raw_vec, category_names) %>% rev()\n  \n  # return the lists\n  combine_vec <- c(athlete_vec, split_vec)\n  \n  combine_vec\n}\n\n# use apply to generate list of lists\nlist_qbr_stats <- lapply(1:length_df, qbr_stat_fun)\n\n# Combine the lists into a dataframe\nlist_pbp_df <- do.call(\"rbind.data.frame\", list_qbr_stats)\n\n# check it out\nlist_pbp_df %>% glimpse()\n\nRows: 30\nColumns: 13\n$ displayName   <chr> \"Lamar Jackson\", \"Patrick Mahomes\", \"Drew Brees\", \"Dak P…\n$ teamName      <chr> \"Ravens\", \"Chiefs\", \"Saints\", \"Cowboys\", \"Seahawks\", \"Li…\n$ teamShortName <chr> \"BAL\", \"KC\", \"NO\", \"DAL\", \"SEA\", \"DET\", \"HOU\", \"MIA\", \"T…\n$ TQBR          <dbl> 83.0, 77.7, 73.3, 71.9, 71.5, 71.3, 70.5, 68.3, 64.2, 64…\n$ TOT           <dbl> 103.7, 97.3, 62.6, 93.1, 90.9, 56.1, 91.6, 70.7, 45.8, 7…\n$ SAC           <dbl> -7.4, -6.5, -6.0, -9.7, -20.6, -8.0, -18.5, -13.1, -13.7…\n$ RUN           <dbl> 39.1, 14.3, 1.6, 10.0, 10.6, 1.6, 19.8, 6.3, 11.7, 2.7, …\n$ QBR           <dbl> 82.3, 79.4, 75.7, 72.8, 71.2, 74.7, 71.2, 66.6, 67.2, 65…\n$ QBP           <dbl> 613, 585, 419, 690, 674, 353, 662, 620, 374, 598, 745, 5…\n$ PEN           <dbl> 2.2, 5.0, 1.9, 2.6, 1.5, 1.9, 1.4, 3.7, 2.3, 1.1, 5.8, 5…\n$ PAS           <dbl> 55.0, 71.6, 53.1, 70.7, 58.3, 44.5, 52.0, 47.6, 18.1, 54…\n$ PA            <dbl> 66.7, 55.8, 33.7, 48.1, 43.0, 27.0, 42.3, 30.2, 19.0, 27…\n$ EXP           <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n\n\nNow, I typically don’t suggest using a for loop as per Advanced R this approach can be prone to some common pitfalls which can lead to performance deficits or side effects. Similarily, the apply family of functions are very powerful but for some folks they find that it doesn’t quite fit with their mental model or is inconsistent in the expected output.\nAs an alternative to loops and/or apply, we can use purrr, AND purrr can also help us a lot with actually parsing through the JSON itself! I also think that other tidyverse tools like tidyr for unnest_wider and unpack/hoist are useful here as alternative strategies!"
  },
  {
    "objectID": "posts/2020-05-22-parsing-json-in-r-with-jsonlite/index.html#purrrpluck",
    "href": "posts/2020-05-22-parsing-json-in-r-with-jsonlite/index.html#purrrpluck",
    "title": "Easily parsing JSON in R with jsonlite and purrr",
    "section": "purrr::pluck()",
    "text": "purrr::pluck()\nThe first function from purrr we’ll use is pluck, which provides a consistent and generalized form of [[. This allows you to quickly move through lists and nested lists.\nLet’s get back to our QB data with pluck! There are still a lot of elements we don’t need, but we’ll get rid of those when we put all the data together.\n\nraw_json %>% \n  # equivalent to raw_json[[\"athletes\"]][[1]][[\"athlete\"]]\n  purrr::pluck(\"athletes\", 1,  \"athlete\") %>% \n  str(max.level = 1)\n\nList of 20\n $ id           : chr \"3916387\"\n $ uid          : chr \"s:20~l:28~a:3916387\"\n $ guid         : chr \"7d76fbb11c5ed9f4954fcad43f720ae2\"\n $ type         : chr \"football\"\n $ firstName    : chr \"Lamar\"\n $ lastName     : chr \"Jackson\"\n $ displayName  : chr \"Lamar Jackson\"\n $ shortName    : chr \"L. Jackson\"\n $ debutYear    : int 2018\n $ links        :List of 7\n $ headshot     :List of 2\n $ position     :List of 7\n $ status       :List of 4\n $ age          : int 25\n $ teamName     : chr \"Ravens\"\n $ teamShortName: chr \"BAL\"\n $ teams        :List of 1\n $ slug         : chr \"lamar-jackson\"\n $ teamId       : chr \"33\"\n $ teamUId      : chr \"s:20~l:28~t:33\"\n\n\nWhat about that pesky headshot column that reports as a list of lists? We can just add an additional depth argument with \"headshot\" and see that it gives us a URL to the QB’s photo and a repeat of the QB’s name. We’ll use this a bit later to get the URL only.\n\nraw_json %>% \n  # equivalent to raw_json[[\"athletes\"]][[1]][[\"athlete\"]][[\"headshot\"]]\n  purrr::pluck(\"athletes\", 1, \"athlete\", \"headshot\")\n\n$href\n[1] \"https://a.espncdn.com/i/headshots/nfl/players/full/3916387.png\"\n\n$alt\n[1] \"Lamar Jackson\""
  },
  {
    "objectID": "posts/2020-05-22-parsing-json-in-r-with-jsonlite/index.html#purrrmap",
    "href": "posts/2020-05-22-parsing-json-in-r-with-jsonlite/index.html#purrrmap",
    "title": "Easily parsing JSON in R with jsonlite and purrr",
    "section": "purrr::map",
    "text": "purrr::map\nSo pluck allows us to quickly get to the data of interest, but what about replacing our for loop to get at the vectors for each of the QB’s individual stats? map() can help us accomplish this!\nDefine a function\nAgain, purrr is used for functional programming, so we need to define a function to iterate with. We’ll define this as get_qbr_data() and test it out! It gets us a nicely extracted named numeric vector. The names are useful as when we go to unnest_wider() the dataset it will automatically assign the column names for us.\n\n# get names of the QBR categories with pluck\ncategory_names <- pluck(raw_json, \"categories\", 1, \"labels\") %>% unlist()\n\ncategory_names\n\n [1] \"TQBR\" \"PA\"   \"QBP\"  \"TOT\"  \"PAS\"  \"RUN\"  \"EXP\"  \"PEN\"  \"QBR\"  \"SAC\" \n\n# Get the QBR stats by each player (row_n = row number of player in the df)\nget_qbr_data <- function(row_n) {\n  player_stats <- raw_json %>% \n    purrr::pluck(\"athletes\", row_n, \"categories\", 1, \"totals\") %>% \n    # assign names from category\n    set_names(nm = category_names)\n  \n  player_nm <- raw_json %>% \n    purrr::pluck(\"athletes\", row_n, \"athlete\") %>% \n    keep(names(.) %in% c(\"displayName\", \"teamName\", \"teamShortName\")) %>% \n    unlist()\n  \n  headshot <- raw_json %>% \n    purrr::pluck(\"athletes\", row_n, \"athlete\", \"headshot\", \"href\")\n  \n  #output named list\n  c(player_nm, headshot = headshot, player_stats)\n}\n\n# test the function\nget_qbr_data(1)\n\n$displayName\n[1] \"Lamar Jackson\"\n\n$teamName\n[1] \"Ravens\"\n\n$teamShortName\n[1] \"BAL\"\n\n$headshot\n[1] \"https://a.espncdn.com/i/headshots/nfl/players/full/3916387.png\"\n\n$TQBR\n[1] \"83.0\"\n\n$PA\n[1] \"66.7\"\n\n$QBP\n[1] \"613\"\n\n$TOT\n[1] \"103.7\"\n\n$PAS\n[1] \"55.0\"\n\n$RUN\n[1] \"39.1\"\n\n$EXP\n[1] \"0.0\"\n\n$PEN\n[1] \"2.2\"\n\n$QBR\n[1] \"82.3\"\n\n$SAC\n[1] \"-7.4\"\n\n\nNote, while this looks like a 1x10 dataframe, it’s still just a vector with name attributes.\n\n# What type?\nget_qbr_data(1) %>% str()\n\nList of 14\n $ displayName  : chr \"Lamar Jackson\"\n $ teamName     : chr \"Ravens\"\n $ teamShortName: chr \"BAL\"\n $ headshot     : chr \"https://a.espncdn.com/i/headshots/nfl/players/full/3916387.png\"\n $ TQBR         : chr \"83.0\"\n $ PA           : chr \"66.7\"\n $ QBP          : chr \"613\"\n $ TOT          : chr \"103.7\"\n $ PAS          : chr \"55.0\"\n $ RUN          : chr \"39.1\"\n $ EXP          : chr \"0.0\"\n $ PEN          : chr \"2.2\"\n $ QBR          : chr \"82.3\"\n $ SAC          : chr \"-7.4\""
  },
  {
    "objectID": "posts/2020-08-05-a-bar-chart-5-ways/index.html",
    "href": "posts/2020-08-05-a-bar-chart-5-ways/index.html",
    "title": "A bar chart 5 ways in ggplot2",
    "section": "",
    "text": "Awesome work Thomas!\n\n— Andy Kirk (@visualisingdata) July 17, 2019\n\n\nAndy Kirk put together Five Ways to present bar charts as part of his Five ways to... series back in 2019. The plots below are his original ideas, just recreated in ggplot2.\nI originally recreated his plots in ggplot2 and published them as a gist and on Twitter in July 2019, stumbled upon it again recently, and thought why not capture it as a proper blog-post!\nAdditionally, when I originally made these remakes, ggplot2 required coord_flip() whereas the most recent version of ggplot2 allows you to natively create horizontal bar charts! I’ve thus changed a little bit of the code from the original gist to reflect the new options in ggplot2.\nAgain thank you to Andy Kirk for the prompt! Make sure to check out his blog in general for all sorts of great data viz tips."
  },
  {
    "objectID": "posts/2020-08-05-a-bar-chart-5-ways/index.html#source-data",
    "href": "posts/2020-08-05-a-bar-chart-5-ways/index.html#source-data",
    "title": "A bar chart 5 ways in ggplot2",
    "section": "Source Data",
    "text": "Source Data\nThe data comes from Wikipedia, specifically a list of the most streamed songs on Spotify. We can scrape the table into R w/ rvest.\n\nlibrary(rvest)\nlibrary(tidyverse)\n\nNow that we have the libraries loaded, let’s read in the data, pull in the top 100, and add some new columns to use across our charts.\n\nurl <- \"https://en.wikipedia.org/wiki/List_of_most-streamed_songs_on_Spotify\"\n\ndf <- url %>% \n  read_html() %>% \n  html_table(fill = TRUE) %>% \n  .[[1]] %>% \n  select(Rank:`Date published`) %>% \n  set_names(nm = c(\"rank\", \"song_name\", \"streams\", \"artist\", \"date_published\")) %>% \n  slice(1:100) %>% \n  mutate(num_rank = parse_number(rank),\n         streams_comma = streams,\n         streams = parse_number(streams)/1000,\n         streams_text = if_else(\n           num_rank == 1,\n           paste(round(streams, digits = 2), \"billion streams\"),\n           as.character(round(streams, digits = 2))\n           ),\n         lab_text = glue::glue(\"{rank}. {song_name} by {artist}\"),\n  ) %>% \n  as_tibble()\n\ndf %>% glimpse()\n\nRows: 100\nColumns: 9\n$ rank           <chr> \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\"…\n$ song_name      <chr> \"\\\"Shape of  You\\\"\", \"\\\"Blinding Lights\\\"\", \"\\\"Dance Mo…\n$ streams        <dbl> 3.109, 2.920, 2.542, 2.403, 2.327, 2.289, 2.268, 2.263,…\n$ artist         <chr> \"Ed Sheeran\", \"The Weeknd\", \"Tones and I\", \"Post Malone…\n$ date_published <chr> \"28 March 2017\", \"29 November 2019\", \"10 May 2019\", \"15…\n$ num_rank       <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, …\n$ streams_comma  <chr> \"3,109\", \"2,920\", \"2,542\", \"2,403\", \"2,327\", \"2,289\", \"…\n$ streams_text   <chr> \"3.11 billion streams\", \"2.92\", \"2.54\", \"2.4\", \"2.33\", …\n$ lab_text       <glue> \"1. \\\"Shape of  You\\\" by Ed Sheeran\", \"2. \\\"Blinding L…\n\n\n\nNote that there is \\ in front of the song name and in the lab_text as there we have to escape the \" in each of those strings.\n\nData is ready to go!"
  },
  {
    "objectID": "posts/2019-01-09-add-a-logo-to-your-plot/index.html",
    "href": "posts/2019-01-09-add-a-logo-to-your-plot/index.html",
    "title": "Add a logo to your plot",
    "section": "",
    "text": "via GIPHY\nIf you missed out on Portlandia, you should take some time to watch this clip of the “Put a bird on it” episode.\nJust like Bryce and Lisa - we can put birds on anything with the magick package from ROpenSci!\nSo let’s get started putting birds on things!"
  },
  {
    "objectID": "posts/2019-01-09-add-a-logo-to-your-plot/index.html#read-in-a-plot",
    "href": "posts/2019-01-09-add-a-logo-to-your-plot/index.html#read-in-a-plot",
    "title": "Add a logo to your plot",
    "section": "Read in a plot",
    "text": "Read in a plot\nSo let’s read in our publication plot to work with! Please notice that this can be a local file with traditional path structure or a hosted image as a url. I’m using URLs so you can try these out yourself!\n\npub_plot <- image_read(\"https://raw.githubusercontent.com/jthomasmock/tomtom/master/vignettes/basic_plot.png\")\n\nlogo <- image_read(\"https://www.rstudio.com/wp-content/uploads/2018/10/RStudio-Logo-Flat.png\") %>% \n  image_resize(300)\n\nprint(pub_plot)\n\n# A tibble: 1 × 7\n  format width height colorspace matte filesize density\n  <chr>  <int>  <int> <chr>      <lgl>    <int> <chr>  \n1 PNG     2222   1951 sRGB       TRUE    168897 72x72  \n\n\n\n\nprint(logo)\n\n# A tibble: 1 × 7\n  format width height colorspace matte filesize density\n  <chr>  <int>  <int> <chr>      <lgl>    <int> <chr>  \n1 PNG      300    105 sRGB       TRUE         0 57x57"
  },
  {
    "objectID": "posts/2019-01-09-add-a-logo-to-your-plot/index.html#where-to-put-the-logo",
    "href": "posts/2019-01-09-add-a-logo-to-your-plot/index.html#where-to-put-the-logo",
    "title": "Add a logo to your plot",
    "section": "Where to put the logo?",
    "text": "Where to put the logo?\nWe can then overlay the logo over the plot, let’s try bottom left, and we want ~ 1% padding for aesthetics - so we can use the following code to get dimensions and pixel numbers.\n\n# get dims of the plot\nplot_height <- magick::image_info(pub_plot)$height\nplot_width <- magick::image_info(pub_plot)$width\n\n# get dims of the logo\nlogo_width <- magick::image_info(logo)$width\nlogo_height <- magick::image_info(logo)$height\n\n# get number of pixels to be 1% from the bottom of the plot\n# while accounting for the logo height\nplot_height - logo_height - plot_height * 0.01\n\n[1] 1826.49\n\n# get number of pixels to be 1% from the left of the plot\nplot_width * 0.01\n\n[1] 22.22"
  },
  {
    "objectID": "posts/2019-01-09-add-a-logo-to-your-plot/index.html#add-the-logo",
    "href": "posts/2019-01-09-add-a-logo-to-your-plot/index.html#add-the-logo",
    "title": "Add a logo to your plot",
    "section": "Add the logo",
    "text": "Add the logo\nBy using offset = \"+22+1826\" we indicate that we are placing the logo 22 pixels to the right and 1826 pixels down.\n\npub_plot %>% \n  image_composite(logo, offset = \"+22+1826\")\n\n\n\n\nBoom! We have our logo overlay on the plot in the right location! But we had to manually figure out and set the logo position, which is less than ideal for programmatic use down the road. I also manually resized the logo to 300 pixels in an earlier step - we should make that automagick as well!"
  },
  {
    "objectID": "posts/2019-01-09-add-a-logo-to-your-plot/index.html#put-it-in-a-function-bird-not-included",
    "href": "posts/2019-01-09-add-a-logo-to-your-plot/index.html#put-it-in-a-function-bird-not-included",
    "title": "Add a logo to your plot",
    "section": "Put it in a function! (Bird not included)",
    "text": "Put it in a function! (Bird not included)\nTo make the logo add process more reproducible, we can build a function to take the various heights and widths of the logo/plot and automatically resize the logo to match as well as calculating the number of pixels to put it in each respective corner. The logo_scale argument defaults to 10 - so the logo will be 1/10th the width of the plot.\n\nplot_with_logo <- add_logo(\n  plot_path = \"\", # url or local file for the plot\n  logo_path = \"\", # url or local file for the logo\n  logo_position = \"\" # choose a corner\n  # 'top left', 'top right', 'bottom left' or 'bottom right'\n  #logo_scale = 10 as default, but can change to manually make logo bigger\n)\n\n# save the image and write to working directory\nmagick::image_write(plot_with_logo, \"plot_with_logo.png\")"
  },
  {
    "objectID": "posts/2019-01-09-add-a-logo-to-your-plot/index.html#the-function-details",
    "href": "posts/2019-01-09-add-a-logo-to-your-plot/index.html#the-function-details",
    "title": "Add a logo to your plot",
    "section": "The function details",
    "text": "The function details\nThis function takes in two images, gets the dimension information, then pastes the logo at 1/10th scale in the specified corner with 1% padding. The function also has a warning if you input a logo_position that is not included.\n\nadd_logo <- function(plot_path, logo_path, logo_position, logo_scale = 10){\n\n    # Requires magick R Package https://github.com/ropensci/magick\n\n    # Useful error message for logo position\n    if (!logo_position %in% c(\"top right\", \"top left\", \"bottom right\", \"bottom left\")) {\n        stop(\"Error Message: Uh oh! Logo Position not recognized\\n  Try: logo_positon = 'top left', 'top right', 'bottom left', or 'bottom right'\")\n    }\n\n    # read in raw images\n    plot <- magick::image_read(plot_path)\n    logo_raw <- magick::image_read(logo_path)\n\n    # get dimensions of plot for scaling\n    plot_height <- magick::image_info(plot)$height\n    plot_width <- magick::image_info(plot)$width\n\n    # default scale to 1/10th width of plot\n    # Can change with logo_scale\n    logo <- magick::image_scale(logo_raw, as.character(plot_width/logo_scale))\n\n    # Get width of logo\n    logo_width <- magick::image_info(logo)$width\n    logo_height <- magick::image_info(logo)$height\n\n    # Set position of logo\n    # Position starts at 0,0 at top left\n    # Using 0.01 for 1% - aesthetic padding\n\n    if (logo_position == \"top right\") {\n        x_pos = plot_width - logo_width - 0.01 * plot_width\n        y_pos = 0.01 * plot_height\n    } else if (logo_position == \"top left\") {\n        x_pos = 0.01 * plot_width\n        y_pos = 0.01 * plot_height\n    } else if (logo_position == \"bottom right\") {\n        x_pos = plot_width - logo_width - 0.01 * plot_width\n        y_pos = plot_height - logo_height - 0.01 * plot_height\n    } else if (logo_position == \"bottom left\") {\n        x_pos = 0.01 * plot_width\n        y_pos = plot_height - logo_height - 0.01 * plot_height\n    }\n\n    # Compose the actual overlay\n    magick::image_composite(plot, logo, offset = paste0(\"+\", x_pos, \"+\", y_pos))\n\n}\n\n\n\n\n\n\nSo there you go! Happy logo adding and bird putting!\nFor more information on adding logos to plots with magick::image_append() instead, check out this blog post by Daniel Hadley on using magick::image_append to add a logo or his RStudioConf talk on the same idea.\nCheers!\n\n\n\n\n\n\n\nExpand for Session Info\n\n\n\n\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.0 (2022-04-22)\n os       macOS Monterey 12.2.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       America/Chicago\n date     2022-04-28\n pandoc   2.18 @ /Applications/RStudio.app/Contents/MacOS/quarto/bin/tools/ (via rmarkdown)\n quarto   0.9.294 @ /usr/local/bin/quarto\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version date (UTC) lib source\n dplyr       * 1.0.8   2022-02-08 [1] CRAN (R 4.2.0)\n forcats     * 0.5.1   2021-01-27 [1] CRAN (R 4.2.0)\n ggplot2     * 3.3.5   2021-06-25 [1] CRAN (R 4.2.0)\n magick      * 2.7.3   2021-08-18 [1] CRAN (R 4.2.0)\n purrr       * 0.3.4   2020-04-17 [1] CRAN (R 4.2.0)\n readr       * 2.1.2   2022-01-30 [1] CRAN (R 4.2.0)\n sessioninfo * 1.2.2   2021-12-06 [1] CRAN (R 4.2.0)\n stringr     * 1.4.0   2019-02-10 [1] CRAN (R 4.2.0)\n tibble      * 3.1.6   2021-11-07 [1] CRAN (R 4.2.0)\n tidyr       * 1.2.0   2022-02-01 [1] CRAN (R 4.2.0)\n tidyverse   * 1.3.1   2021-04-15 [1] CRAN (R 4.2.0)\n\n [1] /Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/library\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "posts/2020-05-13-qb-salaries-vs-playoff-appearances/index.html",
    "href": "posts/2020-05-13-qb-salaries-vs-playoff-appearances/index.html",
    "title": "QB Salaries vs Playoff Appearances",
    "section": "",
    "text": "Highest cap hits from 2014-19:Matthew Stafford ($130M)Ben Roethlisberger ($128M)Aaron Rodgers ($126M)Drew Brees ($125M)Eli Manning ($124M)Matt Ryan ($118M)Philip Rivers ($117M)Joe Flacco ($106M)Cam Newton ($104M)None won the Super Bowl during that time.\n\n— Paul Hembekides (@PaulHembo) May 12, 2020\n\nMoo had a good counter-argument (just include the 10th QB) - Tom Brady ruins part of the narrative. Additionally, just include playoff appearances and/or wins.\n\n\nThe thing here is the following:If you include Brady who is the next in the list ($100M), these 10 QBs combine for 3 of 6 Super Bowl titles and 6 of 12 Super Bowl appearances.Accounting for 50% is pretty good for 10/32 of the league, isn't it? https://t.co/C18MQAHfL8\n\n— Moo (@PFF_Moo) May 12, 2020\n\nSo let’s make a table of salary data vs playoff appearances! We could make this static (screenshot for Twitter) - but just for funs lets stretch a bit and make an interactive table with nice formatting.\n\nreactable - interactive data tables\nreactable is an R wrapper for the react table javascript library. Greg Lin at RStudio recently made this package and you can install it from CRAN with install.packages(\"reactable\"). I adapted this table from some examples at the reactable package site.\nRaw data comes from: Pro Football Reference & Over the Cap\nA very basic reactable table can be created as so:\n\nplayoff_salary %>%\n  reactable()\n\n\n\n\n\n\nMore Complex\nAt the risk of drawing the rest of the *&?$ing owl here is a more complex interactive table using the same data.\nPart 2 of this blogpost will go step-by-step into creating more complex tables, but for now…enjoy and consume at your own risk!\n(Full code at bottom of this post) :::{.column-body-outset}\n\n\n\n\n\n2014-2019 Salary and Playoff Appearances\nQBs limited to playoff games where they threw a pass\n\n\nTABLE: @THOMAS_MOCK | DATA: PRO-FOOTBALL-REFERENCE.COM & OVERTHECAP.COM\n\n\n\n:::\n\n\n\n\n\n\n\n\n\nRaw Code to generate the table\nBelow is the raw code to generate the table - I’ll do a deeper dive later, but as of now here is the raw code I used, including some HTML and CSS helpers. This is all adapted from the reactable cookbook.\nThe CSS and HTML helpers do some light-lifting for custom text and borders.\n\nmake_color_pal <- function(colors, bias = 1) {\n  get_color <- colorRamp(colors, bias = bias)\n  function(x) rgb(get_color(x), maxColorValue = 255)\n}\n\ngood_color <- make_color_pal(c(\"#ffffff\", \"#f2fbd2\", \"#c9ecb4\", \"#93d3ab\", \"#35b0ab\"), bias = 2)\n\ntbl <- playoff_salary %>%\n  arrange(desc(salary)) %>%\n  mutate(\n    `Salary Rank` = rank(desc(salary)),\n    salary = round(salary, 1)\n  ) %>%\n  select(`Salary Rank`, player:Superbowl, everything()) %>%\n  reactable(\n    pagination = FALSE,\n    compact = TRUE,\n    borderless = FALSE,\n    striped = FALSE,\n    fullWidth = FALSE,\n    theme = reactableTheme(\n      headerStyle = list(\n        \"&:hover[aria-sort]\" = list(background = \"hsl(0, 0%, 96%)\"),\n        \"&[aria-sort='ascending'], &[aria-sort='descending']\" = list(background = \"hsl(0, 0%, 96%)\"),\n        borderColor = \"#555\"\n      )\n    ),\n    defaultColDef = colDef(\n      align = \"center\",\n      minWidth = 100\n    ),\n    columns = list(\n      salary = colDef(\n        name = \"Salary\",\n        style = function(value) {\n          value\n          normalized <- (value - min(playoff_salary$salary)) / (max(playoff_salary$salary) - min(playoff_salary$salary))\n          color <- good_color(normalized)\n          list(background = color)\n        },\n        cell = JS(\"function(cellInfo) {\n                          return cellInfo.value + 'M'}\")\n      ),\n      Total = colDef(\n        style = function(value) {\n          value\n          normalized <- (value - min(playoff_salary$Total)) / (max(playoff_salary$Total) - min(playoff_salary$Total))\n          color <- good_color(normalized)\n          list(background = color)\n        },\n        class = \"border-left\"\n      ),\n      player = colDef(\n        name = \"Name\",\n        minWidth = 140,\n        align = \"left\"\n      )\n    )\n  )\n\n\n\n\n\ndiv(\n  class = \"salary\",\n  div(\n    class = \"title\",\n    h2(\"2014-2019 Salary and Playoff Appearances\"),\n    \"QBs limited to playoff games where they threw a pass\"\n  ),\n  tbl,\n  tags$span(style = \"color:#C8C8C8\", \"TABLE: @THOMAS_MOCK | DATA: PRO-FOOTBALL-REFERENCE.COM & OVERTHECAP.COM\")\n)\n\n\ntags$link(href = \"https://fonts.googleapis.com/css?family=Karla:400,700|Fira+Mono&display=fallback\", rel = \"stylesheet\")\n\n\n.salary {\n  font-family: Karla, \"Helvetica Neue\", Helvetica, Arial, sans-serif;\n  font-size: 14px;\n}\n\n.number {\n  font-family: \"Fira Mono\", Consolas, Monaco, monospace;\n  font-size: 16px;\n  line-height: 30px;\n  white-space: pre;\n}\n\n.title {\n  margin: 18px 0;\n  font-size: 16px;\n}\n\n.title h2 {\n  font-size: 20px;\n  font-weight: 600;\n}\n\n\n.header:hover,\n.header[aria-sort=\"ascending\"],\n.header[aria-sort=\"descending\"] {\n  background-color: #eee;\n}\n\n.salary-table {\n  margin-bottom: 20px;\n}\n\n/* Align header text to the bottom */\n.header,\n.group-header {\n  display: flex;\n  flex-direction: column;\n  justify-content: flex-end;\n}\n\n.header {\n  border-bottom-color: #555;\n  font-size: 13px;\n  font-weight: 400;\n  text-transform: uppercase;\n}\n\n/* Highlight headers when sorting */\n.header:hover,\n.header[aria-sort=\"ascending\"],\n.header[aria-sort=\"descending\"] {\n  background-color: #eee;\n}\n\n.border-left {\n  border-left: 2px solid #555;\n}\n\n/* Use box-shadow to create row borders that appear behind vertical borders */\n.cell {\n  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);\n}\n\n\n\n\n\n\n\nExpand for Session Info\n\n\n\n\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.0 (2022-04-22)\n os       macOS Monterey 12.2.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       America/Chicago\n date     2022-04-28\n pandoc   2.18 @ /Applications/RStudio.app/Contents/MacOS/quarto/bin/tools/ (via rmarkdown)\n quarto   0.9.294 @ /usr/local/bin/quarto\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version date (UTC) lib source\n dplyr       * 1.0.8   2022-02-08 [1] CRAN (R 4.2.0)\n forcats     * 0.5.1   2021-01-27 [1] CRAN (R 4.2.0)\n ggplot2     * 3.3.5   2021-06-25 [1] CRAN (R 4.2.0)\n htmltools   * 0.5.2   2021-08-25 [1] CRAN (R 4.2.0)\n purrr       * 0.3.4   2020-04-17 [1] CRAN (R 4.2.0)\n reactable   * 0.2.3   2020-10-04 [1] CRAN (R 4.2.0)\n readr       * 2.1.2   2022-01-30 [1] CRAN (R 4.2.0)\n sessioninfo * 1.2.2   2021-12-06 [1] CRAN (R 4.2.0)\n stringr     * 1.4.0   2019-02-10 [1] CRAN (R 4.2.0)\n tibble      * 3.1.6   2021-11-07 [1] CRAN (R 4.2.0)\n tidyr       * 1.2.0   2022-02-01 [1] CRAN (R 4.2.0)\n tidyverse   * 1.3.1   2021-04-15 [1] CRAN (R 4.2.0)\n\n [1] /Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/library\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "posts/2020-09-26-functions-and-themes-for-gt-tables/index.html#gt-tables",
    "href": "posts/2020-09-26-functions-and-themes-for-gt-tables/index.html#gt-tables",
    "title": "Functions and Themes for gt tables",
    "section": "\ngt tables",
    "text": "gt tables\nI’m continuing my series on gt tables with an exploration of gt functions and themes. Technically, they could be treated as the same thing but slightly different use cases.\nFor a function - I would think of the gt table as the final output, whereas a theme is applied to an existing gt table.\n\nlibrary(tidyverse)\nlibrary(gt)\nlibrary(espnscrapeR)\n\nIf you’ve never written a function, I’d recommend reading the functions chapter from the R4DS book.\nFor an example, here’s a quick function with gt:\n\nmtcars_table <- function(cyl_match = 6){\n  mtcars %>% \n    filter(cyl == cyl_match) %>% \n    head() %>% \n    gt() %>% \n    tab_header(\n      title = glue::glue(\"Table for cars with {cyl_match} cylinders\")\n    )\n}\n\nmtcars_table(4)\n\n\n\n\n\n\nTable for cars with 4 cylinders\n    \n\nmpg\n      cyl\n      disp\n      hp\n      drat\n      wt\n      qsec\n      vs\n      am\n      gear\n      carb\n    \n\n\n22.8\n4\n108.0\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\n24.4\n4\n146.7\n62\n3.69\n3.190\n20.00\n1\n0\n4\n2\n\n\n22.8\n4\n140.8\n95\n3.92\n3.150\n22.90\n1\n0\n4\n2\n\n\n32.4\n4\n78.7\n66\n4.08\n2.200\n19.47\n1\n1\n4\n1\n\n\n30.4\n4\n75.7\n52\n4.93\n1.615\n18.52\n1\n1\n4\n2\n\n\n33.9\n4\n71.1\n65\n4.22\n1.835\n19.90\n1\n1\n4\n1\n\n\n\n\n\n\nIn this case, we’re just using the table to generate our output of interest. Now something cool about gt since it’s pipe-oriented, is that you can continue working with the table. So let’s make some changes from our gt function.\n\nmtcars_table(6) %>% \n  opt_all_caps() %>% \n  opt_align_table_header(\"left\")\n\n\n\n\n\n\nTable for cars with 6 cylinders\n    \n\nmpg\n      cyl\n      disp\n      hp\n      drat\n      wt\n      qsec\n      vs\n      am\n      gear\n      carb\n    \n\n\n21.0\n6\n160.0\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\n21.0\n6\n160.0\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\n21.4\n6\n258.0\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\n18.1\n6\n225.0\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\n19.2\n6\n167.6\n123\n3.92\n3.440\n18.30\n1\n0\n4\n4\n\n\n17.8\n6\n167.6\n123\n3.92\n3.440\n18.90\n1\n0\n4\n4\n\n\n\n\n\n\nSo our function can generate a gt table, and we can then apply any other changes we need to the existing table.\nSince this is a toy example, it’s not very exciting, so let’s continue on!\nBetter Example\nLet’s grab a quick example from my espnscrapeR package. Each week, QBs are given a QBR (Quarterback Rating) score from ESPN.\n\nlibrary(espnscrapeR)\n\nget_nfl_qbr(season = 2020, week = 1)\n\nScraping weekly QBR for week 1 of 2020!\n\n\n# A tibble: 32 × 30\n   season season_type game_id  game_week week_text team_abb player_id name_short\n    <dbl> <chr>       <chr>        <int> <chr>     <chr>    <chr>     <chr>     \n 1   2020 Regular     4012201…         1 Week 1    BAL      3916387   L. Jackson\n 2   2020 Regular     4012203…         1 Week 1    GB       8439      A. Rodgers\n 3   2020 Regular     4012203…         1 Week 1    SEA      14881     R. Wilson \n 4   2020 Regular     4012202…         1 Week 1    KC       3139477   P. Mahomes\n 5   2020 Regular     4012203…         1 Week 1    ARI      3917315   K. Murray \n 6   2020 Regular     4012201…         1 Week 1    NE       13994     C. Newton \n 7   2020 Regular     4012203…         1 Week 1    DAL      2577417   D. Presco…\n 8   2020 Regular     4012201…         1 Week 1    JAX      4038524   G. Minshew\n 9   2020 Regular     4012202…         1 Week 1    TEN      14876     R. Tanneh…\n10   2020 Regular     4012203…         1 Week 1    NO       2580      D. Brees  \n# … with 22 more rows, and 22 more variables: rank <dbl>, qbr_total <dbl>,\n#   pts_added <dbl>, qb_plays <dbl>, epa_total <dbl>, pass <dbl>, run <dbl>,\n#   exp_sack <dbl>, penalty <dbl>, qbr_raw <dbl>, sack <dbl>, name_first <chr>,\n#   name_last <chr>, name_display <chr>, headshot_href <chr>, team <chr>,\n#   opp_id <chr>, opp_abb <chr>, opp_team <chr>, opp_name <chr>,\n#   week_num <int>, qualified <lgl>\n\n\nLet’s use a function to generate a relatively clean table quickly. Our goal here is to take the process of collecting and cleaning data then generating a gt table into a simple function for the year + week of interest.\n\n\nTable\n2020 Week 3\nCode\n\n\n\n\nqbr_table(2020, 1)\n\n\n\nScraping weekly QBR for week 1 of 2020!\n\n\n\n\n\n\n\nTop 10 QBs for week 1 of 2020\n    \n\nrk\n      team\n      name\n      qbr\n      plays\n      pass\n      run\n      sack\n    \n\n\n1\nRavens\nL. Jackson\n93.2\n34\n7.9\n-0.6\n-0.4\n\n\n2\nPackers\nA. Rodgers\n91.4\n48\n9.9\n0.7\n0.0\n\n\n3\nSeahawks\nR. Wilson\n81.8\n46\n8.1\n-0.8\n-1.5\n\n\n4\nChiefs\nP. Mahomes\n80.7\n36\n7.7\n0.0\n-0.5\n\n\n5\nCardinals\nK. Murray\n79.0\n56\n4.3\n5.7\n-0.6\n\n\n6\nPatriots\nC. Newton\n77.6\n35\n2.9\n4.0\n-1.2\n\n\n7\nCowboys\nD. Prescott\n76.2\n47\n5.6\n1.1\n-1.6\n\n\n8\nJaguars\nG. Minshew\n70.3\n29\n4.7\n-0.3\n-2.2\n\n\n9\nTitans\nR. Tannehill\n70.0\n51\n8.5\n0.0\n-0.1\n\n\n10\nSaints\nD. Brees\n68.5\n36\n3.6\n-0.4\n-0.7\n\n\n\n\n\n\n\n\n\nqbr_table(2020, 3)\n\nScraping weekly QBR for week 3 of 2020!\n\n\n\n\n\n\n\nTop 10 QBs for week 3 of 2020\n    \n\nrk\n      team\n      name\n      qbr\n      plays\n      pass\n      run\n      sack\n    \n\n\n1\nChiefs\nP. Mahomes\n98.0\n49\n12.3\n2.5\n0.0\n\n\n2\nDolphins\nR. Fitzpatrick\n95.8\n31\n5.9\n2.1\n-0.1\n\n\n3\nPackers\nA. Rodgers\n89.4\n38\n6.0\n1.9\n-0.7\n\n\n4\nBills\nJ. Allen\n87.0\n44\n9.5\n0.5\n-2.3\n\n\n5\nColts\nP. Rivers\n86.2\n23\n5.6\n0.0\n0.0\n\n\n6\nSaints\nD. Brees\n85.5\n40\n7.6\n0.0\n-0.9\n\n\n7\nSeahawks\nR. Wilson\n83.4\n54\n11.9\n0.1\n-1.6\n\n\n8\nTexans\nD. Watson\n81.4\n34\n5.2\n0.1\n-2.3\n\n\n9\n49ers\nN. Mullens\n78.0\n42\n6.3\n0.1\n-0.9\n\n\n10\nCowboys\nD. Prescott\n74.4\n69\n9.1\n1.3\n-0.6\n\n\n\n\n\n\n\n\n\nqbr_table <- function(season_in, week_in){\n  raw_df <- get_nfl_qbr(season = season_in, week = week_in)\n  \n  raw_df %>% \n    slice(1:10) %>% \n    select(\n      rk = rank, team, name = name_short, qbr = qbr_total, \n      plays = qb_plays, pass, run, sack\n      ) %>% \n    gt() %>% \n    opt_all_caps() %>% \n    tab_options(\n      table.width = px(600),\n      heading.title.font.weight = \"bold\",\n      heading.align = \"left\"\n    ) %>% \n    tab_header(\n      title = glue::glue(\"Top 10 QBs for week {week_in} of {season_in}\")\n    )\n}\n\nqbr_table(2020, 1)\n\n\n\n\nBoom! Ready to share an update on the top 10 QBs by QBR for week 1, or week 2 or week 3, or week 16 from 2015, or ANY other week/season combo! Putting this all into a function lets us simply focus on which data to input and generate a nice table.\nNote you could still do a lot to this table to get it publication ready or specific to your “brand”, which gets us into the next part - themes!"
  },
  {
    "objectID": "posts/2020-09-26-functions-and-themes-for-gt-tables/index.html#gt-themes",
    "href": "posts/2020-09-26-functions-and-themes-for-gt-tables/index.html#gt-themes",
    "title": "Functions and Themes for gt tables",
    "section": "\ngt Themes",
    "text": "gt Themes\nWe’re going to explore 3 different formats for elegant tables with examples from ESPN, ProFootball Focus, and FiveThirtyEight. Of the three, I personally think that FiveThirtyEight has some of the best minimalist tables on the web right now, but for the sake of different tastes we’ll go through each!\nBefore diving right into the themes - I’d first like to show a quick example of a theme and walk through the code. Hopefully this gives you enough to make your own themes down the line!\nYou can think of gt themes in a similar fashion to ggplot2 themes. Just as theme_bw() just changes the appearance (eg theme) of the plot, a custom-defined gt theme will affect the overall appearance of a gt table (although as a function you could make it do even more!).\n\nmtcars %>% \n  ggplot(aes(x = disp, y = mpg)) +\n  geom_point() +\n  # Here is a built in theme for ggplot2\n  theme_bw()\n\n\n\n\nBasic Theme\nThe core idea of a theme is that it’s a function that passes data and ..., where the data is actually a gt object, and the ... are a placeholder for user-defined expressions. The ... can also be called “dot-dot-dot”, “the dots” or “ellipsis”, and you can read more about them in the Tidy evaluation book. A quick quote about them from that book chapter:\n\nThe dot-dot-dot argument is one of the nicest aspects of the R language. A function that takes ... accepts any number of arguments, named or unnamed.\n\nWhat this really means is that we are leaving any argument on the table for tab_options() which has the widest range of possible arguments in gt (> 100 possible arguments). You can see all the possible options in the gt reference.\nOur basic example passes data as the first argument into tab_options() and leaves a ... inside tab_options().\n\nbasic_theme <- function(data, ...){\n  data %>% \n    tab_options(\n      table.background.color = \"purple\",\n      ...\n    )\n}\n\nIf we use this theme, it will just change the table background color.\n\nmtcars %>% \n  head() %>% \n  gt() %>% \n  basic_theme()\n\n\n\n\n\n\nmpg\n      cyl\n      disp\n      hp\n      drat\n      wt\n      qsec\n      vs\n      am\n      gear\n      carb\n    \n\n\n21.0\n6\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\n21.0\n6\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\n22.8\n4\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\n21.4\n6\n258\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\n18.7\n8\n360\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\n18.1\n6\n225\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\n\n\n\n\nHowever, since we left the ... inside our theme, we can pass additional arguments into the basic_theme(). Let’s change the column label background to red.\n\nmtcars %>% \n  head() %>% \n  gt() %>% \n  basic_theme(\n    column_labels.background.color = \"red\"\n  )\n\n\n\n\n\n\nmpg\n      cyl\n      disp\n      hp\n      drat\n      wt\n      qsec\n      vs\n      am\n      gear\n      carb\n    \n\n\n21.0\n6\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\n21.0\n6\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\n22.8\n4\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\n21.4\n6\n258\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\n18.7\n8\n360\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\n18.1\n6\n225\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\n\n\n\n\nAs a final note, you can keep piping the results into further gt arguments!\n\nmtcars %>% \n  head() %>% \n  gt() %>% \n  basic_theme(\n    column_labels.background.color = \"red\",\n    table.font.size = px(12),\n    column_labels.font.size = px(20),\n    row.striping.background_color = \"#9678b6\",\n    heading.align = \"left\",\n    heading.title.font.size = px(30)\n  ) %>% \n  opt_row_striping() %>% \n  tab_header(title = \"Important table with theme\")\n\n\n\n\n\n\nImportant table with theme\n    \n\nmpg\n      cyl\n      disp\n      hp\n      drat\n      wt\n      qsec\n      vs\n      am\n      gear\n      carb\n    \n\n\n21.0\n6\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\n21.0\n6\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\n22.8\n4\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\n21.4\n6\n258\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\n18.7\n8\n360\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\n18.1\n6\n225\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\n\n\n\n\nNOTE: While I’ve passed multiple arguments to our theme function as a show of possibility, the goal here is to push as much as the default theme elements you want to change into our theme function ahead of time to save repetitive typing!\nEnough of fun but toy examples - let’s dive into the real themes!\nESPN\nOur ESPN table is again using the original QBR data, and they are clean and simple. All caps on the column labels, row striping, but also add the player’s team as smaller gray text after the player’s name. Note that they also use hyperlinks to the player page (I’ll just focus on showing an example of blue text). Lastly, ESPN also uses interactive tables so there is a highlighted column for sorting. I’ll cover reactable themes on a later date so for now we’ll focus on static HTML with gt.\n\n\n\n\n\nESPN Table\nOriginal\nTable Code\nTheme Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nespn_qbr <- espnscrapeR::get_nfl_qbr(2020) %>% \n  select(\n    rk = rank, team, name, qbr = qbr_total, paa = points_added, plays = qb_plays,\n    epa = total_epa, pass, run, sack, pen = penalty, raw = raw_qbr\n    )\n\nespn_qbr %>% \n  mutate(name = paste0(\n    \"<span style='font-size:16px; color:royalblue;'>\",\n    name,\n    \"</span>\",\n    \" <span style='font-size:12px; color:grey;'>\",\n    word(team, start = -1), \"</span>\"),\n    name = map(name, ~gt::html(as.character(.x)))\n  ) %>%\n  select(-team) %>% \n  slice(1:15) %>% \n  gt() %>% \n  tab_header(title = md(\"**NFL Total QBR - 2020 Season Leaders**\")) %>% \n  gt_theme_espn() %>% \n  cols_align(\"left\", columns = vars(name)) %>% \n  tab_source_note(md(\"**Data:** ESPN<br>**Table:** @thomas_mock\"))\n\n\n\n\ngt_theme_espn <- function(data, ...){\n  data %>% \n    opt_all_caps()  %>%\n    opt_table_font(\n      font = list(\n        google_font(\"Lato\"),\n        default_fonts()\n      )\n    )  %>% \n    opt_row_striping() %>% \n    tab_options(\n      row.striping.background_color = \"#fafafa\",\n      table_body.hlines.color = \"#f6f7f7\",\n      source_notes.font.size = 12,\n      table.font.size = 16,\n      table.width = px(700),\n      heading.align = \"left\",\n      heading.title.font.size = 24,\n      table.border.top.color = \"transparent\",\n      table.border.top.width = px(3),\n      data_row.padding = px(7),\n      ...\n    ) \n}\n\n\n\n\nPFF\nThe data for this example is FAKE example data for some edge defenders. Quick example gt of this data below.\n\n\nTable\nCode\n\n\n\n\n\nGetting NFL teams!\n\n\nJoining, by = \"team\"\n\n\n\n\n\n\n\nrank\n      name\n      team\n      number\n      def\n      rdef\n      prush\n    \n\n\n1\nF.Name 8\nNO\n85\n92.4\n75.1\n59.2\n\n\n2\nF.Name 10\nDET\n55\n92.1\n80.8\n60.1\n\n\n3\nF.Name 11\nMIN\n57\n91.7\n85.1\n68.7\n\n\n4\nF.Name 1\nPIT\n77\n91.5\n73.0\n72.9\n\n\n5\nF.Name 15\nDEN\n52\n91.1\n89.7\n75.4\n\n\n6\nF.Name 2\nKC\n93\n88.9\n59.8\n86.3\n\n\n\n\n\n\n\n\n\n# Get the team logos\nteam_df <- espnscrapeR::get_nfl_teams() %>% \n  select(team = team_abb, logo)\n\nn_play <- 15\n\n# set seed for reproducibility\nset.seed(2020)\n\n# generate fake data\nfake_df <- tibble(\n  rank = c(1:n_play),\n  name = paste0(\"F.Name \", 1:n_play),\n  team = c(\n    \"PIT\", \"KC\", \"CLE\", \"HOU\", \"BAL\", \"JAX\", \"LV\", \"NO\", \n    \"LAR\", \"DET\", \"MIN\", \"NYJ\", \"DAL\", \"CAR\", \"DEN\"),\n  number = sample(50:99, size = n_play),\n  def = runif(n_play, min = 50.0, 94.0),\n  rdef = runif(n_play, min = 50.0, 94.0),\n  prush = runif(n_play, min = 50.0, 94.0),\n  cov = runif(n_play, min = 50.0, 94.0),\n  def_snaps = sample(85:130, size = n_play),\n  rdef_snaps = sample(12:40, size = n_play),\n  prush_snaps = NA,\n  cov_snaps = sample(0:10, size = n_play, replace = TRUE)\n  ) %>% \n  mutate(\n    prush_snaps = def_snaps - rdef_snaps - cov_snaps\n  ) %>%\n  left_join(team_df) %>%\n  select(rank:name, logo, everything()) %>% \n  arrange(desc(def)) %>% \n  mutate(rank = row_number())\n\nfake_df %>% \n  select(1:8, -logo) %>% \n  head() %>% \n  gt() %>%\n  fmt_number(\n    columns = 5:7,\n    decimals = 1\n  )\n\nNow, that’s an ok table, but we can do a lot better with a theme, especially one to relatively match the theme PFF uses! Example from their Position Grade data.\nThere’s a few things of interest we want to do to:\n- Row striping without horizontal lines\n- Dark gray column labels background (but light gray for spanners) and all caps labels\n- Team logos\n- Bold text for PFF grade, but normal weights for snap counts\n\n\n\n\n\n[PFF-themed Table\nPFF Example\nTable Code\nTheme Code\n\n\n\n\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\nWarning: `columns = TRUE` has been deprecated in gt 0.3.0:\n* please use `columns = everything()` instead\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfake_df %>% \n  gt() %>% \n  fmt_number(\n    columns = 6:9,\n    decimals = 1\n    ) %>% \n  gt_theme_pff()\n\n\n\n\ngt_theme_pff <- function(data, ...) {\n  data %>%\n    # Add team logos w/ web_image\n    text_transform(\n      locations = cells_body(\n        vars(logo)\n      ),\n      fn = function(x) {\n        web_image(\n          url = x,\n          height = 25\n        )\n      }\n    ) %>%\n    # add spanner for PFF Grade\n    tab_spanner(\n      label = \"PFF GRADE\",\n      columns = vars(def, rdef, prush, cov)\n    ) %>%\n    # add spanner for SNAPS\n    tab_spanner(\n      label = \"SNAPS\",\n      columns = contains(\"snaps\")\n    ) %>%\n    # Add a \"blank\" spanner to add white space\n    tab_spanner(\n      label = \"BLANK\",\n      columns = 1:5\n    ) %>%\n    # Relabel columns\n    cols_label(\n      def_snaps = \"DEF\",\n      rdef_snaps = \"RDEF\",\n      prush_snaps = \"PRUSH\",\n      cov_snaps = \"COV\",\n      number = \"#\",\n      logo = \"\"\n    ) %>%\n    # if missing, replace NA w/ ---\n    fmt_missing(\n      columns = everything(),\n      missing_text = \"---\"\n    ) %>%\n    # add exact color from PFF table to spanners\n    tab_style(\n      style = list(\n        cell_fill(color = \"#e4e8ed\"),\n        cell_text(color = \"#878e94\"),\n        cell_borders(sides = \"left\", color = \"white\", weight = px(3))\n      ),\n      locations = list(\n        cells_column_spanners(\n          spanners = c(\"PFF GRADE\", \"SNAPS\")\n        )\n      )\n    ) %>%\n    # hide spanner with transparent color\n    tab_style(\n      style = list(\n        cell_fill(color = \"transparent\"),\n        cell_text(color = \"transparent\")\n      ),\n      locations = list(\n        cells_column_spanners(\n          spanners = c(\"BLANK\")\n        )\n      )\n    ) %>%\n    # Change font color and weight for numeric col\n    tab_style(\n      style = list(\n        cell_text(color = \"#3a3d42\", weight = \"bold\")\n      ),\n      locations = cells_body(\n        columns = 5:9\n      )\n    ) %>%\n    # Add pound sign in front of numbers\n    text_transform(\n      locations = cells_body(\n        columns = vars(number)\n      ),\n      fn = function(x) {\n        paste0(\"#\", x)\n      }\n    ) %>%\n    # Make column labels and spanners all caps\n    opt_all_caps() %>%\n    # add row striping\n    opt_row_striping() %>%\n    # change overall table styling for borders and striping\n    tab_options(\n      column_labels.background.color = \"#585d63\",\n      table_body.hlines.color = \"transparent\",\n      table.border.top.width = px(3),\n      table.border.top.color = \"transparent\",\n      table.border.bottom.color = \"transparent\",\n      table.border.bottom.width = px(3),\n      column_labels.border.top.width = px(3),\n      column_labels.border.top.color = \"transparent\",\n      column_labels.border.bottom.width = px(3),\n      column_labels.border.bottom.color = \"transparent\",\n      row.striping.background_color = \"#f9f9fb\",\n      data_row.padding = px(3),\n      ...\n    ) %>%\n    cols_width(\n      1 ~ px(75),\n      2 ~ px(125),\n      3 ~ px(30),\n      4 ~ px(40),\n      everything() ~ px(60)\n    ) %>% \n    # change color of border separating the text from the sourcenote\n    tab_style(\n      style = cell_borders(\n        sides = \"bottom\", color = \"#585d63\", weight = px(2)\n      ),\n      locations = cells_body(\n        columns = TRUE,\n        rows = nrow(data$`_data`)\n      )\n    ) %>%\n    # change font to Lato throughout (note no need to have Lato locally!)\n    opt_table_font(\n      font = c(\n        google_font(name = \"Lato\"),\n        default_fonts()\n      )\n    ) %>%\n    # add source note\n    tab_source_note(\n      source_note = md(\"**Data:** _FAKE DATA_ Pro Football Focus<br>**Table:** @thomas_mock\")\n    )\n}\n\n\n\n\nWhile this theme is great, it’s very tailored to this specific data, so it’s closer to a function to generate PFF defensive grade tables. This is fine, as it would greatly speed up the ability to generate these for sharing somewhere, but it’s not a very generic function that could be used for novel data structures. This is mainly as we are doing some sneaky things to get the grey boxes around PFF GRADE and SNAPS that involve transparent backgrounds at specific locations. You could adapt big chunks of this code to use elsewhere though, and note that it would still work for CBs, LBs, Edge, DL, and Safeties. That’s pretty useful!\nFiveThirtyEight\nNow, since FiveThirtyEight tables are more minimal, the theme we’ll use for those tables can be essentially be extended to almost any table! The original data and table come from a FiveThirtyEight article from 2018.\n\n\nFiveThirtyEight Table\nOriginal\nTable Code\nTheme Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlibrary(rvest)\n\nurl <- \"https://fivethirtyeight.com/features/sorry-running-backs-even-your-receiving-value-can-be-easily-replaced/\"\n\nrb_receiving <- url %>% \n  xml2::read_html() %>% \n  rvest::html_table() %>% \n  purrr::chuck(1) %>% \n  purrr::set_names(nm = c(\"team\", \"attempts\", \"successful\", \"success_rate\")) %>% \n  dplyr::as_tibble() %>% \n  filter(team != \"team\") %>% \n  mutate(success_rate = stringr::str_remove(success_rate, \"%\")) %>% \n  mutate(across(c(attempts:success_rate), as.double))\n\n\ntab_538 <- rb_receiving %>%\n  gt() %>%\n  tab_spanner(\n    label = \"PASSES TO RBS\",\n    columns = vars(attempts, successful)\n  ) %>% \n  data_color(\n    columns = vars(success_rate),\n    colors = scales::col_numeric(\n      palette = c(\"white\", \"#3fc1c9\"),\n      domain = NULL\n    )\n  ) %>% \n  cols_label(\n    success_rate = \"SUCCESS RATE (%)\"\n  ) %>% \n  tab_source_note(\n    source_note = md(\"SOURCE: ESPN STATS & INFORMATION GROUP<br>TABLE: @THOMAS_MOCK\")\n  ) %>% \n  gt_theme_538(table.width = px(550))\n\n\n\nHere’s the theme code for the FiveThirtyEight theme.\n\ngt_theme_538 <- function(data,...) {\n  data %>%\n  opt_all_caps()  %>%\n  opt_table_font(\n    font = list(\n      google_font(\"Chivo\"),\n      default_fonts()\n    )\n  ) %>%\n    tab_style(\n      style = cell_borders(\n        sides = \"bottom\", color = \"transparent\", weight = px(2)\n      ),\n      locations = cells_body(\n        columns = TRUE,\n        # This is a relatively sneaky way of changing the bottom border\n        # Regardless of data size\n        rows = nrow(data$`_data`)\n      )\n    )  %>% \n  tab_options(\n    column_labels.background.color = \"white\",\n    table.border.top.width = px(3),\n    table.border.top.color = \"transparent\",\n    table.border.bottom.color = \"transparent\",\n    table.border.bottom.width = px(3),\n    column_labels.border.top.width = px(3),\n    column_labels.border.top.color = \"transparent\",\n    column_labels.border.bottom.width = px(3),\n    column_labels.border.bottom.color = \"black\",\n    data_row.padding = px(3),\n    source_notes.font.size = 12,\n    table.font.size = 16,\n    heading.align = \"left\",\n    ...\n  ) \n}\n\n\n\n\nNow, since that data is public via nflfastR, we could try and recreate that table for 2018 or 2019 (or really any year between 1999 and 2020). There’s a small amount of difference between what FiveThirtyEight reported and what we calculated with nflfastR data, but perhaps they excluded some other plays (or excluded FBs). Feel free to dive in a bit deeper if you’re interested in recreating (all the code is included below).\n\n\n2018 Table\n2019 Table\nTable Code\nData Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# 2018 recreation\nseason_stats %>% \n  filter(season == 2018) %>% \n  select(-season) %>% \n  gt() %>%\n  tab_spanner(\n    label = \"PASSES TO RBS\",\n    columns = vars(Attempts, Successful)\n  ) %>% \n  tab_header(\n    title = md(\"**The Chiefs got the most out of the running back pass**\"),\n    subtitle = md(\"NFL teams by success rate of passes to running backs, as measured by positive<br>expected points added, for the 2018 regular season\")\n    ) %>% \n  data_color(\n    columns = vars(success_rate),\n    colors = scales::col_numeric(\n      palette = c(\"white\", \"#3fc1c9\"),\n      domain = NULL\n    )\n  ) %>% \n  cols_label(\n    success_rate = \"SUCCESS RATE (%)\"\n  ) %>% \n  tab_source_note(\n    source_note = md(\"SOURCE: NFLFASTR<br>TABLE: @THOMAS_MOCK\")\n  ) %>% \n  gt_theme_538(table.width = px(550))\n\n# 2019 table\nseason_stats %>% \n  filter(season == 2019) %>% \n  select(-season) %>% \n  gt() %>%\n  tab_header(\n    title = md(\"**The Panthers got the most out of the running back pass**\"),\n    subtitle = md(\"NFL teams by success rate of passes to running backs, as measured by positive<br>expected points added, for the 2019 regular season\")\n    ) %>% \n  tab_spanner(\n    label = \"PASSES TO RBS\",\n    columns = vars(Attempts, Successful)\n  ) %>% \n  data_color(\n    columns = vars(success_rate),\n    colors = scales::col_numeric(\n      palette = c(\"white\", \"#3fc1c9\"),\n      domain = NULL\n    )\n  ) %>% \n  cols_label(\n    success_rate = \"SUCCESS RATE (%)\"\n  ) %>% \n  tab_source_note(\n    source_note = md(\"SOURCE: NFLFASTR<br>TABLE: @THOMAS_MOCK\")\n  ) %>% \n  gt_theme_538(table.width = px(550))\n\n\n\n\nrosters <- read_csv(\"https://raw.githubusercontent.com/guga31bb/nflfastR-data/master/roster-data/roster.csv\") %>%\n  filter(teamPlayers.position %in% c(\"QB\", \"WR\", \"RB\", \"FB\", \"TE\"), team.season %in% c(2018, 2019)) %>% \n  select(\n    position = teamPlayers.position, receiver_jersey_number = teamPlayers.jerseyNumber, \n    posteam = team.abbr, season = team.season\n    )\n\nseasons <- 2018:2019\n\npbp <- purrr::map_df(seasons, function(x) {\n  readr::read_csv(\n    glue::glue(\"https://raw.githubusercontent.com/guga31bb/nflfastR-data/master/data/play_by_play_{x}.csv.gz\")\n  )\n})\n\ndata_clean <- pbp %>%\n  filter(pass == 1 & sack == 0 & qb_scramble == 0, !is.na(receiver_jersey_number)) %>%\n  filter(week <= 17) %>% \n  select(\n    season, name, pass, desc, posteam, epa, defteam, complete_pass, incomplete_pass,\n    air_yards, receiver_player_name, receiver_jersey_number, down, success, complete_pass\n  ) %>%\n  left_join(rosters, by = c(\"receiver_jersey_number\", \"posteam\", \"season\")) %>% \n  filter(!is.na(position)) %>% \n  mutate(position = if_else(position == \"FB\", \"RB\", position))\n\npos <- data_clean %>%\n  filter(position == \"RB\")\n\nseason_stats <- pos %>% \n  filter(!is.na(success)) %>% \n  select(posteam, success, season) %>% \n  group_by(season) %>% \n  add_count(posteam) %>% \n  count(posteam, success) %>% \n  mutate(success = if_else(success == 0, \"Attempts\", \"Successful\")) %>% \n  pivot_wider(names_from = success, values_from = n) %>% \n  mutate(\n    Attempts = Successful + Attempts,\n    success_rate = Successful/Attempts,\n    success_rate = round(success_rate, digits = 3) * 100\n    ) %>% \n  arrange(desc(success_rate)) %>% \n  ungroup()\n\n\n\n\nLast example - remember that our ESPN or FiveThirtyEight themes can be applied to novel data structures, while the PFF theme made additional changes for gt that were specific to at least the same columns we expect.\n\nmtcars %>% \n  slice(1:10) %>% \n  gt() %>% \n  gt_theme_538() %>% \n  tab_header(title = md(\"**FiveThirtyEight Style**\"))\n\n\n\n\n\n\n\nmtcars %>% \n  slice(1:10) %>% \n  gt() %>% \n  gt_theme_espn() %>% \n  tab_header(title = md(\"**ESPN Style**\"))\n\n\n\n\n\n\n\n\n\n\n\n\nExpand for Session Info\n\n\n\n\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.0 (2022-04-22)\n os       macOS Monterey 12.2.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       America/Chicago\n date     2022-04-28\n pandoc   2.18 @ /Applications/RStudio.app/Contents/MacOS/quarto/bin/tools/ (via rmarkdown)\n quarto   0.9.294 @ /usr/local/bin/quarto\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version    date (UTC) lib source\n dplyr       * 1.0.8      2022-02-08 [1] CRAN (R 4.2.0)\n espnscrapeR * 0.6.5      2022-04-26 [1] Github (jthomasmock/espnscrapeR@084ce80)\n forcats     * 0.5.1      2021-01-27 [1] CRAN (R 4.2.0)\n ggplot2     * 3.3.5      2021-06-25 [1] CRAN (R 4.2.0)\n gt          * 0.5.0.9000 2022-04-27 [1] Github (rstudio/gt@0d4c83d)\n purrr       * 0.3.4      2020-04-17 [1] CRAN (R 4.2.0)\n readr       * 2.1.2      2022-01-30 [1] CRAN (R 4.2.0)\n sessioninfo * 1.2.2      2021-12-06 [1] CRAN (R 4.2.0)\n stringr     * 1.4.0      2019-02-10 [1] CRAN (R 4.2.0)\n tibble      * 3.1.6      2021-11-07 [1] CRAN (R 4.2.0)\n tidyr       * 1.2.0      2022-02-01 [1] CRAN (R 4.2.0)\n tidyverse   * 1.3.1      2021-04-15 [1] CRAN (R 4.2.0)\n\n [1] /Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/library\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "posts/2021-02-13-joins-vs-casewhen-speed-and-memory-tradeoffs/index.html",
    "href": "posts/2021-02-13-joins-vs-casewhen-speed-and-memory-tradeoffs/index.html",
    "title": "Joins vs case whens - speed and memory tradeoffs",
    "section": "",
    "text": "Speed and Memory\nI’m going to preface this by also saying that this is a particular straight forward problem to translate into a join, and it has 32 total comparisons. Most uses of case_when() or fcase() will be more traditional and/or complex logic problems and be much fewer than 30!!!\nNow with that being said, you may still say, well I’m not convinced that join() method is any easier or faster to code out for humans, and we’re all free to make our own decisions! I do want to note that case_when() gets memory-inefficient much faster than ???_join().\nWe can really highlight the differences in the execution time and the memory allocated via the bench package. I’m using bench to execute the two different methods 3x time, compare the timing and the memory used, along with some other stats.\nIn the expandable section below we have a repeat of our above left_join() and case_when() calls.\n\njoin_expr <- function(){\n  left_join(ex_df, team_join, by = \"team\") %>% \n    slice(1)\n}\n\ncase_when_expr <- function(){\n  ex_df %>% \n    mutate(\n      team_name = case_when(\n        team == \"ARI\" ~ \"Cardinals\",\n        team == \"ATL\" ~ \"Falcons\",\n        team == \"BAL\" ~ \"Ravens\",\n        team == \"BUF\" ~ \"Bills\",\n        team == \"CAR\" ~ \"Panthers\",\n        team == \"CHI\" ~ \"Bears\",\n        team == \"CIN\" ~ \"Bengals\",\n        team == \"CLE\" ~ \"Browns\",\n        team == \"DAL\" ~ \"Cowboys\",\n        team == \"DEN\" ~ \"Broncos\",\n        team == \"DET\" ~ \"Lions\",\n        team == \"GB\" ~ \"Packers\",\n        team == \"HOU\" ~ \"Texans\",\n        team == \"IND\" ~ \"Colts\",\n        team == \"JAX\" ~ \"Jaguars\",\n        team == \"KC\" ~ \"Chiefs\",\n        team == \"LV\" ~ \"Raiders\",\n        team == \"LAC\" ~ \"Chargers\",\n        team == \"LAR\" ~ \"Rams\",\n        team == \"MIA\" ~ \"Dolphins\",\n        team == \"MIN\" ~ \"Vikings\",\n        team == \"NE\" ~ \"Patriots\",\n        team == \"NO\" ~ \"Saints\",\n        team == \"NYG\" ~ \"Giants\",\n        team == \"NYJ\" ~ \"Jets\",\n        team == \"PHI\" ~ \"Eagles\",\n        team == \"PIT\" ~ \"Steelers\",\n        team == \"SF\" ~ \"49ers\",\n        team == \"SEA\" ~ \"Seahawks\",\n        team == \"TB\" ~ \"Buccaneers\",\n        team == \"TEN\" ~ \"Titans\",\n        team == \"WSH\" ~ NA_character_,\n        TRUE ~ NA_character_\n      )\n    ) %>% slice(1)\n} \n\nWe can then compare their execution multiple times with the bench package. This will vary by the execution, but with 3 iterations and 100,000 rows, I have seen about a 10x speed improvement in left_join vs case_when. Note that in most cases this is still pretty much instantaneous in “human time”.\n\nVisual reaction time in young adults is in the range of about 250 ms per Jain et al.\n\nHowever, do note that we use about 28-30 times more memory for the case_when() statement.\n\nbench::mark(\n  min_time = 0.1,\n  max_iterations = 3,\n  min_iterations = 3,\n  case_when_expr(),\n  join_expr()\n) %>% \n  select(expression, min, median, mem_alloc, n_itr)\n\n# A tibble: 2 × 4\n  expression            min   median mem_alloc\n  <bch:expr>       <bch:tm> <bch:tm> <bch:byt>\n1 case_when_expr()  66.02ms  99.43ms  150.82MB\n2 join_expr()        5.07ms   5.15ms    5.37MB\n\n\nThe 150 Mb of memory used, may not seem like a lot with smaller datasets (100,000), but if we were to bump this up to 1,000,000 rows we see a similar 10x increase of memory. Specifically we are now up to ~1.5 Gb of memory used for case_when(). So if you’re going beyond the millions or 10s of millions of rows AND are trying to do a LOT of comparisons, probably a good idea to start refactoring into a join if possible!\n\n# 1,000,000 rows as 1e6\nsample_size <- 1e6\n\nset.seed(829)\n\nex_df <- tibble(\n  team = sample(all_teams$team_abb, size = sample_size, replace = TRUE),\n  stat = rnorm(sample_size, mean = 0.1, sd = 0.1)\n)\n\nbench::mark(\n  min_time = 0.1,\n  max_iterations = 3,\n  min_iterations = 3,\n  case_when_expr(),\n  join_expr()\n) %>% \n  select(expression, min, median, mem_alloc, n_itr)\n\n# A tibble: 2 × 4\n  expression            min   median mem_alloc\n  <bch:expr>       <bch:tm> <bch:tm> <bch:byt>\n1 case_when_expr()  595.8ms  636.3ms    1.47GB\n2 join_expr()        42.7ms   45.9ms   53.43MB\n\n\nThere are situations where a join doesn’t solve the problem, so we can go one step further and add in our data.table::fcase() or dtplyr-translation of dplyr into data.table. All the example reprex code is in an expandable chunk below.\n\nlibrary(dtplyr)\n\ncase_when_dplyr <- function(){\n  ex_df %>% \n    mutate(\n      team_name = case_when(\n        team == \"ARI\" ~ \"Cardinals\",\n        team == \"ATL\" ~ \"Falcons\",\n        team == \"BAL\" ~ \"Ravens\",\n        team == \"BUF\" ~ \"Bills\",\n        team == \"CAR\" ~ \"Panthers\",\n        team == \"CHI\" ~ \"Bears\",\n        team == \"CIN\" ~ \"Bengals\",\n        team == \"CLE\" ~ \"Browns\",\n        team == \"DAL\" ~ \"Cowboys\",\n        team == \"DEN\" ~ \"Broncos\",\n        team == \"DET\" ~ \"Lions\",\n        team == \"GB\" ~ \"Packers\",\n        team == \"HOU\" ~ \"Texans\",\n        team == \"IND\" ~ \"Colts\",\n        team == \"JAX\" ~ \"Jaguars\",\n        team == \"KC\" ~ \"Chiefs\",\n        team == \"LV\" ~ \"Raiders\",\n        team == \"LAC\" ~ \"Chargers\",\n        team == \"LAR\" ~ \"Rams\",\n        team == \"MIA\" ~ \"Dolphins\",\n        team == \"MIN\" ~ \"Vikings\",\n        team == \"NE\" ~ \"Patriots\",\n        team == \"NO\" ~ \"Saints\",\n        team == \"NYG\" ~ \"Giants\",\n        team == \"NYJ\" ~ \"Jets\",\n        team == \"PHI\" ~ \"Eagles\",\n        team == \"PIT\" ~ \"Steelers\",\n        team == \"SF\" ~ \"49ers\",\n        team == \"SEA\" ~ \"Seahawks\",\n        team == \"TB\" ~ \"Buccaneers\",\n        team == \"TEN\" ~ \"Titans\",\n        team == \"WSH\" ~ NA_character_,\n        TRUE ~ NA_character_\n      )\n    )\n} \n\n\njoin_dplyr <- function(){\n  left_join(ex_df, team_join, by = \"team\")\n}\n\njoin_dtplyr <- function(){\n  dt_ex_df <- lazy_dt(ex_df)\n  team_join <- lazy_dt(team_join)\n    \n  dt_ex_df %>% \n    left_join(team_join, by = \"team\") %>% \n    select(team, stat, team_name) %>% \n    as_tibble() \n}\n\ncase_when_dtplyr <- function(){\n  lazy_dt(ex_df) %>% \n    mutate(\n      team_name = case_when(\n        team == \"ARI\" ~ \"Cardinals\",\n        team == \"ATL\" ~ \"Falcons\",\n        team == \"BAL\" ~ \"Ravens\",\n        team == \"BUF\" ~ \"Bills\",\n        team == \"CAR\" ~ \"Panthers\",\n        team == \"CHI\" ~ \"Bears\",\n        team == \"CIN\" ~ \"Bengals\",\n        team == \"CLE\" ~ \"Browns\",\n        team == \"DAL\" ~ \"Cowboys\",\n        team == \"DEN\" ~ \"Broncos\",\n        team == \"DET\" ~ \"Lions\",\n        team == \"GB\" ~ \"Packers\",\n        team == \"HOU\" ~ \"Texans\",\n        team == \"IND\" ~ \"Colts\",\n        team == \"JAX\" ~ \"Jaguars\",\n        team == \"KC\" ~ \"Chiefs\",\n        team == \"LV\" ~ \"Raiders\",\n        team == \"LAC\" ~ \"Chargers\",\n        team == \"LAR\" ~ \"Rams\",\n        team == \"MIA\" ~ \"Dolphins\",\n        team == \"MIN\" ~ \"Vikings\",\n        team == \"NE\" ~ \"Patriots\",\n        team == \"NO\" ~ \"Saints\",\n        team == \"NYG\" ~ \"Giants\",\n        team == \"NYJ\" ~ \"Jets\",\n        team == \"PHI\" ~ \"Eagles\",\n        team == \"PIT\" ~ \"Steelers\",\n        team == \"SF\" ~ \"49ers\",\n        team == \"SEA\" ~ \"Seahawks\",\n        team == \"TB\" ~ \"Buccaneers\",\n        team == \"TEN\" ~ \"Titans\",\n        team == \"WSH\" ~ NA_character_,\n        TRUE ~ NA_character_\n      )\n    ) %>% \n    as_tibble()\n  \n}\n\nfcase_dplyr <- function(){\n  ex_df %>% \n    mutate(\n      team_name = fcase(\n        team == \"ARI\", \"Cardinals\",\n        team == \"ATL\", \"Falcons\",\n        team == \"BAL\", \"Ravens\",\n        team == \"BUF\", \"Bills\",\n        team == \"CAR\", \"Panthers\",\n        team == \"CHI\", \"Bears\",\n        team == \"CIN\", \"Bengals\",\n        team == \"CLE\", \"Browns\",\n        team == \"DAL\", \"Cowboys\",\n        team == \"DEN\", \"Broncos\",\n        team == \"DET\", \"Lions\",\n        team == \"GB\" ,\"Packers\",\n        team == \"HOU\", \"Texans\",\n        team == \"IND\", \"Colts\",\n        team == \"JAX\", \"Jaguars\",\n        team == \"KC\" ,\"Chiefs\",\n        team == \"LV\" ,\"Raiders\",\n        team == \"LAC\", \"Chargers\",\n        team == \"LAR\", \"Rams\",\n        team == \"MIA\", \"Dolphins\",\n        team == \"MIN\", \"Vikings\",\n        team == \"NE\" ,\"Patriots\",\n        team == \"NO\" ,\"Saints\",\n        team == \"NYG\", \"Giants\",\n        team == \"NYJ\", \"Jets\",\n        team == \"PHI\", \"Eagles\",\n        team == \"PIT\", \"Steelers\",\n        team == \"SF\" ,\"49ers\",\n        team == \"SEA\", \"Seahawks\",\n        team == \"TB\" ,\"Buccaneers\",\n        team == \"TEN\", \"Titans\",\n        team == \"WSH\", NA_character_\n      )\n    )\n}\n  \n\nfcase_dt_native <- function(){\n  data.table(ex_df)[, team_name := fcase(\n    team == \"ARI\", \"Cardinals\",\n    team == \"ATL\", \"Falcons\",\n    team == \"BAL\", \"Ravens\",\n    team == \"BUF\", \"Bills\",\n    team == \"CAR\", \"Panthers\",\n    team == \"CHI\", \"Bears\",\n    team == \"CIN\", \"Bengals\",\n    team == \"CLE\", \"Browns\",\n    team == \"DAL\", \"Cowboys\",\n    team == \"DEN\", \"Broncos\",\n    team == \"DET\", \"Lions\",\n    team == \"GB\" ,\"Packers\",\n    team == \"HOU\", \"Texans\",\n    team == \"IND\", \"Colts\",\n    team == \"JAX\", \"Jaguars\",\n    team == \"KC\" ,\"Chiefs\",\n    team == \"LV\" ,\"Raiders\",\n    team == \"LAC\", \"Chargers\",\n    team == \"LAR\", \"Rams\",\n    team == \"MIA\", \"Dolphins\",\n    team == \"MIN\", \"Vikings\",\n    team == \"NE\" ,\"Patriots\",\n    team == \"NO\" ,\"Saints\",\n    team == \"NYG\", \"Giants\",\n    team == \"NYJ\", \"Jets\",\n    team == \"PHI\", \"Eagles\",\n    team == \"PIT\", \"Steelers\",\n    team == \"SF\" ,\"49ers\",\n    team == \"SEA\", \"Seahawks\",\n    team == \"TB\" ,\"Buccaneers\",\n    team == \"TEN\", \"Titans\",\n    team == \"WSH\", NA_character_\n  )] %>% \n    as_tibble()\n}\n\njoin_dt_native <- function(){\n  data.table(ex_df)[data.table(team_join), on = .(team), team_name := team_name] %>% \n    as_tibble()\n}\n\nFinally we can check the timing/memory usage for all of the combos. In short, join()-methods are fastest and use the least memory, fcase() whether in native data.table or dplyr is a bit slower/more memory than join but still ~5x faster/more memory efficient than case_when(), and case_when() is the slowest/most memory hungry (but translates into SQL if needed).\nOverall, I’m really happy that we have the ability to mix and match functions from various awesome packages depending on the problems we’re trying to solve!\n\nbench::mark(\n  min_time = 0.1,\n  max_iterations = 3,\n  min_iterations = 3,\n  case_when_dplyr(),\n  case_when_dtplyr(),\n  fcase_dplyr(),\n  fcase_dt_native(),\n  join_dplyr(),\n  join_dt_native(),\n  check = FALSE\n) %>% \n  select(expression, min, median, mem_alloc, n_itr)\n\n# A tibble: 6 × 4\n  expression              min   median mem_alloc\n  <bch:expr>         <bch:tm> <bch:tm> <bch:byt>\n1 case_when_dplyr()   583.4ms  624.6ms    1.47GB\n2 case_when_dtplyr()  121.9ms  127.7ms  165.18MB\n3 fcase_dplyr()       120.3ms  120.5ms  133.72MB\n4 fcase_dt_native()   121.9ms  129.1ms  164.39MB\n5 join_dplyr()         41.1ms   42.7ms   53.43MB\n6 join_dt_native()     31.9ms   35.6ms   61.63MB\n\n\n\n\n\n\n\n\nExpand for Session Info\n\n\n\n\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.0 (2022-04-22)\n os       macOS Monterey 12.2.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       America/Chicago\n date     2022-04-28\n pandoc   2.18 @ /Applications/RStudio.app/Contents/MacOS/quarto/bin/tools/ (via rmarkdown)\n quarto   0.9.294 @ /usr/local/bin/quarto\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version date (UTC) lib source\n bench       * 1.1.2   2021-11-30 [1] CRAN (R 4.2.0)\n data.table  * 1.14.2  2021-09-27 [1] CRAN (R 4.2.0)\n datapasta   * 3.1.1   2022-04-26 [1] Github (MilesMcBain/datapasta@69d2a69)\n dplyr       * 1.0.8   2022-02-08 [1] CRAN (R 4.2.0)\n dtplyr      * 1.2.1   2022-01-19 [1] CRAN (R 4.2.0)\n espnscrapeR * 0.6.5   2022-04-26 [1] Github (jthomasmock/espnscrapeR@084ce80)\n forcats     * 0.5.1   2021-01-27 [1] CRAN (R 4.2.0)\n ggplot2     * 3.3.5   2021-06-25 [1] CRAN (R 4.2.0)\n purrr       * 0.3.4   2020-04-17 [1] CRAN (R 4.2.0)\n readr       * 2.1.2   2022-01-30 [1] CRAN (R 4.2.0)\n sessioninfo * 1.2.2   2021-12-06 [1] CRAN (R 4.2.0)\n stringr     * 1.4.0   2019-02-10 [1] CRAN (R 4.2.0)\n tibble      * 3.1.6   2021-11-07 [1] CRAN (R 4.2.0)\n tictoc      * 1.0.1   2021-04-19 [1] CRAN (R 4.2.0)\n tidyr       * 1.2.0   2022-02-01 [1] CRAN (R 4.2.0)\n tidyverse   * 1.3.1   2021-04-15 [1] CRAN (R 4.2.0)\n\n [1] /Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/library\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "posts/2020-09-04-10-table-rules-in-r/index.html",
    "href": "posts/2020-09-04-10-table-rules-in-r/index.html",
    "title": "10+ Guidelines for Better Tables in R",
    "section": "",
    "text": "I recently published \"Ten Guidelines for Better Tables\" in the Journal of Benefit Cost Analysis (@benefitcost) on ways to improve your data tables. Here's a thread summarizing the 10 guidelines. Full paper is here: https://t.co/VSGYnfg7iP pic.twitter.com/W6qbsktioL\n\n— Jon Schwabish (@jschwabish) August 3, 2020\n\nAfter seeing Jon’s Twitter thread, I asked him if I could adapt the examples over to R. He graciously agreed, so I’ve gone ahead and adapted some examples from his 10 Guidelines article 1 below in the R package gt. Jon also has a Better Data Visualizations book coming out in Jan 2021 - check it out at Columbia University Press.1 https://www.cambridge.org/core/journals/journal-of-benefit-cost-analysis/article/ten-guidelines-for-better-tables/74C6FD9FEB12038A52A95B9FBCA05A12\nPlease note that the 10 Guidelines section headers are quoted verbatim from Jon’s article (after asking permission), while the tables themselves and text descriptions are original content inspired from his work.\n10 Rules for Tables\n- Twitter Thread - In this thread, Jon covers the highpoints of each of the 10 guidelines\n- 10 Guidelines in the Journal of Benefit Cost Analysis - In this article, Jon dives even deeper into the WHY and longer explanations of the guidelines, along with some best practice examples"
  },
  {
    "objectID": "posts/2020-09-04-10-table-rules-in-r/index.html#basic-gt-table",
    "href": "posts/2020-09-04-10-table-rules-in-r/index.html#basic-gt-table",
    "title": "10+ Guidelines for Better Tables in R",
    "section": "Basic gt Table",
    "text": "Basic gt Table\nYou can create a table by passing in data to gt(), and the idea is that you progressively add layers/changes to the gt table via the pipe.\n\n# This works!\n# gt(yield_data_wide)\n\n# pipe also works!\nyield_data_wide %>% \n  gt()\n\n\n\n\n\n\nCountry\n      crop\n      2014\n      2015\n      2016\n    \n\n\nChina\nmaize\n5.8091\n5.8929\n5.9667\n\n\nChina\npotatoes\n17.1416\n17.2684\n17.6866\n\n\nIndia\nmaize\n2.6107\n2.5972\n2.6162\n\n\nIndia\npotatoes\n22.9224\n23.1257\n20.5087\n\n\nIndonesia\nmaize\n4.9540\n5.1784\n5.3052\n\n\nIndonesia\npotatoes\n17.6668\n18.2027\n18.2549\n\n\nMexico\nmaize\n3.2964\n3.4782\n3.7180\n\n\nMexico\npotatoes\n27.3384\n27.1435\n27.9260\n\n\nPakistan\nmaize\n4.3211\n4.4248\n4.5491\n\n\nPakistan\npotatoes\n18.1506\n23.4439\n22.4346\n\n\nUnited States\nmaize\n10.7326\n10.5723\n11.7433\n\n\nUnited States\npotatoes\n47.1507\n46.9000\n48.6408\n\n\n\n\n\n\nAdd Groups\nYou can “split” a table intro groups by passes a grouped tibble…\n\nyield_data_wide %>% \n  head() %>% \n  group_by(Country) %>% # respects grouping from dplyr\n  gt(rowname_col = \"crop\") \n\n\n\n\n\n\n\n      2014\n      2015\n      2016\n    \n\n\nChina\n    \n\nmaize\n5.8091\n5.8929\n5.9667\n\n\npotatoes\n17.1416\n17.2684\n17.6866\n\n\nIndia\n    \n\nmaize\n2.6107\n2.5972\n2.6162\n\n\npotatoes\n22.9224\n23.1257\n20.5087\n\n\nIndonesia\n    \n\nmaize\n4.9540\n5.1784\n5.3052\n\n\npotatoes\n17.6668\n18.2027\n18.2549\n\n\n\n\n\n\nOr by adding it as an explicit argument within gt.\n\nyield_data_wide %>% \n  head() %>%\n  gt(\n    groupname_col = \"crop\",\n    rowname_col = \"Country\"\n  ) \n\n\n\n\n\n\n\n      2014\n      2015\n      2016\n    \n\n\nmaize\n    \n\nChina\n5.8091\n5.8929\n5.9667\n\n\nIndia\n2.6107\n2.5972\n2.6162\n\n\nIndonesia\n4.9540\n5.1784\n5.3052\n\n\npotatoes\n    \n\nChina\n17.1416\n17.2684\n17.6866\n\n\nIndia\n22.9224\n23.1257\n20.5087\n\n\nIndonesia\n17.6668\n18.2027\n18.2549\n\n\n\n\n\n\nGroups are also useful for groupwise summary rows! Notice I’m also using fmt_number() to decrease the decimal point precision of the numbers. It will default to 2 decimal places, although you can specify whatever number of decimals you want. You may also notice that I referenced the columns by position in fmt_number(), but used tidy-eval w/ vars() in summary_rows(). You can always fall back to either method!\n\nyield_data_wide %>% \n  mutate(crop = str_to_title(crop)) %>% \n  group_by(crop) %>% \n  gt(\n    rowname_col = \"Country\"\n  ) %>% \n  fmt_number(\n    columns = 2:5, # reference cols by position\n    decimals = 2 # decrease decimal places\n    ) %>% \n  summary_rows(\n    groups = TRUE,\n    columns = vars(`2014`, `2015`, `2016`), # reference cols by name\n    fns = list(\n      avg = ~mean(.), # add as many summary stats as you want!\n      sd = ~sd(.)\n    )\n  )\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\n\n      2014\n      2015\n      2016\n    \n\n\nMaize\n    \n\nChina\n5.81\n5.89\n5.97\n\n\nIndia\n2.61\n2.60\n2.62\n\n\nIndonesia\n4.95\n5.18\n5.31\n\n\nMexico\n3.30\n3.48\n3.72\n\n\nPakistan\n4.32\n4.42\n4.55\n\n\nUnited States\n10.73\n10.57\n11.74\n\n\navg\n5.29\n5.36\n5.65\n\n\nsd\n2.90\n2.81\n3.21\n\n\nPotatoes\n    \n\nChina\n17.14\n17.27\n17.69\n\n\nIndia\n22.92\n23.13\n20.51\n\n\nIndonesia\n17.67\n18.20\n18.25\n\n\nMexico\n27.34\n27.14\n27.93\n\n\nPakistan\n18.15\n23.44\n22.43\n\n\nUnited States\n47.15\n46.90\n48.64\n\n\navg\n25.06\n26.01\n25.91\n\n\nsd\n11.51\n10.86\n11.73\n\n\n\n\n\n\nAdd spanners\nTable spanners can be added quickly with tab_spanner() and again use either position (column number) or + vars(name).\n\nyield_data_wide %>% \n  head() %>%\n  gt(\n    groupname_col = \"crop\",\n    rowname_col = \"Country\"\n  ) %>% \n  tab_spanner(\n    label = \"Yield in Tonnes/Hectare\", \n    columns = 2:5\n    )\n\n\n\n\n\n\n\n\n      \n        Yield in Tonnes/Hectare\n      \n    \n\n2014\n      2015\n      2016\n    \n\n\n\nmaize\n    \n\nChina\n5.8091\n5.8929\n5.9667\n\n\nIndia\n2.6107\n2.5972\n2.6162\n\n\nIndonesia\n4.9540\n5.1784\n5.3052\n\n\npotatoes\n    \n\nChina\n17.1416\n17.2684\n17.6866\n\n\nIndia\n22.9224\n23.1257\n20.5087\n\n\nIndonesia\n17.6668\n18.2027\n18.2549\n\n\n\n\n\n\nAdd notes and titles\nFootnotes can be added with tab_footnote(). Note that this is our first use of the locations argument. Locations is used with things like cells_column_labels() or cells_body(), cells_summary() to offer very tight control of where to place certain changes. While you can still reference columns by position, note that I use 1:3 here instead of 2:5 since I’m referencing just the column labels. You can again use vars(name) instead of position.\n\nyield_data_wide %>% \n  head() %>%\n  gt(\n    groupname_col = \"crop\",\n    rowname_col = \"Country\"\n  ) %>% \n  tab_footnote(\n    footnote = \"Yield in Tonnes/Hectare\", \n    locations = cells_column_labels(\n      columns = 1:3 # note\n      )\n    )\n\n\n\n\n\n\n\n      20141\n\n      2015\n      2016\n    \n\n\nmaize\n    \n\nChina\n5.8091\n5.8929\n5.9667\n\n\nIndia\n2.6107\n2.5972\n2.6162\n\n\nIndonesia\n4.9540\n5.1784\n5.3052\n\n\npotatoes\n    \n\nChina\n17.1416\n17.2684\n17.6866\n\n\nIndia\n22.9224\n23.1257\n20.5087\n\n\nIndonesia\n17.6668\n18.2027\n18.2549\n\n\n\n\n1 Yield in Tonnes/Hectare\n    \n\n\n\n\nAdding a source_note()\n\nyield_data_wide %>% \n  head() %>%\n  gt(\n    groupname_col = \"crop\",\n    rowname_col = \"Country\"\n  ) %>% \n  tab_footnote(\n    footnote = \"Yield in Tonnes/Hectare\", \n    locations = cells_column_labels(\n      columns = 1:3 # note\n      )\n    ) %>% \n  tab_source_note(source_note = \"Data: OurWorldInData\")\n\n\n\n\n\n\n\n      20141\n\n      2015\n      2016\n    \n\n\nmaize\n    \n\nChina\n5.8091\n5.8929\n5.9667\n\n\nIndia\n2.6107\n2.5972\n2.6162\n\n\nIndonesia\n4.9540\n5.1784\n5.3052\n\n\npotatoes\n    \n\nChina\n17.1416\n17.2684\n17.6866\n\n\nIndia\n22.9224\n23.1257\n20.5087\n\n\nIndonesia\n17.6668\n18.2027\n18.2549\n\n\n\nData: OurWorldInData\n    \n\n\n1 Yield in Tonnes/Hectare\n    \n\n\n\n\nAdding a title or subtitle with tab_header() and notice that I used md() around the title and html() around subtitle to adjust their appearance. You can use these to parse those types of arbitrary code within a specific portion of the table.\n\nyield_data_wide %>% \n  head() %>%\n  gt(\n    groupname_col = \"crop\",\n    rowname_col = \"Country\"\n  ) %>%\n  tab_header(\n    title = md(\"**Crop Yields between 2014 and 2016**\"),\n    subtitle = html(\"<em>Countries limited to Asia</em>\")\n  )\n\n\n\n\n\n\n\nCrop Yields between 2014 and 2016\n    \n\nCountries limited to Asia\n    \n\n\n\n      2014\n      2015\n      2016\n    \n\n\nmaize\n    \n\nChina\n5.8091\n5.8929\n5.9667\n\n\nIndia\n2.6107\n2.5972\n2.6162\n\n\nIndonesia\n4.9540\n5.1784\n5.3052\n\n\npotatoes\n    \n\nChina\n17.1416\n17.2684\n17.6866\n\n\nIndia\n22.9224\n23.1257\n20.5087\n\n\nIndonesia\n17.6668\n18.2027\n18.2549\n\n\n\n\n\n\nAdjust appearance\nYou can customize large chunks of the table appearance all at once via tab_options(). The full reference to ALL the options you can customize are in the gt packagedown site.\n\nyield_data_wide %>% \n  head() %>%\n  gt(\n    groupname_col = \"crop\",\n    rowname_col = \"Country\"\n  ) %>%\n  tab_header(\n    title = \"Crop Yields between 2014 and 2016\",\n    subtitle = \"Countries limited to Asia\"\n  ) %>% \n  tab_options(\n    heading.subtitle.font.size = 12,\n    heading.align = \"left\",\n    table.border.top.color = \"black\",\n    column_labels.border.bottom.color = \"black\",\n    column_labels.border.bottom.width= px(3),\n  )\n\n\n\n\n\n\n\nCrop Yields between 2014 and 2016\n    \n\nCountries limited to Asia\n    \n\n\n\n      2014\n      2015\n      2016\n    \n\n\nmaize\n    \n\nChina\n5.8091\n5.8929\n5.9667\n\n\nIndia\n2.6107\n2.5972\n2.6162\n\n\nIndonesia\n4.9540\n5.1784\n5.3052\n\n\npotatoes\n    \n\nChina\n17.1416\n17.2684\n17.6866\n\n\nIndia\n22.9224\n23.1257\n20.5087\n\n\nIndonesia\n17.6668\n18.2027\n18.2549\n\n\n\n\n\n\nBecause gt is built up by a series of piped examples, you can also pass along additional changes/customization as a function almost like a ggplot2 theme! You’ll notice that it’s VERY easy and quick to build up the bulk of a gt table, but you can also spend 2-3x the amount of code to add all sorts of little tweaks and customizations. Saving some of these tweaks as a “theme” can save you lots of repeated code calls!\n\nmy_theme <- function(data) {\n  tab_options(\n    data = data,\n    heading.subtitle.font.size = 12,\n    heading.align = \"left\",\n    table.border.top.color = \"black\",\n    column_labels.border.bottom.color = \"black\",\n    column_labels.border.bottom.width= px(3),\n  )\n}\n\nyield_data_wide %>% \n  head() %>%\n  gt(\n    groupname_col = \"crop\",\n    rowname_col = \"Country\"\n  ) %>%\n  tab_header(\n    title = \"Crop Yields between 2014 and 2016\",\n    subtitle = \"Countries limited to Asia\"\n  ) %>% \n  my_theme()\n\n\n\n\n\n\n\nCrop Yields between 2014 and 2016\n    \n\nCountries limited to Asia\n    \n\n\n\n      2014\n      2015\n      2016\n    \n\n\nmaize\n    \n\nChina\n5.8091\n5.8929\n5.9667\n\n\nIndia\n2.6107\n2.5972\n2.6162\n\n\nIndonesia\n4.9540\n5.1784\n5.3052\n\n\npotatoes\n    \n\nChina\n17.1416\n17.2684\n17.6866\n\n\nIndia\n22.9224\n23.1257\n20.5087\n\n\nIndonesia\n17.6668\n18.2027\n18.2549\n\n\n\n\n\n\nIf you want to style values or a specific cell, you’ll want to use tab_style(), note that you can reference specific types of changes in the style, and by wrapping it in a list as seen below you can make multiple changes at a time. You are limited to one set of locations however.\nLocations can take column/row by position (eg columns = 1, rows = c(5:6)) or with columns by name via vars(col_name). Lastly, you can use logical expressions in rows = to match certain criteria to assign a style. Here I’m assigning red italics to China’s crop outputs only with the following code: rows = Country == \"China\".\n\nyield_data_wide %>% \n  head() %>%\n  gt() %>% \n  tab_style(\n    style = list(\n      cell_text(weight = \"bold\")\n    ),\n    locations = cells_column_labels(everything())\n  ) %>% \n  tab_style(\n    style = list(\n      cell_fill(color = \"black\", alpha = 0.2),\n      cell_borders(\n        side = c(\"left\", \"right\"), \n        color = \"black\",\n        weight = px(2)\n        )\n      ),\n    locations = cells_body(\n      columns = vars(crop)\n      )\n  ) %>% \n  tab_style(\n    style = list(\n      cell_text(color = \"red\", style = \"italic\")\n    ),\n    locations = cells_body(\n      columns = 3:5,\n      rows = Country == \"China\"\n    )\n  ) \n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\nCountry\n      crop\n      2014\n      2015\n      2016\n    \n\n\nChina\nmaize\n5.8091\n5.8929\n5.9667\n\n\nChina\npotatoes\n17.1416\n17.2684\n17.6866\n\n\nIndia\nmaize\n2.6107\n2.5972\n2.6162\n\n\nIndia\npotatoes\n22.9224\n23.1257\n20.5087\n\n\nIndonesia\nmaize\n4.9540\n5.1784\n5.3052\n\n\nIndonesia\npotatoes\n17.6668\n18.2027\n18.2549\n\n\n\n\n\n\nIf you want to do more of a dataviz style color gradient rather than assigning colors one at a time, you can use data_color() along with something like scales::col_numeric(). Note that I’m using paletteer to provide the palette, but you can also provide your own palette. Also - domain could be specified for a specific range, otherwise it will fit the colors to whatever range is present in the data.\n\nyield_data_wide %>% \n  head() %>%\n  gt(\n    groupname_col = \"crop\",\n    rowname_col = \"Country\"\n  ) %>% \n  data_color(\n    columns = vars(`2014`, `2015`, `2016`),\n    colors = scales::col_numeric(\n      paletteer::paletteer_d(\n        palette = \"ggsci::red_material\") %>% as.character(),\n        domain = NULL\n        )\n      )\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\n\n      2014\n      2015\n      2016\n    \n\n\nmaize\n    \n\nChina\n5.8091\n5.8929\n5.9667\n\n\nIndia\n2.6107\n2.5972\n2.6162\n\n\nIndonesia\n4.9540\n5.1784\n5.3052\n\n\npotatoes\n    \n\nChina\n17.1416\n17.2684\n17.6866\n\n\nIndia\n22.9224\n23.1257\n20.5087\n\n\nIndonesia\n17.6668\n18.2027\n18.2549\n\n\n\n\n\n\nHere we create our own palette with just a vector of color names (could also be a vector of hex colors). You can see now that the red is dark enough that gt automatically changes the colors of the text to better contrast. You can turn this feature off with autocolor_text = FALSE\n\nyield_data_wide %>% \n  head() %>%\n  gt(\n    groupname_col = \"crop\",\n    rowname_col = \"Country\"\n  ) %>% \n  data_color(\n    columns = vars(`2014`, `2015`, `2016`),\n    colors = scales::col_numeric(\n      c(\"white\", \"pink\", \"red\"),\n        domain = NULL\n        )\n      )\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\n\n      2014\n      2015\n      2016\n    \n\n\nmaize\n    \n\nChina\n5.8091\n5.8929\n5.9667\n\n\nIndia\n2.6107\n2.5972\n2.6162\n\n\nIndonesia\n4.9540\n5.1784\n5.3052\n\n\npotatoes\n    \n\nChina\n17.1416\n17.2684\n17.6866\n\n\nIndia\n22.9224\n23.1257\n20.5087\n\n\nIndonesia\n17.6668\n18.2027\n18.2549\n\n\n\n\n\n\nThat’s it for the basics of gt! Now, let’s dive into Jon Schwabish’s “10 Guidelines for Better Tables” where we can apply some of these techniques to some table examples."
  },
  {
    "objectID": "posts/2020-09-04-10-table-rules-in-r/index.html#rule-1-offset-the-heads-from-the-body",
    "href": "posts/2020-09-04-10-table-rules-in-r/index.html#rule-1-offset-the-heads-from-the-body",
    "title": "10+ Guidelines for Better Tables in R",
    "section": "Rule 1: Offset the Heads from the Body",
    "text": "Rule 1: Offset the Heads from the Body\nThe goal here is to clearly separate your column titles from the body of the table. Typically bold face, separator lines indicate categories/labels (column titles) from values (table body).\nFirst we can prep the data to align with the examples.\n\n# data prep\npotato_data <- yield_data %>% \n  filter(Country %in% country_sel, crop == \"potatoes\", year %in% c(2013:2016)) %>% \n  filter(crop == \"potatoes\") %>% \n  pivot_wider(names_from = year, values_from = \"yield\")\n\n1. Poor Example\nRule 1 | Poor example gt code\n\npotato_tb <- potato_data %>% \n  gt() %>% \n  cols_hide(vars(crop)) %>% \n  opt_table_lines(extent = \"none\") %>% \n  fmt_number(\n    columns = 3:6,\n    decimals = 2\n  )\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\npotato_tb\n\n\n\n\n\n\nCountry\n      2013\n      2014\n      2015\n      2016\n    \n\n\nChina\n17.09\n17.14\n17.27\n17.69\n\n\nIndia\n22.76\n22.92\n23.13\n20.51\n\n\nIndonesia\n16.02\n17.67\n18.20\n18.25\n\n\nMexico\n26.78\n27.34\n27.14\n27.93\n\n\nPakistan\n21.81\n18.15\n23.44\n22.43\n\n\nUnited States\n46.36\n47.15\n46.90\n48.64\n\n\n\n\n\n\n1. Improved Example\nRule 1 | Improved gt code \n\nrule1_good <- potato_tb %>% \n  tab_style(\n    style = list(\n      cell_text(weight = \"bold\")\n    ),\n    locations = cells_column_labels(everything())\n  ) %>% \n  opt_table_lines(extent = \"default\") %>%\n  tab_options(\n    column_labels.border.top.color = \"white\",\n    column_labels.border.top.width = px(3),\n    column_labels.border.bottom.color = \"black\",\n    table_body.hlines.color = \"white\",\n    table.border.bottom.color = \"white\",\n    table.border.bottom.width = px(3)\n  ) %>% tab_source_note(md(\"**Table**: @thomas_mock | **Data**: OurWorldInData.org<br>**Inspiration**: @jschwabish\"))\n\n\nrule1_good\n\n\n\n\n\n\nCountry\n      2013\n      2014\n      2015\n      2016\n    \n\n\nChina\n17.09\n17.14\n17.27\n17.69\n\n\nIndia\n22.76\n22.92\n23.13\n20.51\n\n\nIndonesia\n16.02\n17.67\n18.20\n18.25\n\n\nMexico\n26.78\n27.34\n27.14\n27.93\n\n\nPakistan\n21.81\n18.15\n23.44\n22.43\n\n\nUnited States\n46.36\n47.15\n46.90\n48.64\n\n\n\n\nTable: @thomas_mock | Data: OurWorldInData.orgInspiration: @jschwabish"
  },
  {
    "objectID": "posts/2020-09-04-10-table-rules-in-r/index.html#rule-2-use-subtle-dividers-rather-than-heavy-gridlines",
    "href": "posts/2020-09-04-10-table-rules-in-r/index.html#rule-2-use-subtle-dividers-rather-than-heavy-gridlines",
    "title": "10+ Guidelines for Better Tables in R",
    "section": "Rule 2: Use Subtle Dividers Rather Than Heavy Gridlines",
    "text": "Rule 2: Use Subtle Dividers Rather Than Heavy Gridlines\nThe idea here is that you want to clearly indicate dividers when necessary. Especially with many column labels, you want to make sure that changes in the structure are clear.\n\n# data prep\nrule2_data <- yield_data %>% \n  filter(Country %in% country_sel, crop == \"potatoes\", year %in% c(2007:2016)) %>% \n  filter(crop == \"potatoes\") %>% \n  select(-crop) %>% \n  pivot_wider(names_from = year, values_from = \"yield\") %>% \n  rowwise() %>% \n  mutate(\n    avg_07_11 = mean(`2007`:`2011`),\n    .before = `2012`\n    ) %>% \n  mutate(\n    avg_12_16 = mean(`2012`:`2016`)\n  ) %>% \n  ungroup()\n\n2. Poor Example\nIn this case, while you can probably tell clearly that the bottom row is the Average of each column, did you notice the Avg for 2007-11 and 2012-16?\nRule 2 | Poor example gt code\n\nrule2_tab1 <- rule2_data %>% \n  gt(\n    rowname_col = \"Country\"\n  ) %>% \n  cols_label(\n    avg_07_11 = \"Avg.\",\n    avg_12_16 = \"Avg.\"\n  ) %>% \n  cols_width(\n    1 ~ px(125)\n  ) %>% \n  fmt_number(\n    columns = 2:last_col()\n  ) %>% \n  tab_style(\n    style = cell_borders(\n      side = \"all\",\n      color = \"grey\",\n      weight = px(1),\n      style = \"solid\"\n    ),\n    locations = list(\n      cells_body(\n        everything()\n        ),\n      cells_column_labels(\n        everything()\n      )\n      )\n  ) %>% \n  grand_summary_rows(\n    columns = 2:last_col(),\n    fns = list(\n      \"Average\" = ~mean(.)\n    ),\n    formatter = fmt_number\n  )\n\n\nrule2_tab1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n      2007\n      2008\n      2009\n      2010\n      2011\n      Avg.\n      2012\n      2013\n      2014\n      2015\n      2016\n      Avg.\n    \n\n\nChina\n14.63\n15.18\n14.42\n15.67\n16.28\n15.13\n16.77\n17.09\n17.14\n17.27\n17.69\n16.77\n\n\nIndia\n16.41\n19.30\n18.81\n19.93\n22.72\n19.41\n21.75\n22.76\n22.92\n23.13\n20.51\n21.25\n\n\nIndonesia\n16.09\n16.67\n16.51\n15.94\n15.96\n16.09\n16.58\n16.02\n17.67\n18.20\n18.25\n17.08\n\n\nMexico\n27.06\n27.73\n27.74\n27.76\n26.27\n27.06\n26.81\n26.78\n27.34\n27.14\n27.93\n27.31\n\n\nPakistan\n19.35\n16.46\n20.28\n22.68\n21.92\n20.35\n18.34\n21.81\n18.15\n23.44\n22.43\n20.34\n\n\nUnited States\n44.43\n44.44\n46.44\n44.94\n44.69\n44.43\n45.78\n46.36\n47.15\n46.90\n48.64\n46.78\n\n\nAverage\n23.00\n23.29\n24.03\n24.49\n24.64\n23.75\n24.34\n25.13\n25.06\n26.01\n25.91\n24.92\n\n\n\n\n\n\n2. Improved Example\nIn this improved example we’ve clearly indicated the Avg. columns. Note that I’ve also manually calculated a summary row at the bottom just as an alternative example, although you could again create a grand_summary_row() with gt and probably should since you could add as many arbitrary summary rows as you’d like (by group even!). We used that in the previous example.\nRule 2 | Improved gt code\n\nrule2_tab2 <- rule2_data %>% \n  add_row(\n    rule2_data %>% \n      summarize(\n        across(where(is.double), \n               list(Average = mean),\n               .names = \"{col}\")\n      ) %>% \n      mutate(Country = \"Average\")\n  ) %>% \n  gt() %>% \n  cols_label(\n    avg_07_11 = \"Avg.\",\n    avg_12_16 = \"Avg.\"\n  ) %>%\n  fmt_number(\n    columns = 2:last_col()\n  ) %>% \n  tab_style(\n    style = cell_fill(\n      color = \"lightgrey\"\n    ),\n    locations = list(\n      cells_body(\n        columns = vars(avg_07_11, avg_12_16)\n        ),\n      cells_column_labels(\n        columns = vars(avg_07_11, avg_12_16)\n      )\n      )\n  ) %>%\n  tab_style(\n    style = cell_borders(\n      sides = \"top\",\n      color = \"black\",\n      weight = px(2)\n    ),\n    locations = cells_body(\n      columns = everything(),\n      rows = Country == \"Average\"\n    )\n  ) %>% \n  tab_style(\n    style = list(\n      cell_text(weight = \"bold\")\n    ),\n    locations = cells_column_labels(everything())\n  ) %>% \n  tab_options(\n    column_labels.border.top.color = \"black\",\n    column_labels.border.top.width = px(3),\n    column_labels.border.bottom.color = \"black\"\n  )\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\nrule2_tab2 %>% \n  tab_source_note(md(\"**Table**: @thomas_mock | **Data**: OurWorldInData.org<br>**Inspiration**: @jschwabish\"))\n\n\n\n\n\n\nCountry\n      2007\n      2008\n      2009\n      2010\n      2011\n      Avg.\n      2012\n      2013\n      2014\n      2015\n      2016\n      Avg.\n    \n\n\nChina\n14.63\n15.18\n14.42\n15.67\n16.28\n15.13\n16.77\n17.09\n17.14\n17.27\n17.69\n16.77\n\n\nIndia\n16.41\n19.30\n18.81\n19.93\n22.72\n19.41\n21.75\n22.76\n22.92\n23.13\n20.51\n21.25\n\n\nIndonesia\n16.09\n16.67\n16.51\n15.94\n15.96\n16.09\n16.58\n16.02\n17.67\n18.20\n18.25\n17.08\n\n\nMexico\n27.06\n27.73\n27.74\n27.76\n26.27\n27.06\n26.81\n26.78\n27.34\n27.14\n27.93\n27.31\n\n\nPakistan\n19.35\n16.46\n20.28\n22.68\n21.92\n20.35\n18.34\n21.81\n18.15\n23.44\n22.43\n20.34\n\n\nUnited States\n44.43\n44.44\n46.44\n44.94\n44.69\n44.43\n45.78\n46.36\n47.15\n46.90\n48.64\n46.78\n\n\nAverage\n23.00\n23.29\n24.03\n24.49\n24.64\n23.75\n24.34\n25.13\n25.06\n26.01\n25.91\n24.92\n\n\n\n\nTable: @thomas_mock | Data: OurWorldInData.orgInspiration: @jschwabish"
  },
  {
    "objectID": "posts/2020-09-04-10-table-rules-in-r/index.html#rule-3-right-align-numbers-and-heads",
    "href": "posts/2020-09-04-10-table-rules-in-r/index.html#rule-3-right-align-numbers-and-heads",
    "title": "10+ Guidelines for Better Tables in R",
    "section": "Rule 3: Right-Align Numbers and Heads",
    "text": "Rule 3: Right-Align Numbers and Heads\nIn this case, you want to right align numbers and ideally choose mono-spaced or numerically-aligned fonts, while avoiding “oldstyle” fonts which have numbers with varying vertical placement. Importantly, gt already automatically follows best practices for the most part so we have to change some of the defaults to get bad examples.\n\n# Prep data\nrule3_data <- yield_data %>% \n  filter(Country == \"United States\", year %in% c(2016)) %>% \n  mutate(crop = str_to_title(crop)) %>% \n  pivot_wider(names_from = year, values_from = \"yield\") %>% \n  arrange(crop) %>% \n  select(-Country, Crop = crop)\n\n3. Comparison of alignment\nNotice that left-alignment or center-alignment of numbers impairs the ability to clearly compare numbers and decimal places. Right-alignment lets you align decimal places and numbers for easy parsing.\nRule 3 | Alignment gt code\n\nrule3_align <- rule3_data %>% \n  mutate(`Center align` = `2016`,\n             `Right align` = `2016`) %>%\n  rename(`Left align` = 2) %>% \n  gt() %>% \n  tab_style(\n    style = list(\n      cell_text(weight = \"bold\")\n    ),\n    locations = cells_column_labels(everything())\n  ) %>% \n  fmt_number(\n    columns = 2:4\n  ) %>% \n  cols_align(align = \"left\",\n             columns = 2) %>% \n  cols_align(align = \"center\",\n             columns = 3) %>% \n  cols_align(align = \"right\",\n             columns = 4) %>% \n  tab_options(\n    column_labels.border.top.color = \"white\",\n    column_labels.border.top.width = px(3),\n    column_labels.border.bottom.color = \"black\",\n    table_body.hlines.color = \"white\",\n    table.border.bottom.color = \"white\",\n    table.border.bottom.width = px(3)\n  )\n\n\nrule3_align %>% \n  tab_source_note(md(\"**Table**: @thomas_mock | **Data**: OurWorldInData.org<br>**Inspiration**: @jschwabish\"))\n\n\n\n\n\n\nCrop\n      Left align\n      Center align\n      Right align\n    \n\n\nBeans\n2.06\n2.06\n2.06\n\n\nMaize\n11.74\n11.74\n11.74\n\n\nPotatoes\n48.64\n48.64\n48.64\n\n\nRice\n8.11\n8.11\n8.11\n\n\nSoybeans\n3.49\n3.49\n3.49\n\n\nWheat\n3.54\n3.54\n3.54\n\n\n\n\nTable: @thomas_mock | Data: OurWorldInData.orgInspiration: @jschwabish\n    \n\n\n\n\n3. Addendums to alignment\nWhen aligning text of equal length (long or very short), center alignment of text can be fine or even preferable. For example, very short text with a long header can be better suited to center-align. Equal length text can be centered without negatively affecting the ability to quickly read.\n\nrule3_data_addendum <- yield_data %>% \n  filter(\n    Country %in% c(\"Africa\"), \n    year >= 2015,\n    str_length(crop) == 5\n    ) %>%\n  group_by(year) %>% \n  mutate(\n    crop = str_to_title(crop),\n    max_yield = max(yield),\n    `Top Crop` = if_else(yield == max_yield, \"Y\", \"N\")\n    ) %>%\n  select(Year = year, Crop = crop, `Top Crop`, Yield = yield) %>% \n  ungroup()\n\nWhile the table below could be improved in other ways and has quite a bit of repetition, note that the Top Crop column has too much white space on the right side due to defaulting to left-alignment. This makes it “stick” too much to the adjacent column.\n\nrule3_data_addendum %>% \n  gt()\n\n\n\n\n\n\nYear\n      Crop\n      Top Crop\n      Yield\n    \n\n\n2015\nWheat\nY\n2.8369\n\n\n2015\nMaize\nN\n1.9433\n\n\n2015\nBeans\nN\n0.9054\n\n\n2016\nWheat\nY\n2.4504\n\n\n2016\nMaize\nN\n1.8745\n\n\n2016\nBeans\nN\n0.8678\n\n\n2017\nWheat\nY\n2.5580\n\n\n2017\nMaize\nN\n2.0922\n\n\n2017\nBeans\nN\n0.9035\n\n\n2018\nWheat\nY\n2.8639\n\n\n2018\nMaize\nN\n2.0402\n\n\n2018\nBeans\nN\n0.8954\n\n\n\n\n\n\nMoving the Top Crop column to center-alignment makes it easier to visually parse the column, and note that centering the Crop Column has no negative effect on the alignment or ability to read as each cell value has equal length (as long as the font-choice is one that doesn’t have major differenceds in charater width). The left-alignment rule for text is a good default, but is more effective with variable width text especially with large variation (ie length = 10 interspersed with length = 5).\n\nrule3_data_addendum %>% \n  gt() %>% \n  gt::cols_align(\n    align = \"center\",\n    columns = vars(`Top Crop`, Crop)\n  )\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\nYear\n      Crop\n      Top Crop\n      Yield\n    \n\n\n2015\nWheat\nY\n2.8369\n\n\n2015\nMaize\nN\n1.9433\n\n\n2015\nBeans\nN\n0.9054\n\n\n2016\nWheat\nY\n2.4504\n\n\n2016\nMaize\nN\n1.8745\n\n\n2016\nBeans\nN\n0.8678\n\n\n2017\nWheat\nY\n2.5580\n\n\n2017\nMaize\nN\n2.0922\n\n\n2017\nBeans\nN\n0.9035\n\n\n2018\nWheat\nY\n2.8639\n\n\n2018\nMaize\nN\n2.0402\n\n\n2018\nBeans\nN\n0.8954\n\n\n\n\n\n\nAs an aside, note that pivot_wider() can also improve the function of this table, reducing repetition of both the Crop and Top Crop columns. Again, center alignment helps with the Top Crop column regardless.\n\nrule3_data_addendum %>% \n  pivot_wider(names_from = Year, values_from = Yield) %>% \n  gt() %>% \n  gt::cols_align(\n    align = \"center\",\n    columns = vars(`Top Crop`)\n  ) \n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\nCrop\n      Top Crop\n      2015\n      2016\n      2017\n      2018\n    \n\n\nWheat\nY\n2.8369\n2.4504\n2.5580\n2.8639\n\n\nMaize\nN\n1.9433\n1.8745\n2.0922\n2.0402\n\n\nBeans\nN\n0.9054\n0.8678\n0.9035\n0.8954\n\n\n\n\n\n\n3. Choose fonts carefully\nFor the fonts below, notice that the Default for gt along with a monospaced font in Fira Mono have nice alignment of decimal places and equally-spaced numbers. In contrast, Karla, Cabin, and Georgia have issues with alignment of numbers/decimals horizontally and vertically. We’ve underlined the numbers so you can see the vertical-spacing issues with Georgia specifically.\nRule 3 | Choosing Fonts gt code\n\nrule3_text <- rule3_data %>% \n  mutate(Karla = `2016`,\n             Cabin = `2016`,\n             Georgia = `2016`,\n             `Fira Mono` = `2016`) %>%\n  rename(Default = 2) %>% \n  gt() %>% \n  tab_style(\n    style = list(\n      cell_text(font = \"Default\", decorate = \"underline\")\n    ),\n    locations = list(\n      cells_column_labels(\n        vars(Default)\n        ),\n      cells_body(\n        vars(Default)\n      )\n  )\n  ) %>% \n  tab_style(\n    style = list(\n      cell_text(font = \"Karla\", decorate = \"underline\")\n    ),\n    locations = list(\n      cells_column_labels(\n        vars(Karla)\n      ),\n      cells_body(\n        vars(Karla)\n      )\n    )\n  )  %>% \n  tab_style(\n    style = list(\n      cell_text(font = \"Cabin\", decorate = \"underline\")\n    ),\n    locations = list(\n      cells_column_labels(\n        vars(Cabin)\n      ),\n      cells_body(\n        vars(Cabin)\n      )\n    )\n  ) %>% \n  tab_style(\n    style = list(\n      cell_text(font = \"Georgia\", decorate = \"underline\")\n    ),\n    locations = list(\n      cells_column_labels(\n        vars(Georgia)\n      ),\n      cells_body(\n        vars(Georgia)\n      )\n    )\n  ) %>% \n  tab_style(\n    style = list(\n      cell_text(font = \"Fira Mono\", decorate = \"underline\")\n    ),\n    locations = list(\n      cells_column_labels(\n        vars(`Fira Mono`)\n      ),\n      cells_body(\n        vars(`Fira Mono`)\n      )\n    )\n  ) %>% \n  fmt_number(columns = 2:6) %>% \n  tab_spanner(\n    label = \"Good\",\n    columns = c(2, 6)\n  ) %>% \n  tab_spanner(\n    \"Bad\",\n    3:5\n  ) %>% \n  tab_options(\n    column_labels.border.top.color = \"white\",\n    column_labels.border.top.width = px(3),\n    column_labels.border.bottom.color = \"black\",\n    table_body.hlines.color = \"white\",\n    table.border.bottom.color = \"white\",\n    table.border.bottom.width = px(3)\n  )\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\nrule3_text %>% \n  tab_source_note(md(\"**Table**: @thomas_mock | **Data**: OurWorldInData.org<br>**Inspiration**: @jschwabish\"))\n\n\n\n\n\n\n\nCrop\n      \n        Good\n      \n      \n        Bad\n      \n    \n\nDefault\n      Fira Mono\n      Karla\n      Cabin\n      Georgia\n    \n\n\n\nBeans\n2.06\n2.06\n2.06\n2.06\n2.06\n\n\nMaize\n11.74\n11.74\n11.74\n11.74\n11.74\n\n\nPotatoes\n48.64\n48.64\n48.64\n48.64\n48.64\n\n\nRice\n8.11\n8.11\n8.11\n8.11\n8.11\n\n\nSoybeans\n3.49\n3.49\n3.49\n3.49\n3.49\n\n\nWheat\n3.54\n3.54\n3.54\n3.54\n3.54\n\n\n\n\nTable: @thomas_mock | Data: OurWorldInData.orgInspiration: @jschwabish"
  },
  {
    "objectID": "posts/2020-09-04-10-table-rules-in-r/index.html#rule-4-left-align-text-and-heads",
    "href": "posts/2020-09-04-10-table-rules-in-r/index.html#rule-4-left-align-text-and-heads",
    "title": "10+ Guidelines for Better Tables in R",
    "section": "Rule 4: Left-align Text and Heads",
    "text": "Rule 4: Left-align Text and Heads\nFor labels/strings it is typically more appropriate to left-align. This allows your eye to follow both short and long text vertically to scan a table, along with a clear border.\nRule 4 | Alignment gt code\n\ncountry_names <- c(\n  \"British Virgin Islands\",\n  \"Cayman Islands\",\n  \"Democratic Republic of Congo\",\n  \"Luxembourg\", \n  \"United States\",\n  \"Germany\",\n  \"New Zealand\",\n  \"Costa Rica\",\n  \"Peru\"\n)\n\nrule4_tab_left <- tibble(\n  right = country_names,\n  center = country_names,\n  left = country_names\n) %>% \n  gt()  %>% \n  cols_align(align = \"left\",\n             columns = 3) %>% \n  cols_align(align = \"center\",\n             columns = 2) %>% \n  cols_align(align = \"right\",\n             columns = 1) %>% \n  cols_width(\n    everything() ~ px(250)\n  ) %>% \n  tab_options(\n    column_labels.border.top.color = \"white\",\n    column_labels.border.top.width = px(3),\n    column_labels.border.bottom.color = \"black\",\n    column_labels.font.weight = \"bold\",\n    table_body.hlines.color = \"white\",\n    table.border.bottom.color = \"white\",\n    table.border.bottom.width = px(3),\n    data_row.padding = px(3)\n  ) %>% \n  cols_label(\n    right = md(\"Right aligned and<br>hard to read\"),\n    center = md(\"Centered and<br>even harder to read\"),\n    left = md(\"Left-aligned and<br>easiest to read\")\n  ) %>% \n  tab_source_note(md(\"**Table**: @thomas_mock | **Data**: OurWorldInData.org<br>**Inspiration**: @jschwabish\"))\n\n\nrule4_tab_left\n\n\n\n\n\n\n\n\n\n\n\nRight aligned andhard to read\n      Centered andeven harder to read\n      Left-aligned andeasiest to read\n    \n\n\nBritish Virgin Islands\nBritish Virgin Islands\nBritish Virgin Islands\n\n\nCayman Islands\nCayman Islands\nCayman Islands\n\n\nDemocratic Republic of Congo\nDemocratic Republic of Congo\nDemocratic Republic of Congo\n\n\nLuxembourg\nLuxembourg\nLuxembourg\n\n\nUnited States\nUnited States\nUnited States\n\n\nGermany\nGermany\nGermany\n\n\nNew Zealand\nNew Zealand\nNew Zealand\n\n\nCosta Rica\nCosta Rica\nCosta Rica\n\n\nPeru\nPeru\nPeru\n\n\n\n\nTable: @thomas_mock | Data: OurWorldInData.orgInspiration: @jschwabish"
  },
  {
    "objectID": "posts/2020-09-04-10-table-rules-in-r/index.html#rule-5-select-the-appropriate-level-of-precision",
    "href": "posts/2020-09-04-10-table-rules-in-r/index.html#rule-5-select-the-appropriate-level-of-precision",
    "title": "10+ Guidelines for Better Tables in R",
    "section": "Rule 5: Select the Appropriate Level of Precision",
    "text": "Rule 5: Select the Appropriate Level of Precision\nWhile you can sometimes justify increased decimal places, often 1 or 2 can help with the appearance of the table and clean up the overall flow. Additionally, for many measure the accuracy in your dataset may be more detailed than what is appropriate from the data collection tool itself.\nRule 5 | Precision gt code\n\nrule5_tab <- yield_data %>% \n  filter(Country %in% country_sel, crop == \"potatoes\", year %in% c(2016)) %>% \n  select(Country, yield) %>% \n  mutate(few = yield, right = yield) %>% \n  gt() %>% \n  fmt_number(\n    columns = vars(few),\n    decimals = 0\n  ) %>% \n  fmt_number(\n    columns = vars(right),\n    decimals = 1\n  ) %>% \n  cols_label(\n    yield = md(\"Too many<br>decimals\"),\n    few = md(\"Too few<br>decimals\"),\n    right = md(\"About<br>right\")\n  ) %>% \n  tab_source_note(md(\"**Table**: @thomas_mock | **Data**: OurWorldInData.org<br>**Inspiration**: @jschwabish\"))\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\nrule5_tab\n\n\n\n\n\n\nCountry\n      Too manydecimals\n      Too fewdecimals\n      Aboutright\n    \n\n\nChina\n17.6866\n18\n17.7\n\n\nIndia\n20.5087\n21\n20.5\n\n\nIndonesia\n18.2549\n18\n18.3\n\n\nMexico\n27.9260\n28\n27.9\n\n\nPakistan\n22.4346\n22\n22.4\n\n\nUnited States\n48.6408\n49\n48.6\n\n\n\n\nTable: @thomas_mock | Data: OurWorldInData.orgInspiration: @jschwabish"
  },
  {
    "objectID": "posts/2020-09-04-10-table-rules-in-r/index.html#rule-6-guide-your-reader-with-space-between-rows-and-columns",
    "href": "posts/2020-09-04-10-table-rules-in-r/index.html#rule-6-guide-your-reader-with-space-between-rows-and-columns",
    "title": "10+ Guidelines for Better Tables in R",
    "section": "Rule 6: Guide Your Reader with Space between Rows and Columns",
    "text": "Rule 6: Guide Your Reader with Space between Rows and Columns\nWhile there is a bit of art to the science of spacing - think of how you want to guide the reader. You want to make it easy to move horizontally and/or vertically depending on the purpose of the table. Additionally, increasing spacing can improve the overall readability of the table although TOO much space can be distracting.\nRule 6 | Table Spacing gt code\n\nrule6_data <- yield_data %>% \n  filter(Country %in% country_sel, crop == \"potatoes\", year %in% c(2014:2016)) %>% \n  filter(crop == \"potatoes\") %>% \n  pivot_wider(names_from = year, values_from = \"yield\") %>% \n  select(-crop)\n\nrule6_tb <- rule6_data %>% \n  add_row(\n    rule6_data %>% \n      summarize(\n        across(where(is.double), \n               list(Average = mean),\n               .names = \"{col}\")\n      ) %>% \n      mutate(Country = \"Average\")\n  ) %>% \n  gt() %>% \n  fmt_number(\n    columns = 2:4,\n    decimals = 2\n  ) %>% \n  tab_style(\n    style = list(\n      cell_text(weight = \"bold\")\n    ),\n    locations = cells_column_labels(everything())\n  ) %>% \n  tab_style(\n    style = cell_borders(\n      sides = \"top\",\n      color = \"black\",\n      weight = px(2)\n    ),\n    locations = cells_body(\n      columns = everything(),\n      rows = Country == \"Average\"\n    )\n  ) %>% \n  tab_options(\n    column_labels.border.top.color = \"white\",\n    column_labels.border.top.width = px(3),\n    column_labels.border.bottom.color = \"black\",\n    table_body.hlines.color = \"white\",\n    table.border.bottom.color = \"white\",\n    table.border.bottom.width = px(3)\n      ) %>% \n  cols_width(vars(Country) ~ px(125),\n             2:4 ~ px(75))\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\nNote that while this table is useful it guides the reader towards vertical comparison within year.\n\nrule6_tb %>% \n  tab_source_note(md(\"**Table**: @thomas_mock | **Data**: OurWorldInData.org<br>**Inspiration**: @jschwabish\"))\n\n\n\n\n\n\n\n\n\n\n\n\nCountry\n      2014\n      2015\n      2016\n    \n\n\nChina\n17.14\n17.27\n17.69\n\n\nIndia\n22.92\n23.13\n20.51\n\n\nIndonesia\n17.67\n18.20\n18.25\n\n\nMexico\n27.34\n27.14\n27.93\n\n\nPakistan\n18.15\n23.44\n22.43\n\n\nUnited States\n47.15\n46.90\n48.64\n\n\nAverage\n25.06\n26.01\n25.91\n\n\n\n\nTable: @thomas_mock | Data: OurWorldInData.orgInspiration: @jschwabish\n    \n\n\n\n\nAlternatively, this “taller” table pushes the reader towards horizontal tracking of the table.\n\nrule6_tb %>% \n  tab_options(data_row.padding = px(20)) %>% \n  tab_source_note(md(\"**Table**: @thomas_mock | **Data**: OurWorldInData.org<br>**Inspiration**: @jschwabish\"))\n\n\n\n\n\n\n\n\n\n\n\n\nCountry\n      2014\n      2015\n      2016\n    \n\n\nChina\n17.14\n17.27\n17.69\n\n\nIndia\n22.92\n23.13\n20.51\n\n\nIndonesia\n17.67\n18.20\n18.25\n\n\nMexico\n27.34\n27.14\n27.93\n\n\nPakistan\n18.15\n23.44\n22.43\n\n\nUnited States\n47.15\n46.90\n48.64\n\n\nAverage\n25.06\n26.01\n25.91\n\n\n\n\nTable: @thomas_mock | Data: OurWorldInData.orgInspiration: @jschwabish"
  },
  {
    "objectID": "posts/2020-09-04-10-table-rules-in-r/index.html#rule-7-remove-unit-repetition",
    "href": "posts/2020-09-04-10-table-rules-in-r/index.html#rule-7-remove-unit-repetition",
    "title": "10+ Guidelines for Better Tables in R",
    "section": "Rule 7: Remove Unit Repetition",
    "text": "Rule 7: Remove Unit Repetition\nThe goal here is to remove repetition of units to improve readability and increase the signal to noise ratio in the table. For our example, we are dropping the % sign after the first appearance. While this is easy to do with currency symbols at the start of the row, the % sign at the end alters the alignment of the cells. gt actually has an open Github Issue to allow for this feature, but in the meantime I have two strategies to accomplish the % trick as seen below.\n\nrule6_tb %>% \n  fmt_percent(\n    columns = 2:4,\n    rows = 1,\n    scale_values = FALSE\n  ) %>% \n  tab_source_note(md(\"**Table**: @thomas_mock | **Data**: OurWorldInData.org<br>**Inspiration**: @jschwabish\"))\n\n\n\n\n\n\n\n\n\n\n\n\nCountry\n      2014\n      2015\n      2016\n    \n\n\nChina\n17.14%\n17.27%\n17.69%\n\n\nIndia\n22.92\n23.13\n20.51\n\n\nIndonesia\n17.67\n18.20\n18.25\n\n\nMexico\n27.34\n27.14\n27.93\n\n\nPakistan\n18.15\n23.44\n22.43\n\n\nUnited States\n47.15\n46.90\n48.64\n\n\nAverage\n25.06\n26.01\n25.91\n\n\n\n\nTable: @thomas_mock | Data: OurWorldInData.orgInspiration: @jschwabish\n    \n\n\n\n\nWe can try to align left for examples that ALL have the same range (ie all in the 10’s) as the numbers will align properly, although variation in the units can again mess up the alignment.\n\nrule6_tb %>% \n  fmt_percent(\n    columns = 2:4,\n    rows = 1,\n    scale_values = FALSE\n  ) %>% \n  cols_align(\n    columns = 2:4,\n    align = \"left\"\n  ) %>% \n  tab_source_note(md(\"**Table**: @thomas_mock | **Data**: OurWorldInData.org<br>**Inspiration**: @jschwabish\"))\n\n\n\n\n\n\n\n\n\n\n\n\nCountry\n      2014\n      2015\n      2016\n    \n\n\nChina\n17.14%\n17.27%\n17.69%\n\n\nIndia\n22.92\n23.13\n20.51\n\n\nIndonesia\n17.67\n18.20\n18.25\n\n\nMexico\n27.34\n27.14\n27.93\n\n\nPakistan\n18.15\n23.44\n22.43\n\n\nUnited States\n47.15\n46.90\n48.64\n\n\nAverage\n25.06\n26.01\n25.91\n\n\n\n\nTable: @thomas_mock | Data: OurWorldInData.orgInspiration: @jschwabish\n    \n\n\n\n\nA custom function could be used (and I’ve done that with gtExtras::fmt_symbol_first). Note that that while the function below works just fine, the gtExtras function is much more robust to user input.\n\nfmt_pct_first <- function(x, rows = 1){\n  sym_add <- ifelse(rows == 1, \"%\", \"&nbsp;\")\n  x <- format(round(x, digits = 2), nsmall = 2)\n  paste0(x, sym_add)\n}\n\nhead(mtcars) %>%\n  gt() %>%\n  fmt(mpg, rows = 1, function(x) fmt_pct_first(x, 1)) %>%\n  fmt(mpg, rows = 2:6, function(x) fmt_pct_first(x, 2:6)) %>% \n  # have to use monospace font to control alignment properly\n  tab_style(style = cell_text(font = \"monospace\"), \n    locations = cells_body(mpg))\n\n\n\n\n\n\nmpg\n      cyl\n      disp\n      hp\n      drat\n      wt\n      qsec\n      vs\n      am\n      gear\n      carb\n    \n\n\n21.00%\n6\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\n21.00 \n6\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\n22.80 \n4\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\n21.40 \n6\n258\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\n18.70 \n8\n360\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\n18.10 \n6\n225\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\n\n\n\n\nAlternatively, you could always add the % sign to each of the column labels, so that it’s clear that the columns are actually percentages rather than just raw numbers.\n\nrule6_tb %>% \n  cols_label(\n    `2014` = \"2014 (%)\",\n    `2015` = \"2015 (%)\",\n    `2016` = \"2016 (%)\"\n  ) %>% \n  cols_width(\n    2:4 ~ px(100)\n  )  %>% \n  tab_source_note(md(\"**Table**: @thomas_mock | **Data**: OurWorldInData.org<br>**Inspiration**: @jschwabish\"))\n\n\n\n\n\n\n\n\n\n\n\n\nCountry\n      2014 (%)\n      2015 (%)\n      2016 (%)\n    \n\n\nChina\n17.14\n17.27\n17.69\n\n\nIndia\n22.92\n23.13\n20.51\n\n\nIndonesia\n17.67\n18.20\n18.25\n\n\nMexico\n27.34\n27.14\n27.93\n\n\nPakistan\n18.15\n23.44\n22.43\n\n\nUnited States\n47.15\n46.90\n48.64\n\n\nAverage\n25.06\n26.01\n25.91\n\n\n\n\nTable: @thomas_mock | Data: OurWorldInData.orgInspiration: @jschwabish\n    \n\n\n\n\nOr add a spanner across the columns.\n\nrule6_tb %>% \n  tab_spanner(\n    label = md(\"**% Yield of Total**\"),\n    columns = 2:4\n  )  %>% \n  tab_source_note(md(\"**Table**: @thomas_mock | **Data**: OurWorldInData.org<br>**Inspiration**: @jschwabish\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\nCountry\n      \n        % Yield of Total\n      \n    \n\n2014\n      2015\n      2016\n    \n\n\n\nChina\n17.14\n17.27\n17.69\n\n\nIndia\n22.92\n23.13\n20.51\n\n\nIndonesia\n17.67\n18.20\n18.25\n\n\nMexico\n27.34\n27.14\n27.93\n\n\nPakistan\n18.15\n23.44\n22.43\n\n\nUnited States\n47.15\n46.90\n48.64\n\n\nAverage\n25.06\n26.01\n25.91\n\n\n\n\nTable: @thomas_mock | Data: OurWorldInData.orgInspiration: @jschwabish\n    \n\n\n\n\nLastly - you could add a footnote.\n\nrule6_tb %>% \n  tab_footnote(\n    footnote = md(\"**% Yield of Total**\"),\n    locations = cells_column_labels(2:4)\n  )  %>% \n  tab_source_note(md(\"**Table**: @thomas_mock | **Data**: OurWorldInData.org<br>**Inspiration**: @jschwabish\"))\n\n\n\n\n\n\n\n\n\n\n\n\nCountry\n      20141\n\n      20151\n\n      20161\n\n    \n\n\nChina\n17.14\n17.27\n17.69\n\n\nIndia\n22.92\n23.13\n20.51\n\n\nIndonesia\n17.67\n18.20\n18.25\n\n\nMexico\n27.34\n27.14\n27.93\n\n\nPakistan\n18.15\n23.44\n22.43\n\n\nUnited States\n47.15\n46.90\n48.64\n\n\nAverage\n25.06\n26.01\n25.91\n\n\n\n\nTable: @thomas_mock | Data: OurWorldInData.orgInspiration: @jschwabish\n    \n\n\n1% Yield of Total\n\n    \n\n\n\n\nTradeoffs\nThere are trade offs with these steps beyond the core idea of just reducing repetition. Ideally gt will add native support for dropping repeated units, but in the meantime these strategies can let you add context to a table without just keeping a unit in every column.\nAs a truly final aside, note that for some currencies or other measures that are available at the start of a value rather than an end work out perfectly!\n\nrule6_tb %>% \n  fmt_currency(\n    columns = 2:4,\n    rows = 1\n  )  %>% \n  tab_source_note(md(\"**Table**: @thomas_mock | **Data**: OurWorldInData.org<br>**Inspiration**: @jschwabish\"))\n\n\n\n\n\n\n\n\n\n\n\n\nCountry\n      2014\n      2015\n      2016\n    \n\n\nChina\n$17.14\n$17.27\n$17.69\n\n\nIndia\n22.92\n23.13\n20.51\n\n\nIndonesia\n17.67\n18.20\n18.25\n\n\nMexico\n27.34\n27.14\n27.93\n\n\nPakistan\n18.15\n23.44\n22.43\n\n\nUnited States\n47.15\n46.90\n48.64\n\n\nAverage\n25.06\n26.01\n25.91\n\n\n\n\nTable: @thomas_mock | Data: OurWorldInData.orgInspiration: @jschwabish"
  },
  {
    "objectID": "posts/2020-09-04-10-table-rules-in-r/index.html#rule-8-highlight-outliers",
    "href": "posts/2020-09-04-10-table-rules-in-r/index.html#rule-8-highlight-outliers",
    "title": "10+ Guidelines for Better Tables in R",
    "section": "Rule 8: Highlight Outliers",
    "text": "Rule 8: Highlight Outliers\nWith large data tables, it can be useful to take a page from our Data Viz and highlight outliers with color or shape.\n\nrule8_data <- yield_data %>% \n  filter(Country %in% country_sel, crop == \"potatoes\", year %in% 2009:2017) %>% \n  group_by(Country) %>% \n  mutate(pct_change = (yield/lag(yield)-1)*100) %>% \n  ungroup() %>% \n  filter(between(year, 2010, 2016)) %>% \n  select(Country, year, pct_change) %>% \n  pivot_wider(names_from = year, values_from = pct_change)\n\nThe plain data we don’t fully recognize the negative values instantly.\nRule 8 | Plain table gt code\n\nrule8_tb <- rule8_data %>% \n  gt() %>% \n  fmt_number(2:last_col()) %>% \n  cols_label(\n    Country = \"\"\n  ) %>% \n  tab_style(\n    style = list(\n      cell_text(weight = \"bold\")\n    ),\n    locations = cells_column_labels(everything())\n  ) %>% \n  tab_options(\n    column_labels.border.top.color = \"white\",\n    column_labels.border.top.width = px(3),\n    column_labels.border.bottom.color = \"black\",\n    column_labels.border.bottom.width = px(3),\n    table_body.hlines.color = \"white\",\n    table.border.bottom.color = \"black\",\n    table.border.bottom.width = px(3)\n  ) %>% \n  cols_width(vars(Country) ~ px(125),\n             2:last_col() ~ px(75))\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\nrule8_tb %>% \n  tab_source_note(md(\"**Table**: @thomas_mock | **Data**: OurWorldInData.org<br>**Inspiration**: @jschwabish\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n      2010\n      2011\n      2012\n      2013\n      2014\n      2015\n      2016\n    \n\n\nChina\n8.68\n3.92\n3.00\n1.91\n0.30\n0.74\n2.42\n\n\nIndia\n5.95\n14.02\n−4.27\n4.63\n0.71\n0.89\n−11.32\n\n\nIndonesia\n−3.44\n0.07\n3.92\n−3.40\n10.29\n3.03\n0.29\n\n\nMexico\n0.07\n−5.35\n2.04\n−0.13\n2.10\n−0.71\n2.88\n\n\nPakistan\n11.82\n−3.36\n−16.33\n18.89\n−16.76\n29.16\n−4.31\n\n\nUnited States\n−3.23\n−0.56\n2.43\n1.27\n1.71\n−0.53\n3.71\n\n\n\n\nTable: @thomas_mock | Data: OurWorldInData.orgInspiration: @jschwabish\n    \n\n\n\n\nHowever, with a bit of color added we can clearly focus on the outliers.\nRule 8 | Text color gt code\n\nrule8_color <- rule8_tb %>% \n  tab_style(\n    style = cell_text(color = \"red\"),\n    locations = list(\n      cells_body(\n        columns = 2,\n        rows = `2010` < 0\n    ),\n    cells_body(\n      columns = 3,\n      rows = `2011` < 0\n    ),\n    cells_body(\n      columns = 4,\n      rows = `2012` < 0\n    ),\n    cells_body(\n      columns = 5,\n      rows = `2013` < 0\n    ),\n    cells_body(\n      columns = 6,\n      rows = `2014` < 0\n    ),\n    cells_body(\n      columns = 7,\n      rows = `2015` < 0\n    ),\n    cells_body(\n      columns = 8,\n      rows = `2016` < 0\n    )\n  )\n  ) %>% \n  tab_source_note(md(\"**Table**: @thomas_mock | **Data**: OurWorldInData.org<br>**Inspiration**: @jschwabish\"))\n\n\nrule8_color\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n      2010\n      2011\n      2012\n      2013\n      2014\n      2015\n      2016\n    \n\n\nChina\n8.68\n3.92\n3.00\n1.91\n0.30\n0.74\n2.42\n\n\nIndia\n5.95\n14.02\n−4.27\n4.63\n0.71\n0.89\n−11.32\n\n\nIndonesia\n−3.44\n0.07\n3.92\n−3.40\n10.29\n3.03\n0.29\n\n\nMexico\n0.07\n−5.35\n2.04\n−0.13\n2.10\n−0.71\n2.88\n\n\nPakistan\n11.82\n−3.36\n−16.33\n18.89\n−16.76\n29.16\n−4.31\n\n\nUnited States\n−3.23\n−0.56\n2.43\n1.27\n1.71\n−0.53\n3.71\n\n\n\n\nTable: @thomas_mock | Data: OurWorldInData.orgInspiration: @jschwabish\n    \n\n\n\n\nWe can really pull the focus with background fill of each cell outlier.\nRule 8 | Cell fill gt code\n\nrule8_fill <- rule8_tb %>% \n  tab_style(\n    style = list(\n      cell_fill(color = scales::alpha(\"red\", 0.7)),\n      cell_text(color = \"white\", weight = \"bold\")\n      ),\n    locations = list(\n      cells_body(\n        columns = 2,\n        rows = `2010` < 0\n      ),\n      cells_body(\n        columns = 3,\n        rows = `2011` < 0\n      ),\n      cells_body(\n        columns = 4,\n        rows = `2012` < 0\n      ),\n      cells_body(\n        columns = 5,\n        rows = `2013` < 0\n      ),\n      cells_body(\n        columns = 6,\n        rows = `2014` < 0\n      ),\n      cells_body(\n        columns = 7,\n        rows = `2015` < 0\n      ),\n      cells_body(\n        columns = 8,\n        rows = `2016` < 0\n      )\n    )\n  ) %>% \n  tab_source_note(md(\"**Table**: @thomas_mock | **Data**: OurWorldInData.org<br>**Inspiration**: @jschwabish\"))\n\n\nrule8_fill\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n      2010\n      2011\n      2012\n      2013\n      2014\n      2015\n      2016\n    \n\n\nChina\n8.68\n3.92\n3.00\n1.91\n0.30\n0.74\n2.42\n\n\nIndia\n5.95\n14.02\n−4.27\n4.63\n0.71\n0.89\n−11.32\n\n\nIndonesia\n−3.44\n0.07\n3.92\n−3.40\n10.29\n3.03\n0.29\n\n\nMexico\n0.07\n−5.35\n2.04\n−0.13\n2.10\n−0.71\n2.88\n\n\nPakistan\n11.82\n−3.36\n−16.33\n18.89\n−16.76\n29.16\n−4.31\n\n\nUnited States\n−3.23\n−0.56\n2.43\n1.27\n1.71\n−0.53\n3.71\n\n\n\n\nTable: @thomas_mock | Data: OurWorldInData.orgInspiration: @jschwabish"
  },
  {
    "objectID": "posts/2020-09-04-10-table-rules-in-r/index.html#rule-9-group-similar-data-and-increase-white-space",
    "href": "posts/2020-09-04-10-table-rules-in-r/index.html#rule-9-group-similar-data-and-increase-white-space",
    "title": "10+ Guidelines for Better Tables in R",
    "section": "Rule 9: Group Similar Data and Increase White Space",
    "text": "Rule 9: Group Similar Data and Increase White Space\nIn this rule, you want to make sure to group similar categories to make parsing the table easier. We can also increase white space, or even remove repeats to increase the data-to-ink ratio.\n\nrule9_data <- yield_data %>% \n  filter(Country %in% country_sel[-5], year %in% c(2015, 2016),\n         crop %in% c(\"wheat\", \"potatoes\", \"rice\", \"soybeans\"),\n         !is.na(yield)) %>% \n  pivot_wider(names_from = year, values_from = yield) %>% \n  rowwise() %>% \n  mutate(crop = str_to_title(crop),\n         pct_change = (`2016`/`2015`-1)*100) %>%\n  group_by(Country) %>% \n  arrange(desc(`2015`)) %>% \n  ungroup() \n\n9. Bad Example\nHere we can see the table is a bit hard to follow with the Country labels not being grouped.\nRule 9 | Bad example gt code\n\nrule9_bad <- rule9_data %>% \n  gt() %>% \n  fmt_number(\n    columns = vars(`2015`, `2016`, pct_change)\n  ) %>% \n  tab_spanner(columns = vars(`2015`, `2016`),\n              label = md(\"**Yield in Tonnes/Hectare**\")) %>%  \n  cols_width(\n    vars(crop) ~ px(125),\n    vars(`2015`, `2016`, pct_change) ~ 100\n  ) %>% \n  tab_source_note(md(\"**Table**: @thomas_mock | **Data**: OurWorldInData.org<br>**Inspiration**: @jschwabish\"))\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\nrule9_bad\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCountry\n      crop\n      \n        Yield in Tonnes/Hectare\n      \n      pct_change\n    \n\n2015\n      2016\n    \n\n\n\nUnited States\nPotatoes\n46.90\n48.64\n3.71\n\n\nPakistan\nPotatoes\n23.44\n22.43\n−4.31\n\n\nIndia\nPotatoes\n23.13\n20.51\n−11.32\n\n\nIndonesia\nPotatoes\n18.20\n18.25\n0.29\n\n\nChina\nPotatoes\n17.27\n17.69\n2.42\n\n\nUnited States\nRice\n8.37\n8.11\n−3.11\n\n\nChina\nRice\n6.89\n6.86\n−0.44\n\n\nChina\nWheat\n5.39\n5.40\n0.07\n\n\nIndonesia\nRice\n5.34\n5.24\n−1.97\n\n\nPakistan\nRice\n3.72\n3.77\n1.28\n\n\nIndia\nRice\n3.61\n3.79\n5.06\n\n\nUnited States\nSoybeans\n3.23\n3.49\n8.20\n\n\nUnited States\nWheat\n2.93\n3.54\n20.85\n\n\nIndia\nWheat\n2.75\n3.03\n10.34\n\n\nPakistan\nWheat\n2.73\n2.78\n1.96\n\n\nChina\nSoybeans\n1.81\n1.80\n−0.46\n\n\nIndonesia\nSoybeans\n1.57\n1.49\n−5.04\n\n\nIndia\nSoybeans\n0.73\n1.18\n60.27\n\n\nPakistan\nSoybeans\n0.54\n0.85\n58.61\n\n\n\n\nTable: @thomas_mock | Data: OurWorldInData.orgInspiration: @jschwabish\n    \n\n\n\n\n9. gt native grouping\ngt provides row group levels that we can use to separate by Country.\nRule 9 | Groups gt code\n\nrule9_grp <- rule9_data %>% \n  gt(groupname_col = \"Country\") %>% \n  tab_stubhead(\"label\") %>% \n  tab_options(\n    table.width = px(300)\n  ) %>% \n  cols_label(\n    crop = \"\",\n    pct_change = md(\"Percent<br>Change\")\n  ) %>% \n  fmt_number(\n    columns = vars(`2015`, `2016`, pct_change)\n  ) %>% \n  tab_style(\n    style = cell_text(color = \"black\", weight = \"bold\"),\n    locations = list(\n      cells_row_groups(),\n      cells_column_labels(everything())\n    )\n  ) %>% \n  tab_spanner(columns = vars(`2015`, `2016`),\n              label = md(\"**Yield in Tonnes/Hectare**\")) %>%  \n  cols_width(\n    vars(crop) ~ px(125),\n    vars(`2015`, `2016`, pct_change) ~ 100\n  ) %>% \n  tab_options(\n    row_group.border.top.width = px(3),\n    row_group.border.top.color = \"black\",\n    row_group.border.bottom.color = \"black\",\n    table_body.hlines.color = \"white\",\n    table.border.top.color = \"white\",\n    table.border.top.width = px(3),\n    table.border.bottom.color = \"white\",\n    table.border.bottom.width = px(3),\n    column_labels.border.bottom.color = \"black\",\n    column_labels.border.bottom.width = px(2)\n  ) %>% \n  tab_source_note(md(\"**Table**: @thomas_mock | **Data**: OurWorldInData.org<br>**Inspiration**: @jschwabish\"))\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\nrule9_grp\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n      \n        Yield in Tonnes/Hectare\n      \n      PercentChange\n    \n\n2015\n      2016\n    \n\n\n\nUnited States\n    \n\nPotatoes\n46.90\n48.64\n3.71\n\n\nRice\n8.37\n8.11\n−3.11\n\n\nSoybeans\n3.23\n3.49\n8.20\n\n\nWheat\n2.93\n3.54\n20.85\n\n\nPakistan\n    \n\nPotatoes\n23.44\n22.43\n−4.31\n\n\nRice\n3.72\n3.77\n1.28\n\n\nWheat\n2.73\n2.78\n1.96\n\n\nSoybeans\n0.54\n0.85\n58.61\n\n\nIndia\n    \n\nPotatoes\n23.13\n20.51\n−11.32\n\n\nRice\n3.61\n3.79\n5.06\n\n\nWheat\n2.75\n3.03\n10.34\n\n\nSoybeans\n0.73\n1.18\n60.27\n\n\nIndonesia\n    \n\nPotatoes\n18.20\n18.25\n0.29\n\n\nRice\n5.34\n5.24\n−1.97\n\n\nSoybeans\n1.57\n1.49\n−5.04\n\n\nChina\n    \n\nPotatoes\n17.27\n17.69\n2.42\n\n\nRice\n6.89\n6.86\n−0.44\n\n\nWheat\n5.39\n5.40\n0.07\n\n\nSoybeans\n1.81\n1.80\n−0.46\n\n\n\n\nTable: @thomas_mock | Data: OurWorldInData.orgInspiration: @jschwabish\n    \n\n\n\n\n9. Remove duplicate data\nAlternatively, we can remove some observations to create more white space, similar to Jon’s example. Here we are relying purely on white space rather than horizontal dividers. We can use gt::text_transform() to keep all the observations from our data in, but not display the repeats of Country in the gt table.\nRule 9 | Group example gt code\n\nrule9_dup <- rule9_data %>% \n  arrange(Country) %>% \n  gt() %>% \n  cols_label(\n    Country = \"\",\n    crop = \"Crop\",\n    pct_change = md(\"Percent<br>Change\")\n  ) %>% \n  tab_spanner(columns = vars(`2015`, `2016`),\n              label = md(\"**Yield in Tonnes/Hectare**\")) %>% \n  fmt_number(\n    columns = vars(`2015`, `2016`, pct_change)\n  ) %>% \n  text_transform(\n    locations = cells_body(\n      columns = vars(Country),\n      rows = crop != \"Potatoes\"\n    ),\n    fn = function(x){\n      paste0(\"\")\n    }\n  ) %>% \n  tab_style(\n    style = cell_text(color = \"black\", weight = \"bold\"),\n    locations = list(\n      cells_row_groups(),\n      cells_column_labels(everything())\n    )\n  ) %>% \n  cols_width(\n    vars(Country, crop) ~ px(125),\n    vars(`2015`, `2016`, pct_change) ~ 100\n  ) %>% \n  tab_options(\n    column_labels.border.bottom.color = \"black\",\n    column_labels.border.bottom.width = px(2),\n    table_body.hlines.color = \"white\",\n    table.border.top.color = \"white\",\n    table.border.top.width = px(3),\n    table.border.bottom.color = \"white\",\n    table.border.bottom.width = px(3),\n  ) %>% \n  tab_source_note(md(\"**Table**: @thomas_mock | **Data**: OurWorldInData.org<br>**Inspiration**: @jschwabish\"))\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\nrule9_dup\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n      Crop\n      \n        Yield in Tonnes/Hectare\n      \n      PercentChange\n    \n\n2015\n      2016\n    \n\n\n\nChina\nPotatoes\n17.27\n17.69\n2.42\n\n\n\nRice\n6.89\n6.86\n−0.44\n\n\n\nWheat\n5.39\n5.40\n0.07\n\n\n\nSoybeans\n1.81\n1.80\n−0.46\n\n\nIndia\nPotatoes\n23.13\n20.51\n−11.32\n\n\n\nRice\n3.61\n3.79\n5.06\n\n\n\nWheat\n2.75\n3.03\n10.34\n\n\n\nSoybeans\n0.73\n1.18\n60.27\n\n\nIndonesia\nPotatoes\n18.20\n18.25\n0.29\n\n\n\nRice\n5.34\n5.24\n−1.97\n\n\n\nSoybeans\n1.57\n1.49\n−5.04\n\n\nPakistan\nPotatoes\n23.44\n22.43\n−4.31\n\n\n\nRice\n3.72\n3.77\n1.28\n\n\n\nWheat\n2.73\n2.78\n1.96\n\n\n\nSoybeans\n0.54\n0.85\n58.61\n\n\nUnited States\nPotatoes\n46.90\n48.64\n3.71\n\n\n\nRice\n8.37\n8.11\n−3.11\n\n\n\nSoybeans\n3.23\n3.49\n8.20\n\n\n\nWheat\n2.93\n3.54\n20.85\n\n\n\n\nTable: @thomas_mock | Data: OurWorldInData.orgInspiration: @jschwabish"
  },
  {
    "objectID": "posts/2020-09-04-10-table-rules-in-r/index.html#rule-10-add-visualizations-when-appropriate",
    "href": "posts/2020-09-04-10-table-rules-in-r/index.html#rule-10-add-visualizations-when-appropriate",
    "title": "10+ Guidelines for Better Tables in R",
    "section": "Rule 10: Add visualizations When Appropriate",
    "text": "Rule 10: Add visualizations When Appropriate\nWhile data viz and tables are different tools, you can combine them in clever ways to further engage the reader. Embedded data viz can reveal trends, while the table itself shows the raw data for lookup.\n\nrule10_data <- yield_data %>% \n  filter(\n    year %in% c(2013,2017), \n    crop == \"potatoes\", \n    Country %in% c(\n      country_sel, \"Germany\", \"Brazil\", \"Ireland\", \"Lebanon\", \"Italy\", \n      \"Netherlands\", \"France\", \"Denmark\", \"El Salvador\", \"Denmark\"\n      )\n    ) %>% \n  pivot_wider(names_from = year, values_from = yield)\n\n10. Sparklines\nFor example one we can use sparklines to indicate trends across time. There’s quite a bit of code below, and we actually use two datasets. Since we are creating the sparklines outside of gt make sure to align the graphs + data as gt doesn’t control the overall relationship. For example, if you arrange() by a specific column you’ll need to make sure to do it across both datasets.\nRule 10 | Sparkline example gt code\n\nplot_spark <- function(data){\n  data %>% \n    mutate(\n      yield_start = if_else(year == 2013, yield, NA_real_),\n      yield_end = if_else(year == 2017, yield, NA_real_)\n    ) %>% \n    tidyr::fill(yield_start, yield_end, .direction = \"downup\") %>% \n    mutate(color = if_else(yield_end-yield_start < 0, \"red\", \"blue\")) %>% \n    ggplot(aes(x = year, y = yield, color = color)) +\n    geom_line(size = 15) +\n    theme_void() +\n    scale_color_identity() +\n    theme(legend.position = \"none\")\n}\n\n# SPARKLINE\n\nyield_plots <- yield_data %>% \n  filter(\n    year %in% c(2013:2017), \n    crop == \"potatoes\", \n    Country %in% c(\n      country_sel, \"Germany\", \"Brazil\", \"Ireland\", \"Lebanon\", \"Italy\", \n      \"Netherlands\", \"France\", \"Denmark\", \"El Salvador\", \"Denmark\"\n    )\n  ) %>% \n  nest(yields = c(year, yield)) %>% \n  mutate(plot = map(yields, plot_spark))\n\n# SPARKLINES PLOT\n\nrule10_spark <- rule10_data %>% \n  mutate(ggplot = NA) %>% \n  select(-crop) %>% \n  gt() %>% \n  text_transform(\n    locations = cells_body(vars(ggplot)),\n    fn = function(x){\n      map(yield_plots$plot, ggplot_image, height = px(15), aspect_ratio = 4)\n    }\n  ) %>% \n  cols_width(vars(ggplot) ~ px(100)) %>% \n  cols_label(\n    ggplot = \"2013-2017\"\n  ) %>% \n  fmt_number(2:3) %>% \n  tab_spanner(\n    label = \"Potato Yield in Tonnes/Hectare\",\n    columns = c(2,3)\n  ) %>% \n  tab_style(\n    style = cell_text(color = \"black\", weight = \"bold\"),\n    locations = list(\n      cells_column_spanners(everything()),\n      cells_column_labels(everything())\n    )\n  ) %>%  \n  tab_options(\n    row_group.border.top.width = px(3),\n    row_group.border.top.color = \"black\",\n    row_group.border.bottom.color = \"black\",\n    table_body.hlines.color = \"white\",\n    table.border.top.color = \"white\",\n    table.border.top.width = px(3),\n    table.border.bottom.color = \"white\",\n    table.border.bottom.width = px(3),\n    column_labels.border.bottom.color = \"black\",\n    column_labels.border.bottom.width = px(2),\n  ) %>% \n  tab_source_note(md(\"**Table**: @thomas_mock | **Data**: OurWorldInData.org<br>**Inspiration**: @jschwabish\"))\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\nrule10_spark\n\n\n\n\n\n\n\n\n\n\n\n\n\nCountry\n      \n        Potato Yield in Tonnes/Hectare\n      \n      2013-2017\n    \n\n2013\n      2017\n    \n\n\n\nBrazil\n27.75\n30.94\n\n\n\nChina\n17.09\n18.21\n\n\n\nDenmark\n41.57\n43.68\n\n\n\nEl Salvador\n42.60\n29.22\n\n\n\nFrance\n43.16\n44.05\n\n\n\nGermany\n39.83\n46.79\n\n\n\nIndia\n22.76\n22.31\n\n\n\nIndonesia\n16.02\n15.40\n\n\n\nIreland\n38.33\n44.83\n\n\n\nItaly\n25.25\n27.73\n\n\n\nLebanon\n26.08\n25.14\n\n\n\nMexico\n26.78\n28.95\n\n\n\nNetherlands\n42.21\n45.97\n\n\n\nPakistan\n21.81\n21.45\n\n\n\nUnited States\n46.36\n48.39\n\n\n\n\n\nTable: @thomas_mock | Data: OurWorldInData.orgInspiration: @jschwabish\n    \n\n\n\n\n10. Barplot\nFor this example we can use barplots to indicate the average across the 5 years. Note that rather than building a ggplot for each of the rows, we can take some influence from the formattable R package and create a bar with just HTML/CSS! There’s quite a bit of code below, but note that the gt package requires you to parse the HTML with gt::html(). Overall this method is “cleaner” than via ggplot as you are mutating columns within the same dataset, and it’s much faster since you are just parsing HTML rather than creating, saving, and importing several ggplot images.\nMany thanks to the formattable author Renkun Kun and others like rtjohnson12 who have shown examples about how to build up a bar chart with HTML! Thanks also to Christophe Dervieux for a great example of gt + custom HTML on RStudio Community.\nRule 10 | Barplot example gt code\n\n# Example of using glue to just paste the value into pre-created HTML block\n# Example adapted from rtjohnson12 at: \n# https://github.com/renkun-ken/formattable/issues/79#issuecomment-573165954\n\nbar_chart <- function(value, color = \"red\", display_value = NULL){\n  \n  # Choose to display percent of total\n  if (is.null(display_value)) {\n    display_value <- \"&nbsp;\"\n  } else {\n    display_value <- display_value\n  }\n  \n  # paste color and value into the html string\n  glue::glue(\"<span style=\\\"display: inline-block; direction: ltr; border-radius: 4px; padding-right: 2px; background-color: {color}; color: {color}; width: {value}%\\\"> {display_value} </span>\")\n}\n\n# create a color palette w/ paletteer\n# note you could just pass a single color directly to the bar_chart function\ncol_pal <- function(value){\n  \n  # set high and low\n  domain_range <- range(c(rule10_data$`2013`, rule10_data$`2017`))\n  \n  # create the color based of domain\n  scales::col_numeric(\n    paletteer::paletteer_d(\"ggsci::blue_material\") %>% as.character(), \n    domain = c(min(value), max(value))\n      )(value)\n}\n\n# BARPLOT\n\nbar_yields <- yield_data %>% \n  filter(\n    year %in% c(2013:2017), \n    crop == \"potatoes\", \n    Country %in% c(\n      country_sel, \"Germany\", \"Brazil\", \"Ireland\", \"Lebanon\", \"Italy\", \n      \"Netherlands\", \"France\", \"Denmark\", \"El Salvador\", \"Denmark\"\n      )\n    ) %>% \n  pivot_wider(names_from = year, values_from = yield) %>%  \n  select(-crop) %>% \n  rowwise() %>% \n  mutate(\n    mean = mean(c(`2013`, `2014`, `2015`, `2016`, `2017`))\n    ) %>% \n  ungroup() %>% \n  select(Country, `2013`, `2017`, `mean`) %>% \n  mutate(\n    bar = round(mean/max(mean)*100, digits = 2),\n    color = col_pal(bar),\n    bar_chart = bar_chart(bar, color = color),\n    bar_chart = map(bar_chart, ~gt::html(as.character(.x)))) %>% \n  select(-bar, -color)\n  \n# BARPLOT\n\nrule10_bar <- bar_yields %>% \n  gt() %>% \n  cols_width(vars(bar_chart) ~ px(100),\n             vars(`2013`) ~ px(75),\n             vars(`2017`) ~ px(75)\n             ) %>% \n  cols_label(\n    mean = md(\"Average<br>2013-17\"),\n    bar_chart = \"\"\n  ) %>% \n  cols_align(\n    align = \"right\",\n    columns = 2:4\n  ) %>% \n  cols_align(\n    align = \"left\",\n    columns = vars(bar_chart)\n  ) %>% \n  fmt_number(2:4) %>% \n  tab_style(\n    style = cell_text(color = \"black\", weight = \"bold\"),\n    locations = list(\n      cells_column_labels(everything())\n    )\n  ) %>%  \n  tab_options(\n    row_group.border.top.width = px(3),\n    row_group.border.top.color = \"black\",\n    row_group.border.bottom.color = \"black\",\n    table_body.hlines.color = \"white\",\n    table.border.top.color = \"white\",\n    table.border.top.width = px(3),\n    table.border.bottom.color = \"white\",\n    table.border.bottom.width = px(3),\n    table_body.border.bottom.width = px(2),\n    table_body.border.bottom.color = \"black\",\n    column_labels.border.bottom.color = \"black\",\n    column_labels.border.bottom.width = px(3)\n  ) %>% \n  tab_footnote(footnote = \"Potato Yield in Tonnes per Hectare\",\n               locations = cells_column_labels(\n                 columns =2:4\n               )) %>% \n  tab_source_note(md(\"**Table**: @thomas_mock | **Data**: OurWorldInData.org<br>**Inspiration**: @jschwabish\"))\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\nrule10_bar\n\n\n\n\n\n\n\n\n\n\n\n\n\nCountry\n      20131\n\n      20171\n\n      Average2013-171\n\n      \n    \n\n\nBrazil\n27.75\n30.94\n29.12\n   \n\n\nChina\n17.09\n18.21\n17.48\n   \n\n\nDenmark\n41.57\n43.68\n42.45\n   \n\n\nEl Salvador\n42.60\n29.22\n29.92\n   \n\n\nFrance\n43.16\n44.05\n43.30\n   \n\n\nGermany\n39.83\n46.79\n44.45\n   \n\n\nIndia\n22.76\n22.31\n22.32\n   \n\n\nIndonesia\n16.02\n15.40\n17.11\n   \n\n\nIreland\n38.33\n44.83\n40.99\n   \n\n\nItaly\n25.25\n27.73\n26.93\n   \n\n\nLebanon\n26.08\n25.14\n25.27\n   \n\n\nMexico\n26.78\n28.95\n27.63\n   \n\n\nNetherlands\n42.21\n45.97\n43.71\n   \n\n\nPakistan\n21.81\n21.45\n21.46\n   \n\n\nUnited States\n46.36\n48.39\n47.49\n   \n\n\n\n\nTable: @thomas_mock | Data: OurWorldInData.orgInspiration: @jschwabish\n    \n\n\n1 Potato Yield in Tonnes per Hectare\n    \n\n\n\n\n10. Heatmap\nLastly, you can add colors across the entire plot itself to show trends across the data over time and across country.\nRule 10 | Heatmap example gt code\n\nrule10_wide <- yield_data %>% \n  filter(\n    year %in% c(2013:2017), \n    crop == \"potatoes\", \n    Country %in% c(\n      country_sel, \"Germany\", \"Brazil\", \"Ireland\", \"Lebanon\", \"Italy\", \n      \"Netherlands\", \"France\", \"Denmark\", \"El Salvador\", \"Denmark\"\n    )\n  ) %>% \n  pivot_wider(names_from = year, values_from = yield)\n\nrule10_heat <- rule10_wide %>% \n  arrange(desc(`2013`)) %>% \n  select(-crop) %>% \n  gt() %>% \n  data_color(\n    columns = 2:6, \n    colors = scales::col_numeric(\n      palette = paletteer::paletteer_d(\n        palette = \"ggsci::blue_material\"\n      ) %>% as.character(),\n      domain = NULL\n    )\n  ) %>% \n  fmt_number(2:6) %>% \n  tab_spanner(\n    label = \"Potato Yield in Tonnes/Hectare\",\n    columns = c(2:6)\n  ) %>% \n  tab_style(\n    style = cell_text(color = \"black\", weight = \"bold\"),\n    locations = list(\n      cells_column_spanners(everything()),\n      cells_column_labels(everything())\n    )\n  ) %>%  \n  cols_width(\n    1 ~ px(125),\n    2:6 ~ px(65)\n  ) %>% \n  tab_options(\n    row_group.border.top.width = px(3),\n    row_group.border.top.color = \"black\",\n    row_group.border.bottom.color = \"black\",\n    table_body.hlines.color = \"white\",\n    table.border.top.color = \"white\",\n    table.border.top.width = px(3),\n    table.border.bottom.color = \"white\",\n    table.border.bottom.width = px(3),\n    column_labels.border.bottom.color = \"black\",\n    column_labels.border.bottom.width = px(2),\n  ) %>% \n  tab_source_note(md(\"**Table**: @thomas_mock | **Data**: OurWorldInData.org<br>**Inspiration**: @jschwabish\"))\n\n\nrule10_heat\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCountry\n      \n        Potato Yield in Tonnes/Hectare\n      \n    \n\n2013\n      2014\n      2015\n      2016\n      2017\n    \n\n\n\nUnited States\n46.36\n47.15\n46.90\n48.64\n48.39\n\n\nFrance\n43.16\n47.98\n42.51\n38.83\n44.05\n\n\nEl Salvador\n42.60\n26.25\n26.01\n25.54\n29.22\n\n\nNetherlands\n42.21\n45.66\n42.73\n42.00\n45.97\n\n\nDenmark\n41.57\n43.12\n41.41\n42.48\n43.68\n\n\nGermany\n39.83\n47.42\n43.81\n44.40\n46.79\n\n\nIreland\n38.33\n40.32\n42.36\n39.11\n44.83\n\n\nBrazil\n27.75\n27.94\n29.32\n29.66\n30.94\n\n\nMexico\n26.78\n27.34\n27.14\n27.93\n28.95\n\n\nLebanon\n26.08\n25.23\n24.82\n25.07\n25.14\n\n\nItaly\n25.25\n26.08\n27.16\n28.44\n27.73\n\n\nIndia\n22.76\n22.92\n23.13\n20.51\n22.31\n\n\nPakistan\n21.81\n18.15\n23.44\n22.43\n21.45\n\n\nChina\n17.09\n17.14\n17.27\n17.69\n18.21\n\n\nIndonesia\n16.02\n17.67\n18.20\n18.25\n15.40\n\n\n\n\nTable: @thomas_mock | Data: OurWorldInData.orgInspiration: @jschwabish\n    \n\n\n\n\n10. Percent Change\nOk I lied! One more example, with color for a numeric column.\nRule 10 | Percent change example gt code\n\nrule10_wide <- yield_data %>% \n  filter(\n    year %in% c(2013:2017), \n    crop == \"potatoes\", \n    Country %in% c(\n      country_sel, \"Germany\", \"Brazil\", \"Ireland\", \"Lebanon\", \"Italy\", \n      \"Netherlands\", \"France\", \"Denmark\", \"El Salvador\", \"Denmark\"\n    )\n  ) %>% \n  pivot_wider(names_from = year, values_from = yield)\n\nrule10_pct <- rule10_wide %>% \n  arrange(Country) %>% \n  select(-crop) %>% \n  mutate(pct_change = (`2017`/`2013`-1)*100) %>% \n  gt()%>% \n  fmt_number(2:7) %>% \n  cols_label(\n    pct_change = md(\"Percent Change\")\n  ) %>% \n  tab_style(\n    style = list(\n      cell_text(color = \"red\")\n    ),\n    locations = cells_body(\n      columns = vars(pct_change),\n      rows = pct_change <= 0\n    )\n  ) %>% \n  tab_style(\n    style = list(\n      cell_text(color = \"blue\")\n    ),\n    locations = cells_body(\n      columns = vars(pct_change),\n      rows = pct_change > 0\n    )\n  ) %>% \n  tab_spanner(\n    label = \"Potato Yield in Tonnes/Hectare\",\n    columns = c(2:6)\n  ) %>% \n  tab_style(\n    style = cell_text(color = \"black\", weight = \"bold\"),\n    locations = list(\n      cells_column_spanners(everything()),\n      cells_column_labels(everything())\n    )\n  ) %>%  \n  tab_options(\n    row_group.border.top.width = px(3),\n    row_group.border.top.color = \"black\",\n    row_group.border.bottom.color = \"black\",\n    table_body.hlines.color = \"white\",\n    table.border.top.color = \"white\",\n    table.border.top.width = px(3),\n    table.border.bottom.color = \"white\",\n    table.border.bottom.width = px(3),\n    column_labels.border.bottom.color = \"black\",\n    column_labels.border.bottom.width = px(2),\n  ) %>% \n  tab_source_note(md(\"**Table**: @thomas_mock | **Data**: OurWorldInData.org<br>**Inspiration**: @jschwabish\"))\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\nrule10_pct\n\n\n\n\n\n\n\nCountry\n      \n        Potato Yield in Tonnes/Hectare\n      \n      Percent Change\n    \n\n2013\n      2014\n      2015\n      2016\n      2017\n    \n\n\n\nBrazil\n27.75\n27.94\n29.32\n29.66\n30.94\n11.49\n\n\nChina\n17.09\n17.14\n17.27\n17.69\n18.21\n6.54\n\n\nDenmark\n41.57\n43.12\n41.41\n42.48\n43.68\n5.07\n\n\nEl Salvador\n42.60\n26.25\n26.01\n25.54\n29.22\n−31.41\n\n\nFrance\n43.16\n47.98\n42.51\n38.83\n44.05\n2.06\n\n\nGermany\n39.83\n47.42\n43.81\n44.40\n46.79\n17.48\n\n\nIndia\n22.76\n22.92\n23.13\n20.51\n22.31\n−2.00\n\n\nIndonesia\n16.02\n17.67\n18.20\n18.25\n15.40\n−3.83\n\n\nIreland\n38.33\n40.32\n42.36\n39.11\n44.83\n16.96\n\n\nItaly\n25.25\n26.08\n27.16\n28.44\n27.73\n9.83\n\n\nLebanon\n26.08\n25.23\n24.82\n25.07\n25.14\n−3.60\n\n\nMexico\n26.78\n27.34\n27.14\n27.93\n28.95\n8.12\n\n\nNetherlands\n42.21\n45.66\n42.73\n42.00\n45.97\n8.92\n\n\nPakistan\n21.81\n18.15\n23.44\n22.43\n21.45\n−1.63\n\n\nUnited States\n46.36\n47.15\n46.90\n48.64\n48.39\n4.38\n\n\n\n\nTable: @thomas_mock | Data: OurWorldInData.orgInspiration: @jschwabish"
  },
  {
    "objectID": "posts/2020-09-04-10-table-rules-in-r/index.html#rule-11-add-context-to-the-table",
    "href": "posts/2020-09-04-10-table-rules-in-r/index.html#rule-11-add-context-to-the-table",
    "title": "10+ Guidelines for Better Tables in R",
    "section": "Rule 11: Add Context to the Table",
    "text": "Rule 11: Add Context to the Table\nI’ll add one more guideline of my own! We’ve been playing fairly fast and loose with not naming many of the tables and not providing all the context about even what’s in the table, mostly because we’re more concerned with showing curated and specific examples. However, naming and adding context to the table is important. This can be accomplished many different ways with gt.\nAdd a title\nGoing back to our first table - let’s tell the reader what the actual data is!\n\nrule1_good %>% \n  tab_header(\n    title = md(\"**Potato yields in 6 major countries**\"),\n    subtitle = \"Yield in Tonnes/Hectare\"\n    ) %>% \n  tab_options(heading.align = \"left\",\n              table.border.top.color = \"white\",\n              table.border.top.width = px(3))\n\n\n\n\n\n\n\nPotato yields in 6 major countries\n    \n\nYield in Tonnes/Hectare\n    \n\n\nCountry\n      2013\n      2014\n      2015\n      2016\n    \n\n\nChina\n17.09\n17.14\n17.27\n17.69\n\n\nIndia\n22.76\n22.92\n23.13\n20.51\n\n\nIndonesia\n16.02\n17.67\n18.20\n18.25\n\n\nMexico\n26.78\n27.34\n27.14\n27.93\n\n\nPakistan\n21.81\n18.15\n23.44\n22.43\n\n\nUnited States\n46.36\n47.15\n46.90\n48.64\n\n\n\n\nTable: @thomas_mock | Data: OurWorldInData.orgInspiration: @jschwabish\n    \n\n\n\n\nAdd a a Footer\nAlternatively, we could also add a footer to explain the yields.\n\nrule1_good %>% \n  tab_footnote(\n    footnote = \"Annual Potato Yield in Tonnes/Hectare\",\n    locations = cells_column_labels(2:5)\n  )\n\n\n\n\n\n\nCountry\n      20131\n\n      20141\n\n      20151\n\n      2016\n    \n\n\nChina\n17.09\n17.14\n17.27\n17.69\n\n\nIndia\n22.76\n22.92\n23.13\n20.51\n\n\nIndonesia\n16.02\n17.67\n18.20\n18.25\n\n\nMexico\n26.78\n27.34\n27.14\n27.93\n\n\nPakistan\n21.81\n18.15\n23.44\n22.43\n\n\nUnited States\n46.36\n47.15\n46.90\n48.64\n\n\n\n\nTable: @thomas_mock | Data: OurWorldInData.orgInspiration: @jschwabish\n    \n\n\n1 Annual Potato Yield in Tonnes/Hectare\n    \n\n\n\n\nRedo an example\nGoing a bit further into our rule 10 examples, while we added some nice color - we could further clarify the percent change, was it the sum of changes? Change from specific years? It was just the change from 2013 vs 2017.\n\nrule10_pct %>% \n  tab_footnote(\n    \"Percent Change: 2013 vs 2017\",\n    locations = cells_column_labels(7)\n  )\n\n\n\n\n\n\n\nCountry\n      \n        Potato Yield in Tonnes/Hectare\n      \n      Percent Change1\n\n    \n\n2013\n      2014\n      2015\n      2016\n      2017\n    \n\n\n\nBrazil\n27.75\n27.94\n29.32\n29.66\n30.94\n11.49\n\n\nChina\n17.09\n17.14\n17.27\n17.69\n18.21\n6.54\n\n\nDenmark\n41.57\n43.12\n41.41\n42.48\n43.68\n5.07\n\n\nEl Salvador\n42.60\n26.25\n26.01\n25.54\n29.22\n−31.41\n\n\nFrance\n43.16\n47.98\n42.51\n38.83\n44.05\n2.06\n\n\nGermany\n39.83\n47.42\n43.81\n44.40\n46.79\n17.48\n\n\nIndia\n22.76\n22.92\n23.13\n20.51\n22.31\n−2.00\n\n\nIndonesia\n16.02\n17.67\n18.20\n18.25\n15.40\n−3.83\n\n\nIreland\n38.33\n40.32\n42.36\n39.11\n44.83\n16.96\n\n\nItaly\n25.25\n26.08\n27.16\n28.44\n27.73\n9.83\n\n\nLebanon\n26.08\n25.23\n24.82\n25.07\n25.14\n−3.60\n\n\nMexico\n26.78\n27.34\n27.14\n27.93\n28.95\n8.12\n\n\nNetherlands\n42.21\n45.66\n42.73\n42.00\n45.97\n8.92\n\n\nPakistan\n21.81\n18.15\n23.44\n22.43\n21.45\n−1.63\n\n\nUnited States\n46.36\n47.15\n46.90\n48.64\n48.39\n4.38\n\n\n\n\nTable: @thomas_mock | Data: OurWorldInData.orgInspiration: @jschwabish\n    \n\n\n1 Percent Change: 2013 vs 2017\n    \n\n\n\n\nWhat about our lovely table that had both column and row summaries? We renamed our column summaries to just Avg. and Avg. - we can assume that the reader understands it is the summary of the columns to their immediate left, but it can be helpful to also explicitly tell the reader what the calculation is. What if the second Avg. was in fact the average from all years (2007 to 2016), rather than just 2012 through 2016?\n\nrule2_tab2 %>% \n  tab_source_note(md(\"**Table**: @thomas_mock | **Data**: OurWorldInData.org<br>**Inspiration**: @jschwabish\")) %>% \n  tab_footnote(\n    footnote = \"Average of 2007 through 2011\",\n    locations = cells_column_labels(vars(avg_07_11))\n  ) %>% \n  tab_footnote(\n    footnote = \"Average of 2012 through 2016\",\n    locations = cells_column_labels(vars(avg_12_16))\n  ) \n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\nCountry\n      2007\n      2008\n      2009\n      2010\n      2011\n      Avg.1\n\n      2012\n      2013\n      2014\n      2015\n      2016\n      Avg.2\n\n    \n\n\nChina\n14.63\n15.18\n14.42\n15.67\n16.28\n15.13\n16.77\n17.09\n17.14\n17.27\n17.69\n16.77\n\n\nIndia\n16.41\n19.30\n18.81\n19.93\n22.72\n19.41\n21.75\n22.76\n22.92\n23.13\n20.51\n21.25\n\n\nIndonesia\n16.09\n16.67\n16.51\n15.94\n15.96\n16.09\n16.58\n16.02\n17.67\n18.20\n18.25\n17.08\n\n\nMexico\n27.06\n27.73\n27.74\n27.76\n26.27\n27.06\n26.81\n26.78\n27.34\n27.14\n27.93\n27.31\n\n\nPakistan\n19.35\n16.46\n20.28\n22.68\n21.92\n20.35\n18.34\n21.81\n18.15\n23.44\n22.43\n20.34\n\n\nUnited States\n44.43\n44.44\n46.44\n44.94\n44.69\n44.43\n45.78\n46.36\n47.15\n46.90\n48.64\n46.78\n\n\nAverage\n23.00\n23.29\n24.03\n24.49\n24.64\n23.75\n24.34\n25.13\n25.06\n26.01\n25.91\n24.92\n\n\n\n\nTable: @thomas_mock | Data: OurWorldInData.orgInspiration: @jschwabish\n    \n\n\n\n1 Average of 2007 through 2011\n    \n\n\n2 Average of 2012 through 2016\n    \n\n\n\n\n\nSo that’s it for now - thanks for reading through and if you have more needs make sure to check out the gt site.\n\n\n\n\n\n\nExpand for Session Info\n\n\n\n\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.0 (2022-04-22)\n os       macOS Monterey 12.2.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       America/Chicago\n date     2022-05-03\n pandoc   2.18 @ /Applications/RStudio.app/Contents/MacOS/quarto/bin/tools/ (via rmarkdown)\n quarto   0.9.294 @ /usr/local/bin/quarto\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version    date (UTC) lib source\n dplyr       * 1.0.8      2022-02-08 [1] CRAN (R 4.2.0)\n forcats     * 0.5.1      2021-01-27 [1] CRAN (R 4.2.0)\n ggplot2     * 3.3.5      2021-06-25 [1] CRAN (R 4.2.0)\n gt          * 0.5.0.9000 2022-04-27 [1] Github (rstudio/gt@0d4c83d)\n purrr       * 0.3.4      2020-04-17 [1] CRAN (R 4.2.0)\n readr       * 2.1.2      2022-01-30 [1] CRAN (R 4.2.0)\n sessioninfo * 1.2.2      2021-12-06 [1] CRAN (R 4.2.0)\n stringr     * 1.4.0      2019-02-10 [1] CRAN (R 4.2.0)\n tibble      * 3.1.6      2021-11-07 [1] CRAN (R 4.2.0)\n tidyr       * 1.2.0      2022-02-01 [1] CRAN (R 4.2.0)\n tidyverse   * 1.3.1      2021-04-15 [1] CRAN (R 4.2.0)\n\n [1] /Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/library\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "posts/2020-08-28-heatmaps-in-ggplot2/index.html",
    "href": "posts/2020-08-28-heatmaps-in-ggplot2/index.html",
    "title": "Heatmaps in ggplot2",
    "section": "",
    "text": "Many thanks to Ethan Douglas for sharing his heatmap python code on OpenSource Football! 1 This is a similar walkthrough to Ethan’s post, but in R + ggplot2. Additionally, credit for both collecting the data and the original plot go to Ethan.1 Douglas (2020, Aug. 21). Open Source Football: NFL Pass Location Visualization. Retrieved from https://mrcaseb.github.io/open-source-football/posts/2020-08-22-nfl-pass-location-visualization/"
  },
  {
    "objectID": "posts/2020-08-28-heatmaps-in-ggplot2/index.html#load-everything",
    "href": "posts/2020-08-28-heatmaps-in-ggplot2/index.html#load-everything",
    "title": "Heatmaps in ggplot2",
    "section": "Load Everything",
    "text": "Load Everything\n\nlibrary(tidyverse) # all the things\nlibrary(ggExtra)   # marginal plots\nlibrary(ggtext)    # color your text\nlibrary(patchwork) # combine multiple plots\nlibrary(paletteer) # get all the color palettes\nlibrary(scales)    # helper functions from ggplot2\n\n\nsouce_url <- \"https://raw.githubusercontent.com/ArrowheadAnalytics/next-gen-scrapy-2.0/master/pass_and_game_data.csv\"\n\npass_map_df <- read_csv(souce_url) %>%\n  na.omit()\n\nglimpse(pass_map_df)\n\nRows: 37,408\nColumns: 42\n$ posteam          <chr> \"BAL\", \"BAL\", \"BAL\", \"BAL\", \"BAL\", \"BAL\", \"BAL\", \"BAL…\n$ week             <dbl> 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 1…\n$ name             <chr> \"Joseph Flacco\", \"Joseph Flacco\", \"Joseph Flacco\", \"J…\n$ pass_type        <chr> \"COMPLETE\", \"COMPLETE\", \"COMPLETE\", \"COMPLETE\", \"COMP…\n$ x                <dbl> 1.4, 12.6, -11.1, 18.3, 9.6, -13.8, -4.4, 17.1, -20.0…\n$ y                <dbl> 2.0, -6.6, -0.1, 8.1, 1.9, 12.1, 6.8, -4.4, 2.3, 14.1…\n$ season           <dbl> 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017,…\n$ game_id          <chr> \"2017_12_HOU_BAL\", \"2017_12_HOU_BAL\", \"2017_12_HOU_BA…\n$ game_type        <chr> \"REG\", \"REG\", \"REG\", \"REG\", \"REG\", \"REG\", \"REG\", \"REG…\n$ gameday          <date> 2017-11-27, 2017-11-27, 2017-11-27, 2017-11-27, 2017…\n$ weekday          <chr> \"Monday\", \"Monday\", \"Monday\", \"Monday\", \"Monday\", \"Mo…\n$ gametime         <time> 20:30:00, 20:30:00, 20:30:00, 20:30:00, 20:30:00, 20…\n$ away_team        <chr> \"HOU\", \"HOU\", \"HOU\", \"HOU\", \"HOU\", \"HOU\", \"HOU\", \"HOU…\n$ away_score       <dbl> 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 1…\n$ home_team        <chr> \"BAL\", \"BAL\", \"BAL\", \"BAL\", \"BAL\", \"BAL\", \"BAL\", \"BAL…\n$ home_score       <dbl> 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 2…\n$ location         <chr> \"Home\", \"Home\", \"Home\", \"Home\", \"Home\", \"Home\", \"Home…\n$ result           <dbl> 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,…\n$ total            <dbl> 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 3…\n$ overtime         <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ old_game_id      <dbl> 2017112700, 2017112700, 2017112700, 2017112700, 20171…\n$ away_rest        <dbl> 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,…\n$ home_rest        <dbl> 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,…\n$ away_moneyline   <dbl> 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311…\n$ home_moneyline   <dbl> -357, -357, -357, -357, -357, -357, -357, -357, -357,…\n$ spread_line      <dbl> 7.5, 7.5, 7.5, 7.5, 7.5, 7.5, 7.5, 7.5, 7.5, 7.5, 7.5…\n$ away_spread_odds <dbl> -103, -103, -103, -103, -103, -103, -103, -103, -103,…\n$ home_spread_odds <dbl> -107, -107, -107, -107, -107, -107, -107, -107, -107,…\n$ total_line       <dbl> 39.5, 39.5, 39.5, 39.5, 39.5, 39.5, 39.5, 39.5, 39.5,…\n$ under_odds       <dbl> -102, -102, -102, -102, -102, -102, -102, -102, -102,…\n$ over_odds        <dbl> -108, -108, -108, -108, -108, -108, -108, -108, -108,…\n$ div_game         <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ roof             <chr> \"outdoors\", \"outdoors\", \"outdoors\", \"outdoors\", \"outd…\n$ surface          <chr> \"grass\", \"grass\", \"grass\", \"grass\", \"grass\", \"grass\",…\n$ temp             <dbl> 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 5…\n$ wind             <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ away_coach       <chr> \"Bill O'Brien\", \"Bill O'Brien\", \"Bill O'Brien\", \"Bill…\n$ home_coach       <chr> \"John Harbaugh\", \"John Harbaugh\", \"John Harbaugh\", \"J…\n$ referee          <chr> \"Brad Allen\", \"Brad Allen\", \"Brad Allen\", \"Brad Allen…\n$ stadium_id       <chr> \"BAL00\", \"BAL00\", \"BAL00\", \"BAL00\", \"BAL00\", \"BAL00\",…\n$ stadium          <chr> \"M&T Bank Stadium\", \"M&T Bank Stadium\", \"M&T Bank Sta…\n$ defteam          <chr> \"HOU\", \"HOU\", \"HOU\", \"HOU\", \"HOU\", \"HOU\", \"HOU\", \"HOU…"
  },
  {
    "objectID": "posts/2020-08-28-heatmaps-in-ggplot2/index.html#why-not-just-plot-the-points",
    "href": "posts/2020-08-28-heatmaps-in-ggplot2/index.html#why-not-just-plot-the-points",
    "title": "Heatmaps in ggplot2",
    "section": "Why not just plot the points?",
    "text": "Why not just plot the points?\nWhy even mess around with heatmaps or 2d density plots? Well, we run the risk of overplotting by graphing just the points without thinking or adjusting any of the aesthetics.\nHadley Wickham in ggplot2: Elegant Graphics for Data Analysis:\n\nWhen the data is large, points will be often plotted on top of each other, obscuring the true relationship. In extreme cases, you will only be able to see the extent of the data, and any conclusions drawn from the graphic will be suspect. This problem is called overplotting.\n\nHadley uses an example with just 2000 data points, which already has a lot of overplotting due to a small sample x-y space. We have about 43,000 passes for this dataset, spread out over a relatively large space. We still need to be careful of overplotting though!\n\n\nData to Viz and Clause Wilke have good writeups on overplotting as well\nClaus Wilke | Fundamentals of Data Visualization3\n3 https://clauswilke.com/dataviz/While it’s not really focused on the problem at hand, Claus Wilke has a wonderful book on the Fundaments of Data Visualization. His chapters below are applicable and very helpful for best practices:\n\n\nVisualizing Distributions - Histograms and density plots\n\nMain idea here is potentially overlapping plots to see where differences arise. Code adapted from Claus Wilke’s source code. 44 https://github.com/clauswilke/dataviz/blob/master/visualizing_distributions_I.Rmd#L303-L323\n\npass_map_df %>% \n  filter(str_detect(name, \"Derek Carr|Mahomes\")) %>% \n  mutate(name = factor(name)) %>% \n  ggplot() +\n  geom_density(aes(x = y, y = ..count.., fill = name, color = name),\n               alpha = 0.5) +\n  geom_vline(xintercept = 5, color = \"red\", size = 1, alpha = 0.5) +\n  coord_cartesian(xlim = c(-10, 40)) +\n  scale_x_continuous(breaks = seq(-10, 40, 5), name = \"Yardline\") +\n  scale_y_continuous(breaks = seq(0, 100, 10), name = \"scaled density\") +\n  scale_fill_manual(values = c(\"#0072B2\", \"#D55E00\"), name = \"QB\") +\n  scale_color_manual(values = scales::muted(c(\"#0072B2\", \"#D55E00\")), name = \"QB\") +\n  guides(fill = guide_legend(override.aes = list(linetype = 0))) +\n  theme_minimal() +\n  theme(\n    axis.line.x = element_blank(),\n    legend.position = c(.9, .87),\n    legend.justification = c(\"right\", \"top\"),\n    legend.box.background = element_rect(fill = \"white\", color = \"white\"),\n    plot.margin = margin(3, 7, 3, 1.5)\n  )\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\nWarning: The dot-dot notation (`..count..`) was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(count)` instead.\n\n\n\n\n\n\n\nVisualizing many distributions at once - Plotting multiple or many distributions at once, and introduces the ggridges package\n\nMain idea here is overlapping many distributions at once, to see general trends or differences.\nggridges has a vignette on now to use it, but here’s a minimal example with the data at hand. Note that we are doing 1 dimensional density, so we could use this with nflfastR data as well!\n\nlibrary(ggridges)\n\npass_map_df %>% \n  filter(str_detect(name, \"Wilson|Mahomes|Prescott|Watson|Rodgers\")) %>% \n  mutate(name = word(name, 2)) %>% \n  ggplot(aes(x = y, group = name, y = name)) +\n  stat_density_ridges(quantile_lines = TRUE, quantiles = 2, scale = 2) +\n  theme_ridges() +\n  scale_x_continuous(breaks = seq(-10, 60, 10), name = \"Yardline\") +\n  labs(y = \"\")\n\nPicking joint bandwidth of 2.1\n\n\nWarning: Using the `size` aesthietic with geom_segment was deprecated in ggplot2 3.4.0.\nℹ Please use the `linewidth` aesthetic instead.\n\n\n\n\n\n\n\nHandling overlapping points - Dealing with overplotting with small data or big data\n\nWe create some bins and then plot the data for Mahomes. Here the data is relatively small, but still stacks.\n\nbin_data <- pass_map_df %>% \n  filter(str_detect(name, \"Mahomes\"), between(y, -5, 20)) %>% \n  # create 5 yard bins on y axis\n  mutate(y_bins = y - y %% 5) \n\nbin_data %>% \n  ggplot(aes(x = x, y = y_bins)) +\n  geom_point() +\n  scale_y_continuous(breaks = seq(-5, 20, 5))\n\n\n\n\nWe can add transparency with alpha along with geom_jitter() to add some random noise in the y-direction w/ height. Note that this is kind of a silly example since we have x and y coords, but you can imagine a situation where you only have binned data or like nflfastR you have large bins (left, middle right and short, long).\n\nbin_data %>% \n  ggplot(aes(x = x, y = y_bins)) +\n  geom_jitter(height = 0.3, alpha = 0.5) +\n  scale_y_continuous(breaks = seq(-5, 20, 5))\n\n\n\n\nClaus then goes on to cover details with geom_bin_2d(), geom_hex(), and geom_contour(), still worth reading but stuff we’ve covered in the bulk of this post. Again, Claus’ book is amazing, and a great resource regardless of what software you are plotting in. He used R, but intentionally left out code and focused on concepts.\nFear the beard\nWe can display our points with a quick geom_point() call but this returns a lot of overplotting albeit in a happy beard shape!\n\npass_map_df %>%\n  ggplot(aes(x = x, y = y)) +\n  geom_point()\n\n\n\n\nWe can add 90% transparency with alpha = 0.1 or set alpha as uirea ratio, and change the color to red, but this still leaves us with difficulty parsing through the high vs medium pass locations. Although the 1/20 ratio gets us a bit farther. The ratio denominator can be though of as the “number of points that must overplotted to give a solid color.” 55 https://ggplot2-book.org/statistical-summaries.html#overplotting\nPasses around the 5 yard mark appear to be as common as at the 10 and even 20 yard mark in some cases! We know this isn’t true from nflfastR data. Maybe we can try to get closer views of the actual distributions with ggMarginal from the ggExtra R package, which provides marginal histograms, box plots, or density plots.\n\nred_beard <- pass_map_df %>%\n  ggplot(aes(x = x, y = y)) +\n  geom_point(alpha = 0.1, color = \"red\") +\n  labs(title = \"Alpha = 0.1 or 90% transparency\")\n\nred_beard_ratio <- pass_map_df %>%\n  ggplot(aes(x = x, y = y)) +\n  geom_point(alpha = 1/20, color = \"red\") +\n  labs(title = \"Alpha = 1/20, so 20 points must be stacked to give solid color\")\n\n\nred_beard + red_beard_ratio\n\n\n\n\nWe can add some marginal plots to help out a bit, but that still doesn’t solve the problem of honing in on specific areas of interest that well.\n\n# add density or histogram in the margins\nggMarginal(red_beard, type = \"density\", fill = \"red\")\n\n\n\n\n\n# add density or histogram in the margins\nggMarginal(red_beard, type = \"histogram\", fill = \"red\")"
  },
  {
    "objectID": "posts/2020-08-28-heatmaps-in-ggplot2/index.html#d-density-alternatives",
    "href": "posts/2020-08-28-heatmaps-in-ggplot2/index.html#d-density-alternatives",
    "title": "Heatmaps in ggplot2",
    "section": "2D Density Alternatives",
    "text": "2D Density Alternatives\nSince we’re actually interested in the density/counts of observations at each x-y coordinate instead of plotting each individual point, we also have a few other tools in our toolbox! We can use geom_hex() or geom_bin_2d(). Note that there are a few other methods such as geom_raster() which require you to provide your own “z” metric, and there are stat_? versions of each of these geoms for more custom calculations.\n\n\nIf you read the ggplot2 + overplotting ggplot2 book chapter, you can find more reproducible longer form examples and strategies with geom_raster() and geom_bin_2d().\n\nraster_plot <- pass_map_df |> \n  mutate(x = round(x),\n         y = round(y)) |> \n  group_by(x,y) |> \n  count() |> \n  ggplot(aes(x =x, y = y, fill = n)) +\n  geom_raster() +\n  scale_fill_gradient(low = \"red\", high = \"yellow\") +\n  geom_hline(yintercept = c(2, 7), color = \"grey\") +\n  scale_y_continuous(breaks = seq(-10, 60, 5))\n\n\nraster_plot\n\n\n\nbin2d <- pass_map_df %>%\n  ggplot(aes(x = x, y = y)) +\n  geom_bin_2d(\n    binwidth = c(1, 1)\n  ) +\n  scale_fill_gradient(low = \"red\", high = \"yellow\") +\n  geom_hline(yintercept = c(2, 7), color = \"grey\") +\n  scale_y_continuous(breaks = seq(-10, 60, 5))\n\nbin2d\n\n\n\n\nWe can now see that while there ARE passes all over the field, the majority are around the 2-7 yard mark with small but relatively dense pockets elsewhere. Passes are most frequently thrown at 4, 5 or 6 yards and ~68% of passes are thrown 10 yards or shorter.\n\n# histogram of just Y coord\npass_map_df %>%\n  ggplot(aes(x = y)) +\n  geom_histogram(binwidth = 1) +\n  geom_vline(xintercept = c(5)) +\n  scale_x_continuous(breaks = seq(-10, 60, 5))\n\n\n\n# calc some percentages\npass_by_y <- pass_map_df %>%\n  mutate(y_rnd = round(y, digits = 0)) %>%\n  count(y_rnd) %>%\n  mutate(\n    total = sum(n),\n    pct_total = n / total,\n    roll_total = cumsum(pct_total)\n  )\n\n# ~35.6% of passes between 2-7 yards\npass_by_y %>%\n  filter(between(y_rnd, 2, 7)) %>%\n  summarize(pct = sum(pct_total))\n\n# A tibble: 1 × 1\n    pct\n  <dbl>\n1 0.346\n\n# passes are most commonly thrown at 4-6 yards\n# 68% of passes are thrown 10 yards or shorter\npass_by_y %>%\n  arrange(desc(pct_total))\n\n# A tibble: 67 × 5\n   y_rnd     n total pct_total roll_total\n   <dbl> <int> <int>     <dbl>      <dbl>\n 1     4  2732 37408    0.0730      0.409\n 2     5  2528 37408    0.0676      0.477\n 3     6  2399 37408    0.0641      0.541\n 4     2  2103 37408    0.0562      0.286\n 5     3  1879 37408    0.0502      0.336\n 6     1  1476 37408    0.0395      0.230\n 7     0  1365 37408    0.0365      0.190\n 8     7  1320 37408    0.0353      0.576\n 9     8  1297 37408    0.0347      0.611\n10    12  1226 37408    0.0328      0.730\n# … with 57 more rows\n\n\nDon’t bury the lede?\nAnother major advantage of geom_hex or geom_bin_2d() is they’re remarkably faster for big data than plotting geom_point() along with reducing the likelihood of overplotting! For a toy example of about 1.7 million points, geom_hex() executes in about 2 sec vs 20 sec with geom_point(), and then subsequent 30-60 sec to “draw” the output in the viewer of R/RStudio.\n\n\nUsing these techniques are useful, as they are both computationally helpful (aka faster), and can help you better understand plots of “bigger” data."
  },
  {
    "objectID": "posts/2020-08-28-heatmaps-in-ggplot2/index.html#d-density-of-smaller-data",
    "href": "posts/2020-08-28-heatmaps-in-ggplot2/index.html#d-density-of-smaller-data",
    "title": "Heatmaps in ggplot2",
    "section": "2D Density of “smaller” data",
    "text": "2D Density of “smaller” data\nSo we’ve covered hex and rectangular 2d bins. To me, these are not as attractive for “small data” like we may see for individual QB plots. Let’s take Patrick Mahomes for example, he only has ~1,000 passes in this dataset. We can plot with a geom_hex() for each 1x1 yard chunk like we did before, but I honestly have trouble determining trends of where he likes to throw with that graphic.\n\npass_map_df %>%\n  filter(str_detect(name, c(\"Mahomes\"))) %>%\n  ggplot(aes(x = x, y = y)) +\n  geom_bin_2d(binwidth = c(1, 1)) +\n  scale_y_continuous(breaks = seq(-10, 60, 5))\n\n\n\n\nWe could always use larger bins, but if we’re just trying to see large trends we have another strategy in geom_density_2d().\n\nPerform a 2D kernel density estimation using MASS::kde2d() and display the results with contours. This can be useful for dealing with overplotting. This is a 2D version of geom_density(). geom_density_2d() draws contour lines, and geom_density_2d_filled() draws filled contour bands.\n\nThis essentially fits a polygon around the most frequent points by x/y coordinates, and then colors them according to density. In this case, x/y is basically the position on the field and “z” is the density of how many plots were thrown to that area.\n\npass_map_df %>%\n  filter(str_detect(name, c(\"Mahomes\"))) %>%\n  ggplot(aes(x = x, y = y)) +\n  geom_density_2d_filled() +\n  scale_y_continuous(breaks = seq(-10, 60, 5))\n\n\n\n\nNow if we want to get even more clever, we can use this compare passing heatmaps of specific QBs. We can normalize across the facets, and drop the least frequent passes with specific breaks. I’ve binned into 10 specific breakpoints, and by setting breaks between 0.1 and 1.0, we also drop the very least frequent passes which otherwise show up as a light fill of the entire remaining plot. Additionally, by adding a horizontal reference line we can pretty clearly see that Carr’s most common passes are behind the 5 yard line, while Mahomes has passed beyond the 5 yard line much more frequently.\n\npass_map_df %>%\n  filter(str_detect(name, c(\"Mahomes|Derek Carr\"))) %>%\n  ggplot(aes(x = x, y = y)) +\n  geom_density_2d_filled(\n    aes(fill = ..level..),\n    contour_var = \"ndensity\", # normalize to each QBs total passes\n    breaks = seq(0.1, 1.0, length.out = 10) # drop the lowest passes\n  ) +\n  scale_y_continuous(breaks = seq(-10, 60, 5)) +\n  facet_wrap(~name) +\n  geom_hline(yintercept = 5)\n\n\n\n\nThis is all well and good, but it’s not the prettiest piece of dataviz.\nThanks again to Ethan Douglas and his post on OpenSourceFootball.com 6, we have a good framework about how to approach building a NFL field as a graph.6 Douglas (2020, Aug. 21). Open Source Football: NFL Pass Location Visualization. Retrieved from https://mrcaseb.github.io/open-source-football/posts/2020-08-22-nfl-pass-location-visualization/"
  },
  {
    "objectID": "posts/2020-08-28-heatmaps-in-ggplot2/index.html#build-the-field",
    "href": "posts/2020-08-28-heatmaps-in-ggplot2/index.html#build-the-field",
    "title": "Heatmaps in ggplot2",
    "section": "Build the field",
    "text": "Build the field\n\nnot_div_5 <- function(x) {\n  # select only elements of the vector not divisible by 5\n  x[x %% 5 != 0]\n}\n\ncenter_df <- tibble(\n  x = c(rep(-3.1, 60), rep(3.1, 60)),\n  y = seq(-14, 59, 1) %>% rep(2) %>% not_div_5(),\n  text = \"--\"\n)\n\n# line labels\nannotate_df <- tibble(\n  x = c(12.88, -12.88) %>% rep(each = 5),\n  y = seq(10, 50, 10) %>% rep(2),\n  text = seq(10, 50, 10) %>% rep(2) %>% str_replace(\"(.)(.)\", \"\\\\1 \\\\2\"),\n  rotation = c(90, 270) %>% rep(each = 5)\n)\n\n# yardlines\nyardline_df <- tibble(\n  y = seq(-15, 60, 5),\n  yend = seq(-15, 60, 5),\n  x = rep(-56 / 2, 16),\n  xend = rep(56 / 2, 16)\n)\n\n# sidelines\nsideline_df <- tibble(\n  y = c(-15.15, -15.15),\n  yend = c(60.15, 60.15),\n  x = c(-56 / 2, 56 / 2),\n  xend = c(-56 / 2, 56 / 2)\n)\n\nAfter building some datasets, we can now plot just the field without any other data. This looks nice enough, but I don’t want to copy paste it for all the remaining examples, so let’s try putting it into a function that we can call with + add_field()!\n\nggplot(data = NULL, aes(x = x, y = y)) +\n  coord_cartesian(\n    xlim = c(-53.333 / 2, 53.333 / 2),\n    ylim = c(-15, 60)\n  ) +\n  geom_text(\n    data = annotate_df, aes(label = text, angle = rotation),\n    color = \"black\", size = 8\n  ) +\n  geom_segment(\n    data = yardline_df, color = \"black\", size = 1,\n    aes(x = x, y = y, xend = xend, yend = yend)\n  ) +\n  geom_segment(\n    x = -56 / 2, y = 0, xend = 56 / 2, yend = 0,\n    color = \"blue\", size = 1, alpha = 0.5\n  ) +\n  geom_segment(\n    data = sideline_df, color = \"black\", size = 2,\n    aes(x = x, y = y, xend = xend, yend = yend)\n  ) +\n  geom_text(\n    data = center_df,\n    aes(label = text), color = \"black\", vjust = 0.32\n  ) +\n  theme_void()\n\n\n\n\nWrap the field in a function\nWe can turn this into a function so that we don’t have to copy-paste it all over the place. Note that I’m wrapping it in a list so I can use it with + in a sequence of ggplot2 calls.\nI’m also using front_col and back_col to let us switch from white on black to black on white if needed.\n\nadd_field <- function() {\n  list(\n    coord_cartesian(\n      xlim = c(-53.333 / 2, 53.333 / 2),\n      ylim = c(-15, 60)\n    ),\n    geom_text(\n      data = annotate_df, aes(label = text, angle = rotation),\n      color = front_col, size = 8\n    ),\n    geom_segment(\n      data = yardline_df, color = front_col, size = 1,\n      aes(x = x, y = y, xend = xend, yend = yend)\n    ),\n    geom_segment(\n      x = -56 / 2, y = 0, xend = 56 / 2, yend = 0,\n      color = \"blue\", size = 1, alpha = 0.5\n    ),\n    geom_segment(\n      data = sideline_df, color = front_col, size = 2,\n      aes(x = x, y = y, xend = xend, yend = yend)\n    ),\n    geom_text(\n      data = center_df,\n      aes(label = text), color = front_col, vjust = 0.32\n    ),\n    theme_void(),\n    theme(\n      strip.text = element_text(size = 20, color = front_col),\n      plot.background = element_rect(fill = back_col, color = NA),\n      legend.position = \"none\",\n      plot.margin = unit(c(2, 1, 0.5, 1), unit = \"cm\"),\n      plot.caption = element_text(color = front_col),\n      plot.title = element_text(color = front_col),\n      plot.subtitle = element_text(color = front_col),\n      panel.background = element_rect(fill = back_col, color = NA),\n      panel.border = element_blank()\n    )\n  )\n}\n\nQB Comparison\nFirst let’s filter down to just our two QBs to compare, Patrick Mahomes and Russell Wilson.\n\npasser_df <- pass_map_df %>%\n  filter(str_detect(name, c(\"Mahomes|Russell\"))) %>%\n  mutate(name = factor(name, levels = c(\"Patrick Mahomes\", \"Russell Wilson\"))) %>%\n  select(name, x, y)\n\npasser_df %>%\n  ggplot(aes(x = x, y = y)) +\n  geom_density2d_filled() +\n  theme(legend.position = \"none\")\n\n\n\n\nWe’ll specify fill and color to both scale with the level/density and normal density peaks across our plots, and finally set our breaks to drop the lowest bin of passes.\n\npass_map <- passer_df %>%\n  ggplot(aes(x = x, y = y)) +\n  geom_density_2d_filled(\n    aes(fill = ..level.., color = ..level..),\n    contour_var = \"ndensity\", # normalize across facets\n    breaks = seq(0.1, 1.0, length.out = 10)\n  ) +\n  facet_wrap(~name)\n\npass_map\n\n\n\n\nWe can quickly add the field background to this with our function add_field()!\n\nback_col <- \"white\"\nfront_col <- \"black\"\n\npass_map +\n  add_field()"
  },
  {
    "objectID": "posts/2020-08-28-heatmaps-in-ggplot2/index.html#specify-color-schemes",
    "href": "posts/2020-08-28-heatmaps-in-ggplot2/index.html#specify-color-schemes",
    "title": "Heatmaps in ggplot2",
    "section": "Specify Color schemes",
    "text": "Specify Color schemes\nWhile that’s essentially our final graph perhaps you don’t want to use viridis which is the default color scheme. We can generate custom color palettes or use a pre-built color palette via the paleteer R package. Note that the 3 color palettes I create all do essentially the same thing but it’s:\n\nBuilding your own custom color sequence with grDevices::colorRampPalette()\n\nReturning a pre-built palette w/ paletteer::paletteer_d()\n\nExpanding a pre-built palette to be longer with colorRampPalette\n\n\n\nheat_colors <- grDevices::colorRampPalette(c(\"#800026FF\", \"#FC4E2AFF\", \"#FEB24CFF\", \"#FFFFCCFF\"))(10)\n\nheat_palette <- paletteer::paletteer_d(\"RColorBrewer::YlOrRd\", n = 9, direction = -1)\n\nheat_colors_interpolated <- colorRampPalette(paletteer::paletteer_d(\"RColorBrewer::YlOrRd\", n = 9, direction = -1))(10)\n\nheat_colors %>% scales::show_col()\n\n\n\nheat_palette %>% scales::show_col()\n\n\n\nheat_colors_interpolated %>% scales::show_col()\n\n\n\n\n\npass_map +\n  add_field() +\n  scale_fill_manual(values = c(heat_colors_interpolated), aesthetics = c(\"fill\", \"color\"))\n\n\n\n\nAnd also in black!\n\nback_col <- \"black\"\nfront_col <- \"white\"\n\npass_map +\n  add_field() +\n  scale_fill_manual(values = c(heat_colors_interpolated), aesthetics = c(\"fill\", \"color\"))"
  },
  {
    "objectID": "posts/2020-08-28-heatmaps-in-ggplot2/index.html#pff_moo-style-field",
    "href": "posts/2020-08-28-heatmaps-in-ggplot2/index.html#pff_moo-style-field",
    "title": "Heatmaps in ggplot2",
    "section": "PFF_Moo style Field",
    "text": "PFF_Moo style Field\nPFF_Moo takes a different approach to field lines, which can be recreated below. 77 https://twitter.com/PFF_Moo/status/1235681100837486592?s=20\n\nnot_div_5 <- function(x) {\n  # select only elements of the vector not divisible by 5\n  x[x %% 5 != 0]\n}\n\ncenter_df <- tibble(\n  x = c(rep(-3.1, 60), rep(3.1, 60)),\n  y = seq(-14, 59, 1) %>% rep(2) %>% not_div_5(),\n  text = \"--\"\n)\n\n# line labels\nhoriz_yd_df <- tibble(\n  x = c(12.88, -12.88) %>% rep(each = 14),\n  y = seq(-10, 55, 5) %>% rep(2),\n  text = seq(-10, 55, 5) %>% rep(2)\n)\n\n# yardlines\nyardline_df <- tibble(\n  y = seq(-15, 60, 5),\n  yend = seq(-15, 60, 5),\n  x = rep(-56 / 2, 16),\n  xend = rep(56 / 2, 16)\n)\n\n# sidelines\nsideline_df <- tibble(\n  y = c(-15.15, -15.15),\n  yend = c(60.15, 60.15),\n  x = c(-56.5 / 2, 56.5 / 2),\n  xend = c(-56.5 / 2, 56.5 / 2)\n)\n\nadd_moo_field <- function() {\n  list(\n    coord_cartesian(\n      xlim = c(-53.333/2, 53.333/2),\n      ylim = c(-15, 60)\n    ),\n    geom_segment(\n      data = yardline_df, color = front_col, size = 0.5,\n      linetype = \"dashed\", alpha = 0.5,\n      aes(x = x, y = y, xend = xend, yend = yend)\n    ),\n    geom_segment(\n      aes(x = -56 / 2, y = 0, xend = 56 / 2, yend = 0),\n      color = \"blue\", size = 1\n    ),\n    geom_segment(\n      data = sideline_df, color = front_col, size = 2,\n      aes(x = x, y = y, xend = xend, yend = yend)\n    ),\n    geom_text(\n      data = center_df,\n      aes(label = text), color = front_col, vjust = 0.32\n    ),\n    geom_text(\n      data = horiz_yd_df, aes(label = text),\n      color = front_col, size = 4, fontface = \"bold\"\n    ),\n    theme_void(),\n    theme(\n      strip.text = element_text(size = 20, color = front_col),\n      plot.background = element_rect(fill = back_col, color = NA),\n      legend.position = \"none\",\n      plot.margin = unit(c(2, 1, 0.5, 1), unit = \"cm\"),\n      plot.caption = element_text(color = front_col),\n      plot.title = element_text(color = front_col),\n      plot.subtitle = element_text(color = front_col),\n      panel.background = element_rect(fill = back_col, color = NA),\n      panel.border = element_blank()\n    )\n  )\n}\n\nback_col <- \"white\"\nfront_col <- \"black\"\n\n\nggplot(pass_map_df, aes(x = x, y = y)) +\n  geom_density_2d_filled(\n    aes(fill = ..level..),\n    contour_var = \"ndensity\", # normalize to each QBs total passes\n    breaks = seq(0.1, 1.0, length.out = 10) # drop the lowest passes\n  ) +\n  add_moo_field()"
  },
  {
    "objectID": "posts/2020-08-28-heatmaps-in-ggplot2/index.html#get-the-raw-density-estimates",
    "href": "posts/2020-08-28-heatmaps-in-ggplot2/index.html#get-the-raw-density-estimates",
    "title": "Heatmaps in ggplot2",
    "section": "Get the raw density estimates",
    "text": "Get the raw density estimates\nLastly, we can also get the raw density measures to use against the points for example or for other more computational measures as opposed to just graphics. 8 Note that this is for ALL the QBs at once.8 Function adapted from Kamil Slowikowski\n\nget_density <- function(x, y, ...) {\n  density_out <- MASS::kde2d(x, y, ...)\n  int_x <- findInterval(x, density_out$x)\n  int_y <- findInterval(y, density_out$y)\n  comb_int <- cbind(int_x, int_y)\n  return(density_out$z[comb_int])\n}\n\ndensity_map <- pass_map_df %>% \n  select(x, y, name) %>% \n  # function works in dplyr!\n  mutate(density = get_density(x, y, n = 100))\n\ndensity_map %>% \n  ggplot(aes(x = x, y = y, color = density)) +\n  geom_point(alpha = 0.2) +\n  scale_color_gradient(low = \"red\", high = \"yellow\")\n\n\n\n\n\n\nHere’s the bin2d plot for comparison:\n\n\n\n\n\nCompare 2D Density\nNow for this, we’re actually creating two separate 2 dimensional density estimates, and then subtracting the density of QB2’s passes from QB1’s.\nThis requires us to play around a bit more with matrices, which is a good exercise! I’m going to keep working to see if this could fit into a tibble oriented workflow, but so far it’s a matrix up to the end. Credit to eipi10 for code I adapted from Stack Overflow. 99 https://stackoverflow.com/questions/28521145/r-calculate-and-plot-difference-between-two-density-countours\n\nqb_density_compare <- function(pass_df, qb1_name, qb2_name, n = 200){\n  \n  # filter to qb1\n  qb1 <- pass_df %>% \n    select(x, y, name) %>% \n    filter(str_detect(name, qb1_name))\n  \n  #filter to qb2\n  qb2 <- pass_df %>% \n    select(x, y, name) %>% \n    filter(str_detect(name, qb2_name))\n  \n  # get x/y coords as vectors\n  qb1_x <- pull(qb1, x)\n  qb1_y <- pull(qb1, y)\n  \n  # get x/y coords as vectors\n  qb2_x <- pull(qb2, x)\n  qb2_y <- pull(qb2, y)\n\n  # get x and y range to compute comparisons across\n  x_rng = range(c(qb1_x, qb2_x))\n  y_rng = range(c(qb1_y, qb2_y))\n  \n  # Explicitly calculate bandwidth for future use\n  bandwidth_x <- MASS::bandwidth.nrd(c(qb1_x, qb2_x))\n  bandwidth_y <- MASS::bandwidth.nrd(c(qb1_y, qb2_y))\n  \n  bandwidth_calc <- c(bandwidth_x, bandwidth_y)\n  \n  # Calculate the 2d density estimate over the common range\n  d2_qb1 = MASS::kde2d(qb1_x, qb1_y, h = bandwidth_calc, n=n, lims=c(x_rng, y_rng))\n  d2_qb2 = MASS::kde2d(qb2_x, qb2_y, h = bandwidth_calc, n=n, lims=c(x_rng, y_rng))\n  \n  # create diff df\n  qb_diff <- d2_qb1\n  \n  # matrix subtraction density from qb2 from qb1\n  qb_diff$z <- d2_qb1$z - d2_qb2$z\n  \n  # add matrix col names\n  colnames(qb_diff$z) = qb_diff$y\n  \n  #### return tidy tibble ####\n  qb_diff$z %>% \n    # each col_name is actually the y from the matrix\n    as_tibble() %>% \n    # add back the x\n    mutate(x= qb_diff$x) %>% \n    pivot_longer(-x, names_to = \"y\", values_to = \"z\") %>% \n    mutate(y = as.double(y),\n           bandwidth = list(bandwidth_calc),\n           comparison = glue::glue(\"{qb1_name} (QB1) vs {qb2_name} (QB2)\"))\n\n}\n\nCall the function\nNow we can just call the function to generate a beautiful dataset to plot or work with!\nLet’s compare… Mahomes vs Rodgers.\n\ncompared_z <- qb_density_compare(pass_map_df, \"Mahomes\", \"Rodgers\", n = 200) \n\n(compared_plot <- compared_z %>% \n  ggplot(aes(x, y)) +\n  \n  # add core heatmap - note that geom_raster or geom_tile both work\n  geom_raster(aes(x, y, fill=z))  +\n  \n  # add contour polygon lines around the most dense points\n  stat_contour(aes(color=..level.., z = z)) +\n  \n  # add a fill gradient from low (blue) to high (red) \n  # with white as the zero midpoint\n  scale_fill_gradient2(low=\"blue\",mid=\"white\", high=\"red\", midpoint=0) +\n  scale_color_gradient2(low=\"blue\", mid=\"white\", high=\"red\", midpoint=0) +\n  # drop the legends\n  guides(color=FALSE, fill = FALSE) +\n  add_moo_field() +\n  labs(title = unique(compared_z$comparison),\n       subtitle = \"Color is more passes by <span style='color:red'>**QB1**</span> or by <span style='color:blue'>**QB2**</span>\",\n       caption = \"Plot: @thomas_mock | Data: @ChiefsAnalytics\")) +\n  # add some customizations to the plot\n  theme(legend.position = \"top\", legend.key.width = unit(2, \"cm\"),\n        plot.title = element_text(size = 20, hjust = 0.5, face = \"bold\"),\n        plot.subtitle = element_markdown(size = 12, hjust = 0.5),\n        plot.caption = element_text(face = \"bold\")) \n\nWarning: The `<scale>` argument of `guides()` cannot be `FALSE`. Use \"none\" instead as\nof ggplot2 3.3.4.\n\n\n\n\n\nTry it out for yourself!\n\n\n\n\n\n\nExpand for Session Info\n\n\n\n\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.0 (2022-04-22)\n os       macOS Monterey 12.6\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       America/Chicago\n date     2022-11-10\n pandoc   2.19.2 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/ (via rmarkdown)\n quarto   1.2.242 @ /usr/local/bin/quarto\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version    date (UTC) lib source\n dplyr       * 1.0.10     2022-09-01 [1] CRAN (R 4.2.0)\n forcats     * 0.5.1      2021-01-27 [1] CRAN (R 4.2.0)\n ggExtra     * 0.10.0     2022-03-23 [1] CRAN (R 4.2.0)\n ggplot2     * 3.4.0      2022-11-04 [1] CRAN (R 4.2.0)\n ggridges    * 0.5.3      2021-01-08 [1] CRAN (R 4.2.0)\n ggtext      * 0.1.1      2022-09-14 [1] Github (wilkelab/ggtext@50fdaba)\n lubridate   * 1.8.0      2021-10-07 [1] CRAN (R 4.2.0)\n paletteer   * 1.5.0      2022-10-19 [1] CRAN (R 4.2.0)\n patchwork   * 1.1.0.9000 2022-04-26 [1] Github (thomasp85/patchwork@79223d3)\n purrr       * 0.3.5      2022-10-06 [1] CRAN (R 4.2.0)\n readr       * 2.1.3      2022-10-01 [1] CRAN (R 4.2.0)\n scales      * 1.2.1      2022-08-20 [1] CRAN (R 4.2.0)\n sessioninfo * 1.2.2      2021-12-06 [1] CRAN (R 4.2.0)\n stringr     * 1.4.1      2022-08-20 [1] CRAN (R 4.2.0)\n tibble      * 3.1.8      2022-07-22 [1] CRAN (R 4.2.0)\n tidyr       * 1.2.1      2022-09-08 [1] CRAN (R 4.2.0)\n tidyverse   * 1.3.2.9000 2022-08-16 [1] Github (tidyverse/tidyverse@3be8283)\n\n [1] /Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/library\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "posts/2019-01-02-tidytuesday-enhancements/index.html",
    "href": "posts/2019-01-02-tidytuesday-enhancements/index.html",
    "title": "TidyTuesday enhancements",
    "section": "",
    "text": "One of my #rstats goals for 2019 was to make #TidyTuesday better, both from the experience on GitHub and the weekly posting for myself and for others.\nThe first thing I did for the project was to re-organize the GitHub repo, moving all the 2018 data into an archived folder and making a new 2019 folder to begin populating with new data! Additionally, with some help from Philip Khor via a pull-request - the GitHub repo is now full of relative (rather than absolute) paths to make life easier for anyone that forks the repo.\nI reorganized the Useful Links section at the bottom of the repo to make it more succinct, adding a few more links including Happy Git with R by Jenny Bryan! If you are just getting started with GitHub and want to learn more about Git, GitHub, and using it from within RStudio - check out her resources!"
  },
  {
    "objectID": "posts/2019-01-02-tidytuesday-enhancements/index.html#ways-to-contribute",
    "href": "posts/2019-01-02-tidytuesday-enhancements/index.html#ways-to-contribute",
    "title": "TidyTuesday enhancements",
    "section": "Ways to contribute",
    "text": "Ways to contribute\nI’m always on the lookout for interesting datasets, and a way for you to contribute to TidyTuesday beyond a weekly post is submitting a dataset you find in the wild as an Issue on the TidyTuesday repo. Please link to the dataset and add any additional info as to why you thought it was interesting or an article/plot that corresponds to that data.\nI added the Submitting Code Chunks section directly to the readme doc. This is for some code, script, etc that you found useful when working with TidyTuesday. It’s also a chance for a low-stress pull-request as that’s how we will be adding code chunks! Please see the guide here about the format to submit."
  },
  {
    "objectID": "posts/2019-01-02-tidytuesday-enhancements/index.html#improving-my-weekly-tweet-submission-process",
    "href": "posts/2019-01-02-tidytuesday-enhancements/index.html#improving-my-weekly-tweet-submission-process",
    "title": "TidyTuesday enhancements",
    "section": "Improving my Weekly Tweet Submission Process",
    "text": "Improving my Weekly Tweet Submission Process\nI generally switched between a lot of tabs, eg GitHub, short links, manually adding pics, etc while getting the weekly post setup. I knew there was a way to at least partially automate this, so I looked into my options.\nThe rtweet package has a post to Twitter function via rtweet::post_tweet() which allows you to programmatically post tweets! However - to get where I wanted to be I had to add a few more things and do some interesting refactoring!"
  },
  {
    "objectID": "posts/2019-01-02-tidytuesday-enhancements/index.html#my-weekly-tidytuesday-tweet",
    "href": "posts/2019-01-02-tidytuesday-enhancements/index.html#my-weekly-tidytuesday-tweet",
    "title": "TidyTuesday enhancements",
    "section": "My Weekly #TidyTuesday Tweet",
    "text": "My Weekly #TidyTuesday Tweet\nIf I simply wanted to post a tweet following the format for #TidyTuesday I could do something like the following.\n\nrtweet::post_tweet(\"The @r4dscommunity welcomes you to Week 2 of #TidyTuesday! We're exploring data about *esoteric topic*!\n                   Data: link_to_data\n                   Article: link_to_article\",\n                   media = \"tt_logo.png\")\n\nHowever this results in the following Tweet:\n\nThis is not exactly what I want… the text isn’t aligned properly, I want more than 1 pic, and I really would prefer to use emoji to save characters over Data: and Article:.\nSo on to the next step!\nHadley Wickham has the emo package which allows you to input various emoji into R/R Markdown. This package perfectly solves our emoji needs! I can use code like emo::ji(\"folder\") to get 📁 or emo::ji(\"news\") to get 📰!\nBut I still need to get my text aligned properly… So I broke some formatting rules for normal code, but it got the job done for this rtweet use! Basically, I forced the text to be fully left-aligned, added in some spacing where necessary, and used paste0() to get everything squished together in a coherent tweet (with multiple pics!).\n\nrtweet::post_tweet(status = paste0(\n\"The @R4DScommunity welcomes you to week 2 of #TidyTuesday!  We're exploring *esoteric topic*!\n \n\",\n        emo::ji(\"folder\"),\n        \" http://bit.ly/tidyreadme\n\",\n        emo::ji(\"news\"),\n        \" http://cool.article.com\n\n#r4ds #tidyverse #rstats #dataviz\"),\n\n# The below code is relative to my project\n# You need to specify path to the images for tweeting\n\n        media = c(\"tt_logo.png\",\n                  \"tt_rules.png\")\n        )\n\n\nThis is a great start! However, I want to make this a bit more robust, as I don’t want to edit it all by hand, when I can generate it programmatically. Refactoring code is always an adventure, so let’s take a look at our code to see what is static and what changes.\nMix of static and dynamic:\n\n\nThe @r4dscommunity welcomes you to week {week} of #Tidy Tuesday\n\n\nWe're exploring {data to explore}!\n\nThe link to the readme is static, but we change the link to an article.\n\nThe logo and rules are always the same, but up to two additional pics are dynamic.\n\nSo how do you generate dynamic and static text together? With glue of course! The glue package glues strings together in R, and allows for interpreted strings with the use of {} for example glue::glue(\"Glue is an {adjective} package!\") where the {adjective} indicates an intepreted add-in. So if I had adjective <- \"awesome\" the string would print as \"Glue is an awesome package!\".\nSince we are going to be linking local pics, I’m also using the here package to make moving between folders in my project easier. My folder is organized like so: TidyTuesday/2019/2019-01-08/.\nSo I can use here::here(\"2019\", \"2019-01-08\", \"pic1.png\") to get the file directory for pic1.png. Since the date 2019-01-08 changes each week, I will also add it as a variable to define.\nAnyway, back to refactoring.\n\n# Dynamic Variables\nweek_num <- 2\nexploring <- \"Esoteric data!\"\nshort_link <- \"http://bit.ly/WHATEVER\"\nweek_date <- \"2019-01-08\"\n\n# Static framework\nrtweet::post_tweet(status = glue::glue(\n\"The @R4DScommunity welcomes you to week {week_num} of #TidyTuesday!  We're exploring {exploring}!\n \n\",\n        emo::ji(\"folder\"),\n        \" http://bit.ly/tidyreadme\n\",\n        emo::ji(\"news\"),\n        \" {short_link}\n\n#r4ds #tidyverse #rstats #dataviz\"),\n# The below code is relative to my project\n# You would need to specify path to the images for tweeting\n        media = c(here::here(\"static_img\", \"tt_logo.png\"),   # I have two static pics\n                  here::here(\"static_img\", \"tt_rules.png\"),  # so they go in /static\n                  here::here(\"2019\", week_date, \"pic1.png\"), # notice I have week_date\n                  here::here(\"2019\", week_date, \"pic2.png\")  # here instead of 2019-01-01\n        ))\n\nNow this will generate the correctly formatted tweet, include the correct additional pictures and text, but more importantly the use of glue and here means I can define the dynamic portions at the top and leave the static body the same.\nHowever, we can refactor things further!\nWe can refactor to a function AND since I only post these tweets on the Monday before #TidyTuesday, I can build variable dates into the function. Really the only thing I need to manually change is what data we are exploring and the short article link.\nBefore we get into the function, I am using a number of packages for my ease.\n\n# Packages used in this script\nlibrary(rtweet) # For Tweeting\nlibrary(glue) # For interpretation inside strings\nlibrary(emo) # For emojis!\nlibrary(lubridate) # Working with date-times\nlibrary(here) # Easier file navigation inside projects\nlibrary(purrr) # for pluck - I'm lazy. :shrug:\n\n\n# Only two inputs!\n# exploring = what we are exploring in text\n# short_link = the article link\n\npost_tidytuesday <- function(exploring, short_link){\n        \n        # set date for files structure and names\n        week_date <- as.character(lubridate::today() + 1)\n        \n        # Today's date + 1 = tomorrow\n        # Then time diff between tomorrow and 1st tidytuesday in number of weeks\n        week_num <- as.numeric((lubridate::today() + 1) - lubridate::ymd(20190101))/7 + 1\n        \n        # post the tweet with fill\n        rtweet::post_tweet(status = glue::glue(\n                \"The @R4DScommunity welcomes you to week {week_num} of #TidyTuesday!  We're exploring {exploring}!\n \n\",\n                emo::ji(\"folder\"),\n                \" http://bit.ly/tidyreadme\n\",\n                emo::ji(\"news\"),\n                \" {short_link}\n\n#r4ds #tidyverse #rstats #dataviz\"),\n                \n                # The below code is relative to my project\n                # You need to specify path to the images for tweeting\n                media = c(here::here(\"static_img\", \"tt_logo.png\"),\n                          here::here(\"static_img\", \"tt_rules.png\"),\n                          here::here(\"2019\", week_date, \"pic1.png\"),\n                          here::here(\"2019\", week_date, \"pic1.png\")\n                ))    \n}\n\nNow we have a nice function and when I want to post on Monday morning, I can just do the following!\n\npost_tidytuesday(\n  exploring = \"Esoteric data!\",\n  short_link = \"http://bit.ly/tidy_post\"\n)\n\nThe link to GitHub for this code.\nPackage Links\nrtweetglueemolubridateherepurrr::pluck()"
  },
  {
    "objectID": "posts/2019-01-02-tidytuesday-enhancements/index.html#step-2-for-next-time",
    "href": "posts/2019-01-02-tidytuesday-enhancements/index.html#step-2-for-next-time",
    "title": "TidyTuesday enhancements",
    "section": "Step 2 (for next time)",
    "text": "Step 2 (for next time)\nHow to improve YOUR #TidyTuesday process and get your code directly from RStudio into Carbon.now.sh for pretty “screenshots”!\n\n\n\n\n\n\nExpand for Session Info\n\n\n\n\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.0 (2022-04-22)\n os       macOS Monterey 12.2.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       America/Chicago\n date     2022-04-28\n pandoc   2.18 @ /Applications/RStudio.app/Contents/MacOS/quarto/bin/tools/ (via rmarkdown)\n quarto   0.9.294 @ /usr/local/bin/quarto\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version date (UTC) lib source\n sessioninfo * 1.2.2   2021-12-06 [1] CRAN (R 4.2.0)\n\n [1] /Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/library\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "posts/2020-05-13-reactable-tables-the-rest-of-the-owl/index.html",
    "href": "posts/2020-05-13-reactable-tables-the-rest-of-the-owl/index.html",
    "title": "reactable - An Interactive Tables Guide",
    "section": "",
    "text": "It is a beautiful owl/table though isn’t it?\nPart 2 of this guide will go through how to in fact draw the rest of the owl, as the previous post barely covered the how and instead focused on a clean final product."
  },
  {
    "objectID": "posts/2020-05-13-reactable-tables-the-rest-of-the-owl/index.html#reactable---interactive-data-tables",
    "href": "posts/2020-05-13-reactable-tables-the-rest-of-the-owl/index.html#reactable---interactive-data-tables",
    "title": "reactable - An Interactive Tables Guide",
    "section": "\nreactable - interactive data tables",
    "text": "reactable - interactive data tables\nreactable is an R wrapper for the react table javascript library. Greg Lin at RStudio recently made this package and you can install it from CRAN with install.packages(\"reactable\"). I adapted this table from some examples at the reactable package site.\nIf you want to go much deeper than this basic guide, check out the reactable site, which has lots of examples!\nRaw data comes from: Pro Football Reference & Over the Cap"
  },
  {
    "objectID": "posts/2020-05-13-reactable-tables-the-rest-of-the-owl/index.html#read-in-the-data",
    "href": "posts/2020-05-13-reactable-tables-the-rest-of-the-owl/index.html#read-in-the-data",
    "title": "reactable - An Interactive Tables Guide",
    "section": "Read in the Data",
    "text": "Read in the Data\nI’ve gone through collecting the data and have put into a non-tidy wide format for Salary Rank, playoff week and appearances, Total appearances, and finally salary from 2014-2019. The raw CSV is available on GitHub\n\nlibrary(reactable) # for interactive tables\nlibrary(tidyverse) # all the things\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──\n\n\n✔ ggplot2 3.3.5     ✔ purrr   0.3.4\n✔ tibble  3.1.6     ✔ dplyr   1.0.8\n✔ tidyr   1.2.0     ✔ stringr 1.4.0\n✔ readr   2.1.2     ✔ forcats 0.5.1\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(htmltools) # for building div/links\nlibrary(paletteer) # for all the palettes\n\nplayoff_salary <- read_csv(\"playoff_salary.csv\")\n\nRows: 36 Columns: 8\n\n\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): player\ndbl (7): Salary Rank, Wildcard, Division, Conference, Superbowl, Total, salary\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nglimpse(playoff_salary)\n\nRows: 36\nColumns: 8\n$ `Salary Rank` <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1…\n$ player        <chr> \"Matt Stafford\", \"Ben Roethlisberger\", \"Aaron Rodgers\", …\n$ Wildcard      <dbl> 2, 3, 2, 2, 1, 1, 1, 1, 2, 1, 2, 2, 4, 1, 2, 0, 0, 1, 1,…\n$ Division      <dbl> 0, 3, 4, 2, 0, 2, 1, 1, 2, 5, 1, 2, 4, 0, 2, 1, 1, 1, 1,…\n$ Conference    <dbl> 0, 1, 3, 1, 0, 1, 0, 0, 1, 5, 0, 0, 1, 0, 1, 1, 1, 1, 0,…\n$ Superbowl     <dbl> 0, 0, 0, 0, 0, 1, 0, 0, 1, 4, 0, 0, 1, 0, 0, 0, 1, 0, 0,…\n$ Total         <dbl> 2, 7, 9, 5, 1, 5, 2, 2, 6, 15, 3, 4, 10, 1, 5, 2, 3, 3, …\n$ salary        <dbl> 129.7, 127.7, 125.6, 125.2, 124.2, 118.0, 117.3, 106.1, …"
  },
  {
    "objectID": "posts/2020-05-13-reactable-tables-the-rest-of-the-owl/index.html#basics-of-reactable",
    "href": "posts/2020-05-13-reactable-tables-the-rest-of-the-owl/index.html#basics-of-reactable",
    "title": "reactable - An Interactive Tables Guide",
    "section": "Basics of reactable",
    "text": "Basics of reactable\nA very basic reactable table can be created as so:\n\nplayoff_salary %>%\n  reactable()\n\n\n\n\n\n\nImmediately we have reactive table split into 4x pages with 10 observations per page.\nThe core parts we want to change are:\n- Conditional color formatting for Total Appearances and Salary\n- All on one page\n- Change the font"
  },
  {
    "objectID": "posts/2020-05-13-reactable-tables-the-rest-of-the-owl/index.html#color-function",
    "href": "posts/2020-05-13-reactable-tables-the-rest-of-the-owl/index.html#color-function",
    "title": "reactable - An Interactive Tables Guide",
    "section": "Color Function",
    "text": "Color Function\nI borrowed my function to generate colors scales through grDevices::colorRamp() from Greg Lin’s examples. This makes use of colorRamp to generate a sequence of colors and then pull them according to a sliding scale normalized to 0-1.\n\n# greg's palette\nscales::show_col(c(\"#ffffff\", \"#f2fbd2\", \"#c9ecb4\", \"#93d3ab\", \"#35b0ab\"))\n\n\n\n\nBack to our color scale, we can display an example step-by-step.\n\n# Function by Greg Lin\n# Notice bias here = a positive number. \n# Higher values give more widely spaced colors at the high end\n\nmake_color_pal <- function(colors, bias = 1) {\n  get_color <- colorRamp(colors, bias = bias)\n  function(x) rgb(get_color(x), maxColorValue = 255)\n}\n\ngood_color <- make_color_pal(c(\"#ffffff\", \"#f2fbd2\", \"#c9ecb4\", \"#93d3ab\", \"#35b0ab\"), bias = 2)\n\n# Generate a vector of example numbers between 0 and 1\nseq(0.1, 0.9, length.out = 12)\n\n [1] 0.1000000 0.1727273 0.2454545 0.3181818 0.3909091 0.4636364 0.5363636\n [8] 0.6090909 0.6818182 0.7545455 0.8272727 0.9000000\n\n# create matching colors\ngood_color(seq(0.1, 0.9, length.out = 12))\n\n [1] \"#E9F8CB\" \"#D9F2C0\" \"#C9ECB4\" \"#BDE6B2\" \"#B0E0AF\" \"#A4DAAD\" \"#97D5AB\"\n [8] \"#88CFAB\" \"#79C9AB\" \"#69C3AB\" \"#5ABDAB\" \"#4AB8AB\"\n\n# display the colors\nseq(0.1, 0.9, length.out = 12) %>% \n  good_color() %>% \n  scales::show_col()\n\n\n\n\nThe palette that Greg and FiveThirtyEight used for this plot is roughly similar to the lower half of viridis - a commonly used continuous color scale that is mostly color-blind friendly."
  },
  {
    "objectID": "posts/2020-05-13-reactable-tables-the-rest-of-the-owl/index.html#format-total-column",
    "href": "posts/2020-05-13-reactable-tables-the-rest-of-the-owl/index.html#format-total-column",
    "title": "reactable - An Interactive Tables Guide",
    "section": "Format Total Column",
    "text": "Format Total Column\nNow we can use a similar approach to add color to our Total playoff appearances column.\n\ntbl <- playoff_salary %>% \n  mutate(salary = round(salary, 1)) %>% \n  reactable(\n    pagination = FALSE,\n    compact = TRUE,\n    borderless = FALSE,\n    striped = FALSE,\n    fullWidth = FALSE,\n    defaultColDef = colDef(\n      align = \"center\",\n      minWidth = 100\n    ),\n    # Add theme for the top border\n    theme = reactableTheme(\n      headerStyle = list(\n        \"&:hover[aria-sort]\" = list(background = \"hsl(0, 0%, 96%)\"),\n        \"&[aria-sort='ascending'], &[aria-sort='descending']\" = list(background = \"hsl(0, 0%, 96%)\"),\n        borderColor = \"#555\"\n      )\n    ),\n    columns = list(\n      salary = colDef(\n        name = \"Salary\",\n        style = function(value) {\n          value\n          normalized <- (value - min(playoff_salary$salary)) / (max(playoff_salary$salary) - min(playoff_salary$salary))\n          color <- good_color(normalized)\n          list(background = color)\n        },\n        cell = JS(\"function(cellInfo) {return '$' + cellInfo.value + 'M'}\")\n      ),\n      \n      ##########################\n      ### This section changed\n      ##########################\n      # We can now do a similar function for Total to color according to a\n      # normalized scale\n      Total = colDef(\n        style = function(value) {\n          value\n          normalized <- (value - min(playoff_salary$Total)) / (max(playoff_salary$Total) - min(playoff_salary$Total))\n          color <- good_color(normalized)\n          list(background = color)\n        },\n        # we'll also add a border to the left of this column\n        class = \"border-left\"\n      ),\n      # and change the width/alignment of the player column\n      player = colDef(\n        # Change player to Name\n        name = \"Name\",\n        # Widen it so that player names don't get wrapped as much\n        minWidth = 140,\n        # Align left as it is a wide column\n        # this overrides the default above\n        align = \"left\"\n      )\n    )\n  )\n\ntbl"
  },
  {
    "objectID": "posts/2020-05-13-reactable-tables-the-rest-of-the-owl/index.html#build-structure",
    "href": "posts/2020-05-13-reactable-tables-the-rest-of-the-owl/index.html#build-structure",
    "title": "reactable - An Interactive Tables Guide",
    "section": "Build structure",
    "text": "Build structure\nBy building up our plot inside div containers and assiging a class we can use CSS to further style or add to our table. The main things I’m interested in is changing the base font to one I love (Fira Mono)! However, Greg included some niceties for some additional table formatting that I copied over as well.\nMy mental model of div building is that it’s like nesting dolls. Main div which is the whole table, header and footer, and then additional nested div for other classes that we can call against. :::{.column-page}\n\ndiv(\n  # this class can be called with CSS now via .salary\n  class = \"salary\",\n  div(\n    # this can be called with CSS now via .title\n    class = \"title\",\n    h2(\"2014-2019 Salary and Playoff Appearances\"),\n    # This is kind of like a sub-title, but really it's just raw text\n    \"QBs limited to playoff games where they threw a pass\"\n  ),\n  # The actual table\n  tbl,\n  # I use a span here so I can assigna  color to this text\n  tags$span(style = \"color:#C8C8C8\", \"TABLE: @THOMAS_MOCK | DATA: PRO-FOOTBALL-REFERENCE.COM & OVERTHECAP.COM\")\n)\n\n\n\n\n2014-2019 Salary and Playoff Appearances\nQBs limited to playoff games where they threw a pass\n\n\nTABLE: @THOMAS_MOCK | DATA: PRO-FOOTBALL-REFERENCE.COM & OVERTHECAP.COM\n\n\n\n:::\nImport Google Font\nI want to use a Google font (Karla + Fira Mono).\nYou can see all the Google Fonts here. At fonts.google.com you’ll:\n- Search for specific fonts\n- Select the Style you want (+ button)\n- Open the sidebar to extract the API call for embedding\nExample image below\n\n\nSteps to select, get and copy embed for Google Fonts\n\n\nYou then paste the text inside the <link > into a tags$link() call from htmltools package.\nFor example:\n<link href=\"https://fonts.googleapis.com/css?family=Karla:400,700|Fira+Mono&display=fallback\" rel=\"stylesheet\">\nturns into the below:\n\ntags$link(href = \"https://fonts.googleapis.com/css?family=Karla:400,700|Fira+Mono&display=fallback\", rel = \"stylesheet\")"
  },
  {
    "objectID": "posts/2020-05-13-reactable-tables-the-rest-of-the-owl/index.html#add-css",
    "href": "posts/2020-05-13-reactable-tables-the-rest-of-the-owl/index.html#add-css",
    "title": "reactable - An Interactive Tables Guide",
    "section": "Add CSS",
    "text": "Add CSS\nThis is a CSS chunk and the CSS is applied to objects matching their name, ie .salary matches the div we built earlier, .number applies to all class = number from our table, .title applies to the class = title in our table.\nNote that if I work locally not all of this will show up, but once the complete RMarkdown is knit together it will work.\n\n.salary {\n  font-family: Karla, \"Helvetica Neue\", Helvetica, Arial, sans-serif;\n  font-size: 14px;\n}\n\n.number {\n  font-family: \"Fira Mono\", Consolas, Monaco, monospace;\n  font-size: 16px;\n  line-height: 30px;\n  white-space: pre;\n}\n\n.title {\n  margin: 18px 0;\n  font-size: 16px;\n}\n\n.title h2 {\n  font-size: 20px;\n  font-weight: 600;\n}\n\n.header:hover,\n.header[aria-sort=\"ascending\"],\n.header[aria-sort=\"descending\"] {\n  background-color: #eee;\n}\n\n.salary-table {\n  margin-bottom: 20px;\n}\n\n/* Align header text to the bottom */\n.header,\n.group-header {\n  display: flex;\n  flex-direction: column;\n  justify-content: flex-end;\n}\n\n.header {\n  border-bottom-color: #555;\n  font-size: 13px;\n  font-weight: 400;\n  text-transform: uppercase;\n}\n\n/* Highlight headers when sorting */\n.header:hover,\n.header[aria-sort=\"ascending\"],\n.header[aria-sort=\"descending\"] {\n  background-color: #eee;\n}\n\n.border-left {\n  border-left: 2px solid #555;\n}\n\n/* Use box-shadow to create row borders that appear behind vertical borders */\n.cell {\n  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);\n}"
  },
  {
    "objectID": "posts/2020-10-11-embedding-images-in-ggplot/index.html",
    "href": "posts/2020-10-11-embedding-images-in-ggplot/index.html",
    "title": "Plotting Points as Images in ggplot",
    "section": "",
    "text": "ggimage\nFirst we have ggimage + end of column labels. I also want to note that I’m explicitly showing the code here, and using tictoc to display how long saving these images will take. In general, displaying embedded images is a bit slower than an equivalent basic ggplot. Since I want to show what the images will look like after export, I’m also using knitr::include_graphics() to include the actual exported PNG in this RMarkdown-based website. I’ve also included tictoc for how long each code-section took to save so you can see that each method is about 5-8 seconds.\nNOTE: I realise this graphic is distorted, it’s an intentional display of a problem you may run into\n\ntic()\nqb_col_img <- basic_plot +\n  geom_image(\n    aes(\n      x = rank, y = qbr_total,\n      image = headshot_href\n      )\n    )\n\n# Not displaying the image directly, \n# but reading in the exported img after\n# qb_col_img\n\n# saving it as a rectangle\nggsave(\n  \"qbr-ggimage.png\", qb_col_img, \n  height = 10, width = 16, dpi = \"retina\"\n  )\n\ntoc()\n\n4.307 sec elapsed\n\n\n\n\n\n\n\nYou’ll notice that since we have a rectangle-shaped graph, the images have been distorted to be wider than they should. Now if you want the images to come out without being distorted, you need to specify the specific aspect ratio you’re using. Just in case you haven’t heard of an aspect ratio, I’ll also provide a definition as the ratio of width to height.\n\nggimage and Aspect Ratio\nNote that geom_image() has the following parameters:\ngeom_image(\n  mapping = NULL,\n  data = NULL,\n  stat = \"identity\",\n  position = \"identity\",\n  inherit.aes = TRUE,\n  na.rm = FALSE,\n  by = \"width\",\n  nudge_x = 0,\n  ...\n)\nThere isn’t an explicit option for aspect ratio, but it exists as asp. So if we consider ahead of time the dimensions of the plot we want to make, we can define the aspect ratio at the plot level and at the ggsave level. Per some experiments on Windows specifically, we also need to include aspect ratio in the theme() call as well, and make sure this again aligns with your ggsave() call.\n\n# Define an aspect ratio to use throughout\n# This value is the golden ratio\n# which provides a wider than tall rectangle\nasp_ratio <- 1.618 \n\ntic()\nqb_col_img_asp <- basic_plot +\n  # note we can also control the size of the image according to it's width\n  geom_image(\n    aes(\n      x = rank, y = qbr_total,\n      image = headshot_href\n      ), \n    # Set size, and aspect ratio\n    size = 0.05, by = \"width\", asp = asp_ratio\n    ) +\n  # Second step\n  theme(aspect.ratio = 1/asp_ratio)\n\n# include aspect ratio in ggsave\nggsave(\n  \"qbr-img-asp.png\", qb_col_img_asp, \n  # make the width equivalent to the aspect.ratio\n  height = 10, width = 10 * asp_ratio, dpi = \"retina\"\n  )\ntoc()\n\n2.723 sec elapsed\n\n\n\n\n\n\n\nWhile this may seem like a bit of work, it’s a good habit to think explicitly about what size or ratio you want to save your plots out as (it can inform how big to make your text amongst other things).\nHowever, there’s an even easier way thanks to ggtext!\n\nggtext + column end labels.\nNext we have ggtext + column labels. Here ggtext::geom_richtext() handles the proper scaling of the image without really any intervention from us! While geom_richtext() is very useful we’re sort of using it out of its normal context. The overall purpose of ggtext is to provide “improved text rendering support for ggplot2”. The ggtext site has all the capabilities and function details. In short, ggtext provides a limited subset of markdown/HTML/CSS syntax as an interface to changing text in ggplot2.\nThus, to achieve our goal of embedding images, we can create an img HTML tag to embed an image rather than just format text. Note that again, while this looks like a HTML call it works anywhere you want to use ggplot2. Credit to Emil Hvitfeldt for the idea of using an img tag and the function we’re adapting to embed images.\n\n# Don't forget, we already created an img label column with HTML\nlink_to_img <- function(x, width = 50) {\n  glue::glue(\"<img src='{x}' width='{width}'/>\")\n}\n\n\ntic()\nqb_col_text <- basic_plot + \n    geom_richtext(\n      aes(x = rank, y = qbr_total, label = label), \n      size = 1,\n      fill = NA, label.color = NA, # remove background and outline\n      label.padding = grid::unit(rep(0, 4), \"pt\") # remove padding\n      )\n\nggsave(\"qbr-ggtext.png\", qb_col_text, height = 10, width = 10 * asp_ratio, dpi = \"retina\")\ntoc()\n\n7.364 sec elapsed\n\n\n\n\n\n\n\n\nggtext + Axis Labels\nNow we could also change the images on the x-axis w/ the code below, and note that we’re mainly taking the same code, but changing the core aes() call to have x = label and axis.text.x = ggtext::element_markdown() - full details shown below.\n\n# Here are the parts we're changing\n\n# change x-axis to be the label we've created\naes(x = fct_reorder(label, qbr_total, .desc = TRUE))\n\n# and changing the theme to include element_markdown()\ntheme(\n  axis.ticks.x = element_blank(),\n  # add element_markdown to axis.text.x\n  # this will parse the labels to add img\n  axis.text.x = element_markdown(margin = margin(t = -25, unit = \"pt\"))\n  )\n\nHere’s the full code of the call with again some highlighted portions where we’ve changed code.\n\ntic()\naxis_plot <- all_data %>% \n  mutate(label = link_to_img(headshot_href),\n         rank = as.integer(rank)) %>% \n  ggplot() +\n  geom_col(\n    aes(\n      ## CHANGE IS HERE ##\n      # apply label to x axis labels\n      x = fct_reorder(label, qbr_total, .desc = TRUE), \n      y = qbr_total,\n      fill = team_color, color = team_alt_color\n      ),\n    width = 0.4\n    ) + \n  scale_color_identity(aesthetics =  c(\"fill\", \"color\")) +\n  geom_hline(yintercept = 0, color = \"black\", size = 1) +\n  theme_minimal() +\n  scale_y_continuous(breaks = scales::pretty_breaks(n = 10)) +\n  labs(x = NULL,\n       y = \"QBR\\n\",\n       title = \"QBR - 2020 Season\",\n       subtitle = \"Weeks: 1-4\",\n       caption = \"<br>**Data:** espnscrapeR | **Plot:** @thomas_mock\") +\n  theme(\n    text = element_text(family = \"Chivo\"),\n    panel.grid.minor = element_blank(),\n    panel.grid.major.x = element_blank(),\n    plot.title = element_text(face = \"bold\", size = 20),\n    plot.subtitle = element_text(size = 16),\n    plot.caption = element_markdown(size = 12),\n    axis.text = element_text(size = 14, face = \"bold\"),\n    axis.title.y = element_text(size = 16, face = \"bold\")\n    ) +\n  theme(\n    axis.ticks.x = element_blank(),\n    # add element_markdown to axis.text.x\n    # this will parse the labels to add img\n    # we're also decreasing the margin so that the logos/heads are close \n    # to the columns\n    axis.text.x = element_markdown(margin = margin(t = -25, unit = \"pt\"))\n    )\n\n# axis_plot\n\nggsave(\n  \"qbr-axis-img.png\", axis_plot, \n  height = 10, width = 10 * asp_ratio, dpi = \"retina\"\n  )\ntoc()\n\n14.824 sec elapsed\n\n\n\n\n\n\n\n\nggtext Negatives\nOK wow, so why not just use ggtext all the time!?\nCons:\n\nIt WAS verrrrrrry slow to draw in the RStudio plot-viewer, like on the order of a few minutes with 33 embedded images, however it would still save to png in a few seconds\n\nThe latest version (ggtext_0.1.0.9000) from GitHub does “draw” in a few seconds though!\n\n\n\nCan’t adjust size in ggplot - has to be done ahead of time w/ HTML syntax in our custom function\n\nI’m fine with these tradeoffs especially as the newer version is fast, and you don’t have to worry about the scaling.\nLatest version of ggtext can be installed via remotes::install_github(\"wilkelab/ggtext\").\nWhat about a table?\nSo a slight hot-take is that since we’re showing values that we’re inherently asking people to look up and compare individual values (ie find your QB of interest vs the field), this should be a table!\nPer Stephen Few:\n\nTables: Display used to look up and compare individual values.\n\n\nGraph: Used to display the relationship among whole sets of values and their overall shape.\n\nNow sure, we’re showing a shape of the graphic, but really this is a way to show how far ahead (or behind) one player is behind another which is comparing individual values. That being said, I think it’s totally fine to use this a graphic, it’s attractive, people seem to enjoy them, and everyone has the free will to make their own graph/table decisions!\nBelow is an example of a table that occupies roughly the same space, tells the same story, uses the same headshots, but also adds more data in QB run vs pass EPA splits along with total plays.\nTable Data + Function\n\ntab_data <- all_data %>% \n  mutate(RK = rank(desc(qbr_total)),\n         RK = as.integer(RK)) %>% \n  select(RK, name, headshot_href, qbr_total, qb_plays, pass, run) \n\ntab_function <- function(data, ...){\n  data %>% \n  gt() %>% \n  text_transform(\n    locations = cells_body(vars(headshot_href)),\n    fn = function(x){\n      web_image(\n        url = x,\n        height = px(30)\n      )\n    }\n  ) %>% \n  cols_label(\n    headshot_href = \"\",\n    name = \"Name\",\n    qbr_total = \"QBR\",\n    qb_plays = \"Plays\",\n    run = \"Run\",\n    pass = \"Pass\"\n  ) %>% \n  data_color(\n    columns = vars(qbr_total),\n    colors = scales::col_numeric(\n      palette = c(\"#af8dc3\", \"#f7f7f7\", \"#7fbf7b\"),\n      domain = c(25, 100)\n    )\n  ) %>% \n  tab_style(\n    style = cell_text(weight = \"bold\"),\n    locations = cells_body(\n      columns = vars(RK, name)\n    )\n  ) %>% \n  tab_options(\n    column_labels.background.color = \"white\",\n    column_labels.font.weight = \"bold\",\n    table.border.top.width = px(3),\n    table.border.top.color = \"transparent\",\n    table.border.bottom.color = \"transparent\",\n    table.border.bottom.width = px(3),\n    column_labels.border.top.width = px(3),\n    column_labels.border.top.color = \"transparent\",\n    column_labels.border.bottom.width = px(3),\n    column_labels.border.bottom.color = \"black\",\n    data_row.padding = px(3),\n    source_notes.font.size = 12,\n    table.font.size = 16,\n    heading.align = \"left\",\n    ...\n  ) %>%\n  opt_table_font(\n    font = list(\n      google_font(\"Chivo\"),\n      default_fonts()\n    )\n  ) \n\n}\n\n\nThe code uses the function defined in the above expandable section, and to get the side-by-side format I decided to save the tables as PNG and then combine with magick::image_append().\n\ntab_data %>% \n  slice(1:17) %>% \n  tab_function()\n\ntab_data %>% \n  slice(178:nrow(.)) %>% \n  tab_function() %>% \n  tab_style(\n    style = cell_borders(\n      sides = \"left\",\n      color = \"black\",\n      weight = px(3)\n    ),\n    locations = \n      list(\n        cells_body(\n          columns = 1\n        ),\n        cells_column_labels(1)\n      )\n  )\n\n\nimg1 <- magick::image_read(\"gt-tab1.png\")\nimg2 <- magick::image_read(\"gt-tab2.png\")\n\nmagick::image_append(c(img1, img2))\n\n\n\n\nThe equivalent plot that displays:\n- Run EPA\n- Pass EPA\n- QBR\n- Player name\nWe’ve also loaded the ggrepel package to add labels. This graphic is getting a bit busy at this point but is still useful. Given that we’re trying to display 4 measures we have had to rely on size for run EPA which adds additional overhead to the understanding of this graphic as well.\n\nlibrary(ggrepel)\n\nscatter_plot <- all_data %>% \n  mutate(label = link_to_img(headshot_href),\n         rank = as.integer(rank)) %>% \n  ggplot() +\n  geom_smooth(aes(x = pass, y = qbr_total), method = \"lm\", color = \"grey\") +\n  ggrepel::geom_text_repel(\n    aes(x = pass, y = qbr_total, label = name_last),\n    box.padding = 0.5, fontface = \"bold\", size = 6\n    ) +\n  geom_point(\n    aes(x = pass, y = qbr_total, size = run, fill = team_color, color = team_alt_color), \n    shape = 21\n    ) +\n  scale_color_identity(aesthetics =  c(\"fill\", \"color\")) +\n  scale_size(name = \"Run EPA\") +\n  theme_minimal() +\n  scale_x_continuous(breaks = scales::pretty_breaks(n = 10)) +\n  scale_y_continuous(breaks = scales::pretty_breaks(n = 10), limits = c(0, 100)) +\n  labs(x = \"\\nPass Expected Points Added\",\n       y = \"QBR\\n\",\n       title = \"QBR - 2020 Season\",\n       subtitle = \"Weeks: 1-4\\nNote that Pass EPA is predictive of QBR\",\n       caption = \"<br>**Data:** espnscrapeR | **Plot:** @thomas_mock\") +\n  theme(\n    text = element_text(family = \"Chivo\"),\n    panel.grid.minor = element_blank(),\n    plot.title = element_text(face = \"bold\", size = 20),\n    plot.subtitle = element_text(size = 16),\n    plot.caption = element_markdown(size = 12),\n    axis.text = element_text(size = 14, face = \"bold\"),\n    axis.title = element_text(size = 16, face = \"bold\"),\n    legend.position = c(0.1,0.85),\n    legend.background = element_rect(fill = \"lightgrey\"),\n    legend.title = element_text(size = 12, face = \"bold\"),\n    legend.text = element_text(size = 10)\n    )\n\nscatter_plot\n\n`geom_smooth()` using formula 'y ~ x'\n\n\n\n\n\nTeam Logos\nTeam logos work just as well, and are arguably a bit easier to parse than player headshots. The strategies are all the same, but just want to show team-logos from nflfastR as well!\nTeam Logo Code\n\ntic()\nqb_col_logo <- all_data %>% \n  mutate(team = if_else(team == \"WSH\", \"WAS\", team)) %>% \n  left_join(\n    nflfastR::teams_colors_logos %>% select(team = team_abbr, team_logo_espn),\n    by = c(\"team\")\n    ) %>% \n  mutate(label = link_to_img(team_logo_espn, width = 35),\n         rank = as.integer(rank)) %>% \n  ggplot() +\n  geom_col(\n    aes(\n      x = rank, y = qbr_total,\n      fill = team_color, color = team_alt_color\n      ),\n    width = 0.4\n    ) + \n  geom_richtext(\n    aes(x = rank, y = qbr_total, label = label), \n    size = 1,\n    fill = NA, label.color = NA, # remove background and outline\n    label.padding = grid::unit(rep(0, 4), \"pt\") # remove padding\n    ) +\n  scale_color_identity(aesthetics =  c(\"fill\", \"color\")) +\n  geom_hline(yintercept = 0, color = \"black\", size = 1) +\n  theme_minimal() +\n  scale_x_continuous(breaks = c(1, seq(5, 30, by = 5)), limits = c(0.5, 34)) +\n  scale_y_continuous(breaks = scales::pretty_breaks(n = 10)) +\n  labs(x = NULL,\n       y = \"QBR\\n\",\n       title = \"QBR - 2020 Season\",\n       subtitle = \"Weeks: 1-4\",\n       caption = \"<br>**Data:** espnscrapeR | **Plot:** @thomas_mock\") +\n  theme(\n    text = element_text(family = \"Chivo\"),\n    panel.grid.minor = element_blank(),\n    plot.title = element_text(face = \"bold\", size = 20),\n    plot.subtitle = element_text(size = 16),\n    plot.caption = element_markdown(size = 12),\n    axis.text = element_text(size = 14, face = \"bold\"),\n    axis.title.y = element_text(size = 16, face = \"bold\")\n    )\n\nggsave(\"qbr-logo-ggtext.png\", qb_col_logo, height = 10, width = 10 * asp_ratio, dpi = \"retina\")\ntoc()\n\n0.816 sec elapsed\n\n\n\n\n\n\n\n\n\n\n\n\n\nExpand for Session Info\n\n\n\n\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.0 (2022-04-22)\n os       macOS Monterey 12.2.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       America/Chicago\n date     2022-04-28\n pandoc   2.18 @ /Applications/RStudio.app/Contents/MacOS/quarto/bin/tools/ (via rmarkdown)\n quarto   0.9.294 @ /usr/local/bin/quarto\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version    date (UTC) lib source\n dplyr       * 1.0.8      2022-02-08 [1] CRAN (R 4.2.0)\n espnscrapeR * 0.6.5      2022-04-26 [1] Github (jthomasmock/espnscrapeR@084ce80)\n forcats     * 0.5.1      2021-01-27 [1] CRAN (R 4.2.0)\n ggimage     * 0.3.1      2022-04-25 [1] CRAN (R 4.2.0)\n ggplot2     * 3.3.5      2021-06-25 [1] CRAN (R 4.2.0)\n ggrepel     * 0.9.1      2021-01-15 [1] CRAN (R 4.2.0)\n ggtext      * 0.1.1      2020-12-17 [1] CRAN (R 4.2.0)\n glue        * 1.6.2      2022-02-24 [1] CRAN (R 4.2.0)\n gt          * 0.5.0.9000 2022-04-27 [1] Github (rstudio/gt@0d4c83d)\n purrr       * 0.3.4      2020-04-17 [1] CRAN (R 4.2.0)\n readr       * 2.1.2      2022-01-30 [1] CRAN (R 4.2.0)\n sessioninfo * 1.2.2      2021-12-06 [1] CRAN (R 4.2.0)\n stringr     * 1.4.0      2019-02-10 [1] CRAN (R 4.2.0)\n systemfonts * 1.0.4      2022-02-11 [1] CRAN (R 4.2.0)\n tibble      * 3.1.6      2021-11-07 [1] CRAN (R 4.2.0)\n tictoc      * 1.0.1      2021-04-19 [1] CRAN (R 4.2.0)\n tidyr       * 1.2.0      2022-02-01 [1] CRAN (R 4.2.0)\n tidyverse   * 1.3.1      2021-04-15 [1] CRAN (R 4.2.0)\n\n [1] /Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/library\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "posts/2020-04-03-crossing-10000-tidy-simulation/index.html",
    "href": "posts/2020-04-03-crossing-10000-tidy-simulation/index.html",
    "title": "Crossing 10,000 - Tidy simulation",
    "section": "",
    "text": "Been following Dave Robinson’s Tidy Simulation Series in #rstatsand decided to try and give it a go.\nWe play a dice game called “10,000” in my wife’s family. The family of games also includes Ten Grand, Farkle, Zilch, and others according to Wikipedia - with the common thread being that you have 5-6 dice, roll them, and add up scoring dice until you stop with a set score or “zippy”, which is a roll with zero scoring die.\nBasic gist: - Roll 5 dice - If you “score” with at least one die, you can stay or keep rolling - If you roll zero scoring die, you lose your turn\nA basic scoring table can be seen below.\n\n\nWarning: `columns = TRUE` has been deprecated in gt 0.3.0:\n* please use `columns = everything()` instead\n\n\n\n\n\n\n\nScoring Table for '10,000'\n    \n\nRoll\n      Score\n    \n\n\n\nEach 1\n\n\n100\n\n\n\n\nEach 5\n\n\n50\n\n\n\n\n3 x 1\n\n\n1,000\n\n\n\n\n4 x 1\n\n\n5,000\n\n\n\n\n5 x 1\n\n\n10,000\n\n\n\n\n3 x n\n\n\nn * 100\n\n\n\n\n4 x n\n\n\nn * 200\n\n\n\n\n5 x n\n\n\nn * 300\n\n\n\n\nShort Straight\n(1:5, 2:6)\n\n\n1000\n\n\n\n\n\nYou add all the scores up so rolling 5 die for example:\n    \n\nYou could get 3 x 1 (1000), a 4 (0), and a 5 (50\n    \n\nThis gets you 1050, with 1 die in hand (1x 4 doesn't score)\n    \n\n\n\n\n\nWe played 10,000 on New Year’s Day, and we had a disagreement about if you have 2/5 scoring die whether to roll 3 or 4.\nI’ve literally never done probability math EVER… but I felt that it was more effective to roll 4 than 3.\nSo I attempted to simulate rolls in #rstats!\n\nSo we need to create a dataset of possible rolls, and how common these are when randomly created. We’ll set a seed so that we can reproduce the code, and for puns sake we’ll roll the dice 10,000 times to match our game’s title.\nImportantly, we also will be breaking this down into 5x 10,000 samples which is: - Rolling 1 dice all the way to rolling 5 dice (max possible).\nGenerating this is fairly straightforward using tidyr::crossing() and purrr::map() + sample().\n\ntidyr::crossing() takes multiple vectors and creates a tibble of all the possible combinations. Thus we can use it to generate the number of dice in hand along with our 10,000 simulations per number of dice in hand. Our toy example below shows the expected behavior, and then we’ll assign the rolls to a stored dataframe.\n\n# Toy example\n# 1 to 5 dice in hand x 5 trials/per dice group = 25 observations\ncrossing(\n  dice_in_hand = seq(1, 5, 1),\n  trial = 1:5\n)\n\n# A tibble: 25 × 2\n   dice_in_hand trial\n          <dbl> <int>\n 1            1     1\n 2            1     2\n 3            1     3\n 4            1     4\n 5            1     5\n 6            2     1\n 7            2     2\n 8            2     3\n 9            2     4\n10            2     5\n# … with 15 more rows\n\n\nFor, the actual dataframe we’ll do an additional step, which is creating a vector of rolls with random sampling based on how many dice are in hand. For our 1:5 dice in hand + 10,000 samples per dice in hand we get 50,000 simulations.\n\nset.seed(37)\nn_rolls <- 10000\n\n# Generate a sample of rolls (10000 sims)\ndice_rolls <- crossing(dice_in_hand = seq(1, 5, 1),\n                       trial = 1:n_rolls) %>%\n  mutate(roll = map(dice_in_hand, ~ sample(1:6, ., replace = TRUE)))\n\ndice_rolls\n\n# A tibble: 50,000 × 3\n   dice_in_hand trial roll     \n          <dbl> <int> <list>   \n 1            1     1 <int [1]>\n 2            1     2 <int [1]>\n 3            1     3 <int [1]>\n 4            1     4 <int [1]>\n 5            1     5 <int [1]>\n 6            1     6 <int [1]>\n 7            1     7 <int [1]>\n 8            1     8 <int [1]>\n 9            1     9 <int [1]>\n10            1    10 <int [1]>\n# … with 49,990 more rows\n\n\n\nWe can take a look at a few of these simulations. In this case, I’ll grab a random trial and see what we got for each of the dice in hand (1, 2, 3, 4 or 5).\n\ndice_rolls %>% \n  filter(trial == 3737) %>% \n  pull(roll)\n\n[[1]]\n[1] 3\n\n[[2]]\n[1] 2 1\n\n[[3]]\n[1] 3 3 3\n\n[[4]]\n[1] 6 5 2 3\n\n[[5]]\n[1] 4 1 6 5 3\n\n\nNow that we have a sense of our 10,000 simulations and our possible outcomes we need to generate some logic for scoring! We could simply count observations, but that won’t tell us the whole story.\n\nI tried this several ways but ended up sticking with vectors. The goal was to have programmatic logic to convert raw dice rolls like 1, 1, 3, 4, 1 to 1,000 (3x 1 = 1,000, 3 and 4 do not score).\n\nWe need to take the raw rolls (1, 1, 3, 4, 1) to counts of each number. I created a counting function which now tells us how many of each possible dice side (1, 2, 3, 4, 5, 6) there are.\n\ncounting_function <- function(dice_in){\n  x1 <- sum(dice_in == 1)\n  x2 <- sum(dice_in == 2)\n  x3 <- sum(dice_in == 3)\n  x4 <- sum(dice_in == 4)\n  x5 <- sum(dice_in == 5)\n  x6 <- sum(dice_in == 6)\n  \n  roll_vec <- c(x1, x2, x3, x4, x5, x6)\n  roll_vec\n}\n\nA test example can be seen below. The output can be read as One 1, One 2, Three 3, Zero 4, Zero 5, and Zero 6. We can then feed this into our downstream functions to get scoring.\n\ncounting_function(c(1, 2, 3, 3, 3))\n\n[1] 1 1 3 0 0 0\n\n\n\n\n\n\nThere are actually many steps to this, but the bulk of it is just logical matching potential outcomes to observations. Each type of scoring (number of ones, number of fives, short straights, triples, quadruplpes, and quintuples) has it’s own check, and then I add the scoring at the end based on the various combos/inputs. Using the same input as our previous example, we should get a total score of 400, which is One 1 at 100 points, and Three 3s at 100 * face value (100 x 3).\n\ncounting_function(c(1, 2, 3, 3, 3)) %>% \n  rigid_scoring_function()\n\n[1] 400\n\n\nLet’s do a few more checks for sanity. A short straight (1:5) should get you 1000, and then let’s try for a zero score with no scoring die.\n\n# should be 1000\ncounting_function(c(5, 1, 3, 4, 2)) %>%\n  rigid_scoring_function()\n\n[1] 1000\n\n# zero\ncounting_function(c(2, 2, 4, 4, 6)) %>%\n  rigid_scoring_function()\n\n[1] 0\n\n\nThe actual logic can be seen below.\n\n# TOO much logic to get actual scores\nrigid_scoring_function <- function(dice_in) {\n  dice_side <- c(1:6)\n\n  n_of_ones <- sum(dice_in[1])\n\n  n_of_fives <- sum(dice_in[5])\n\n  straight_one <- c(1, 1, 1, 1, 1, 0)\n  straight_two <- c(0, 1, 1, 1, 1, 1)\n\n  straight <- any(all(dice_in == straight_two), all(dice_in == straight_one))\n\n  score_fives <- if_else(\n    n_of_fives <= 2 & straight == FALSE,\n    (n_of_fives * 50),\n    0\n  )\n\n  score_ones <- case_when(\n    n_of_ones <= 2 & straight == FALSE ~ (n_of_ones * 100),\n    n_of_ones == 3 ~ 1000,\n    n_of_ones == 4 ~ 5000,\n    n_of_ones == 5 ~ 10000,\n    TRUE ~ 0\n  )\n\n  three_or_more <- sum(dice_in >= 3)\n\n  three_or_more_subset <- dice_in >= 3\n\n  multiply_dups <- case_when(\n    sum(dice_in == 3) == 1 & n_of_ones < 3 ~ 1L,\n    sum(dice_in == 4) == 1 & n_of_ones < 3 ~ 2L,\n    sum(dice_in == 5) == 1 & n_of_ones < 3 ~ 3L,\n    TRUE ~ 0L\n  )\n\n  multi_score <- ifelse(\n    three_or_more == TRUE,\n    dice_side[three_or_more_subset],\n    0\n  ) * 100 * multiply_dups\n\n\n  straight_score <- if_else(straight == TRUE, 1000, 0)\n\n  three_or_more <- any(dice_in >= 3)\n\n  total_score <- sum(score_ones + multi_score + straight_score + score_fives, na.rm = TRUE)\n  total_score\n}\n\n\nGenerating the scores is actually extremely simple now, the hard part was defining the logic above!\nWe use purrr::map() to generate a vector of the rolls using our counting_function(), and then get a score using purrr::map_dbl() to call our rigid_scoring_function() on each vector input of the die rolls! This will take about 15 seconds for calculating scores across the 50,000 total observations.\n\n# Generate the actual scoring from existing sample\ndice_df <- dice_rolls %>%\n  mutate(\n    dice_vector = map(roll, counting_function),\n    rigid_scoring = map_dbl(dice_vector, rigid_scoring_function)\n  )\n\n# sanity check the scoring to get a few different scores\ndice_df %>%\n  select(dice_in_hand, rigid_scoring) %>%\n  sample_n(10)\n\n# A tibble: 10 × 2\n   dice_in_hand rigid_scoring\n          <dbl>         <dbl>\n 1            2             0\n 2            4            50\n 3            4           200\n 4            5           200\n 5            5          1000\n 6            5           150\n 7            4             0\n 8            5           250\n 9            3            50\n10            4           200\n\n\n\nNow that we have the outcome scoring, we can see how the probabilities stack up! Our thesis was that rolling 4x die was more likely to get you both a better score AND less likely to zippy out or get zero. We can see that rolling 4x die vs 3x die is about half as likely to get zero (15% vs 30%) and 2-3x more likely to get good scores (300 to 1,000).\nSuccess! If you roll 5 die, get 2 scoring die, it makes sense to only keep 1 of those scoring dice and and roll the other 4!\nPlease note that I chose a specific set of scores (0, 50, 100, 150, 200, 300, 400, 500, 600, 1000) - as they are possible to get with either 3 or 4 die. There are scores in between 600 - 1000 that can only be achieved with 4 - 5 die in hand so it didn’t make sense to plot them against 3 die.\n\n# Quick plot\nprob_plot <- dice_df %>%\n  filter(dice_in_hand %in% c(3, 4)) %>%\n  filter(rigid_scoring %in% c(0, 50, 100, 150, 200, 300, 400, 500, 600, 1000)) %>%\n  count(rigid_scoring, dice_in_hand) %>%\n  mutate(\n    freq = n / n_rolls,\n    dice_in_hand = factor(dice_in_hand)\n  ) %>%\n  ggplot(aes(x = rigid_scoring, y = freq, color = dice_in_hand)) +\n  geom_path(aes(group = dice_in_hand)) +\n  geom_point(size = 4) +\n  scale_y_log10(labels = scales::percent, breaks = c(0.005, 0.01, 0.015, 0.03, 0.05, 0.075, 0.1, 0.15, 0.3)) +\n  scale_color_manual(\n    name = \"Dice in Hand\",\n    values = c(\"#003399\", \"#ff2b4f\", \"#fcab27\")\n  ) +\n  scale_x_continuous(breaks = c(0, 50, 100, 150, 200, 300, 400, 500, 600, 1000)) +\n  theme_light() +\n  theme(\n    panel.grid.minor = element_blank(),\n    legend.position = c(0.8, 0.8),\n    plot.title = element_text(face = \"bold\"),\n    axis.title = element_text(face = \"bold\")\n  ) +\n  labs(\n    x = \"\\nScore\",\n    y = \"Log10 Percentage Observed\\n\",\n    title = \"The dice game '10,000' consists of rolling up to 5 dice\",\n    subtitle = \"Rolling 4 dice is 2-3x more likely to generate 'good' scores than 3 dice\",\n    caption = \"Plot: @thomas_mock\"\n  )\n\nprob_plot\n\n\n\n\n\nWe can finally also show the total observations for all possible combinations for rolling 3 or 4 die.\n\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\nAll possible scores and frequencies for 3-4 die in hand\n    \n\nScore\n      Dice in Hand\n      Observations\n      Percent Observed\n    \n\n\n0\n3\n2709\n27.09%\n\n\n0\n4\n1588\n15.88%\n\n\n50\n3\n2169\n21.69%\n\n\n50\n4\n1824\n18.24%\n\n\n100\n3\n2868\n28.68%\n\n\n100\n4\n2559\n25.59%\n\n\n150\n3\n1107\n11.07%\n\n\n150\n4\n1514\n15.14%\n\n\n200\n3\n780\n7.80%\n\n\n200\n4\n1200\n12.00%\n\n\n250\n3\n150\n1.50%\n\n\n250\n4\n390\n3.90%\n\n\n300\n3\n34\n0.34%\n\n\n300\n4\n175\n1.75%\n\n\n350\n4\n32\n0.32%\n\n\n400\n3\n57\n0.57%\n\n\n400\n4\n129\n1.29%\n\n\n450\n4\n35\n0.35%\n\n\n500\n3\n49\n0.49%\n\n\n500\n4\n155\n1.55%\n\n\n600\n3\n45\n0.45%\n\n\n600\n4\n119\n1.19%\n\n\n650\n4\n39\n0.39%\n\n\n700\n4\n40\n0.40%\n\n\n800\n4\n10\n0.10%\n\n\n1000\n3\n32\n0.32%\n\n\n1000\n4\n147\n1.47%\n\n\n1050\n4\n26\n0.26%\n\n\n1200\n4\n8\n0.08%\n\n\n5000\n4\n10\n0.10%\n\n\n\n\n\n\n\n\n\n\n\n\nExpand for Session Info\n\n\n\n\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.0 (2022-04-22)\n os       macOS Monterey 12.2.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       America/Chicago\n date     2022-04-28\n pandoc   2.18 @ /Applications/RStudio.app/Contents/MacOS/quarto/bin/tools/ (via rmarkdown)\n quarto   0.9.294 @ /usr/local/bin/quarto\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version    date (UTC) lib source\n dplyr       * 1.0.8      2022-02-08 [1] CRAN (R 4.2.0)\n forcats     * 0.5.1      2021-01-27 [1] CRAN (R 4.2.0)\n ggplot2     * 3.3.5      2021-06-25 [1] CRAN (R 4.2.0)\n gt          * 0.5.0.9000 2022-04-27 [1] Github (rstudio/gt@0d4c83d)\n purrr       * 0.3.4      2020-04-17 [1] CRAN (R 4.2.0)\n readr       * 2.1.2      2022-01-30 [1] CRAN (R 4.2.0)\n sessioninfo * 1.2.2      2021-12-06 [1] CRAN (R 4.2.0)\n stringr     * 1.4.0      2019-02-10 [1] CRAN (R 4.2.0)\n tibble      * 3.1.6      2021-11-07 [1] CRAN (R 4.2.0)\n tictoc      * 1.0.1      2021-04-19 [1] CRAN (R 4.2.0)\n tidyr       * 1.2.0      2022-02-01 [1] CRAN (R 4.2.0)\n tidyverse   * 1.3.1      2021-04-15 [1] CRAN (R 4.2.0)\n\n [1] /Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/library\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "posts/2020-08-01-building-a-blog-with-distill/index.html",
    "href": "posts/2020-08-01-building-a-blog-with-distill/index.html",
    "title": "Building a blog with distill",
    "section": "",
    "text": "Modern building"
  },
  {
    "objectID": "posts/2020-08-01-building-a-blog-with-distill/index.html#why-consider-distill",
    "href": "posts/2020-08-01-building-a-blog-with-distill/index.html#why-consider-distill",
    "title": "Building a blog with distill",
    "section": "Why consider distill?",
    "text": "Why consider distill?\nPros\nNo Hugo dependency, no theme dependency, it’s a very stable format with the ability to customize just enough with a bit of effort. Think a self-hosted Medium.com in appearance. Very minimal, lightly themed, focused on writing and code! Again, I think that for someone getting started with creating websites or blogs it’s a very good starting point.\nWith distill you render/knit your articles locally, so you can quickly check your work without having to deploy to a git branch or to production. I do think that eventually it is a good idea to have git branches for previews or collaboration, but that’s a lot to ask for an initial first stab at a blog/site.\ndistill also natively supports citations, footnotes and asides, a rich auto-generated table of contents, support for HTMLwidgets and/or custom javascript, and a reader friendly typography that is mobile friendly/auto-adapts to mobile.\nAnother nicety is the ability to import a post with import_post(). This means you can take an existing blogpost from another website and import it into your new blog. This “does not require the original R Markdown document used to author the post—you only need access to the published HTML of a post to import it.”\nLastly, I am always amazed at the power of both blogdown and the more recent hugodown, but you are still relying on a changing version of Hugo and your theme over time. For a personal blog I personally prefer distill because I can get busy, neglect my blog for a year, come back to write a new post, and it still just works.\nCons\nHowever, blogdown and hugodown allow dramatically more customization. distill is truly an opinionated framework, and most of the easy customization you can do is fonts, colors, and the navbar. If you expect to create gorgeous custom-layout sites like education.rstudio.com or something like Desirée de Leon’s blog you’re likely going to be disappointed!\nAgain, for my blog I really just wanted a simple but in my opinion elegant minimalist theme, so I was fine with the tradeoff, as I would have built something similar with blogdown anyway!\nblogdown also supports other static site generators like Jekyll in place of Hugo, and a rich set of pre-built themes across the various generators. The structure of the site is extensible as well, so you can generate a site that truly looks like your own creation.\nLastly, note that you DO lose some niceties like hugo shortcodes for embedding, and again there is ONLY ONE THEME. Most appearance customization is done at the level of custom CSS.\nIf you’re still with me, here’s how to make it!"
  },
  {
    "objectID": "posts/2020-08-01-building-a-blog-with-distill/index.html#step-1-install-distill",
    "href": "posts/2020-08-01-building-a-blog-with-distill/index.html#step-1-install-distill",
    "title": "Building a blog with distill",
    "section": "Step 1: Install distill\n",
    "text": "Step 1: Install distill\n\n\ninstall.packages(\"distill”)"
  },
  {
    "objectID": "posts/2020-08-01-building-a-blog-with-distill/index.html#step-2-new-project-from-distill-blog",
    "href": "posts/2020-08-01-building-a-blog-with-distill/index.html#step-2-new-project-from-distill-blog",
    "title": "Building a blog with distill",
    "section": "Step 2: New project from distill blog\n",
    "text": "Step 2: New project from distill blog\n\nWhat this is really doing is running the following command, and generates the output below.\n\n> distill::create_blog(dir = \"demo-distill\", title = \"Demo Distill\")\nCreating website directory demo-distill\nCreating demo-distill/_site.yml\nCreating demo-distill/index.Rmd\nCreating demo-distill/about.Rmd\nCreating demo-distill/_posts/welcome/welcome.Rmd\n\nThis will create a home-directory titled whatever you passed for the dir argument above, so in our case “demo-distill”. This will contain the _site.yml, the about.rmd file, the index.rmd file, and two folders: _posts and _site. You should definitely change the dir and title arguments to whatever you want your site to be named, although you can edit this later with a bit of work.\nWhile you’re welcome to explore _site I consider it something you SHOULD NOT edit by hand and it will commonly get overridden by rebuilding posts or the whole site. _site is essentially where the built site lives as final HTML and other supporting files. The _posts folder on the other hand contains all the raw RMDs you will use to create posts."
  },
  {
    "objectID": "posts/2020-08-01-building-a-blog-with-distill/index.html#step-3-preview",
    "href": "posts/2020-08-01-building-a-blog-with-distill/index.html#step-3-preview",
    "title": "Building a blog with distill",
    "section": "Step 3: Preview",
    "text": "Step 3: Preview\nAt this point the website is technically built! You can “preview” the site by going to:_site -> index.html\nThe index.html is essentially the home page for your blog. You can navigate from there in either the RStudio viewer or send it to a web browser just like a normal webpage.\nNote: you can also use the Build Website button in RStudio to pull up the whole website. This will re-knit and build the entire site from scratch.\n\n\nPreview of the site"
  },
  {
    "objectID": "posts/2020-08-01-building-a-blog-with-distill/index.html#step-4-_site.yml",
    "href": "posts/2020-08-01-building-a-blog-with-distill/index.html#step-4-_site.yml",
    "title": "Building a blog with distill",
    "section": "Step 4: _site.yml\n",
    "text": "Step 4: _site.yml\n\nThe _site.yml is where you control the overall details about your blog such as the name, title, description, and the navbar. You can add new “tabs” by changing the _site.yml file, where the default has a navbar with the site name on the left and a “Home” and “About” Tab on the right.\n\nname: \"demo-distill\"\ntitle: \"Demo Distill\"\ndescription: |\n  Demo Distill\noutput_dir: \"_site\"\nnavbar:\n  right:\n    - text: \"Home\"\n      href: index.html\n    - text: \"About\"\n      href: about.html\noutput: distill::distill_article"
  },
  {
    "objectID": "posts/2020-08-01-building-a-blog-with-distill/index.html#step-5-example-blog-post",
    "href": "posts/2020-08-01-building-a-blog-with-distill/index.html#step-5-example-blog-post",
    "title": "Building a blog with distill",
    "section": "Step 5: Example blog post",
    "text": "Step 5: Example blog post\nNavigate to _posts -> welcome -> welcome.rmd. This is the default “hello world” example that comes with you distill. Note you can delete that folder completely to drop it from the site, but let’s use it as a practice ground first.\nThis is still just a RMarkdown file, but it has a specific YAML header, that contains a title, a description, author, date, and outputs to distill::distill_article().\nTry adding some more text, code, or other content to this blog post and then knit it! It will generate and show the final output in the RStudio viewer.\n\n---\ntitle: \"Welcome to Demo Distill\"\ndescription: |\n  Welcome to our new blog, Demo Distill. We hope you enjoy \n  reading what we have to say!\nauthor:\n  - name: Nora Jones \n    url: https://example.com/norajones\n    affiliation: Spacely Sprockets\n    affiliation_url: https://example.com/spacelysprokets\ndate: 07-27-2020\noutput:\n  distill::distill_article:\n    self_contained: false\n---"
  },
  {
    "objectID": "posts/2020-08-01-building-a-blog-with-distill/index.html#step-6-new-post",
    "href": "posts/2020-08-01-building-a-blog-with-distill/index.html#step-6-new-post",
    "title": "Building a blog with distill",
    "section": "Step 6: New post",
    "text": "Step 6: New post\nTo create a new post, you can run the following command:distill::create_post(\"title of post\")\nFull arguments seen below! I’ll call out two specific things.\n\n\ndraft argument: this prevents the post from being included in the site build until you turn it to FALSE. This is useful if you’re working on a blogpost over time, or want to come back to finish it later.\n\n\ndate_prefix: this adds a date like 2020-08-01-blog-post to the front of whatever your blog-post name is. This is useful as it also creates a folder structure that sorts properly, and prevents name clashes.\n\nWhenever you run the create_post() command it will generate a new folder and the basic RMarkdown doc to get started with the arguments you passed.\ncreate_post(\n  title, # mandatory\n  author = \"auto\",\n  slug = \"auto\", # generates a website slug (URL)\n  date_prefix = TRUE, # adds date for sorting\n  draft = FALSE, \n  edit = interactive()\n)\n\nNote that a nice overview of the Blog Post Workflow is covered at the distill site. This includes collaborating via Git Branches (or using them as previews). I push to my main branch all the time since I’m working solo."
  },
  {
    "objectID": "posts/2020-08-01-building-a-blog-with-distill/index.html#step-7-add-to-git",
    "href": "posts/2020-08-01-building-a-blog-with-distill/index.html#step-7-add-to-git",
    "title": "Building a blog with distill",
    "section": "Step 7: Add to Git",
    "text": "Step 7: Add to Git\nWe’re following instructions at: Chapter 17 Existing project, GitHub last | Happy Git and GitHub for the useR. If you’re a Git expert, feel free to use whatever method you like. From my experience setting up a few blogs this is the least painful if you’re NOT a Git expert.\n\nYou could also do the create GitHub and then connect it to RStudio route Chapter 17 Existing project, GitHub last | Happy Git and GitHub for the useR.\n\nNOTE: if you don’t have a GitHub PAT, get one now by following these instructions B GitHub Personal Access Tokens | Happy Git and GitHub for the useR.\nThis will first use Git locally, and then create a new GitHub repo based off your existing local files.\nRun the usethis::use_git() command, which will kick off some questions:\n\nDon’t commit just yet (Select 3: Not Now)\n\nRestart RStudio (Select 2: Yes)\n\nYou will know it all worked when you have the git logo at the top of RStudio\n\n\nGit logo\n\n\n\nClick on the Git logo and commit everything, notice we can’t push since we haven’t configured GitHub yet\n\n\n\nInitial commit\n\n\n\n\nusethis::use_github() — this works if you have already configured a GitHub Personal Access Token\n\nNext select https if you don’t have SSH keys\n\nSay 1: yup to the title and description\n\n\n\nExample of what your console commands are and their output seen below!\n\n> usethis::use_github()\n✓ Setting active project to '/Users/thomasmock/demo-distill-blog'\n✓ Checking that current branch is 'master'\nWhich git protocol to use? (enter 0 to exit) \n\n1: ssh   <-- presumes that you have set up ssh keys\n2: https <-- choose this if you don't have ssh keys (or don't know if you do)\n\nSelection: 2\n● Tip: To suppress this menu in future, put\n  `options(usethis.protocol = \"https\")`\n  in your script or in a user- or project-level startup file, '.Rprofile'.\n  Call `usethis::edit_r_profile()` to open it for editing.\n● Check title and description\n  Name:        demo-distill-blog\n  Description: \nAre title and description ok?\n\n1: Yup\n2: No way\n3: Negative\n\nSelection: 1\n✓ Creating GitHub repository\n✓ Setting remote 'origin' to 'https://github.com/jthomasmock/demo-distill-blog.git'\n✓ Pushing 'master' branch to GitHub and setting remote tracking branch\n✓ Opening URL 'https://github.com/jthomasmock/demo-distill-blog'\n\nOnce this is all run, it should open up a new webpage with your fancy new GitHub repo! Mine opened at: GitHub - jthomasmock/demo-distill-blog."
  },
  {
    "objectID": "posts/2020-08-01-building-a-blog-with-distill/index.html#step-8-netlify",
    "href": "posts/2020-08-01-building-a-blog-with-distill/index.html#step-8-netlify",
    "title": "Building a blog with distill",
    "section": "Step 8: Netlify",
    "text": "Step 8: Netlify\nNow that we have our files on Github, we’re ready to deploy via Netlify!\nYou’ll need to Create an account at netlify if you don’t have one already.\nOnce you’re logged in:\n\nFirst click on import from Git\n\n\n\nNew site from Git\n\n\n\nClick on Configure netlify on GitHub, and follow their instructions to allow access, and then add the selected repository you want to send over (demo-distill-blog for me)\n\nClick Save!\n\n\n\n\n\nAdd specific repo\n\n\n\nClick on demo-distill-blog or whatever your blog’s name is!\n\nIMPORTANT\n\nMake sure to set the Publish Directory to _site (so Netlify can find the knitted HTML content)\n\nAnd then click deploy!\n\n\n\nMake sure to set publish directory to _site\n\n\n\nYou’ll get a fun temporary name (mine was https://confident-meitner-e6e7dc.netlify.app/). You can change this with the Domain Settings to some-name.netlify.app or even purchase a custom domain like I did for example themockup.blog or what Sharla Gelfand did with sharla.party.\n\nNow your website should be up and running! If you don’t see a site (it 404s), then I would check to make sure you set the Publish Director to _site, otherwise it won’t know where to find the actual HTML content."
  },
  {
    "objectID": "posts/2020-08-01-building-a-blog-with-distill/index.html#step-9-blog-post-workflows",
    "href": "posts/2020-08-01-building-a-blog-with-distill/index.html#step-9-blog-post-workflows",
    "title": "Building a blog with distill",
    "section": "Step 9: Blog post workflows",
    "text": "Step 9: Blog post workflows\n\nWorkflow difference: Furthermore, website pages and root pages of blogs are re-rendered when the site is rebuilt but blog articles are not. Each blog article has to be rendered on its own, with intent. Why? Given that R package upgrades have a tendency to break older code, continuously re-rendering old posts is nearly impossible to do without errors, especially over longer periods of time.\n\nThis means you can “Build Site” frequently locally to check out how things work. This is personally the workflow I prefer vs having to commit the output to GitHub or a GitHub branch just to see the preview. You can also knit individual blog posts and they will adapt to your theme, so you can again test local changes whenever you’d like!\nTo get things into “production” once you have set up Netlify, you’ll just need to knit the new blog post, then commit and push to GitHub.\nYou can use command line git or the git integration in RStudio.\n\n\nExample of git in RStudio\n\n\nBasic idea is click commit and then push.\n\n\nExample of a commit"
  },
  {
    "objectID": "posts/2020-08-01-building-a-blog-with-distill/index.html#customize-appearance",
    "href": "posts/2020-08-01-building-a-blog-with-distill/index.html#customize-appearance",
    "title": "Building a blog with distill",
    "section": "Customize Appearance",
    "text": "Customize Appearance\nProbably of most interest to folks is customizing the appearance of the blog.\n\nIn general the strategy you should use is to inspect parts of the website for the class names and then you can apply CSS to change it\n\nA nice overview of the “Inspect” tool is covered here\n\nHTML/CSS classes and selectors are covered in the Mozilla docs here\n\nTo use a custom CSS file, you’ll need to change the output in _site.yml to include the below:\n\n\noutput: \n  distill::distill_article:\n    css: styles.css\n\nI keep my styles.css file at the same level as my _site.yml file.\nExample changes\nYou’ll need to store all of these in your styles.css file, and note that some of them depend on other changes - specifically to use custom fonts you ALSO have to import the custom fonts!\nBold silver title, pink background\n\n.distill-site-nav {\n  color: #C0C0C0; \n  background-color: #FF1493;\n  font-size: 20px;\n  font-weight: 900;\n}\n\nWant entire webpage to be “pink”?\nbody {\n  background-color: #FF1493;\n}\nChange hover color in nav bar\n.distill-site-nav a:hover {\n  color: #383838;\n}\nChange header font or color\n/* Change appearance of headers */\nh1, h2, h3, h4, h5 {\n  font-family: 'Fira Mono', sans-serif;\n  color: color: #383838;\n}\nImport custom fonts from Google\n/* Import fonts from Google's API */\n@import url('https://fonts.googleapis.com/css2?family=Lato');\n@import url('https://fonts.googleapis.com/css2?family=Fira+Mono');\nUse those fonts throughout\n/* Use specific font in the body of the text */\nhtml, body, p {\n  \n  font-family: 'Lato', sans-serif;\n  font-weight: 200;\n  line-height: 1.3; \n  font-size: 1.0em;\n  color: #333333;\n  font-style: normal;\n  \n}\nChange in-line code\n/* Change the appearance of in-line code chunks */\ncode {\n  font-family: 'Fira Mono', sans-serif;\n  color: #383838;\n  background: #F5F5F5;\n  font-weight: 400;\n  font-size: 0.9em;\n}\nChange code chunk colors\nd-code {\n  background: grey;\n}\n\n\n\n\n\n\nExpand for Session Info\n\n\n\n\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.0 (2022-04-22)\n os       macOS Monterey 12.2.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       America/Chicago\n date     2022-04-28\n pandoc   2.18 @ /Applications/RStudio.app/Contents/MacOS/quarto/bin/tools/ (via rmarkdown)\n quarto   0.9.294 @ /usr/local/bin/quarto\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version date (UTC) lib source\n sessioninfo * 1.2.2   2021-12-06 [1] CRAN (R 4.2.0)\n\n [1] /Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/library\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "posts/2021-08-27-displaying-verbatim-code-chunks-in-xaringan-presentations/index.html",
    "href": "posts/2021-08-27-displaying-verbatim-code-chunks-in-xaringan-presentations/index.html",
    "title": "Displaying verbatim code chunks in RMarkdown and Xaringan presentations",
    "section": "",
    "text": "This will be a short article, but I wanted to note it for my own future use and hopefully a discoverable resource if folks get stuck trying to do the same thing!\nBack to the original blogpost!\nI recently gave a presentation on Advanced RMarkdown use, and part of what I was displaying in my RMarkdown generated xaringan slides was literal RMarkdown code chunks. These verbatim code chunks are very useful and in some cases necessary to accurately convey a teaching example.\nNotably, while these verbatim code chunks are extremely useful some difficulty can arise as you’re essentially nesting R and RMarkdown code/logic inside a RMarkdown document. In order to “tell” RMarkdown to ignore the code and simply print it out verbatim you need to use a few different techniques.\nMore details can be found in the RMarkdown Cookbook."
  },
  {
    "objectID": "posts/2021-08-27-displaying-verbatim-code-chunks-in-xaringan-presentations/index.html#verbatim-code-chunks",
    "href": "posts/2021-08-27-displaying-verbatim-code-chunks-in-xaringan-presentations/index.html#verbatim-code-chunks",
    "title": "Displaying verbatim code chunks in RMarkdown and Xaringan presentations",
    "section": "Verbatim Code Chunks",
    "text": "Verbatim Code Chunks\nThe primary problem here is we need to “tell” RMarkdown not to parse the RMarkdown code chunk as real code. So we need to account for the 3x backticks that make up an R code chunk as seen below.\n\n\n```{r, echo = TRUE}\n...code_goes_here...\n```\n\n\n\ncat() to the rescue\nYou can use cat() to output specific code chunks verbatim as raw text. This can be very fast, but requires you to write code by hand in text.\n\noutput_code <-\n\"````\n```{r, eval=TRUE}`r ''`\nlibrary(dplyr)\nmtcars %>% \n  group_by(cyl) %>% \n  summarize(n = n(), mean = mean(mpg))\n```\\n````\"\n\ncat(output_code)\n\n````\n```{r, eval=TRUE}`r ''`\nlibrary(dplyr)\nmtcars %>% \n  group_by(cyl) %>% \n  summarize(n = n(), mean = mean(mpg))\n```\n````\n\n\nWe need more backticks captain!\nTo return unevaluated verbatim code chunks code you need N + 1 of the max backticks, so for RMarkdown chunks that have 3x backticks, you need to wrap it in 4x backticks on either side of the code.\nYou also need to invalidate the code chunk by adding a blank r '' to the end of the existing code chunk (ie immediately after the {r} like so:\n\n\n```{r}`r''`\n...code_goes_here...\n```\n\n\nAs a code example I can wrap my code in 4x backticks around the 3x backticks, also note the invalidated r expression after the {r}.\n\n\n````\n```{r}`r ''`\nlibrary(dplyr)\nmtcars %>% \n  group_by(cyl) %>% \n  summarize(n = n(), mean = mean(mpg))\n```\n````\n\n\nThat rendered inside RMarkdown outputs:\n```{r}\nlibrary(dplyr)\nmtcars %>% \n  group_by(cyl) %>% \n  summarize(n = n(), mean = mean(mpg))\n```\n\nHowever you may notice that there’s no grey code background for the code chunk. To format it, we can also add the code type to the end of the 4x backticks for formatting purposes. I have a panelset of some of the various code types appended to the 4x backticks below. This affects some highlighting of specific functions/strings/etc in the code as well.\nA note here is that my blog is written in distill, so what you see here is not identical to xaringan which is built on remark.js. As such, I’ve included the distill output below, and after that another embedded version of a minimal xaringan presentation. In xaringan there is also the highlightStyle argument in the YAML which allows for a lot of customization of the code chunk/code/comments colors. The various options for this argument are at the bottom of the remark.js wiki.\n\n{distill} output\n\n\n\n\nBlank\nr\nfortan\nmarkdown\nc\nhaskell\npython\n\n\n\nAdd nothing to end of 4x backticks\n\n````\n````\n\nWhich returns code formatted like the below:\n```{r}\n# load library\nlibrary(dplyr)\n\n# Execute code\nmtcars %>% \n  group_by(cyl) %>% \n  summarize(n = n(), mean = mean(mpg)) %>% \n  mutate(cyl_name = paste(cyl, \"Cylinders\"))\n```\n\n\n\n\nAdd the letter r to end of 4x backticks\n\n````r\n````\n\nWhich returns code formatted like the below:\n```{r}\n# load library\nlibrary(dplyr)\n\n# Execute code\nmtcars %>% \n  group_by(cyl) %>% \n  summarize(n = n(), mean = mean(mpg)) %>% \n  mutate(cyl_name = paste(cyl, \"Cylinders\"))\n```\n\n\n\nAdd fortran to the end of the 4x backticks\n\n````fortran\n````\n\nWhich returns code formatted like the below:\n```{r}\n# load library\nlibrary(dplyr)\n\n# Execute code\nmtcars %>% \n  group_by(cyl) %>% \n  summarize(n = n(), mean = mean(mpg)) %>% \n  mutate(cyl_name = paste(cyl, \"Cylinders\"))\n```\n\n\n\nAdd markdown or md to the end of the 4x backticks\n\n````markdown\n````\n\nWhich returns code formatted like the below:\n```{r}\n# load library\nlibrary(dplyr)\n\n# Execute code\nmtcars %>% \n  group_by(cyl) %>% \n  summarize(n = n(), mean = mean(mpg)) %>% \n  mutate(cyl_name = paste(cyl, \"Cylinders\"))\n```\n\n\n\nAdd the letter c to the end of the 4x backticks\n\n````c\n````\n\nWhich returns code formatted like the below:\n```{r}\n# load library\nlibrary(dplyr)\n\n# Execute code\nmtcars %>% \n  group_by(cyl) %>% \n  summarize(n = n(), mean = mean(mpg)) %>% \n  mutate(cyl_name = paste(cyl, \"Cylinders\"))\n```\n\n\n\nAdd haskell to the end of the 4x backticks\n\n````haskell\n````\n\nWhich returns code formatted like the below:\n```{r}\n# load library\nlibrary(dplyr)\n\n# Execute code\nmtcars %>% \n  group_by(cyl) %>% \n  summarize(n = n(), mean = mean(mpg)) %>% \n  mutate(cyl_name = paste(cyl, \"Cylinders\"))\n```\n\n\n\nAdd python to the end of the 4x backticks\n\n````python\n````\n\nWhich returns code formatted like the below:\n```{python}\n# load library and data\nimport pandas as pd\nimport statsmodels.api as sm\n\nmtcars = sm.datasets.get_rdataset(\"mtcars\", \"datasets\", cache=True).data\n\n# Execute code\n(mtcars\n  .groupby(['cyl'])\n  .agg(['count', 'mean']))\n```\n\n\n\n\n\n\nXaringan output"
  },
  {
    "objectID": "posts/2021-08-27-displaying-verbatim-code-chunks-in-xaringan-presentations/index.html#add-more-complexity",
    "href": "posts/2021-08-27-displaying-verbatim-code-chunks-in-xaringan-presentations/index.html#add-more-complexity",
    "title": "Displaying verbatim code chunks in RMarkdown and Xaringan presentations",
    "section": "Add more complexity",
    "text": "Add more complexity\nNow you can also embed essentially entire RMarkdown documents, including inline code. For inline code such as 'r 1 + 1', you’ll need to use one more technique - also outlined in the RMarkdown Cookbook.\nTo display inline code like r 1+1 you’ll need to use knitr::inline_expr('1+1') which will convert the raw expression to the expected inline output of r 1+1 before it’s evaluated by RMarkdown.\nA meta example from the RMarkdown Cookbook:\n\ncode = 'This will show a verbatim inline R expression `r knitr::inline_expr(\\'knitr::inline_expr(\"1+1\")\\')` in the output.'\n\ncat(code)\n\nThis will show a verbatim inline R expression `r knitr::inline_expr('knitr::inline_expr(\"1+1\")')` in the output.\n\n\nWhich if used as code outputs:\nThis will show a verbatim inline R expression\n`r knitr::inline_expr(\"1+1\")` in the output.\nWe can use a full example below.\nGenerate inline code\nTo generate the verbatim inline code we actually used:\nWe have data about `r knitr::inline_expr(\"nrow(penguins)\")` penguins.  Only \n`r knitr::inline_expr(\"nrow(penguins) - nrow(smaller)\")` are classified as\n`r knitr::inline_expr(\"params$species\")`. The distribution of the \n`r knitr::inline_expr(\"params$species\")` penguins are shown below:\nWhich generated the code below:\n\nWe have data about `r nrow(penguins)`  penguins.  Only \n`r nrow(penguins) - nrow(smaller)` are classified as\n`r params$species`. The distribution of the \n`r params$species` penguins are shown below:\nAll together now\nHere’s YAML + code chunks + inline R expression, all in one code block!\n---\ntitle: \"Penguins\"\ndate: 2020-08-11\noutput: html_document\nparams:\n  species: Adelie\n---\n```{r setup, include = FALSE}\nlibrary(tidyverse)\nlibrary(palmerpenguins)\nsmaller <- penguins %>% \n  filter(species == params$species, \n         !is.na(body_mass_g))\n```\nWe have data about `r nrow(penguins)` penguins.  Only \n`r nrow(penguins) - nrow(smaller)` are classified as\n`r params$species`. The distribution of the \n`r params$species` penguins are shown below:\n\n```{r, echo = FALSE}\nsmaller %>% \n  ggplot(aes(body_mass_g)) + \n  geom_histogram(binwidth = 100)\n```\n\nMake sure to keep track of your back ticks as the code can stop looking like “real” code after staring at for a while. I highly recommend checking yourself as you go, because if you miss a backtick it can be quite tricky to “find the needle in the haystack”…\n\nJust for fun, I’ve included a link to the source code for the above embedded RMarkdown so you can explore it.\nI also highly recommend exploring the source code of the RMarkdown Cookbook to figure out how they did all of their inline embedding.\n\n\n\n\n\n\n\n\n\n\nExpand for Session Info\n\n\n\n\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.0 (2022-04-22)\n os       macOS Monterey 12.2.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       America/Chicago\n date     2022-05-11\n pandoc   2.18 @ /Applications/RStudio.app/Contents/MacOS/quarto/bin/tools/ (via rmarkdown)\n quarto   0.9.387 @ /usr/local/bin/quarto\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version    date (UTC) lib source\n quarto      * 1.1.0.9000 2022-04-26 [1] Github (quarto-dev/quarto-r@e06d096)\n sessioninfo * 1.2.2      2021-12-06 [1] CRAN (R 4.2.0)\n\n [1] /Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/library\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "posts/2021-04-01-three-years-of-tidytuesday/index.html",
    "href": "posts/2021-04-01-three-years-of-tidytuesday/index.html",
    "title": "Three years of TidyTuesday",
    "section": "",
    "text": "The #TidyTuesday project has been active since April 1st of 2018, so today is the 3 year anniversary!\nThere was even a paper published on TidyTuesday!\nOver the past 3 years, 1000s of people have contributed their submissions and “shown their work” with open source R code! Since the primary way people engage with TidyTuesday is via Twitter submissions, I have a weekly tweet collector that stores and uploads the Tweets to the TidyTuesday GitHub.\nThis allows us to do some basic counting of a few different parameters over time. However, before we get to the details I also want to get into a mistake we’ve made and have partially rectified. Thanks to efforts by Dr. Liz Hare and Dr. Silvia Canelon, I was made aware that less than 3% of submissions include alternative text (alt text) describing the graphic. This includes basically ALL of my own tweets.\nI recommend listening to their talk at CSV conf 2021 on May 5th at 10:20am EST for the full details, and some advice on how to improve our accessibility.\nIf you’re not aware, alt text is the primary way that screen reader software used by low vision or blind users interact with many web pages or other software. Per the American Foundation for the Blind:\nPer the National Federation of the Blind, there were ~ 8 million US-based individuals with visual disability as of 2016. While this is less prevalent than color blindness, it doesn’t capture the whole story. Low vision, altered vision, or motor impairment as opposed to clinically-defined blindness is even more prevalent. I think that the thread by Frank Elavsky covers more details that are worth reading, and emphasizing that inclusivity doesn’t stop at color blind safe palettes.\nUltimately, there is a need to move beyond simply thinking about color-blindness, and making sure to include things like alt text, emphasizing contrast, and generally make our data visualization more engaging for all the potential consumers. I’ve not done a great job of this in the past, but am on a journey to “do better”."
  },
  {
    "objectID": "posts/2021-04-01-three-years-of-tidytuesday/index.html#alt-text-for-graphs",
    "href": "posts/2021-04-01-three-years-of-tidytuesday/index.html#alt-text-for-graphs",
    "title": "Three years of TidyTuesday",
    "section": "Alt text for graphs",
    "text": "Alt text for graphs\nThe Data Visualization Society has a great article by Amy Cesal on Writing Alt Text for Data Visualization.\n\nYou probably can’t write text that conveys the entire meaning of a chart. But, that doesn’t mean that you shouldn’t try.\n\nUltimately, this is a hard problem, but just as Amy says - that doesn’t mean we can’t or shouldn’t try to do our best to describe our graphs for folks who aren’t able to see all the details.\nShe recommends alt text that includes:\n\nChart type\n\nThe type of data\n\nReason for including the chart\n\nLink to the data source\n\nThe goal here is to add a rich description of the PURPOSE of the graph, which is ultimately the goal of data visualization - telling a story with data.\nI have a brief script using glue that allows you to write this style of alt text.\n\nwrite_alt_text <- function(\n  chart_type, \n  type_of_data, \n  reason, \n  source\n  ){\n  glue::glue(\n    \"{chart_type} of {type_of_data} where {reason}. \\n\\nData source from {source}\"\n    )\n}\n\n\nwrite_alt_text(\n  \"Bar Chart\", \n  \"tweets from the past week tagged with the TidyTuesday hashtag\", \n  \"Tuesday is the most popular day to post tweets, although about 20-30 tweets are posted every day\", \n  \"the {rtweet} package.\"\n  )\n\nBar Chart of tweets from the past week tagged with the TidyTuesday hashtag where Tuesday is the most popular day to post tweets, although about 20-30 tweets are posted every day. \n\nData source from the {rtweet} package.\n\n\nThis can be easily added to Twitter-based images via the various clients, and will also be able to be uploaded via rtweet in the future. Twitter has a full guide on how to add image alt text.\n\nWhen you Tweet photos using the Twitter app for iOS or Android, or on twitter.com, you have the option to compose a description of the images so the content is accessible to more people, including those who are blind or low-vision.\nGood image descriptions are concise and descriptive, helping people understand what’s happening in an image.\n\nWithout alt text, most images on Twitter will just default to reporting “Image” as the alt text for any images you display. You could imagine that while a picture is worth a 1000 words, that the word “image” is far from helpful in describing said image.\nFurthermore, Penn State has a chart description guide that covers charts and accessibility.\n\nGenerally speaking an ALT tag cannot do justice to a complex chart. One way to describe a chart is to provide both a text summary and a properly coded data table near the chart.\nThis serves multiple audiences because a chart can show trends, but a table can provide exact data for those who are interested.\n\nI love this idea of providing the raw data in a table or a source in addition to the image itself. However, I think that also making sure to write a good text description is better than just sharing the data or table alone.\nLastly, to help you remember to always include alt text for images and gifs on Twitter, you can add extensions like Chrome’s Twitter Required Alt Text. This actually prevents you from uploading images WITHOUT alt text."
  },
  {
    "objectID": "posts/2021-04-01-three-years-of-tidytuesday/index.html#future-effort",
    "href": "posts/2021-04-01-three-years-of-tidytuesday/index.html#future-effort",
    "title": "Three years of TidyTuesday",
    "section": "Future effort",
    "text": "Future effort\nWhile I’ve made some changes to my personal workflow and including alt text in my “automated” tweets around #TidyTuesday, I hope that we as the R community and more specifically the #TidyTuesday community can make it a priority to add more alt text to our graphs and be more inclusive of the wider community.\nWhile I am excited about the work we have done in the past, we obviously have a lot to do in the future to make this a reality. As part of this, I’m going to be walking through some of the past submission data and writing out example alt text, as well as including tables.\nFor RMarkdown docs/blogs, you can add alt text very easily!\nFirst off, the basic syntax provides an area for alt text, detailed in the RMarkdown Cookbook.\n![an informative text](path/to/image.png)\nOR with knitr::include_graphics(), which is what I’ve done for the images below.\n{r, fig.cap=\"alt text\"}\nknitr::include_graphics('figures/my_image.png')"
  },
  {
    "objectID": "posts/2021-04-01-three-years-of-tidytuesday/index.html#tidytuesday-data",
    "href": "posts/2021-04-01-three-years-of-tidytuesday/index.html#tidytuesday-data",
    "title": "Three years of TidyTuesday",
    "section": "\n#TidyTuesday data",
    "text": "#TidyTuesday data\nWith this in mind, we can walk through the past TidyTuesday posts, create some graphics that show the changes, write some alt text that describes said graphs, and include tables to further “tell our story”. All of the historical data/tweets are collected in the TidyTuesday repo.\n\nlibrary(tidyverse)\nlibrary(lubridate)\n\nraw_url <- \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/tidytuesday_tweets/data.csv\"\n\nraw_df <- read_csv(raw_url)\n\nThere are MANY tweets!\n\nraw_df %>% \n  distinct(status_id) %>% \n  count()\n\n# A tibble: 1 × 1\n      n\n  <int>\n1 17284\n\n\nAnd there are still many tweets if we filter to only include Tweets with a few key words of interest to R/Data visualization.\n\nraw_df %>% \n  filter(str_detect(tolower(text), \"rstats|code|plot|graph|viz|data|tidyverse\")) %>%\n  distinct(status_id) %>% \n  count()\n\n# A tibble: 1 × 1\n      n\n  <int>\n1 13076\n\n\nLastly, there are thousands of unique contributors over the past 3 years.\n\nraw_df %>%\n  filter(str_detect(tolower(text), \"rstats|code|plot|graph|viz|data|tidyverse\")) %>%\n  distinct(screen_name) %>%\n  count()\n\n# A tibble: 1 × 1\n      n\n  <int>\n1  2667"
  },
  {
    "objectID": "posts/2021-04-01-three-years-of-tidytuesday/index.html#data-visualizations",
    "href": "posts/2021-04-01-three-years-of-tidytuesday/index.html#data-visualizations",
    "title": "Three years of TidyTuesday",
    "section": "Data visualizations",
    "text": "Data visualizations\nWe can create some graphics based on this data. I’m going to create some summary datasets, and then get the top weeks for labeling.\n\nsum_df <- raw_df %>%\n  filter(str_detect(tolower(text), \"rstats|code|plot|graph|viz|data|tidyverse\")) %>%\n  mutate(\n    created_date = lubridate::as_date(created_at),\n    year = year(created_date),\n    week = week(created_date)\n  ) %>%\n  filter(year %in% 2018:2021) %>% \n  count(year, week) %>%\n  group_by(year) %>%\n  mutate(\n    roll_n = cumsum(n),\n    week = if_else(year > 2018, week - 1, week - 14),\n    year = factor(year, levels = c(2021, 2020, 2019, 2018)),\n    colour = case_when(\n      year == 2021 ~ \"#FF2B4F\",\n      year == 2020 ~ \"#3686d3\",\n      year == 2019 ~ \"#003399\",\n      year == 2018 ~ \"#88398a\",\n      TRUE ~ \"gray80\"\n    )\n  ) %>%\n  ungroup()\n\ntop_weeks <- sum_df %>%\n  group_by(year) %>%\n  arrange(desc(roll_n)) %>%\n  mutate(mean = mean(n)) %>% \n  slice(1) %>% \n  ungroup()\n\nGrowth chart by year\nThe plotting code is below, and the included alt text:\n\nA line chart of TidyTuesday-tagged tweets across the past 3 years, where there is large year over year growth. 2021 is on pace to exceed the total tweet counts from 2020.\n\n\ntt_plot <- ggplot(\n  sum_df,\n  aes(\n    x = week,\n    y = roll_n,\n    color = colour,\n    group = year\n  )\n) +\n  geom_step(size = 1) +\n  geom_point(\n    data = top_weeks,\n    aes(col = colour),\n    size = 2.5,\n    stroke = 1\n  ) +\n  geom_text(\n    data = top_weeks,\n    aes(label = year),\n    size = 8,\n    hjust = c(1, 1, 1, 0),\n    nudge_y = 50,\n    vjust = 0\n  ) +\n  geom_hline(yintercept = 0, size = 1, color = \"black\") +\n  scale_y_continuous(\n    breaks = seq(0, 5500, by = 500),\n    limits = c(0, 5500)\n  ) +\n  scale_x_continuous(\n    breaks = c(seq(0, 50, 5), 52),\n    limits = c(0, 53)\n  ) +\n  scale_color_identity(aesthetics = c(\"colour\", \"fill\")) +\n  labs(\n    x = \"\\nWeek Number\",\n    y = \"Cumulative Tweets\\n\",\n    caption = \"Data: rtweet | Plot: @thomas_mock\",\n    title = \"Cumulative tweets for #TidyTuesday by year\",\n    subtitle = \"Note that Week 1 of 2018 started in April & tweets must contain: 'rstats, code, plot, graph, viz, data or tidyverse'\\n\"\n  ) +\n  tomtom::theme_538() +\n  theme(\n    legend.position = c(0.1, 0.8),\n    legend.background = element_blank(),\n    legend.title = element_blank(),\n    legend.text = element_text(size = 12),\n    plot.background = element_blank(),\n    plot.title = element_text(size = 24)\n  )\n\nggsave(\n  \"tt_tweets.png\",\n  tt_plot,\n  device = ragg::agg_png(\n    width = 10,\n    height = 10,\n    units = \"in\",\n    scaling = 0.8,\n    res = 500\n  )\n)\n\nSaving 12.5 x 12.5 in image\n\n\n\nknitr::include_graphics(\"tt_tweets.png\")\n\n\n\nA line chart of TidyTuesday-tagged tweets across the past 3 years, where there is large year over year growth. 2021 is on pace to exceed the total tweet counts from 2020.\n\n\n\n\nData sourced from the TidyTuesday repo.\n\nlibrary(gt)\n\ntop_weeks %>% \n  select(year:roll_n, mean) %>% \n  gt() %>% \n  fmt_number(columns = vars(roll_n, mean), decimals = 0) %>% \n  cols_label(\n    week = html(\"Week<br>Number\"),\n    n = html(\"Tweets in<br>last week\"),\n    roll_n = html(\"Rolling<br>Tweet Count\"),\n    ) %>% \n  tab_header(\n    title = md(\"**Summary of TidyTuesday Tweets by year**\"),\n  ) %>% \n  espnscrapeR::gt_theme_538() %>% \n  tab_source_note(\n    html(\"<strong>Data Source: </strong><a href='https://github.com/rfordatascience/tidytuesday/blob/master/tidytuesday_tweets/data.csv'>TidyTuesday Repo</a>\")\n  )\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\nSummary of TidyTuesday Tweets by year\n    \n\nyear\n      WeekNumber\n      Tweets inlast week\n      RollingTweet Count\n      mean\n    \n\n\n2021\n52\n2\n4,353\n82\n\n\n2020\n52\n19\n4,694\n89\n\n\n2019\n52\n12\n2,887\n54\n\n\n2018\n39\n7\n1,059\n26\n\n\n\n\nData Source: TidyTuesday Repo\n\n    \n\n\n\n\nPeak weeks by year\nThe next graphic is intended to show the peak number of tweets recorded for each week, separated out by year. The alt text is included below the graphc, but also described as so:\n\nA bar chart of TidyTuesday-tagged tweets across the past 3 years, split into small multiples by year, where each year shows higher weekly peaks over the same week as last year. 2021 is on pace to have the highest number of tweets for most weeks.\n\n\ncol_label_yr <- tibble(\n  week = 13,\n  n = 110,\n  text = \"Average/Year\",\n  colour = \"#FF2B4F\",\n  year = factor(2021)\n)\n\ntt_col <- sum_df %>%\n  group_by(week) %>%\n  mutate(max = max(n), year = factor(year)) %>%\n  ungroup() %>%\n  ggplot(\n    aes(\n      x = week,\n      y = n,\n      fill = colour,\n      group = year\n    ),\n    color = \"white\",\n  ) +\n  geom_col(aes(x = week, y = max), fill = \"lightgrey\", color = \"transparent\", alpha = 0.7, width = 0.7) +\n  geom_col() +\n  geom_text(\n    data = col_label_yr, hjust = 0, vjust = 0, size = 6, \n    fontface = \"bold\", family = \"Chivo\",\n    aes(label = text, x = week, y = n, color = colour)\n    ) +\n  facet_wrap(~year, ncol = 1) +\n  geom_hline(yintercept = 0, size = 1, color = \"black\") +\n  geom_hline(\n    data = group_by(sum_df, year) %>% summarise(mean = mean(n)),\n    aes(yintercept = mean),\n    color = c(\"#FF2B4F\", \"#3686d3\", \"#003399\", \"#88398a\"),\n    size = 1\n  ) +\n  scale_x_continuous(\n    breaks = c(seq(0, 50, 5), 52),\n    limits = c(-1, 53)\n  ) +\n  scale_color_identity(aesthetics = c(\"colour\", \"fill\")) +\n  tomtom::theme_538() +\n  theme(\n    legend.position = c(0.1, 0.8),\n    legend.background = element_blank(),\n    strip.background = element_rect(fill = \"white\", color = \"white\"),\n    strip.text = element_text(color = \"black\", face = \"bold\", size = 16, hjust = 0),\n    legend.title = element_blank(),\n    legend.text = element_text(size = 12),\n    plot.background = element_blank(),\n    plot.title = element_text(size = 24)\n  ) +\n  labs(\n    x = \"\\nWeek Number\",\n    y = \"Weekly Tweets\\n\",\n    caption = \"Data: rtweet | Plot: @thomas_mock\",\n    title = \"Weekly tweets for #TidyTuesday by year\",\n    subtitle = \"Note that Week 1 of 2018 started in April & tweets must contain: 'rstats, code, plot, graph, viz, data or tidyverse'\\n\"\n  )\n\nggsave(\n  \"tt_columns.png\",\n  plot = tt_col,\n  device = ragg::agg_png(\n    width = 10,\n    height = 10,\n    units = \"in\",\n    scaling = 0.8,\n    res = 500\n  )\n)\n\nSaving 12.5 x 12.5 in image\n\n\n\nknitr::include_graphics(\"tt_columns.png\")\n\n\n\nA bar chart of TidyTuesday-tagged tweets across the past 3 years, split into small multiples by year, where each year shows higher weekly peaks over the same week as last year. 2021 is on pace to have the highest number of tweets for most weeks.\n\n\n\n\nData sourced from the TidyTuesday repo.\nBelow is a corresponding table telling part of the same story, namely that 2021 has many of the highest weekly tweet counts seen over the past 3 years.\n\nsum_df %>% \n  filter(week <= 12) %>% \n  group_by(week) %>% \n  filter(n == max(n)) %>% \n  ungroup() %>% \n  arrange(week) %>% \n  select(year:roll_n) %>% \n  gt() %>% \n  tab_style(\n    style = cell_text(color = \"#FF2B4F\", weight = \"bold\"),\n    locations = cells_body(vars(year), rows = year == 2021)\n  ) %>% \n  tab_style(\n    style = cell_text(color = \"#3686d3\", weight = \"bold\"),\n    locations = cells_body(vars(year), rows = year == 2020)\n  ) %>% \n  fmt_number(columns = vars(roll_n), decimals = 0) %>% \n  cols_label(\n    week = html(\"Week<br>Number\"),\n    n = html(\"Weekly<br>Tweets\"),\n    roll_n = html(\"Rolling<br>Total Tweets\"),\n    ) %>% \n  tab_header(\n    title = md(\"**Peak number of tweets by week**\"),\n    subtitle = \"2021 has most of the top counts for each week\"\n  ) %>% \n  espnscrapeR::gt_theme_538() %>% \n  tab_source_note(\n    html(\"<strong>Data Source: </strong><a href='https://github.com/rfordatascience/tidytuesday/blob/master/tidytuesday_tweets/data.csv'>TidyTuesday Repo</a>\")\n  )\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\n\nPeak number of tweets by week\n    \n\n2021 has most of the top counts for each week\n    \n\n\nyear\n      WeekNumber\n      WeeklyTweets\n      RollingTotal Tweets\n    \n\n\n2021\n0\n79\n79\n\n\n2021\n1\n113\n192\n\n\n2021\n2\n150\n342\n\n\n2021\n3\n122\n464\n\n\n2021\n4\n85\n549\n\n\n2021\n5\n100\n649\n\n\n2021\n6\n132\n781\n\n\n2020\n7\n94\n630\n\n\n2020\n8\n100\n730\n\n\n2020\n9\n90\n820\n\n\n2021\n10\n92\n1,116\n\n\n2021\n11\n115\n1,231\n\n\n2021\n12\n108\n1,339\n\n\n\n\nData Source: TidyTuesday Repo\n\n    \n\n\n\n\nPeak users\nThe last chart is the number of unique contributors by year, regardless of whether they contributed in previous years.\n\nuser_year_sum <- raw_df %>%\n  filter(!screen_name %in% c(\"thomas_mock\", \"r4dscommunity\")) %>%\n  filter(str_detect(tolower(text), \"rstats|code|plot|graph|viz|data|tidyverse\")) %>%\n  mutate(created_date = lubridate::as_date(created_at)) %>%\n  mutate(\n    year = year(created_date),\n    week = week(created_date),\n    week = if_else(year > 2018, week - 1, week - 14),\n    year = factor(year, levels = c(2021, 2020, 2019, 2018))\n  ) %>%\n  filter(year %in% 2018:2021) %>% \n  count(screen_name, week, year) %>%\n  mutate(n = 1) %>%\n  arrange(year, week) %>%\n  distinct(screen_name, year, .keep_all = TRUE) %>%\n  group_by(year) %>%\n  mutate(week_roll_n = cumsum(n)) %>%\n  mutate(\n    colour = case_when(\n      year == 2021 ~ \"#FF2B4F\",\n      year == 2020 ~ \"#3686d3\",\n      year == 2019 ~ \"#003399\",\n      year == 2018 ~ \"#88398a\",\n      TRUE ~ \"gray80\"\n    )\n  ) %>%\n  ungroup() %>%\n  mutate(roll_n = cumsum(n))\n\ntop_user_sum <-  user_year_sum %>%\n  group_by(year) %>%\n  arrange(desc(week_roll_n)) %>%\n  group_by(year, week) %>% \n  mutate(sum = sum(n)) %>% \n  group_by(year) %>% \n  mutate(mean = mean(sum)) %>% \n  slice(1) %>% \n  ungroup()\n\nuser_unique_plot <- user_year_sum %>% \n  ggplot(aes(x = week, y = week_roll_n, color = colour, group = year)) +\n  geom_step(size = 1) + \n  geom_point(\n    data = top_user_sum,\n    aes(col = colour),\n    size = 2.5,\n    stroke = 1\n  ) +\n  geom_text(\n    data = top_user_sum,\n    aes(label = year),\n    size = 8,\n    hjust = c(1, 1, 1, 0),\n    nudge_y = 50,\n    vjust = 0\n  ) +\n  geom_hline(yintercept = 0, size = 1, color = \"black\") +\n  scale_y_continuous(\n    breaks = seq(0, 1250, by = 250),\n    limits = c(0, 1300)\n  ) +\n  scale_x_continuous(\n    breaks = c(seq(0, 50, 5), 52),\n    limits = c(0, 53)\n  ) +\n  scale_color_identity(aesthetics = c(\"colour\", \"fill\")) +\n  labs(\n    x = \"\\nWeek Number\",\n    y = \"Unique Users\\n\",\n    caption = \"Data: rtweet | Plot: @thomas_mock\",\n    title = \"Cumulative unique contributors for #TidyTuesday by year\",\n    subtitle = \"Note that Week 1 of 2018 started in April & tweets must contain: 'rstats, code, plot, graph, viz, data or tidyverse'\\n\"\n  ) +\n  tomtom::theme_538() +\n  theme(\n    legend.position = c(0.1, 0.8),\n    legend.background = element_blank(),\n    legend.title = element_blank(),\n    legend.text = element_text(size = 12),\n    plot.background = element_blank(),\n    plot.title = element_text(size = 24)\n  )\n\nggsave(\n  \"tt_users.png\",\n  user_unique_plot,\n  device = ragg::agg_png(\n    width = 10,\n    height = 10,\n    units = \"in\",\n    scaling = 0.8,\n    res = 500\n  )\n)\n\nSaving 12.5 x 12.5 in image\n\n\n\nknitr::include_graphics(\"tt_users.png\")\n\n\n\nA line chart of unique contributors to TidyTuesday across the past 3 years, where there is large year over year growth. 2021 is on pace to exceed the total unique users from 2020.\n\n\n\n\nData sourced from the TidyTuesday repo.\nBelow is a corresponding table telling part of the same story, namely that 2021 has many of the highest weekly user counts recorded over the past 3 years.\n\ntop_user_sum %>% \n  select(year, week, mean, roll_n = week_roll_n) %>% \n  gt() %>% \n  fmt_number(columns = vars(roll_n, mean), decimals = 0) %>% \n  cols_label(\n    week = html(\"Unique<br>Weeks\"),\n    mean = html(\"Average<br>Weekly Users\"),\n    roll_n = html(\"Rolling<br>User Count\"),\n    ) %>% \n  tab_header(\n    title = md(\"**Summary of TidyTuesday Contributors by year**\"),\n    subtitle = \"2021 has the highest unique user per week\"\n  ) %>% \n  espnscrapeR::gt_theme_538() %>% \n  tab_source_note(\n    html(\"<strong>Data Source: </strong><a href='https://github.com/rfordatascience/tidytuesday/blob/master/tidytuesday_tweets/data.csv'>TidyTuesday Repo</a>\")\n  )\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\n\nSummary of TidyTuesday Contributors by year\n    \n\n2021 has the highest unique user per week\n    \n\n\nyear\n      UniqueWeeks\n      AverageWeekly Users\n      RollingUser Count\n    \n\n\n2021\n52\n28\n1,048\n\n\n2020\n52\n26\n1,178\n\n\n2019\n52\n19\n825\n\n\n2018\n39\n11\n284\n\n\n\n\nData Source: TidyTuesday Repo"
  },
  {
    "objectID": "posts/2021-04-01-three-years-of-tidytuesday/index.html#future",
    "href": "posts/2021-04-01-three-years-of-tidytuesday/index.html#future",
    "title": "Three years of TidyTuesday",
    "section": "Future",
    "text": "Future\nAgain, I’m ecstatic about how many contributors and unique tweets there have been to TidyTuesday over the past 3 years, but I hope that we as a community can improve the user experience for potential low vision or blind contributors as well.\nI will continue to try and make TidyTuesday as inclusive as possible, and greatly appreciate any ideas, contributions, or suggestions from the wider community.\n\n\n\n\n\n\nExpand for Session Info\n\n\n\n\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.0 (2022-04-22)\n os       macOS Monterey 12.2.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       America/Chicago\n date     2022-04-28\n pandoc   2.18 @ /Applications/RStudio.app/Contents/MacOS/quarto/bin/tools/ (via rmarkdown)\n quarto   0.9.294 @ /usr/local/bin/quarto\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version    date (UTC) lib source\n dplyr       * 1.0.8      2022-02-08 [1] CRAN (R 4.2.0)\n forcats     * 0.5.1      2021-01-27 [1] CRAN (R 4.2.0)\n ggplot2     * 3.3.5      2021-06-25 [1] CRAN (R 4.2.0)\n gt          * 0.5.0.9000 2022-04-27 [1] Github (rstudio/gt@0d4c83d)\n lubridate   * 1.8.0      2021-10-07 [1] CRAN (R 4.2.0)\n purrr       * 0.3.4      2020-04-17 [1] CRAN (R 4.2.0)\n readr       * 2.1.2      2022-01-30 [1] CRAN (R 4.2.0)\n sessioninfo * 1.2.2      2021-12-06 [1] CRAN (R 4.2.0)\n stringr     * 1.4.0      2019-02-10 [1] CRAN (R 4.2.0)\n tibble      * 3.1.6      2021-11-07 [1] CRAN (R 4.2.0)\n tidyr       * 1.2.0      2022-02-01 [1] CRAN (R 4.2.0)\n tidyverse   * 1.3.1      2021-04-15 [1] CRAN (R 4.2.0)\n\n [1] /Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/library\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "posts/2022-04-18-session-info/index.html",
    "href": "posts/2022-04-18-session-info/index.html",
    "title": "Adding session info to blog posts",
    "section": "",
    "text": "Session info in R has lots of useful information on the state of your working environment at the moment you were coding. While tools such as renv or packrat can help you create project-specific libraries, sessionInfo() at least lets you capture the basic environment details. I’m not wanting to create project-specific libraries, but I’m rather wanting to share a nicely formatted output of my environment metadata.Put another way, renv can be useful for someone (including yourself) to revert back to the specific package environment, whereas the session info simply returns the basic environment info. For a blogpost, I don’t imagine others trying to match to exact package environments, but rather confirm that their package environment is “similar enough”.\nWe can create and capture the session details like so:\n\nbase_sesh <- sessionInfo()\n\nbase_sesh\n\nR version 4.2.0 (2022-04-22)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Monterey 12.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/lib/libRblas.0.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] emo_0.0.0.9000    lubridate_1.8.0   here_1.0.1        digest_0.6.29    \n [5] crayon_1.5.1      rprojroot_2.0.3   assertthat_0.2.1  jsonlite_1.8.0   \n [9] magrittr_2.0.3    evaluate_0.15     rlang_1.0.2       stringi_1.7.6    \n[13] cli_3.3.0         rstudioapi_0.13   generics_0.1.2    rmarkdown_2.14   \n[17] rsthemes_0.3.1    tools_4.2.0       stringr_1.4.0     htmlwidgets_1.5.4\n[21] glue_1.6.2        purrr_0.3.4       yaml_2.3.5        xfun_0.30        \n[25] fastmap_1.1.0     compiler_4.2.0    htmltools_0.5.2   knitr_1.38.3     \n\n\nSince sessionInfo() generates a list, we can explore it like a list or even inject new objects into it.\n\nbase_sesh |> \n  str(max.level = 1)\n\nList of 12\n $ R.version      :List of 14\n $ platform       : chr \"aarch64-apple-darwin20 (64-bit)\"\n $ locale         : chr \"en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\"\n $ running        : chr \"macOS Monterey 12.2.1\"\n $ RNGkind        : chr [1:3] \"Mersenne-Twister\" \"Inversion\" \"Rejection\"\n $ basePkgs       : chr [1:7] \"stats\" \"graphics\" \"grDevices\" \"utils\" ...\n $ loadedOnly     :List of 28\n $ matprod        : chr \"default\"\n $ BLAS           : chr \"/Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/lib/libRblas.0.dylib\"\n $ LAPACK         : chr \"/Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/lib/libRlapack.dylib\"\n $ system.codepage: chr \"NULL\"\n $ codepage       : chr \"NULL\"\n - attr(*, \"class\")= chr \"sessionInfo\"\n\n\nFor example, I can inject my current version of the quarto CLI into the session info.\n\nbase_sesh$quarto <- system(\"quarto -V\", intern = TRUE)\n\nbase_sesh |>\n  str(max.level = 1)\n\nList of 13\n $ R.version      :List of 14\n $ platform       : chr \"aarch64-apple-darwin20 (64-bit)\"\n $ locale         : chr \"en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\"\n $ running        : chr \"macOS Monterey 12.2.1\"\n $ RNGkind        : chr [1:3] \"Mersenne-Twister\" \"Inversion\" \"Rejection\"\n $ basePkgs       : chr [1:7] \"stats\" \"graphics\" \"grDevices\" \"utils\" ...\n $ loadedOnly     :List of 28\n $ matprod        : chr \"default\"\n $ BLAS           : chr \"/Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/lib/libRblas.0.dylib\"\n $ LAPACK         : chr \"/Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/lib/libRlapack.dylib\"\n $ system.codepage: chr \"NULL\"\n $ codepage       : chr \"NULL\"\n $ quarto         : chr [1:2] \"0.9.577\" \"\"\n - attr(*, \"class\")= chr \"sessionInfo\"\n\n\nWe’ve now captured a lot of useful session info and even injected a new item, so that we can remember what version of the Quarto CLI I was using."
  },
  {
    "objectID": "posts/2022-04-18-session-info/index.html#sessioninfo-package",
    "href": "posts/2022-04-18-session-info/index.html#sessioninfo-package",
    "title": "Adding session info to blog posts",
    "section": "\nsessioninfo package",
    "text": "sessioninfo package\nAn alternative to using utils::sessionInfo() would be to use the sessioninfo package. Per the package docs:\n\nQuery and print information about the current R session. It is similar to utils::sessionInfo(), but includes more information about packages, and where they were installed from.\nDifferences from utils::sessionInfo()\n\n\nAdditional platform details: time zone, pandoc version, RStudio version, etc.\nInformation about package sources, e.g. GitHub repo and hash for packages installed from GitHub.\nHighlight package installation problems, e.g. if the loaded and on-disk versions are different, if the MD5 checksum of the package DLL is wrong, etc.\nHighlight packages from unusual sources.\nInformation about external software via external_info().\nInformation about the Python configuration is the reticulate package is loaded and configured.\nInformation about package libraries.\nCompare two session info outputs with the session_diff() function.\nOption to show loaded (default), attached or installed packages, or the recursive dependencies of the specified packages.\n\n\n\n\n\n\n\n\nNote\n\n\n\nNote that I’m really only interested in the session info and which packages were attached (ie via library(pkgname)), so I’ll use the pkgs = \"attached\" argument. This flexibility is nice!\n\n\n\nlibrary(sessioninfo)\nsession_info(pkgs = \"attached\")\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.0 (2022-04-22)\n os       macOS Monterey 12.2.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       America/Chicago\n date     2022-06-13\n pandoc   2.18 @ /Applications/RStudio.app/Contents/MacOS/quarto/bin/tools/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version date (UTC) lib source\n sessioninfo * 1.2.2   2021-12-06 [1] CRAN (R 4.2.0)\n\n [1] /Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/library\n\n──────────────────────────────────────────────────────────────────────────────\n\n\nNow while information such as this is very useful for attaching to things like a reprex, it can also be useful to include for testing purposes or for “posterity” when rendering a document or writing a blogpost.\nAdding to sessioninfo\n\nLet’s also note one more thing - again I’d like to record the Quarto version, since I’m relying on quarto for rendering my blog. We can “inject” the quarto version and path to the sessioninfo list object. I did go ahead and submit a feature request on the sessioninfo repo - maybe quarto info will be incorporated into sessioninfo in the near future!\n\n# save the session info as an object\npkg_sesh <- session_info(pkgs = \"attached\")\n\n# get the quarto version\nquarto_version <- system(\"quarto --version\", intern = TRUE)\n\n# inject the quarto info\npkg_sesh$platform$quarto <- paste(\n  system(\"quarto --version\", intern = TRUE), \n  \"@\", \n  quarto::quarto_path()\n  )\n\n# print it out\npkg_sesh\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.0 (2022-04-22)\n os       macOS Monterey 12.2.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       America/Chicago\n date     2022-06-13\n pandoc   2.18 @ /Applications/RStudio.app/Contents/MacOS/quarto/bin/tools/ (via rmarkdown)\n quarto   0.9.577 @ /usr/local/bin/quarto\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version date (UTC) lib source\n sessioninfo * 1.2.2   2021-12-06 [1] CRAN (R 4.2.0)\n\n [1] /Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/library\n\n──────────────────────────────────────────────────────────────────────────────\n\n\nThat’s looking good!"
  },
  {
    "objectID": "posts/2022-04-18-session-info/index.html#include-in-docs",
    "href": "posts/2022-04-18-session-info/index.html#include-in-docs",
    "title": "Adding session info to blog posts",
    "section": "Include in docs",
    "text": "Include in docs\nNow to add it to the end of our document, we can use a quick HTML <details> tag. This creates a small expandable section. We can also change the title of with the use of a <summary> tag. We can add this to all of our documents/blogposts and capture\n<details><summary>Session Info</summary>\n\n```{r, echo = FALSE}\nlibrary(sessioninfo)\n# save the session info as an object\npkg_sesh <- session_info(pkgs = \"attached\")\n\n# get the quarto version\nquarto_version <- system(\"quarto --version\", intern = TRUE)\n\n# inject the quarto info\npkg_sesh$platform$quarto <- paste(\n  system(\"quarto --version\", intern = TRUE), \n  \"@\", \n  quarto::quarto_path()\n  )\n\n# print it out\npkg_sesh\n```\n\n</details>\nWhich generates something like the below (again note that you need to expand this <details> tag by clicking on it):\n\n\nSession Info\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.0 (2022-04-22)\n os       macOS Monterey 12.2.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       America/Chicago\n date     2022-06-13\n pandoc   2.18 @ /Applications/RStudio.app/Contents/MacOS/quarto/bin/tools/ (via rmarkdown)\n quarto   0.9.577 @ /usr/local/bin/quarto\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version date (UTC) lib source\n sessioninfo * 1.2.2   2021-12-06 [1] CRAN (R 4.2.0)\n\n [1] /Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/library\n\n──────────────────────────────────────────────────────────────────────────────\n\n\n\nQuarto-native callouts\nQuarto itself adds the ability to create boostrap-style callouts and collapsible callouts, so we can simplify our code a bit:\n:::{.callout-tip collapse=\"true\"}\n## Expand for Session Info\n```{r, echo = FALSE}\nlibrary(sessioninfo)\n# save the session info as an object\npkg_sesh <- session_info(pkgs = \"attached\")\n\n# get the quarto version\nquarto_version <- system(\"quarto --version\", intern = TRUE)\n\n# inject the quarto info\npkg_sesh$platform$quarto <- paste(\n  system(\"quarto --version\", intern = TRUE), \n  \"@\", \n  quarto::quarto_path()\n  )\n\n# print it out\npkg_sesh\n```\n\n:::\nWhich will return a colored callout like below:\n\n\n\n\n\n\nExpand for Session Info\n\n\n\n\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.0 (2022-04-22)\n os       macOS Monterey 12.2.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       America/Chicago\n date     2022-06-13\n pandoc   2.18 @ /Applications/RStudio.app/Contents/MacOS/quarto/bin/tools/ (via rmarkdown)\n quarto   0.9.577 @ /usr/local/bin/quarto\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version date (UTC) lib source\n sessioninfo * 1.2.2   2021-12-06 [1] CRAN (R 4.2.0)\n\n [1] /Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/library\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "posts/2022-04-18-session-info/index.html#closing-notes",
    "href": "posts/2022-04-18-session-info/index.html#closing-notes",
    "title": "Adding session info to blog posts",
    "section": "Closing Notes",
    "text": "Closing Notes\nIf you want to see some examples of similar concepts in action on other blogs, check out:\n\nTJ Mahr’s footer.Rmd\nDanielle Navarro’s appendix.R\n\nTJ also uses sessioninfo::session_info() while Danielle takes it a step further and generates a full renv lockfile.\n\n\n\n\n\n\nExpand for Session Info\n\n\n\n\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.0 (2022-04-22)\n os       macOS Monterey 12.2.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       America/Chicago\n date     2022-06-13\n pandoc   2.18 @ /Applications/RStudio.app/Contents/MacOS/quarto/bin/tools/ (via rmarkdown)\n quarto   0.9.577 @ /usr/local/bin/quarto\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version date (UTC) lib source\n sessioninfo * 1.2.2   2021-12-06 [1] CRAN (R 4.2.0)\n\n [1] /Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/library\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "posts/2019-04-28-nflfastr-dbplyr-rsqlite/index.html#more-data",
    "href": "posts/2019-04-28-nflfastr-dbplyr-rsqlite/index.html#more-data",
    "title": "Bigger, nflfastR, dbplyr",
    "section": "More data",
    "text": "More data\nWith more data comes excitement - we can do new analysis with very similar code!\nHowever, the 2000-2019 data consists of ~2.25 GB of data, 291 variables and 903,998 rows… this is 263,063,418 observations! While this is not anywhere close to too much for R to handle, it can start to feel a little intimidating to read it all into memory. I’ll be covering some tooling to work with relatively larger datasets using the same dplyr tools you know and love!"
  },
  {
    "objectID": "posts/2019-04-28-nflfastr-dbplyr-rsqlite/index.html#create-the-sqlite-database",
    "href": "posts/2019-04-28-nflfastr-dbplyr-rsqlite/index.html#create-the-sqlite-database",
    "title": "Bigger, nflfastR, dbplyr",
    "section": "Create the SQLite database",
    "text": "Create the SQLite database\n\nlibrary(RSQLite)\nlibrary(DBI)\n\n# create the \"empty\" database\nmydb <- DBI::dbConnect(RSQLite::SQLite(), \"data/pbp_db.sqlite\")\nmydb\n\n\n# <SQLiteConnection>\n#   Path: /Users/thomasmock/nflscrapR/data/pbp_db.sqlite\n#   Extensions: TRUE\n\n\n# Write the in-memory data into the database as a table\nDBI::dbWriteTable(mydb, \"pbp_raw_2000-2019\", raw_pbp)\n\n# list the table\nDBI::dbListTables(mydb)\n\n\n# [1] \"pbp_raw_2000-2019\"\n\nOk - so to recap in about 2 lines of code we have created and populated a SQLite database solely through R. Now, the SQLite file is only around 1 GB compared to our 2 GB .RDS - so it’s more efficiently stored and allows us to do some other cool things as seen below."
  },
  {
    "objectID": "posts/2019-04-28-nflfastr-dbplyr-rsqlite/index.html#open-a-connection",
    "href": "posts/2019-04-28-nflfastr-dbplyr-rsqlite/index.html#open-a-connection",
    "title": "Bigger, nflfastR, dbplyr",
    "section": "Open a connection",
    "text": "Open a connection\nWe can open the connection by calling tbl() on the database we have open (mydb) and indicating which table we want to query.\n\nlibrary(dbplyr)\n# Open a queryable connection with the database\npbp_db <- tbl(mydb, \"pbp_raw_2000-2019\")\n\npbp_db\n\n\n# Source:   table<pbp_raw_2000-2019> [?? x 291]\n# Database: sqlite 3.30.1 \n# [/Users/thomasmock/nflscrapR/data/pbp_db.sqlite]\n\n#   play_id game_id home_team away_team posteam posteam_type defteam side_of_field yardline_100\n#      <dbl>   <dbl> <chr>     <chr>     <chr>   <chr>        <chr>   <chr>                <dbl>\n#  1      34  2.00e9 NYG       ARI       NYG     home         ARI     NYG                     70\n#  2      70  2.00e9 NYG       ARI       ARI     away         NYG     NYG                     25\n#  3     106  2.00e9 NYG       ARI       ARI     away         NYG     ARI                     65\n#  4     131  2.00e9 NYG       ARI       ARI     away         NYG     ARI                     63\n#  5     148  2.00e9 NYG       ARI       ARI     away         NYG     ARI                     63\n#  6     165  2.00e9 NYG       ARI       ARI     away         NYG     ARI                     63\n#  7     190  2.00e9 NYG       ARI       NYG     home         ARI     NYG                     78\n#  8     211  2.00e9 NYG       ARI       NYG     home         ARI     NYG                     70\n#  9     232  2.00e9 NYG       ARI       NYG     home         ARI     NYG                     67\n# 10     253  2.00e9 NYG       ARI       NYG     home         ARI     NYG                     68\n# # … with more rows, and 282 more variables: game_date <dbl>, quarter_seconds_remaining <dbl>,\n# #   half_seconds_remaining <dbl>, game_seconds_remaining <dbl>, game_half <chr>,\n# #   quarter_end <dbl>, drive <dbl>, sp <dbl>, qtr <dbl>, down <chr>, goal_to_go <dbl>,\n# #   time <chr>, yrdln <chr>, ydstogo <dbl>, ydsnet <dbl>, desc <chr>, play_type <chr>,\n# #   yards_gained <dbl>, shotgun <dbl>, no_huddle <dbl>, qb_dropback <dbl>, qb_kneel <dbl>,\n# #   qb_spike <dbl>, qb_scramble <dbl>, pass_length <chr>, pass_location <chr>,\n# #   air_yards <dbl>, yards_after_catch <dbl>, run_location <chr>, run_gap <chr>,\n# #   field_goal_result <chr>, kick_distance <dbl>, extra_point_result <chr>,\n# #   two_point_conv_result <chr>, home_timeouts_remaining <dbl>,\n# #   away_timeouts_remaining <dbl>, timeout <dbl>, timeout_team <chr>, td_team <chr>,\n# #   posteam_timeouts_remaining <dbl>, defteam_timeouts_remaining <dbl>,\n# #   total_home_score <dbl>, total_away_score <dbl>, posteam_score <dbl>, defteam_score <dbl>,\n# #   score_differential <dbl>, posteam_score_post <dbl>, defteam_score_post <dbl>,\n# #   score_differential_post <dbl>, no_score_prob <dbl>, opp_fg_prob <dbl>,\n# #   opp_safety_prob <dbl>, opp_td_prob <dbl>, fg_prob <dbl>, safety_prob <dbl>,\n# #   td_prob <dbl>, extra_point_prob <dbl>, two_point_conversion_prob <dbl>, ep <dbl>,\n# #   epa <dbl>, total_home_epa <dbl>, total_away_epa <dbl>, total_home_rush_epa <dbl>,\n# #   total_away_rush_epa <dbl>, total_home_pass_epa <dbl>, total_away_pass_epa <dbl>,\n# #   air_epa <dbl>, yac_epa <dbl>, comp_air_epa <dbl>, comp_yac_epa <dbl>,\n# #   total_home_comp_air_epa <dbl>, total_away_comp_air_epa <dbl>,\n# #   total_home_comp_yac_epa <dbl>, total_away_comp_yac_epa <dbl>,\n# #   total_home_raw_air_epa <dbl>, total_away_raw_air_epa <dbl>, total_home_raw_yac_epa <dbl>,\n# #   total_away_raw_yac_epa <dbl>, wp <dbl>, def_wp <dbl>, home_wp <dbl>, away_wp <dbl>,\n# #   wpa <dbl>, home_wp_post <dbl>, away_wp_post <dbl>, total_home_rush_wpa <dbl>,\n# #   total_away_rush_wpa <dbl>, total_home_pass_wpa <dbl>, total_away_pass_wpa <dbl>,\n# #   air_wpa <dbl>, yac_wpa <dbl>, comp_air_wpa <dbl>, comp_yac_wpa <dbl>,\n# #   total_home_comp_air_wpa <dbl>, total_away_comp_air_wpa <dbl>,\n# #   total_home_comp_yac_wpa <dbl>, total_away_comp_yac_wpa <dbl>,\n# #   total_home_raw_air_wpa <dbl>, total_away_raw_air_wpa <dbl>, total_home_raw_yac_wpa <dbl>,\n# #   …\n\nBoom - 1 line of code and we now have a connection - also notice that the output has the following info at the top: > table<pbp_raw_2000-2019> [?? x 291]\nNotice that it has the right number of columns (291) but an unknown number of rows. This is because the data hasn’t been read into memory yet, and it has only returned the essentially the head() of the data. We don’t pull the data into memory until we call a new function - collect() this then pulls the data as it is at that point in the pipe into memory."
  },
  {
    "objectID": "posts/2019-04-28-nflfastr-dbplyr-rsqlite/index.html#query-the-database",
    "href": "posts/2019-04-28-nflfastr-dbplyr-rsqlite/index.html#query-the-database",
    "title": "Bigger, nflfastR, dbplyr",
    "section": "Query the database",
    "text": "Query the database\nNow let’s do a basic query - we’ll time it to see how long this takes on all 263 million observations.\n\ntic()\npbp_db %>% \n  select(play_type, yards_gained, penalty, season) %>% \n  filter(play_type %in% c(\"run\", \"pass\"), penalty == 0) %>% \n  group_by(season, play_type) %>% \n  summarize(avg_yds = mean(yards_gained, na.rm = TRUE),\n            n = n())\ntoc()\n\n\n# Source:   lazy query [?? x 4]\n# Database: sqlite 3.30.1 [/Users/thomasmock/nflscrapR/data/pbp_db.sqlite]\n# Groups:   season\n#    season play_type avg_yds     n\n#     <dbl> <chr>       <dbl> <int>\n#  1   2000 pass         5.84 17567\n#  2   2000 run          4.08 13682\n#  3   2001 pass         5.85 17264\n#  4   2001 run          4.04 13500\n#  5   2002 pass         5.85 18313\n#  6   2002 run          4.27 13746\n#  7   2003 pass         5.79 17322\n#  8   2003 run          4.24 14033\n#  9   2004 pass         6.12 17238\n# 10   2004 run          4.24 13828\n\n# 1.048 sec elapsed  \n\nSo we used our traditional dplyr code, it ran as SQL on the backend and took about 1 sec. Now, 1 sec is not THAT fast - and the same operation IN memory would be about 0.2 sec, but we save a lot of time on the read and can do lots of ad-hoc queries without pulling the data in. Also imagine a world where the data is much larger than memory, this same workflow would work on 100 GB of data or even petabytes of data with translation to spark via sparklyr for example."
  },
  {
    "objectID": "posts/2019-04-28-nflfastr-dbplyr-rsqlite/index.html#collect-the-data",
    "href": "posts/2019-04-28-nflfastr-dbplyr-rsqlite/index.html#collect-the-data",
    "title": "Bigger, nflfastR, dbplyr",
    "section": "Collect the data",
    "text": "Collect the data\nLastly - we can also pull the data into memory, via collect(). This allows us to take the data and either continue to work with the summary or pass it to something like ggplot2.\n\ntic()\npbp_db %>% \n  select(play_type, yards_gained, penalty, season) %>% \n  filter(play_type %in% c(\"run\", \"pass\"), penalty == 0) %>% \n  group_by(season, play_type) %>% \n  summarize(avg_yds = mean(yards_gained, na.rm = TRUE),\n            n = n()) %>% \n  collect() %>% \n  ggplot(aes(x = season, y = avg_yds, color = play_type)) +\n  geom_line()\ntoc()\n\n\n# 1.451 sec elapsed  \n\n\nSo, in about 1.5 seconds we we’re able to query all of 2000-2019 and get a very basic ggplot. Cool!"
  },
  {
    "objectID": "posts/2020-11-29-bullet-chart-variants-in-r/index.html",
    "href": "posts/2020-11-29-bullet-chart-variants-in-r/index.html",
    "title": "Bullet Chart Variants in R",
    "section": "",
    "text": "A bullet chart is a rich variant of the simple bar chart. Most commonly they can be used to replace “flashier” gauges, and are more compact/efficient in their display of multiple measures at once.\nClassically they encode a quantitative measure, a qualitative scale, and a comparison or target measure.\n\n\n\n\nFigure from Stephen Few via Wikipedia\n\n\n\n\nThe original design of bullet charts can be given to Stephen Few, and the above image is from his blog - perceptualedge.com.\nOthers have tried some various strategies to robustly graph these with ggplot2 - notably Bob Rudis’ Rbulletgraph and Ryo Nakagawara/Amit Kohli’s bulletchartr, and my own geom_bullet.\nIt’s a hard problem to solve with a general function, given that often the bullet charts don’t typically adhere nicely to a single data frame and tidy-data principles, typically require re-factoring of the input data or external reference data, or at the least require multiple columns to be charted.\nMy personal attempts are very much modeled after Bob’s approach, which is layering graph components as opposed a single geom_ call.\nThe bulletchartr approach on the other hand (which is relatively similar to my geom_bullet()) is to create a function that takes a summary data frame and plots several columns from the data.\n\nbulletchartr::bullet_chart(dataframe = bc_ex)\n\n\n\n\n\n\nThis is a fine approach for an opinionated take on bullet charts, but I’ll focus on building your own from scratch in case you only want some of the features."
  },
  {
    "objectID": "posts/2020-11-29-bullet-chart-variants-in-r/index.html#component-parts",
    "href": "posts/2020-11-29-bullet-chart-variants-in-r/index.html#component-parts",
    "title": "Bullet Chart Variants in R",
    "section": "Component Parts",
    "text": "Component Parts\nWe can break down the bullet chart into the comparative range and the quantitative measure. Thus we can approximate the chart by overlaying 2x geom_col() calls in ggplot2.\n\nlibrary(tidyverse)\n\n\ntibble(\n  name = \"Example\",\n  quant_value = 75,\n  qualitative = 100\n) %>% \n  ggplot(aes(x = quant_value, y = name)) +\n  geom_col(aes(x = qualitative), fill = \"grey\") +\n  geom_col(width = 0.5, fill = \"black\") +\n  coord_cartesian(ylim = c(0.3, 1.7)) +\n  theme_minimal() +\n  theme(panel.grid.major.y = element_blank())\n\n\n\n\nAlternatively, we can do it in one call if the data is arranged in a longer format.\n\nex_df <- tibble(\n  name = rep(\"Example\", 2),\n  group = c(\"Qualitative\", \"Measure\"),\n  value = c(100, 75),\n  width = c(0.9, 0.5)\n)\nex_df %>% \n  ggplot(aes(x = value, y = name, fill = group)) +\n  geom_col(width = ex_df$width) +\n  coord_cartesian(ylim = c(0.3, 1.7)) +\n  scale_fill_manual(values = c(\"black\", \"grey\")) +\n  theme_minimal() +\n  theme(panel.grid.major.y = element_blank())"
  },
  {
    "objectID": "posts/2020-11-29-bullet-chart-variants-in-r/index.html#add-a-target",
    "href": "posts/2020-11-29-bullet-chart-variants-in-r/index.html#add-a-target",
    "title": "Bullet Chart Variants in R",
    "section": "Add a target",
    "text": "Add a target\nNext we can also include a target measure. At this point you can see that we’re really stretching what is reasonable for one dataset, as we’re duplicating a lot of values that don’t really need to be duplicated. We could store this outside or indicate them manually but again you can see why this can in theory be generalized, but it’s complex.\n\nex_df <- bind_rows(\n  tibble(\n  name = rep(\"Ex 1\", 2),\n  group = c(\"Qualitative\", \"Measure\"),\n  color = c(\"grey\", \"black\"),\n  value = c(100, 75),\n  width = c(0.9, 0.5),\n  target = rep(82, 2),\n  ymin = rep(0.7, 2),\n  ymax = rep(1.3, 2)\n  ),\n  tibble(\n  name = rep(\"Ex 2\", 2),\n  group = c(\"Qualitative\", \"Measure\"),\n  color = c(\"grey\", \"black\"),\n  value = c(88, 64),\n  width = c(0.9, 0.5),\n  target = rep(77, 2),\n  ymin = rep(1.7, 2),\n  ymax = rep(2.3, 2)\n  )\n)\n\nex_df %>% \n  ggplot(aes(x = value, y = name, fill = color)) +\n  geom_col(width = c(0.9, 0.5, 0.9, 0.5)) +\n  geom_linerange(\n    aes(x = target, ymin = ymin, ymax = ymax),\n    size = 2, color = \"red\"\n    ) +\n  coord_cartesian(ylim = c(0.3, 2.7)) +\n  scale_fill_identity() +\n  theme_minimal() +\n  theme(panel.grid.major.y = element_blank())"
  },
  {
    "objectID": "posts/2020-11-29-bullet-chart-variants-in-r/index.html#add-qualitative-ranges",
    "href": "posts/2020-11-29-bullet-chart-variants-in-r/index.html#add-qualitative-ranges",
    "title": "Bullet Chart Variants in R",
    "section": "Add qualitative ranges",
    "text": "Add qualitative ranges\nThe next layer of complexity arises around the idea of creating more qualitative ranges (ie poor, good, great). I’ve hidden the code in an expandable section due to the length, but it’s all there! This is an example from an older #TidyTuesday plot I did in 2019.\n\nFull Code\n\nbig_epa_cars <- readr::read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-10-15/big_epa_cars.csv\")\n\ncars_clean <- big_epa_cars %>%\n  janitor::clean_names()\n\nrange_cars <- cars_clean %>%\n  filter(!is.na(eng_dscr)) %>%\n  filter(year == 2018) %>%\n  summarize(\n    q50 = quantile(highway08, probs = 0.50),\n    q95 = quantile(highway08, probs = 0.95),\n    q100 = quantile(highway08, probs = 1.00)\n  )\n\ntop_cars <- cars_clean %>%\n  filter(!is.na(eng_dscr)) %>%\n  filter(year == 2018) %>%\n  group_by(make) %>%\n  top_n(1, city08) %>%\n  ungroup() %>%\n  filter(make %in% c(\n    \"Subaru\",\n    \"Volvo\",\n    \"Chevrolet\",\n    \"Ford\",\n    \"Mazda\",\n    \"Honda\",\n    \"Toyota\",\n    \"Volkswagen\"\n  )) %>%\n  distinct(make, .keep_all = TRUE) %>%\n  select(make, model, highway08, city08, eng_dscr, year) %>%\n  arrange(desc(highway08), city08) %>%\n  mutate(\n    eng_type = if_else(\n      str_detect(eng_dscr, \"PHEV|Hybrid\"), \n      \"Hybrid\", \"Gas\"\n      )\n    ) %>%\n  mutate(make_model = paste(make, eng_type, sep = \" - \"))\n\nmpg_levels <- top_cars %>%\n  arrange(desc(highway08), city08) %>%\n  pull(make_model)\n\nplot_cars <- top_cars %>%\n  mutate(\n    min_mpg = pull(range_cars, q50),\n    middle_mpg = pull(range_cars, q95),\n    max_mpg = pull(range_cars, q100)\n  ) %>%\n  mutate(make_model = factor(make_model, levels = rev(mpg_levels)))\n\nbar_cars <- plot_cars %>%\n  distinct(make, .keep_all = TRUE)\n\ncar_plot <- bar_cars %>%\n  ggplot() +\n  geom_col(\n    aes(x = make_model, y = max_mpg),\n    fill = \"#A9A9A9\",\n    width = 0.6,\n    alpha = 0.9\n  ) +\n  geom_col(\n    aes(x = make_model, y = middle_mpg),\n    fill = \"#808080\",\n    width = 0.6,\n    alpha = 0.9\n  ) +\n  geom_col(\n    aes(x = make_model, y = min_mpg),\n    fill = \"#696969\",\n    width = 0.6,\n    alpha = 0.9\n  ) +\n  geom_col(\n    aes(x = make_model, y = highway08),\n    fill = \"black\",\n    color = NA,\n    width = 0.2\n  ) +\n  geom_errorbar(\n    aes(x = make_model, ymin = city08, ymax = city08),\n    color = \"red\",\n    width = 0.45,\n    size = 2\n  ) +\n  coord_flip() +\n  theme_minimal() +\n  labs(\n    x = \"\",\n    y = \"\\nMiles per Gallon\",\n    title = \"Some hybrids are more efficient in the <span style='color:#FF0000'>**City**</span> than <span style='color:#000000'>**Highway**</span>\",\n    subtitle = \"Typically, vehicles are more efficient on the highway\"\n  ) +\n  theme(\n    panel.grid = element_blank(),\n    plot.title = element_markdown(),\n    axis.text = element_text(face = \"bold\")\n  ) +\n  annotate(\n    \"text\",\n    x = c(rep((8 + .45), 4)),\n    y = c(\n      bar_cars$min_mpg[1] * 0.5,\n      bar_cars$middle_mpg[1] * 0.85,\n      bar_cars$max_mpg[1] * 0.8,\n      bar_cars$city08[1]\n    ),\n    label = c(\"Poor\", \"Good\", \"Great\", \"City\"),\n    color = c(rep(\"black\", 3), \"red\")\n  ) +\n  scale_y_continuous(breaks = seq(0, 60, 10)) +\n  NULL\n\n\ncar_plot\n\n\n\n\nAt this point, we’ve essentially recreated the approach of things like geom_bullet() or bulletchartr. As you can see this is a bit of work, but once you have the rough structure setup you could create or use a function (like bulletchartrt) or a geom_ like geom_bullet()."
  },
  {
    "objectID": "posts/2020-11-29-bullet-chart-variants-in-r/index.html#the-buried-lede",
    "href": "posts/2020-11-29-bullet-chart-variants-in-r/index.html#the-buried-lede",
    "title": "Bullet Chart Variants in R",
    "section": "The buried lede",
    "text": "The buried lede\nThe whole reason I got started on this post was my interest in re-creating ESPN’s Playoff Probablity Leverage from Brian Burke’s team. He outlined the process in a nice Twitter thread.\n\n\nAlmost forgot. These leverage graphs get a lot of love here for some reason, on a site where that's rare. So I'm going to thread a tale of how they came to be… pic.twitter.com/0O5fnRxVpu\n\n— Brian Burke (@bburkeESPN) November 26, 2020\n\nNumber one, these are gorgeous, and I really loved the addition of an example legend rather than a long description, which Brian Burke also noted was an extremly simple explanation of a relatively complex chart. Additionally, he mentioned that they were automated, which is always a driving force for why code is useful!\n\n\nI should note that Matt devised the \"key\" at the bottom of the charts that puts the 100 words in my original text box (\"This chart depicts…blah blah…\") into the world's best succinct graphical explainer: pic.twitter.com/tjhbY0XNRn\n\n— Brian Burke (@bburkeESPN) November 26, 2020\n\nWe can pretty quickly recreate the basic concept as seen below. Note that I have some additional data collection steps that we’ll go over in just a second.\n\n\n\n\nteam_df %>%\n  ggplot(aes(x = win_cur, y = fct_reorder(abb_name, win_pct))) +\n  geom_col(aes(x = 100), fill=\"white\", color = \"grey\", width = 0.7) +\n  geom_col(aes(x = win_pct), alpha = 0.5, width = 0.7) +\n  geom_col(width = 0.7) +\n  labs(x = \"Win Probability\", y = \"\")\n\n\n\n\nWe could make these more “bullet-chart-y” by altering the width of the columns, but I honestly think the stacked/alpha approach is more appealing here given the amount of variables. Also, since we’re showing the minimal range and then the potential achievement (leverage) I think the stack is more appropriate than a classical bullet. Regardless, both can work and I’ll leave it up to the reader to decide which is more informative.\n\nteam_df %>%\n  ggplot(aes(x = win_cur, y = fct_reorder(abb_name, win_pct))) +\n  geom_col(aes(x = 100), fill=\"white\", color = \"grey\", width = 0.7) +\n  geom_col(aes(x = win_pct), alpha = 0.5, width = 0.7) +\n  geom_col(width = 0.3) +\n  labs(x = \"Win Probability\", y = \"\")\n\n\n\n\nSo the next step is to add in team colors, replace team names with logos, and add the explanatory legend."
  },
  {
    "objectID": "posts/2020-11-29-bullet-chart-variants-in-r/index.html#data-collection",
    "href": "posts/2020-11-29-bullet-chart-variants-in-r/index.html#data-collection",
    "title": "Bullet Chart Variants in R",
    "section": "Data Collection",
    "text": "Data Collection\nI’m going to be getting team standings, colors and logos from my own espnscrapeR. Also, to cheat I’m not going to do the 20K simulations that ESPN and many others do to create the underlying data, but rather “borrow” the data from the original chart. Note I’m also loading patchwork for combining plots, and ggtext to use for the team logos on the axis. Lastly, I’m using a few custom fonts which I’ll load via the systemfonts package.\n\nlibrary(ggtext)\nlibrary(systemfonts)\nlibrary(patchwork)\n\nteams <- espnscrapeR::get_nfl_standings(2020)\n\nReturning 2020\n\nteam_meta <- espnscrapeR::get_nfl_teams() %>% \n  select(abb_name = team_abb, team_color)\n\nGetting NFL teams!\n\nteam_df <- teams %>% \n  select(abb_name = team_abb, logos = team_logo, playoff_seed = seed) %>% \n  left_join(team_meta) %>% \n  group_by(playoff_seed) %>% \n  mutate(\n    count = row_number(),\n    conf = if_else(count == 1, \"AFC\", \"NFC\")) %>% \n  ungroup() %>% \n  filter(conf == \"AFC\") %>% \n  mutate(\n    win_cur = c(\n      99, 99, 81, 60, 73, 59, 52, 59, 16, 1, 3, 1, 1, 1, 0, 0\n    ),\n    win_pct = c(\n    99,99.01,94, 91, 95, 83, 69, 86, 39, 3, 13, 1, 1,1,1, 0\n    ),\n    win_chg = round(win_pct - win_cur, 1)\n  ) %>% \n  mutate(\n    abb_name = factor(abb_name),\n    abb_name = fct_reorder(abb_name, win_pct, .desc = TRUE),\n    abb_name = fct_rev(abb_name)\n  ) %>% \n  arrange(desc(win_pct))\n\nJoining, by = \"abb_name\"\n\n\nI’ve also defined a function to take the logo url and convert it to a HTML <img> tag which ggtext can then plot in ggplot2 for us!\n\nlink_to_img <- function(x, width = 30) {\n  glue::glue(\"<img src='{x}' width='{width}'/>\")\n}"
  },
  {
    "objectID": "posts/2020-11-29-bullet-chart-variants-in-r/index.html#plot-with-colorslogos",
    "href": "posts/2020-11-29-bullet-chart-variants-in-r/index.html#plot-with-colorslogos",
    "title": "Bullet Chart Variants in R",
    "section": "Plot with colors/logos",
    "text": "Plot with colors/logos\nI’m really pleased with this, as it’s a very close approximation of the original, and Brian Burke did a great job on the original aesthetics. We still need to create the legend plot and then “attach” it to the bottom of this plot. We can combine the plots with patchwork, but first let’s try building it!\n\nteam_logo_plot <- team_df %>%\n  mutate(logos = link_to_img(logos)) %>% \n  ggplot(aes(x = win_cur, y = fct_reorder(logos, win_pct), fill = team_color)) +\n  geom_text(\n    aes(x = 100, label = paste0(win_chg, \"%\")), \n    nudge_x = 6, hjust = 1, fontface= \"bold\", family = \"Chivo\", size = 6\n    ) +\n  geom_col(aes(x = 100), fill=\"white\", color = \"grey\", width = 0.7) +\n  geom_col(aes(x = win_pct), alpha = 0.5, width = 0.7) +\n  geom_col(width = 0.7) +\n  scale_fill_identity() +\n  scale_x_continuous(breaks = c(25, 50, 75), labels = scales::percent_format(scale = 1)) +\n  theme_minimal() +\n  theme(\n    text = element_text(family = \"Chivo\"),\n    panel.grid.major.y = element_blank(),\n    panel.grid.minor = element_blank(),\n    panel.grid.major.x = element_line(color = \"grey\", size = 0.2),\n    panel.ontop = TRUE,\n    axis.text.y = element_markdown(margin = margin(r = -25, unit = \"pt\")),\n    axis.text.x = element_text(size = 16, color = \"grey\"),\n    plot.title = element_text(size = 36, face = \"bold\"),\n    plot.subtitle = element_text(size = 24),\n    plot.margin = unit(c(0.5, 1.5, 0.5, 1.5), \"cm\")\n  ) +\n  labs(\n    x = \"\", y = \"\", \n    title = \"Playoff Probability Leverage\",\n    subtitle = \"AFC Week 12\"\n  )"
  },
  {
    "objectID": "posts/2020-11-29-bullet-chart-variants-in-r/index.html#create-a-legend",
    "href": "posts/2020-11-29-bullet-chart-variants-in-r/index.html#create-a-legend",
    "title": "Bullet Chart Variants in R",
    "section": "Create a legend",
    "text": "Create a legend\nI’m going to be creating a few dataframes to plot in my legend. These include labels, and some “segments” to create the lines around the labels.\n\n# Core dataset with the basic labels\nlabel_df <- tibble(\n  x = c(15, 15, 77, 101),\n  y = c(1.6, 0.35, 0.35, 1),\n  label = c(\"Chance to make playoffs with win \", \"Chance to make playoffs with loss \", \"Leverage\", \"X%\")\n)\n\n\n# the horizontal lines\nseg_df <- tibble(\n  x1 = c(0.2, 90, 0.2, 74.8, 75.3, 90, 103),\n  x2 = c(0.2, 90, 0.2, 74.8, 75.3, 90, 103),\n  y1 = c(1.3, 1.3, rep(.7, 5)),\n  y2 = c(1.61, 1.61, rep(.343, 5))\n\n)\n\n# vertical lines\nseg2_df <- tibble(\n  x1 = c(0.2, 0.2, 75.3),\n  x2 = c(90, 74.8, 103),\n  y1 = c(1.6, .35, .35),\n  y2 = c(1.6, .35, .35)\n)\n\nThe first plot is very simple, and close to our examples at the very beginning of this post!\n\nlegend_plot <- tibble(\n  x = 75,\n  y = factor(\"Y\"),\n  x2 = 90\n) %>%\n  ggplot(aes(x = x, y = y)) +\n  geom_col(aes(x = 100), fill = \"white\", color = \"grey\", width = 0.4) +\n  geom_col(aes(x = x2), width = 0.4, color = \"#DC143C\", fill = \"grey\") +\n  geom_col(width = 0.4, color = \"black\", fill = \"black\")\n\nlegend_plot\n\n\n\n\nYou’ll notice a few things. Since our y-axis is a factor it’s essentially an integer where Y == 1. Each additional factor will be placed at N + 1\n\nlegend_plot +\n  geom_text(aes(x = 50, y = 1, label = \"Label at 1\"), color = \"red\", size = 8) +\n  geom_text(aes(x = 50, y = 1.5, label = \"Label at 1.5\"), color = \"red\", size = 8)\n\n\n\n\nSince we can place labels above or below or measure of interest, we can use that concept to create line segments via geom_segment() at specific locations. You will notice that there is some ovelap/overplotting of the lines - I do this so that there isn’t a gap when things are blown up a bit in the final graph.\nWe can add in the horizontal/vertical lines by two geom_segment layers.\n\nlegend_plot <- tibble(\n  x = 75,\n  y = factor(\"Y\"),\n  x2 = 90\n) %>%\n  ggplot(aes(x = x, y = y)) +\n  geom_col(aes(x = 100), fill = \"white\", color = \"grey\", width = 0.4) +\n  geom_col(aes(x = x2), width = 0.4, color = \"#DC143C\", fill = \"grey\") +\n  geom_col(width = 0.4, color = \"black\", fill = \"black\") +\n  geom_segment(\n    data = seg_df,\n    aes(x = x1, y = y1, xend = x2, yend = y2),\n    color = c(rep(\"black\", 4), rep(\"#DC143C\", 3)),\n    size = 1\n  ) +\n  geom_segment(\n    data = seg2_df,\n    aes(x = x1, y = y1, xend = x2, yend = y2),\n    color = c(\"black\", \"black\", \"#DC143C\"),\n    size = 1\n  ) \n\nlegend_plot\n\n\n\n\nOur final step will be to add the text/labels in, and make sure they have a white background to “hide” the lines behind them.\n\nfinal_legend <- legend_plot +\n  geom_label(\n    data = label_df,\n    aes(x = x, y = y, label = label),\n    hjust = 0, size = 8, fontface = \"bold\", fill = \"white\",\n    color = c(\"black\", \"black\", \"#DC143C\", \"#DC143C\"),\n    label.size = NA,\n    family = \"Oswald\",\n    label.padding = unit(0.05, \"lines\"),\n  ) +\n  coord_cartesian(ylim = c(0.7, 1.2), xlim = c(0, 108)) +\n  theme_void() +\n  theme(\n    plot.margin = unit(c(0.5, 1.5, 0.5, 1.5), \"cm\"),\n    plot.caption = element_markdown(size = 14)\n    )  +\n  labs(\n    caption = \"<br><br>**Plot**: @thomas_mock | **Inspiration**: @bburkeESPN\"\n  )\n\nfinal_legend"
  },
  {
    "objectID": "posts/2020-11-29-bullet-chart-variants-in-r/index.html#combine-the-plots",
    "href": "posts/2020-11-29-bullet-chart-variants-in-r/index.html#combine-the-plots",
    "title": "Bullet Chart Variants in R",
    "section": "Combine the plots",
    "text": "Combine the plots\nNow that both plots are done, we can very quickly combine them with patchwork. patchwork provides additional capabilities for layout/combining plots.\nWe can read the code below as plot1 over plot2 and then height of plot1 == 5, height of plot2 == 1.\n\ncombo_plot <- team_logo_plot / legend_plot + plot_layout(heights = c(5,1))\n\n\n\n\n\n\nAnd that’s it! We’ve recreated Brian Burke’s example in R, and figured out how to make some custom legends and combine them together."
  },
  {
    "objectID": "posts/2020-11-29-bullet-chart-variants-in-r/index.html#another-example",
    "href": "posts/2020-11-29-bullet-chart-variants-in-r/index.html#another-example",
    "title": "Bullet Chart Variants in R",
    "section": "Another example",
    "text": "Another example\nBen Baldwin also had another tweet that inspired me to apply a similar concept. The full code snippet I used is on GitHub. Here, Ben is comparing the Actual and Expected Pass Frequency over/under expected with a lollipop chart. Given that we’re comparing ranges I thought a bullet chart would be a nice alternative!\n\n\nThis is since week 7, whew boy pic.twitter.com/O40sdbbtDA\n\n— Computer Cowboy (@benbbaldwin) November 28, 2020\n\nThe part to note here is we are now comparing one measure to another, as opposed to the theoretical value + the minimal value we saw in the ESPN example. I also used almost the same code as above, but now the actual passing frequency bar is thinner than the expected passing range.\n\nFull Code\n\nlibrary(patchwork)\nlibrary(ggtext)\n\nteam_colors <- nflfastR::teams_colors_logos %>% filter(team_abbr == \"TEN\") %>% \n  select(team_color, team_color2) %>% \n  unlist()\n\n# approximated data\nrun_df <- tibble(\n  down_distance = c(\n    \"1st & 10\",\n    \"2nd & 8+\",\n    \"2nd & 3-7\",\n    \"2nd & 1-2\",\n    \"3rd & 3+\",\n    \"3rd & 1-2\",\n    \"After pass for 1st\",\n    \"After rush for 1st\",\n    \"All plays\"\n  ),\n  actual = c(\n    38, 57, 63, 36, 89, 50, 39, 41, 54\n  ),\n  expected = c(\n    56, 72, 66, 39, 92, 54, 54, 57, 64\n  )\n) %>% \n  mutate(\n    down_distance = factor(down_distance),\n    difference = actual - expected,\n    diff_color = if_else(difference < 0, \"#DC143C\", \"black\")\n    )\n\nrun_plot <- run_df %>%\n  ggplot(aes(x = actual, y = fct_rev(down_distance))) +\n  geom_text(\n    aes(x = 100, label = paste0(difference, \"%\"), color = diff_color), \n    nudge_x = 10, hjust = 1, fontface= \"bold\", family = \"Chivo\", size = 10\n  ) +\n  geom_col(aes(x = 100), width = 0.7, color = \"grey\", alpha = 0.2) +\n  geom_col(aes(x = expected), fill = team_colors[1], alpha = 0.5, width = 0.7) +\n  geom_col(width = 0.3, fill = team_colors[2]) + \n  scale_fill_identity() +\n  scale_x_continuous(breaks = c(25, 50, 75), labels = scales::percent_format(scale = 1)) +\n  theme_minimal() +\n  theme(\n    text = element_text(family = \"Chivo\"),\n    panel.grid.major.y = element_blank(),\n    panel.grid.minor = element_blank(),\n    panel.grid.major.x = element_line(color = \"grey\", size = 0.2),\n    panel.ontop = TRUE,\n    axis.text.y = element_markdown(size = 14, margin = margin(r = -25, unit = \"pt\")),\n    axis.text.x = element_text(size = 16, color = \"grey\"),\n    plot.title = element_markdown(size = 36, face = \"bold\"),\n    plot.subtitle = element_text(size = 24),\n    plot.margin = unit(c(0.5, 1.5, 0.5, 1.5), \"cm\"),\n    legend.position = \"none\"\n  ) +\n  labs(\n    x = \"\", y = \"\", \n    title = glue::glue(\"Titans <span style='color:{team_colors[2]}'>Pass Frequency</span> under <span style='color:{team_colors[1]}'>Expected</span>, 2020\")\n  )\n\n\n# Legend plot -------------------------------------------------------------\n\n\nlabel_df <- tibble(\n  x = c(15, 15, 77, 101),\n  y = c(1.6, 0.35, 0.35, 1),\n  label = c(\"Expected Pass Frequency \", \"Actual Pass Frequency \", \"Difference\", \"X%\")\n)\n\nseg_df <- tibble(\n  x1 = c(0.2, 90, 0.2, 74.8, 75.3, 90, 103),\n  x2 = c(0.2, 90, 0.2, 74.8, 75.3, 90, 103),\n  y1 = c(1.3, 1.3, rep(.7, 5)),\n  y2 = c(1.61, 1.61, rep(.343, 5))\n  \n)\n\nseg2_df <- tibble(\n  x1 = c(0.2, 0.2, 75.3),\n  x2 = c(90, 74.8, 103),\n  y1 = c(1.6, .35, .35),\n  y2 = c(1.6, .35, .35)\n)\n\nlegend_plot <- tibble(\n  x = 75,\n  y = factor(\"Y\"),\n  x2 = 90\n) %>%\n  ggplot(aes(x = x, y = y)) +\n  geom_col(aes(x = 100), fill = \"white\", color = \"grey\", width = 0.4) +\n  geom_col(aes(x = x2), width = 0.4, fill = \"black\", alpha = 0.5) +\n  geom_col(width = 0.2, color = \"black\", fill = \"black\") +\n  geom_segment(\n    data = seg_df,\n    aes(x = x1, y = y1, xend = x2, yend = y2),\n    color = c(rep(\"black\", 4), rep(\"#DC143C\", 3)),\n    size = 1\n  ) +\n  geom_segment(\n    data = seg2_df,\n    aes(x = x1, y = y1, xend = x2, yend = y2),\n    color = c(\"black\", \"black\", \"#DC143C\"),\n    size = 1\n  ) +\n  geom_label(\n    data = label_df,\n    aes(x = x, y = y, label = label),\n    hjust = 0, size = 8, fontface = \"bold\", fill = \"white\",\n    color = c(\"black\", \"black\", \"#DC143C\", \"#DC143C\"),\n    label.size = NA,\n    family = \"Oswald\",\n    label.padding = unit(0.05, \"lines\"),\n  ) +\n  theme_void() +\n  theme(\n    plot.margin = unit(c(0.5, 1.5, 0.5, 1.5), \"cm\"),\n    plot.caption = element_markdown(size = 14)\n  ) +\n  coord_cartesian(ylim = c(0.7, 1.2), xlim = c(0, 108)) +\n  labs(\n    caption = \"<br><br>**Plot**: @thomas_mock | **Inspiration**: @bburkeESPN\"\n  )\n\nlegend_plot\n\n\n\ncombo_plot <- run_plot / legend_plot + plot_layout(heights = c(5,1))\n\ncombo_plot\n\n\n\n# ggsave(\"ten_rush.png\", combo_plot, height = 14, width = 16, units = \"in\", dpi = \"retina\")\n\n\n\n\n\n\n\n\n\n\n\n\nExpand for Session Info\n\n\n\n\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.0 (2022-04-22)\n os       macOS Monterey 12.2.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       America/Chicago\n date     2022-04-28\n pandoc   2.18 @ /Applications/RStudio.app/Contents/MacOS/quarto/bin/tools/ (via rmarkdown)\n quarto   0.9.294 @ /usr/local/bin/quarto\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package      * version    date (UTC) lib source\n bulletchartr * 0.3.1      2022-04-28 [1] Github (ACDIVOCATech/bulletchartr@4725088)\n dplyr        * 1.0.8      2022-02-08 [1] CRAN (R 4.2.0)\n forcats      * 0.5.1      2021-01-27 [1] CRAN (R 4.2.0)\n ggplot2      * 3.3.5      2021-06-25 [1] CRAN (R 4.2.0)\n ggtext       * 0.1.1      2020-12-17 [1] CRAN (R 4.2.0)\n patchwork    * 1.1.0.9000 2022-04-26 [1] Github (thomasp85/patchwork@79223d3)\n purrr        * 0.3.4      2020-04-17 [1] CRAN (R 4.2.0)\n readr        * 2.1.2      2022-01-30 [1] CRAN (R 4.2.0)\n sessioninfo  * 1.2.2      2021-12-06 [1] CRAN (R 4.2.0)\n stringr      * 1.4.0      2019-02-10 [1] CRAN (R 4.2.0)\n systemfonts  * 1.0.4      2022-02-11 [1] CRAN (R 4.2.0)\n tibble       * 3.1.6      2021-11-07 [1] CRAN (R 4.2.0)\n tidyr        * 1.2.0      2022-02-01 [1] CRAN (R 4.2.0)\n tidyverse    * 1.3.1      2021-04-15 [1] CRAN (R 4.2.0)\n\n [1] /Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/library\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "posts/2018-12-11-functional-progamming-in-r-with-purrr/index.html",
    "href": "posts/2018-12-11-functional-progamming-in-r-with-purrr/index.html",
    "title": "Functional Progamming in R with purrr",
    "section": "",
    "text": "print(\"Hello world!\")\n\n[1] \"Hello world!\"\n\n\n\n5 * 6\n\n[1] 30\n\n\n\nx <- c(1, 2, 3, 4, 5)\n\n\n\n[1] 1 2 3 4 5\n\n\nThis is great, you are learning about strings, math, and vectors in R!\nThen you get started with some basic analyses. You want to see if you can find the mean of some numbers.\n\nemployee <- c('John Doe','Peter Gynn','Jolie Hope')\nsalary <- c(21000, 23400, 26800)\nstartdate <- as.Date(c('2010-11-1','2008-3-25','2007-3-14'))\n\n# form dataframe and take mean of salary column\nemploy_data <- data.frame(employee, salary, startdate)\nmean(employ_data$salary)\n\n[1] 23733.33\n\n\nEventually you hopefully get exposed to the tidyverse, and you find how this “opinionated collection of R packages designed for data science” makes data analysis in R easier and more readable!\n\nmtcars %>% \n  group_by(cyl) %>% \n  summarize(mean(mpg))\n\n# A tibble: 3 × 2\n    cyl `mean(mpg)`\n  <dbl>       <dbl>\n1     4        26.7\n2     6        19.7\n3     8        15.1\n\n\nEverything is going great! You’ve likely replaced Excel at this point, and potentially SPSS or some other statistical software suite! But then you run into a problem where you need to use a function repeatedly.\nYou could use something like the following code to calculate one-way ANOVAs for some dependent variables and a set independent variable:\n\naov_mpg <- aov(mpg ~ factor(cyl), data = mtcars)\nsummary(aov_mpg)\n\naov_disp <- aov(disp ~ factor(cyll), data = mtcars)\nsummary(aov_disp)\n\naov_hp <- aov(hp ~ factor(cyl), data = mrcars)\nsummry(aov_hpp)\n\naov_wt <- aov(wt ~ factor(cyl), datas = mtcars)\nsummary(aov_wt)\n\nBut you copy-pasted code 3x, and oops you made some minor misspelling mistakes which throws an error! (The above code leads to errors!)\nAlso, what if you realized that you wanted to actually run these ANOVAs for number of gears instead of number of cylinders? You would have to go back and change the factor(cyl) call to factor(gear) 4x! This is not very efficient, and you’re more likely to end up with mistakes as you have to type everything multiple times!\n\nHow about another example.\nLet’s calculate the R-squared values for the linear relationship between Weight and Miles per Gallon, according to the number of Cylinders.\nI have written code below that does this for 4 cylinder cars from the mtcars dataset. This is a worst case scenario, you know some dplyr code (dplyr::filter), but are not comfortable with the pipe. That’s fine, you accomplish your goal but a lot of coding! You would have to duplicate this code for 6 cylinder and 8 cylinder cars, for even more code…\n\nlibrary(tidyverse)\n# create df for 4 cylinder cars\ncyl_4 <- filter(mtcars, cyl == 4)\n\n# create a linear model on 4 cyl cars\nlm_4 <- lm(mpg ~ wt, data = cyl_4)\n\n# get the summ\nlm_4_summary <- summary(lm_4)\n\n# get the r.squared value\nlm_4cyl_r_squared <- lm_4_summary[\"r.squared\"]\n\n# check the value\nlm_4cyl_r_squared\n\n$r.squared\n[1] 0.5086326\n\n\nAlternatively, you could do the same thing with the pipe. A lot less typing, but to do this for all 3 subsets means we have to copy paste multiple times, so if you end up wanting to do this as a linear model of mpg ~ disp in addition to mpg ~ wt, you would have to duplicate the code 3 more times and change it 3 more times. This may not seem like a big deal, but eventually is a huge deal once you start to scale up the code (say 10+ times or 100+ times, etc).\n\n# piped analysis\nlm_4cyl_rsquared <- mtcars %>% \n  filter(cyl == 4) %>%\n  lm(mpg ~ wt, data = .) %>% \n  summary() %>% \n  .$\"r.squared\"\n\n#check output\nlm_4cyl_r_squared\n\n$r.squared\n[1] 0.5086326\n\n\nTo solve this issue of minimizing repetition with further replication, we can dive straight into purrr! To read more about purrr Hadley Wickham recommends the iteration chapter from “R for Data Science” or alternatively you can look at the purrr documentation. Lastly, Jenny Bryan has a great purrr tutorial here. You can load purrr by itself, but it is also loaded as part of the tidyverse library.\n\n\nI used to be all meep—meep—PANIC about purrr!!\n\n\n\n\nnow I’m all like map %>% map %>% PARTY!\n\n\npurrr allows you to map functions to data. Appropriately the basic function in purrr is called map()! The map functions transform their input by applying a function to each element and returning a vector the same length as the input.\nThe base arguments for map() are: .x - list or atomic vector (logical, integer, double/numeric, and character) .f - function, formula, or atomic vector\nBasically map() takes a function (.f) and applies it to data (.x).\nGoing back to our example of grabbing the R-squared from a linear model, we use the following code with purrr.\n\nmtcars %>%\n  split(.$cyl) %>%\n  map(~ lm(mpg ~ wt, data = .)) %>%\n  map(summary) %>%\n  map_dbl(\"r.squared\")\n\n        4         6         8 \n0.5086326 0.4645102 0.4229655 \n\n\nThis generates an output from all 3 of our linear models according to number of cylinders in 5 lines of code! This is the beauty of purrr, efficient scaling of functions!\nLet’s break down our linear model R-squared code.\nWe take the mtcars dataset, split it into data subsets according to the number of cylinders, apply a linear model of mpg by wt to each subset of data, apply a summary function and then pull out the r.squared value. However, while purrr is readable, we need to cover a few quirks of using it.\n\nmtcars %>%\n  split(.$cyl) %>%\n  map(~ lm(mpg ~ wt, data = .)) %>%\n  map(summary) %>%\n  map_dbl(\"r.squared\")\n\n        4         6         8 \n0.5086326 0.4645102 0.4229655 \n\n\nFor our code here you may have noticed we have a “.” placed twice within the code. This is a placeholder for the data, we can see this below. The “.” indicate the left-hand side data, or in this case mtcars. Our split call splits the mtcars dataframe into 3 dataframes, each stored within a list. This may seem odd, but it allows map to cycle through our 3 dataframes and replicate the lm() function on each of them individually.\n\n# piped version\nmtcars %>% \n  split(.$cyl)\n\n\n# base R version\nsplit(mtcars, mtcars$cyl)\n\n\n\n$`4`\n                mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nDatsun 710     22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1\nMerc 240D      24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2\nMerc 230       22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2\nFiat 128       32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1\nHonda Civic    30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2\nToyota Corolla 33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1\nToyota Corona  21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1\nFiat X1-9      27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1\nPorsche 914-2  26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2\nLotus Europa   30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\nVolvo 142E     21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2\n\n$`6`\n                mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nMazda RX4      21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag  21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\nHornet 4 Drive 21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\nValiant        18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1\nMerc 280       19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4\nMerc 280C      17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4\nFerrari Dino   19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6\n\n$`8`\n                     mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nHornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2\nDuster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4\nMerc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3\nMerc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3\nMerc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3\nCadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4\nLincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4\nChrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4\nDodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2\nAMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2\nCamaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4\nPontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2\nFord Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4\nMaserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8\n\n\nSimilarily, the “.” in or first map call is a placeholder for data, but in this case it will cycle through our list of 3 dataframes generated by the previous pipe. You can see that we get a list of 3 lm() outputs, we need to map a summary call to each of these to get access to R-squared.\n\nmtcars %>%\n  split(.$cyl) %>%\n  map(~ lm(mpg ~ wt, data = .))\n\n$`4`\n\nCall:\nlm(formula = mpg ~ wt, data = .)\n\nCoefficients:\n(Intercept)           wt  \n     39.571       -5.647  \n\n\n$`6`\n\nCall:\nlm(formula = mpg ~ wt, data = .)\n\nCoefficients:\n(Intercept)           wt  \n      28.41        -2.78  \n\n\n$`8`\n\nCall:\nlm(formula = mpg ~ wt, data = .)\n\nCoefficients:\n(Intercept)           wt  \n     23.868       -2.192  \n\n\nWe next map our summary function to each of the list items to get cleaner outputs with R-squared values. We now have the rest of our statistical output, including p values and R-squared.\n\nmtcars %>%\n  split(.$cyl) %>%\n  map(~ lm(mpg ~ wt, data = .)) %>%\n  map(summary)\n\n$`4`\n\nCall:\nlm(formula = mpg ~ wt, data = .)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.1513 -1.9795 -0.6272  1.9299  5.2523 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   39.571      4.347   9.104 7.77e-06 ***\nwt            -5.647      1.850  -3.052   0.0137 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.332 on 9 degrees of freedom\nMultiple R-squared:  0.5086,    Adjusted R-squared:  0.454 \nF-statistic: 9.316 on 1 and 9 DF,  p-value: 0.01374\n\n\n$`6`\n\nCall:\nlm(formula = mpg ~ wt, data = .)\n\nResiduals:\n     Mazda RX4  Mazda RX4 Wag Hornet 4 Drive        Valiant       Merc 280      Merc 280C \n       -0.1250         0.5840         1.9292        -0.6897         0.3547        -1.0453 \n  Ferrari Dino \n       -1.0080 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)   \n(Intercept)   28.409      4.184   6.789  0.00105 **\nwt            -2.780      1.335  -2.083  0.09176 . \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.165 on 5 degrees of freedom\nMultiple R-squared:  0.4645,    Adjusted R-squared:  0.3574 \nF-statistic: 4.337 on 1 and 5 DF,  p-value: 0.09176\n\n\n$`8`\n\nCall:\nlm(formula = mpg ~ wt, data = .)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.1491 -1.4664 -0.8458  1.5711  3.7619 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  23.8680     3.0055   7.942 4.05e-06 ***\nwt           -2.1924     0.7392  -2.966   0.0118 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.024 on 12 degrees of freedom\nMultiple R-squared:  0.423, Adjusted R-squared:  0.3749 \nF-statistic: 8.796 on 1 and 12 DF,  p-value: 0.01179\n\n\nOur last map is a bit different. You can see we use map_dbl this time. This indicates we want our output to be a dbl or numeric outcome. We get nice named numbers!\n\nmtcars %>%\n  split(.$cyl) %>%\n  map(~ lm(mpg ~ wt, data = .)) %>%\n  map(summary) %>%\n  map_dbl(\"r.squared\")\n\n        4         6         8 \n0.5086326 0.4645102 0.4229655 \n\n\nIf we had not indicated map_dbl, but instead used map we would get a list of the same outcome.\n\nmtcars %>%\n  split(.$cyl) %>% \n  map(~ lm(mpg ~ wt, data = .)) %>%\n  map(summary) %>%\n  map(\"r.squared\")\n\n$`4`\n[1] 0.5086326\n\n$`6`\n[1] 0.4645102\n\n$`8`\n[1] 0.4229655\n\n\nYou could also use map_dfr which binds the outputs into rows of a dataframe.\n\nmtcars %>%\n  split(.$cyl) %>% \n  map(~ lm(mpg ~ wt, data = .)) %>%\n  map(summary) %>%\n  map_dfr(\"r.squared\")\n\n# A tibble: 1 × 3\n    `4`   `6`   `8`\n  <dbl> <dbl> <dbl>\n1 0.509 0.465 0.423\n\n\nThere are limitless applications of purrr and other functions within purrr that greatly empower your functional programming in R. I hope that this guide motivates you to add purrr to your toolbox and explore this useful tidyverse package!\nAs a brief teaser to some more applications of purrr, I’ll leave you with this example. I mentioned calculating ANOVAs across multiple variables at the beginning. Break down this example on your own and see what you think! (You can copy paste this code into R, but need to load the tidyverse and broom packages first).\n\nmtcars %>%\n  mutate(cyl = factor(cyl)) %>%\n  select(mpg, disp, hp) %>%\n  map(~ aov(.x ~ cyl, data = mtcars)) %>%\n  map_dfr(~ broom::tidy(.), .id = 'source') %>%\n  mutate(p.value = round(p.value, 5))\n\nIn closing, I’d like to thank several #r4ds Online Learning Community members for their help in my personal understanding of purrr: Frank Farach, Michael Kuehn, and Kent Johnson.\nIf you are interested in joining this community led by Jesse Maegan check out her post here!\n\n\n\n\n\n\nExpand for Session Info\n\n\n\n\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.0 (2022-04-22)\n os       macOS Monterey 12.2.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       America/Chicago\n date     2022-06-17\n pandoc   2.18 @ /Applications/RStudio.app/Contents/MacOS/quarto/bin/tools/ (via rmarkdown)\n quarto   0.9.577 @ /usr/local/bin/quarto\n\n─ Packages ───────────────────────────────────────────────────────────────────────────────────────\n package     * version date (UTC) lib source\n broom       * 0.8.0   2022-04-13 [1] CRAN (R 4.2.0)\n dplyr       * 1.0.9   2022-04-28 [1] CRAN (R 4.2.0)\n forcats     * 0.5.1   2021-01-27 [1] CRAN (R 4.2.0)\n ggplot2     * 3.3.6   2022-05-03 [1] CRAN (R 4.2.0)\n purrr       * 0.3.4   2020-04-17 [1] CRAN (R 4.2.0)\n readr       * 2.1.2   2022-01-30 [1] CRAN (R 4.2.0)\n sessioninfo * 1.2.2   2021-12-06 [1] CRAN (R 4.2.0)\n stringr     * 1.4.0   2019-02-10 [1] CRAN (R 4.2.0)\n tibble      * 3.1.7   2022-05-03 [1] CRAN (R 4.2.0)\n tidyr       * 1.2.0   2022-02-01 [1] CRAN (R 4.2.0)\n tidyverse   * 1.3.1   2021-04-15 [1] CRAN (R 4.2.0)\n\n [1] /Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/library\n\n──────────────────────────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "posts/2020-12-26-creating-and-using-custom-ggplot2-themes/index.html",
    "href": "posts/2020-12-26-creating-and-using-custom-ggplot2-themes/index.html",
    "title": "Creating and using custom ggplot2 themes",
    "section": "",
    "text": "ggplot2 is an R package for producing statistical graphics, and is an implementation of the “Grammar of Graphics” by Leland Wilkinson. As such the primary way that folks use ggplot2 initially is for robust, fast, and easy exploratory data analysis or the creation of scientific/statistical plots while analyzing data. Here the primary use-case is for the data scientist themself, and the quick iteration of graphs. Relatively little time is spent on adjusting the theme or on making the graph “beautiful” as it may be ephemeral, or simply a visual check of the underlying relationships.\nThe next stage in many analyses is creating a graphic primarily intended for others to consume. At this point, the graphic needs to be more engaging, and often needs to be more focused on telling a “story” or reinforcing some point that you are trying to present from the underlying data.\nIn this blogpost, I’ll be covering some example themes, how to create and apply a theme, and then walk through some real life applications. I’ll leave larger color theory, and creating your own ggplot2 color scales for a future blogpost.\n\nggplot2 is remarkably extensible and customizable both through specific graphical components (geom_, scale_, aes, etc) or by theme components (grid lines, background colors, fonts, etc). There is also the concept of fully established themes which change many theme components at once.\nFirst, we’ll get some data and load our libraries of interest.\n\nlibrary(tidyverse)\nlibrary(espnscrapeR)\nlibrary(ggthemes)\n\nWe’re returning some data on NFL win rates, playoff seeding, and point differentials (ie difference between points given up and points scored).\n\nnfl_stand <- 2014:2020 %>% \n  map_dfr(get_nfl_standings)\n\nReturning 2014\n\n\nReturning 2015\n\n\nReturning 2016\n\n\nReturning 2017\n\n\nReturning 2018\n\n\nReturning 2019\n\n\nReturning 2020\n\ndiff_df <- nfl_stand %>% \n  select(season = season, conf, team_name, team_abb = team_abb, team_logo, win_pct, pts_diff) %>% \n  arrange(season, conf, desc(win_pct))\n\ndiff_df\n\n# A tibble: 224 × 7\n   season conf  team_name team_abb team_logo                    win_pct pts_diff\n    <int> <chr> <chr>     <chr>    <chr>                          <dbl>    <dbl>\n 1   2014 AFC   Patriots  NE       https://a.espncdn.com/i/tea…   0.75       155\n 2   2014 AFC   Broncos   DEN      https://a.espncdn.com/i/tea…   0.75       128\n 3   2014 AFC   Steelers  PIT      https://a.espncdn.com/i/tea…   0.688       68\n 4   2014 AFC   Colts     IND      https://a.espncdn.com/i/tea…   0.688       89\n 5   2014 AFC   Bengals   CIN      https://a.espncdn.com/i/tea…   0.656       21\n 6   2014 AFC   Ravens    BAL      https://a.espncdn.com/i/tea…   0.625      107\n 7   2014 AFC   Chiefs    KC       https://a.espncdn.com/i/tea…   0.562       72\n 8   2014 AFC   Texans    HOU      https://a.espncdn.com/i/tea…   0.562       65\n 9   2014 AFC   Chargers  SD       https://a.espncdn.com/i/tea…   0.562        0\n10   2014 AFC   Bills     BUF      https://a.espncdn.com/i/tea…   0.562       54\n# … with 214 more rows\n\n\n\nThe default ggplot2 theme is theme_grey(), it’s major components are a grey panel.background, white panel.grid lines, coupled with a white plot.background, black text and a default black color for geom_ components.\n\nThe signature ggplot2 theme with a grey background and white gridlines, designed to put the data forward yet make comparisons easy.\n\n\nggplot(diff_df, aes(x = pts_diff, y = win_pct)) +\n  geom_point()\n\n\n\n\n\nThis theme drops the panel.background and no longer has the visual separation between the panel vs plot areas.\n\nA minimalistic theme with no background annotations.\n\n\nggplot(diff_df, aes(x = pts_diff, y = win_pct)) +\n  geom_point() +\n  theme_minimal()\n\n\n\n\n\nIt’s major components are a white panel.background, grey panel.grid lines, coupled with a white plot.background, black text and a default black color for geom_ components.\n\nThe classic dark-on-light ggplot2 theme. May work better for presentations displayed with a projector.\n\n\nggplot(diff_df, aes(x = pts_diff, y = win_pct)) +\n  geom_point() +\n  theme_bw()\n\n\n\n\n\nThere are several other themes built into ggplot2, and other packages that provide new themes. The most well-known external theme package is ggthemes, which provides a number of Data Journalism themes such as theme_few(), theme_fivethirtyeight(), theme_economist() and others.\nThese are implementations of very opinionated frameworks, and highlight the extensibility of the ggplot2 theme components.\n\nggplot(diff_df, aes(x = pts_diff, y = win_pct)) +\n  geom_point() +\n  ggthemes::theme_fivethirtyeight()\n\n\n\n\n\nggplot(diff_df, aes(x = pts_diff, y = win_pct)) +\n  geom_point() +\n  ggthemes::theme_economist()\n\n\n\n\n\nYou can always change specific theme components one at a time or in conjunction with a proper theme_. For example, we can apply the theme_fivethirtyeight() theme and then change one of the theme components individually.\n\nggplot(diff_df, aes(x = pts_diff, y = win_pct)) +\n  geom_point() +\n  ggthemes::theme_fivethirtyeight() +\n  theme(\n    panel.grid.major = element_line(color = \"red\")\n  )\n\n\n\n\nThere are dozens of customizable theme components. They are outlined in the ggplot2 documentation. A deep walkthrough of a lot of ggplot2 customizations can be found on Cedric Scherer’s blog. Kieran Healy’s Data Visualization: A practical introduction covers additional considerations for refining and customizing plots and why certain decisions are good.\n\nFor each of the theme components there are one of a few theme elements. For example, to change the axis grid line color, you’ll use element_line() as in the following pseudocode:\nplot_object +\n  theme(panel.grid.major = element_line(color = \"red\"))\nFor the theme elements, there are:\n\nelement_line() - change line element components, takes arguments like color, size, linetype (dotted, dashed, solid, etc)\nelement_rect() - change rectangular components like plot backgrounds, legend backgrounds, etc, takes arguments like fill, color, size\nelement_text() - change text components like axis labels, titles, and takes arguments like family (font family), face (bold, italics, etc), hjust/vjust (horizontal or vertical alignment), color, etc\nelement_blank() - completely remove an element by name\nmargin() - adjust margins of an element, can be used within some other theme componenets, and takes arguments of t (top), r (right), b (bottom), l (left), and unit (unit such as points, in, cm, etc)\nrel() - relative sizing of elements, useful for text especially, ie choosing a base font size and scaling the titles vs body fonts relative to each other\n\nYou can always refer to the ggplot2 documentation for which theme element to use, but you can also typically “guess” which is the right one to use by referring to the output type (ie text uses element_text(), lines use element_line(), etc)."
  },
  {
    "objectID": "posts/2020-12-26-creating-and-using-custom-ggplot2-themes/index.html#playoff-teams",
    "href": "posts/2020-12-26-creating-and-using-custom-ggplot2-themes/index.html#playoff-teams",
    "title": "Creating and using custom ggplot2 themes",
    "section": "Playoff Teams",
    "text": "Playoff Teams\nLet’s add a color that shows where playoff teams fit into the big picture. Note that in 2020 teams with a ranking of 7th or better make the playoffs vs previously only the top 6 teams made it.\n\nAdd Color\n\nnfl_stand %>% \n  mutate(\n    color = case_when(\n      season < 2020 & seed <= 6 ~ \"blue\",\n      season == 2020 & seed <= 7 ~ \"blue\",\n      TRUE ~  \"red\"\n    )\n  ) %>% \n  ggplot(aes(x = pts_diff, y = win_pct)) +\n  geom_vline(xintercept = 0, size = 0.75, color = \"#737373\") +\n  geom_point(aes(color = color))"
  },
  {
    "objectID": "posts/2020-12-26-creating-and-using-custom-ggplot2-themes/index.html#add-some-color",
    "href": "posts/2020-12-26-creating-and-using-custom-ggplot2-themes/index.html#add-some-color",
    "title": "Creating and using custom ggplot2 themes",
    "section": "Add some color",
    "text": "Add some color\nUh-oh… what happened with the colors??? We told it to be blue and red but it reversed the colors!\nWe needed a scale_color_identity() call. While we’re adding color, let’s also add some “color commentary” of the axes, a title, and a source caption. There we go! Now we can show that: “Playoff teams typically have a positive point differential”. I’ll also bump up the size of the points to bump up the “ink to white” ratio and some transparency (alpha) so that overlapping points are clear.\nLastly, I’ve added a vertical line at the 0 mark to clearly indicate the transition from negative to positive point differential.\n\nProper Colors and Text\n\nnfl_stand %>% \n  mutate(\n    color = case_when(\n      season < 2020 & seed <= 6 ~ \"blue\",\n      season == 2020 & seed <= 7 ~ \"blue\",\n      TRUE ~  \"red\"\n    )\n  ) %>% \n  ggplot(aes(x = pts_diff, y = win_pct)) +\n  geom_vline(xintercept = 0, size = 0.75, color = \"#737373\") +\n  geom_point(\n    aes(color = color),\n    size = 3, alpha = 0.8\n    ) +\n  scale_color_identity() +\n  labs(x = \"Points Differential\", y = \"Win Percent\",\n       title = \"Playoff teams typically have a positive point differential\",\n       subtitle = \"Data through week 15 of the 2020 NFL Season\",\n       caption = \"Plot: @thomas_mock | Data: ESPN\")"
  },
  {
    "objectID": "posts/2020-12-26-creating-and-using-custom-ggplot2-themes/index.html#refine-labels",
    "href": "posts/2020-12-26-creating-and-using-custom-ggplot2-themes/index.html#refine-labels",
    "title": "Creating and using custom ggplot2 themes",
    "section": "Refine labels",
    "text": "Refine labels\nNow, because we don’t have a legend for the colors, let’s add some direct labels to indicate what’s going on. I’ll use ggtext to add nicely formatted color text. Note that I’ve also borrowed the NFL shield’s blue and red hex color code to add a bit more engaging color for both the labels and points. Lastly, I’ve also converted the y-axis from decimals to proper percent labels via scales::percent_format() and some better breakpoints.\nThis is starting to look a lot better, but I’m not a huge fan of the base theme.\n\nRefine Labels\n\nlibrary(ggtext)\n\nplayoff_label_scatter <- tibble(\n  pts_diff = c(25,-125), y = c(0.3, 0.8), \n  label = c(\"Missed<br>Playoffs\", \"Made<br>Playoffs\"),\n  color = c(\"#D50A0A\", \"#013369\")\n)\n\n\nplayoff_diff_plot <- nfl_stand %>% \n  mutate(\n    color = case_when(\n      season < 2020 & seed <= 6 ~ \"#013369\",\n      season == 2020 & seed <= 7 ~ \"#013369\",\n      TRUE ~  \"#D50A0A\"\n    )\n  ) %>% \n  ggplot(aes(x = pts_diff, y = win_pct)) +\n  geom_vline(xintercept = 0, size = 0.75, color = \"#737373\") +\n  geom_hline(yintercept = 0, size = 0.75, color = \"#737373\") +\n  geom_point(\n    aes(color = color),\n    size = 3, alpha = 0.8\n    ) +\n  ggtext::geom_richtext(\n    data = playoff_label_scatter,\n    aes(x = pts_diff, y = y, label = label, color = color),\n    fill = \"#f0f0f0\", label.color = NA, # remove background and outline\n    label.padding = grid::unit(rep(0, 4), \"pt\"), # remove padding\n    family = \"Chivo\", hjust = 0.1, fontface = \"bold\",\n    size = 8\n  ) +\n  scale_color_identity() +\n  labs(x = \"Points Differential\", y = \"Win Percent\",\n       title = \"Playoff teams typically have a positive point differential\",\n       subtitle = \"Data through week 15 of the 2020 NFL Season\",\n       caption = str_to_upper(\"Plot: @thomas_mock | Data: ESPN\")) +\n  scale_y_continuous(\n    labels = scales::percent_format(accuracy = 1),\n    breaks = seq(.0, 1, by = .10)\n    ) +\n  scale_x_continuous(\n    breaks = seq(-200, 250, by = 50)\n  )\n\n\nplayoff_diff_plot"
  },
  {
    "objectID": "posts/2020-12-26-creating-and-using-custom-ggplot2-themes/index.html#premade-themes",
    "href": "posts/2020-12-26-creating-and-using-custom-ggplot2-themes/index.html#premade-themes",
    "title": "Creating and using custom ggplot2 themes",
    "section": "Premade themes",
    "text": "Premade themes\nNow, as mentioned earlier we can use themes to change theme components in bulk. Since we’re interested in some FiveThirtyEight style plots, let’s try the theme_fivethirtyeight() from ggthemes.\nThis looks relatively close to the right overall style, but we lost axis labels, and the fonts are still a bit basic. Let’s try and build our own!\n\nplayoff_diff_plot +\n  ggthemes::theme_fivethirtyeight()"
  },
  {
    "objectID": "posts/2020-12-26-creating-and-using-custom-ggplot2-themes/index.html#custom-themes",
    "href": "posts/2020-12-26-creating-and-using-custom-ggplot2-themes/index.html#custom-themes",
    "title": "Creating and using custom ggplot2 themes",
    "section": "Custom Themes",
    "text": "Custom Themes\nThere are two ways of building your own themes:\n\n\ntheme() - Add theme components individually\n\n\ntheme_?? %+replace% - Apply an existing theme and overwriting components of it\n\ntheme()\nLet’s first just build up the theme components, we’ll be attempting to recreate the FiveThirtyEight theme from scratch. I’m focusing on the minimal changes necessary to recreate the plotting style. We need a lightgrey background, grey gridlines, larger text with a specific font. Note that I’m using systemfonts to load all my system font libraries into R.\nA quick example of a FiveThirtyEight style plot:\n\nIn short, a few concepts that make up the FiveThirtyEight “style guide”:\n\nFocus on Web, ie relatively small graphics\n\nLight smoke-grey background with grey gridlines\n\nBlack Plot Titles/Subtitles and Axis Labels\n\nGrey axis text (ie numbers on axis)\n\nLARGE plot titles and axis labels, with medium subtitles and axis text\n\nAlways add a source\n\nBright colors for plots\n\nThere’s a bit more fine details to what makes their plots so good but that covers the big parts we’ll try to capture in our theme. Some of the nuance is up to the individual to enact (ie choosing fonts, specific colors, just how big to make the fonts/points/etc).\nThe first pass at a theme that we’ve created to match that style. I’ve added comments as to what different theme elements change.\n\nCustom Theme Code\n\ntheme_538 <- function(..., base_size = 12) {\n  \n    theme(\n      # plotting components\n      \n      ## drop minor gridlines\n      panel.grid.minor = element_blank(),\n      # change grid lines to gray\n      panel.grid.major =  element_line(color = \"#d0d0d0\"),\n      # fill the plot and panel spaces with grey and remove border\n      panel.background = element_rect(fill = \"#f0f0f0\", color = NA),\n      plot.background = element_rect(fill = \"#f0f0f0\", color = NA),\n      panel.border = element_blank(),\n      # remove strip background\n      strip.background = element_blank(),\n      # adjust the margins of plots and remove axis ticks\n      plot.margin = margin(0.5, 1, 0.5, 1, unit = \"cm\"),\n      axis.ticks = element_blank(),\n      # change text family, size, and adjust position of titles\n      text = element_text(family = \"Chivo\", size = base_size),\n      axis.text = element_text(face = \"bold\", color = \"grey\", size = base_size),\n      axis.title = element_text(face = \"bold\", size = rel(1.33)),\n      axis.title.x = element_text(margin = margin(0.5, 0, 0, 0, unit = \"cm\")),\n      axis.title.y = element_text(margin = margin(0, 0.5, 0, 0, unit = \"cm\"), angle =90),\n      plot.title = element_text(face = \"bold\", size = rel(1.67), hjust = 0),\n      plot.title.position = \"plot\",\n      plot.subtitle = element_text(size = 16, margin = margin(0.2, 0, 1, 0, unit = \"cm\"), hjust = 0),\n      plot.caption = element_text(size = 10, margin = margin(1, 0, 0, 0, unit = \"cm\"), hjust = 1),\n      strip.text = element_text(size = rel(1.33), face = \"bold\"),\n      ...\n    )\n}\n\nNow let’s apply the theme to our plot.\n\nplayoff_diff_plot +\n  theme_538()\n\n\n\n\nI think we’ve created a nice representation of the FiveThirtyEight style!\ntheme_?? %+replace%\nThe %+replace% version instead applies a theme and then completely replaces those components rather than adding to them. This is typically more robust, but requires you to specific more arguments as they’re removed otherwise. For our purposes the code inside theme() is identical but there are situations where building up by theme() alone requires less initial work but is less robust to “real life” edge cases.\n%+replace% theme\n\ntheme_539 <- function(base_size = 12, base_family = \"Chivo\") {\n  \n  theme_grey(base_size = base_size, base_family = base_family) %+replace%\n    theme(\n      panel.grid.minor = element_blank(),\n      axis.ticks = element_blank(),\n      text = element_text(family = \"Chivo\", size = base_size),\n      axis.text = element_text(face = \"bold\", color = \"grey\", size = base_size),\n      axis.title = element_text(face = \"bold\", size = rel(1.33)),\n      axis.title.x = element_text(margin = margin(0.5, 0, 0, 0, unit = \"cm\")),\n      axis.title.y = element_text(margin = margin(0, 0.5, 0, 0, unit = \"cm\"), angle =90),\n      plot.title = element_text(face = \"bold\", size = rel(1.67), hjust = 0),\n      plot.title.position = \"plot\",\n      plot.subtitle = element_text(size = 16, margin = margin(0.2, 0, 1, 0, unit = \"cm\"), hjust = 0),\n      plot.caption = element_text(size = 10, margin = margin(1, 0, 0, 0, unit = \"cm\"), hjust = 1),\n      plot.background = element_rect(fill = \"#f0f0f0\", color = NA),\n      panel.background = element_rect(fill = \"#f0f0f0\", color = NA),\n      panel.grid.major =  element_line(color = \"#d0d0d0\"),\n      panel.border = element_blank(),\n      plot.margin = margin(0.5, 1, 0.5, 1, unit = \"cm\"),\n      strip.background = element_blank(),\n      strip.text = element_text(size = rel(1.33), face = \"bold\")\n    )\n}\n\n\nplayoff_diff_plot +\n  theme_539()"
  },
  {
    "objectID": "posts/2020-12-26-creating-and-using-custom-ggplot2-themes/index.html#same-data-different-story",
    "href": "posts/2020-12-26-creating-and-using-custom-ggplot2-themes/index.html#same-data-different-story",
    "title": "Creating and using custom ggplot2 themes",
    "section": "Same Data, Different Story",
    "text": "Same Data, Different Story\nThe Same Data, Different Story (SDDS) means we can use the same data in a different plot to tell a slightly different story. We can now represent theNow we’re going to use our theme and the same data, but represent the data a bit differently. We’ll load the ggridges package to let us plot many distributions at once. Again we’re adjusting the colors, plotting the data, and adding our theme. Overall this looks pretty excellent out of the gate! This is why themes + custom colors are so useful as you can get 80% of the way there with just those two changes.\nWe can see that for most years playoff teams are more frequently with positive point differentials and non-playoff teams have negative differentials, but there are clear cases (2014, 2016) where the story is not as clean!\n\nlibrary(ggridges)\n\nstand_density <- nfl_stand %>% \n  mutate(\n    color = case_when(\n      season < 2020 & seed <= 6 ~ \"#013369\",\n      season == 2020 & seed <= 7 ~ \"#013369\",\n      TRUE ~  \"#D50A0A\"\n    )\n  ) %>% \n  ggplot(aes(x = pts_diff, y = factor(season), color = color, fill = color)) +\n  geom_vline(xintercept = 0.5, size = 0.75, color = \"#737373\") +\n  geom_density_ridges(alpha = 0.8, scale = 1.1) +\n  scale_color_identity(aesthetics = c(\"fill\", \"color\")) +\n  theme_538()\n\nstand_density\n\nPicking joint bandwidth of 30.5\n\n\n\n\n\nAdd context\nWe can add a bit more context with custom embedded labels, a title, subtitle, etc and by adjusting some of the x/y breaks. I’m going to completely drop the y-gridlines since they’re not needed. Note that for the custom annotations that factors are represented essentially as discrete ordered integers, so for the 7 years we have plotted we can put a label just above the last year by plotting at 7.5 (just above the 7th year/2020).\n\nAdd Context\n\n# create a small dataset for the custom annotations\nplayoff_label_ridge <- tibble(\n  y = c(7.75, 7.75), pts_diff = c(-250,150),\n  label = c(\"Missed<br>Playoffs\", \"Made<br>Playoffs\"),\n  color = c(\"#D50A0A\", \"#013369\")\n)\n\nstand_density +\n  scale_x_continuous(breaks = scales::pretty_breaks(n = 10)) +\n  coord_cartesian(xlim = c(-250, 250)) +\n  ggtext::geom_richtext(\n    data = playoff_label_ridge,\n    aes(x = pts_diff, y = y, label = label, color = color),\n    fill = \"#f0f0f0\", label.color = NA, # remove background and outline\n    label.padding = grid::unit(rep(0, 4), \"pt\"), # remove padding\n    family = \"Chivo\", hjust = 0 , fontface = \"bold\",\n    size = 6\n  ) +\n  theme_538() + \n  theme(panel.grid.major.y = element_blank()) +\n  labs(\n    x = \"Point Differential\", y = \"\",\n    title = \"Playoff teams typically have a positive point differential\",\n    subtitle = \"Data through week 15 of the 2020 NFL Season\",\n    caption = \"Plot: @thomas_mock | Data: ESPN\"\n    )\n\nPicking joint bandwidth of 30.5\n\n\n\n\n\n\n\nPicking joint bandwidth of 30.5\n\n\n\n\n\nAnd if you want to look at the full code to create this all at once, see the expandable tag below.\n\nFull code\n\nlibrary(ggridges)\n\nplayoff_label_ridge <- tibble(\n  y = c(7.5, 7.5), pts_diff = c(-225,150),\n  label = c(\"Missed<br>Playoffs\", \"Made<br>Playoffs\"),\n  color = c(\"#D50A0A\", \"#013369\")\n)\n\n\nnfl_stand %>% \n  mutate(\n    color = case_when(\n      season < 2020 & seed <= 6 ~ \"#013369\",\n      season == 2020 & seed <= 7 ~ \"#013369\",\n      TRUE ~  \"#D50A0A\"\n    )\n  ) %>% \n  ggplot(aes(x = pts_diff, y = factor(season), color = color, fill = color)) +\n  geom_vline(xintercept = 0.5, size = 0.75, color = \"#737373\") +\n  geom_density_ridges(alpha = 0.8, scale = 1.1) +\n  ggtext::geom_richtext(\n    data = playoff_label_ridge,\n    aes(x = pts_diff, y = y, label = label, color = color),\n    fill = \"#f0f0f0\", label.color = NA, # remove background and outline\n    label.padding = grid::unit(rep(0, 4), \"pt\"), # remove padding\n    family = \"Chivo\", hjust = 0 , fontface = \"bold\",\n    size = 6\n  ) +\n  scale_x_continuous(breaks = scales::pretty_breaks(n = 10)) +\n  coord_cartesian(xlim = c(-250, 250)) +\n  scale_color_identity(aesthetics = c(\"fill\", \"color\")) +\n  theme_538() +\n  theme(panel.grid.major.y = element_blank()) +\n  labs(\n    x = \"Point Differential\", y = \"\",\n    title = \"Playoff teams typically have a positive point differential\",\n    subtitle = \"Data through Week 15 of the 2020 NFL Season\",\n    caption = \"Plot: @thomas_mock | Data: ESPN\"\n    )\n\nPicking joint bandwidth of 30.5"
  },
  {
    "objectID": "posts/2020-12-26-creating-and-using-custom-ggplot2-themes/index.html#sdds-2-rise-of-2020",
    "href": "posts/2020-12-26-creating-and-using-custom-ggplot2-themes/index.html#sdds-2-rise-of-2020",
    "title": "Creating and using custom ggplot2 themes",
    "section": "SDDS 2: Rise of 2020",
    "text": "SDDS 2: Rise of 2020\nWe can go one step deeper on the Same Data, Different Story principle and plot the data just a bit differently. Let’s plot the playoff teams for 2020 (top 7), and the top two “on-the-bubble” teams. I’ve added the theme_538(), and a horizontal line at the 0 mark again. Note that I’m using tidytext::reorder_within() to reorder the teams by their playoff seed within a conference. reorder() would work here as well, so tidytext::reorder_within() isn’t truly necessary, but can be very useful when re-ordering columns across facets.\n\nstand_df <- nfl_stand %>% \n  filter(season == 2020)\n\nstand_df %>% \n  filter(seed <= 12) %>% \n  ggplot(aes(x = tidytext::reorder_within(team_abb, seed, conf), y = pts_diff)) +\n  geom_col() + \n  tidytext::scale_x_reordered() +\n  facet_grid(~conf, scales = \"free_x\") +\n  geom_hline(yintercept = 0, size = 0.75, color = \"#737373\") +\n  theme_538()\n\n\n\n\nAdd Context\nRather than labeling the x-axis with team, we could supply playoff seed. We’ll add our titles, captions, etc along with a vertical line for separation of the playoff vs non-playoff teams, and a vertical line to separate the Y-axis from the X-axis baseline. We’ve also expanded the break points on the y-axis and dropped the x-axis gridlines.\n\nAdd Context\n\n# Small label dataset\nplayoff_label <- tibble(\n  seed = c(9, 4),\n  pts_diff = c(30, 100),\n  conf = c(\"AFC\", \"AFC\"),\n  label = c(\"Outside<br>looking in\", \"Playoff<br>teams\"),\n  color = c(\"#D50A0A\", \"#013369\")\n)\n\nstand_df %>%\n  filter(seed <= 12) %>%\n  ggplot(aes(x = as.factor(seed), y = pts_diff)) +\n  geom_col(\n    aes(fill = if_else(seed <= 7, \"#013369\", \"#D50A0A\")),\n    width = 0.8\n  ) +\n  ggtext::geom_richtext(\n    data = playoff_label,\n    aes(label = label, color = color),\n    fill = \"#f0f0f0\",\n    label.color = NA,\n    # remove background and outline\n    label.padding = grid::unit(rep(0, 4), \"pt\"),\n    # remove padding\n    family = \"Chivo\",\n    hjust = 0.1,\n    fontface = \"bold\",\n    size = 6\n  ) +\n  geom_hline(yintercept = 0, size = 0.75, color = \"#737373\") +\n  geom_vline(xintercept = 7.5, size = 1, color = \"grey\") +\n  geom_vline(xintercept = 0.5, size = 0.75, color = \"#737373\") +\n  facet_grid(~conf, scales = \"free_x\") +\n  scale_y_continuous(breaks = scales::pretty_breaks(n = 10)) +\n  scale_fill_identity(aesthetics = c(\"fill\", \"color\")) +\n  theme_538() +\n  theme(panel.grid.major.x = element_blank()) +\n  labs(\n    x = \"Playoff Seed\",\n    y = \"Points Differential\",\n    title = \"Playoff teams typically have a positive point differential\",\n    subtitle = \"Data through week 15 of the 2020 NFL Season\",\n    caption = \"Plot: @thomas_mock | Data: ESPN\"\n  )\n\n\n\n\n\n\n\n\n\nTeam vs Seed\nBy converting the x-axis to playoff seed instead of team, we’ve lost some data here, specifically which teams are which. We could add these back with by adding in an image at the end of each “bar”.\n\nAdd images\n\nlink_to_img <- function(x, width = 25) {\n  glue::glue(\"<img src='{x}' width='{width}'/>\")\n}\n\nplayoff_label <- tibble(\n  seed = c(9, 4),\n  pts_diff = c(90, 110),\n  conf = c(\"AFC\", \"AFC\"),\n  label = c(\"Outside<br>looking in\", \"Playoff<br>teams\"),\n  color = c(\"#D50A0A\", \"#013369\")\n)\n\nstand_plot_logo <- stand_df %>%\n  filter(seed <= 12) %>%\n  mutate(label = link_to_img(team_logo, width = 25)) %>%\n  ggplot(aes(x = as.factor(seed), y = pts_diff)) +\n  geom_col(\n    aes(fill = if_else(seed <= 7, \"#013369\", \"#D50A0A\")),\n    width = 0.8\n  ) +\n  ggtext::geom_richtext(\n    data = playoff_label,\n    aes(label = label, color = color),\n    fill = \"#f0f0f0\",\n    label.color = NA,\n    # remove background and outline\n    label.padding = grid::unit(rep(0, 4), \"pt\"),\n    # remove padding\n    family = \"Chivo\",\n    hjust = 0.1,\n    fontface = \"bold\",\n    size = 5\n  ) +\n  geom_richtext(\n    aes(\n      x = seed,\n      y = pts_diff,\n      label = label,\n      vjust = if_else(pts_diff <= 1, 1.1, -0.1)\n    ),\n    size = 1,\n    fill = \"#f0f0f0\",\n    label.color = NA,\n    # remove background and outline\n    label.padding = grid::unit(rep(0, 4), \"pt\") # remove padding\n  ) +\n  geom_hline(yintercept = 0, size = 0.75, color = \"#737373\") +\n  geom_vline(xintercept = 7.5, size = 1, color = \"grey\") +\n  geom_vline(xintercept = 0.5, size = 0.75, color = \"#737373\") +\n  facet_grid(~conf, scales = \"free_x\") +\n  scale_y_continuous(\n    breaks = seq(-125, 125, by = 25),\n    limits = c(-130, 130)\n  ) +\n  scale_fill_identity(aesthetics = c(\"fill\", \"color\")) +\n  theme_538() +\n  theme(\n    panel.grid.major.x = element_blank()\n  ) +\n  labs(\n    x = \"Playoff Seed\",\n    y = \"Points Differential\",\n    title = \"Playoff teams typically have a positive point differential\",\n    subtitle = \"Amongst the bubble teams, Baltimore appears to be the most 'deservering' of a playoff spot\",\n    caption = \"Plot: @thomas_mock | Data: ESPN\"\n  )\n\nggsave(\"stand_plot_logo.png\", stand_plot_logo, height = 8, width = 10, dpi = 300)\n\nWarning: Removed 4 rows containing missing values (position_stack).\n\n\nWarning: Removed 4 rows containing missing values (geom_rich_text).\n\n\n\nAlternatively, we could convert the X-axis back to team, and then add playoff seed numbers back to each of the bars. This is getting a bit busier, but I think it’s useful to show the if_else() workflow for plotting a “label” at a specific point based on a criterion. That can be very helpful in plotting where you can’t control the “direction” of a bar just like we see here.\n\nDirect Labels\n\nstand_df %>%\n  filter(seed <= 12) %>%\n  ggplot(aes(x = tidytext::reorder_within(team_abb, seed, conf), y = pts_diff)) +\n  geom_col(\n    aes(fill = if_else(seed <= 7, \"#013369\", \"#D50A0A\")),\n    width = 0.8\n  ) +\n  ggtext::geom_richtext(\n    data = playoff_label,\n    aes(x = seed, label = label, color = color),\n    fill = \"#f0f0f0\",\n    label.color = NA,\n    # remove background and outline\n    label.padding = grid::unit(rep(0, 4), \"pt\"),\n    # remove padding\n    family = \"Chivo\",\n    hjust = 0.1,\n    fontface = \"bold\",\n    size = 6\n  ) +\n  ggtext::geom_richtext(\n    aes(label = seed, y = if_else(pts_diff <= 0, 10, -10)),\n    color = \"black\",\n    fill = \"#f0f0f0\",\n    label.color = NA,\n    # remove background and outline\n    label.padding = grid::unit(rep(0, 4), \"pt\"),\n    # remove padding\n    family = \"Chivo\",\n    hjust = 0.5,\n    fontface = \"bold\",\n    size = 4\n  ) +\n  geom_hline(yintercept = 0, size = 0.75, color = \"#737373\") +\n  geom_vline(xintercept = 7.5, size = 1, color = \"grey\") +\n  geom_vline(xintercept = 0.5, size = 0.75, color = \"#737373\") +\n  facet_grid(~conf, scales = \"free_x\") +\n  tidytext::scale_x_reordered() +\n  scale_y_continuous(breaks = scales::pretty_breaks(n = 10)) +\n  scale_fill_identity(aesthetics = c(\"fill\", \"color\")) +\n  theme_538() +\n  theme(\n    panel.grid.major.x = element_blank()\n  ) +\n  labs(\n    x = \"Playoff Seed\",\n    y = \"Points Differential\",\n    title = \"Playoff teams typically have a positive point differential\",\n    subtitle = \"Amongst the bubble teams, Baltimore appears to be the most 'deservering' of a playoff spot\",\n    caption = \"Plot: @thomas_mock | Data: ESPN\"\n  )"
  },
  {
    "objectID": "posts/2020-12-26-creating-and-using-custom-ggplot2-themes/index.html#get-the-data",
    "href": "posts/2020-12-26-creating-and-using-custom-ggplot2-themes/index.html#get-the-data",
    "title": "Creating and using custom ggplot2 themes",
    "section": "Get the data",
    "text": "Get the data\nFirst we have to download the data from PFR. There are two defensive datasets we’ll need, the Advanced Stats for pressure/blitz rates and the general Passing Stats for passes defended + intercetions.\nWe’ll get them via the script below, and then combine by team.\n\nData Collection\n\nraw_url <- \"https://www.pro-football-reference.com/years/2020/opp.htm\"\n\nraw_html <- read_html(raw_url)\n\nraw_table <- raw_html %>% \n  html_table(fill = TRUE) %>% \n  .[[2]] %>% \n  janitor::clean_names() %>% \n  tibble()\n\npressure_df <- raw_table %>% \n  select(tm, blitz_pct = bltz_percent, press_pct = prss_percent) %>% \n  mutate(across(c(blitz_pct, press_pct), parse_number))\n\npass_def_raw <- raw_html %>% \n  html_node(\"#all_passing\") %>% \n  html_nodes(xpath = \"comment()\") %>% \n  html_text() %>% \n  read_html() %>% \n  html_node(\"table\") %>% \n  html_table() %>% \n  janitor::clean_names() %>% \n  tibble()\n\npass_def_df <- pass_def_raw %>% \n  select(tm, pass_att = att, int, pass_def = pd, sack = sk, ypa = y_a, anypa = any_a)\n\nWe can then do our left-join by tm to get our working dataset for this example.\n\ncombo_pass <- left_join(\n  pressure_df, pass_def_df,\n  by = \"tm\"\n)\n\ncombo_pass\n\n# A tibble: 32 × 9\n   tm              blitz_pct press_pct pass_att   int pass_def  sack   ypa anypa\n   <chr>               <dbl>     <dbl>    <dbl> <dbl>    <dbl> <dbl> <dbl> <dbl>\n 1 Atlanta Falcons      32.9      23.6      625    12       51    29   7.9   7.4\n 2 Buffalo Bills        35.8      22.2      573    15       76    38   6.9   5.7\n 3 Carolina Panth…      24        22.4      585     7       58    29   6.9   6.6\n 4 Chicago Bears        21.4      22.4      547    10       71    35   7.2   6.6\n 5 Cincinnati Ben…      31.1      19        541    11       80    17   7.3   7.2\n 6 Cleveland Brow…      21.3      21.9      585    11       74    38   7.2   6.6\n 7 Indianapolis C…      17.1      23.3      562    15       78    40   7.3   6.1\n 8 Arizona Cardin…      39.4      25.9      570    11       57    48   6.9   5.9\n 9 Dallas Cowboys       22.8      22.8      513    10       46    31   7.4   7.1\n10 Denver Broncos       27.9      26.2      567    10       64    42   7.2   6.2\n# … with 22 more rows"
  },
  {
    "objectID": "posts/2020-12-26-creating-and-using-custom-ggplot2-themes/index.html#initial-plot",
    "href": "posts/2020-12-26-creating-and-using-custom-ggplot2-themes/index.html#initial-plot",
    "title": "Creating and using custom ggplot2 themes",
    "section": "Initial Plot",
    "text": "Initial Plot\nWe’ll first plot the data and try out our theme. I want to add the colors of the specific article we’re recreating.\n\ncombo_pass %>% \n  ggplot(aes(x = blitz_pct, y = press_pct)) +\n  geom_point() +\n  labs(\n    x = \"Blitz Rate\", y = \"Pressure Rate\",\n    title = \"The Colts are pressuring QBs without much of a blitz\",\n    subtitle = \"Blitz rate vs. pressure rate for each NFL defense, through Week 15 of the 2020 season\"\n  ) + \n  theme_538()"
  },
  {
    "objectID": "posts/2020-12-26-creating-and-using-custom-ggplot2-themes/index.html#add-color",
    "href": "posts/2020-12-26-creating-and-using-custom-ggplot2-themes/index.html#add-color",
    "title": "Creating and using custom ggplot2 themes",
    "section": "Add color",
    "text": "Add color\nIf we add color specifically for the Colts, and then also expand the axis range to match the article, we get the following plot. I’ll save the mutate calls into a new dataframe, and then plot it.\n\nAdd Color and Text\n\ncolt_df <- combo_pass %>% \n  mutate(\n    color = if_else(tm == \"Indianapolis Colts\", \"#359fda\", \"#91c390\"),\n    fill = colorspace::lighten(color, amount = 0.3)\n    ) %>% \n  rowwise() %>% \n  mutate(\n    att_def = sum(int, pass_def, sack),\n    cov_rate = att_def/pass_att*100\n    ) %>% \n  ungroup() %>% \n  arrange(desc(cov_rate))\n\ncolt_df %>% \n  ggplot(aes(x = blitz_pct, y = press_pct, fill = fill, color = color)) +\n  geom_point(size = 5, pch = 21, alpha = 0.8) +\n  scale_color_identity(aesthetics = c(\"fill\", \"color\")) +\n  labs(\n    x = \"Blitz Rate\", y = \"Pressure Rate\",\n    title = \"The Colts are pressuring QBs without much of a blitz\",\n    subtitle = \"Blitz rate vs. pressure rate for each NFL defense,\\nthrough Week 15 of the 2020 season\",\n    caption = toupper(\"Plot: @thomas_mock | Data: PFR | Inspiration: FiveThirtyEight\")\n  ) +\n  scale_x_continuous(limits = c(10, 45), breaks = seq(10, 45, by = 5)) +\n  scale_y_continuous(limits = c(10, 35), breaks = seq(10, 35, by = 5)) +\n  theme_538()\n\nWarning: Removed 1 rows containing missing values (geom_point).\n\n\n\n\n\n\n\nWarning: Removed 1 rows containing missing values (geom_point)."
  },
  {
    "objectID": "posts/2020-12-26-creating-and-using-custom-ggplot2-themes/index.html#add-labels",
    "href": "posts/2020-12-26-creating-and-using-custom-ggplot2-themes/index.html#add-labels",
    "title": "Creating and using custom ggplot2 themes",
    "section": "Add labels",
    "text": "Add labels\nWe can create a small “helper” dataset to plot the labels, and we’ve basically re-created the original plot!\n\nAdd Labels\n\nlabel_df_press <- tibble(\n  label = c(\"Colts\", \"Everyone else\"),\n  color = c(\"#359fda\", \"#91c390\"),\n  fill = colorspace::lighten(color, amount = 0.3),\n  x = c(16, 30),\n  y = c(25, 29)\n)\n\ncolt_df %>% \n  ggplot(aes(x = blitz_pct, y = press_pct, fill = fill, color = color)) +\n  geom_point(size = 5, pch = 21, alpha = 0.8) +\n  scale_color_identity(aesthetics = c(\"fill\", \"color\")) +\n  labs(\n    x = \"Blitz Rate\", y = \"Pressure Rate\",\n    title = \"The Colts are pressuring QBs without much of a blitz\",\n    subtitle = \"Blitz rate vs. pressure rate for each NFL defense,\\nthrough Week 15 of the 2020 season\",\n    caption = \"Source: Pro-Football-Reference.com\"\n  ) +\n  scale_x_continuous(limits = c(10, 45), breaks = seq(10, 45, by = 5)) +\n  scale_y_continuous(limits = c(10, 35), breaks = seq(10, 35, by = 5)) +\n  geom_label(\n    data = label_df_press,\n    aes(x = x, y = y, color = color, label = label),\n    fill = \"#f0f0f0\",\n    size = 6,\n    fontface = \"bold\",\n    hjust = 0.8,\n    label.size = NA # remove the border\n  ) +\n  theme_538()\n\nWarning: Removed 1 rows containing missing values (geom_point).\n\n\n\n\n\n\n\nWarning: Removed 1 rows containing missing values (geom_point)."
  },
  {
    "objectID": "posts/2020-12-26-creating-and-using-custom-ggplot2-themes/index.html#slope-chart",
    "href": "posts/2020-12-26-creating-and-using-custom-ggplot2-themes/index.html#slope-chart",
    "title": "Creating and using custom ggplot2 themes",
    "section": "Slope Chart",
    "text": "Slope Chart\nBy pivoting the data longer, and converting the blitz/pass affected rate columns into a combined column we can pretty quickly get a decent slope-chat put together. In short, we are creating a new metric and corresponding value column out of the blitz/pass affected rates.\nThis can then be plotted where the metric name is on the x-axis and the metric value is the y-axis. Because both metrics are percentages they’re in the same plotting range.\n\nlong_colts <- colt_df %>%\n  mutate(\n    color = if_else(color == \"#91c390\", \"grey\", \"#359fda\"),\n    fill = color\n  ) %>%\n  rename(pass_affected_rate = cov_rate) %>%\n  pivot_longer(\n    cols = c(blitz_pct, pass_affected_rate), \n    names_to = \"metric\", values_to = \"value\"\n    ) %>%\n  mutate(\n    metric = if_else(\n      metric == \"blitz_pct\", \n      \"Blitz Rate\", \n      \"Pass Affected Rate\"\n      )\n  )\n\nlong_colts\n\n# A tibble: 64 × 13\n   tm    press_pct pass_att   int pass_def  sack   ypa anypa color fill  att_def\n   <chr>     <dbl>    <dbl> <dbl>    <dbl> <dbl> <dbl> <dbl> <chr> <chr>   <dbl>\n 1 Pitt…      35.1      526    18       84    56   6.6   4.7 grey  grey      158\n 2 Pitt…      35.1      526    18       84    56   6.6   4.7 grey  grey      158\n 3 New …      26.3      557    18       84    45   6.7   5.4 grey  grey      147\n 4 New …      26.3      557    18       84    45   6.7   5.4 grey  grey      147\n 5 Miam…      24.8      545    18       76    41   8     6.2 grey  grey      135\n 6 Miam…      24.8      545    18       76    41   8     6.2 grey  grey      135\n 7 Los …      23.4      548    14       68    53   6.2   4.6 grey  grey      135\n 8 Los …      23.4      548    14       68    53   6.2   4.6 grey  grey      135\n 9 Wash…      25.9      529    16       66    47   6.4   4.8 grey  grey      129\n10 Wash…      25.9      529    16       66    47   6.4   4.8 grey  grey      129\n# … with 54 more rows, and 2 more variables: metric <chr>, value <dbl>\n\n\nInitial Slope Chart\nThe initial slope chart is only a few lines of code. We’ll plot metric names on the x-axis, metric values on the y-axis, add lines by team between the compared measures, and then layer points on top of it all.\n\nlong_colts %>%\n  ggplot(aes(x = metric, y = value, group = tm, color = color, fill = fill)) +\n  geom_line(aes(size = if_else(tm == \"Indianapolis Colts\", 2, 0.5))) +\n  geom_point(size = 5, pch = 21, color = \"#f0f0f0\", stroke = 1) +\n  scale_color_identity(aesthetics = c(\"fill\", \"color\")) +\n  scale_size_identity()\n\n\n\n\nAdd theme and context\nWe can further enhance the plot with the title/source data. I’ve also shared a little “hack” that allows you to plot outside of the plot area. By setting clip = 'off' in coord_cartestian(), we can add an annotation that falls “outside” of the plot area. This lets us add a description note similar to what FiveThirtyEight does with some of their plots.\n\nAdd Theme and Context\n\ncolt_slope <- long_colts %>%\n  ggplot(aes(x = metric, y = value, group = tm, color = color, fill = fill)) +\n  geom_line(aes(size = if_else(tm == \"Indianapolis Colts\", 2, 0.5))) +\n  geom_point(size = 5, pch = 21, color = \"#f0f0f0\", stroke = 1) +\n  geom_label(\n    data = filter(long_colts, tm == \"Indianapolis Colts\"),\n    aes(label = paste0(round(value, 0), \"%\")),\n    fill = NA,\n    hjust = c(1, 0),\n    nudge_x = c(-0.02, 0.02),\n    label.size = NA,\n    family = \"Chivo\",\n    fontface = \"bold\",\n    size = 6\n  ) +\n  annotate(\n    \"text\", x = 1, y = 12, vjust = 11, hjust = 0.4, color = \"darkgrey\",\n    family = \"Chivo\",\n    label = \"Pass affected rate = (sacks + ints + passes defended)/pass att\"\n    ) +\n  coord_cartesian(clip = \"off\") +\n  scale_y_continuous(limits = c(12, 43), breaks = scales::pretty_breaks(n = 7)) +\n  scale_x_discrete(expand = c(0.2, 0.2)) +\n  scale_color_identity(aesthetics = c(\"fill\", \"color\")) +\n  scale_size_identity() +\n  theme_538() +\n  theme(\n    panel.grid.major.y = element_blank(),\n    axis.text.y = element_blank(),\n    plot.margin = margin(0.5, 0.5, 0.1, 0.5, unit = \"cm\"),\n    axis.text.x = element_text(color = \"black\", size = 20),\n    plot.caption = element_markdown(size = 14)\n  ) +\n  labs(\n    x = \"\",\n    y = \"\",\n    title = \"The Colts affect more passes with fewer rushers\",\n    subtitle = \"Data since through Week 15 of the 2020 NFL season\",\n    caption = \"**Plot**: @thomas_mock | **Data**: PFR\"\n  )\n\nggsave(\"colt_slope.png\", colt_slope, height = 5, width = 4, dpi = 500, scale = 1.75)\n\nWarning: Removed 1 row(s) containing missing values (geom_path).\n\n\nWarning: Removed 1 rows containing missing values (geom_point)."
  },
  {
    "objectID": "posts/2020-12-26-creating-and-using-custom-ggplot2-themes/index.html#barbell",
    "href": "posts/2020-12-26-creating-and-using-custom-ggplot2-themes/index.html#barbell",
    "title": "Creating and using custom ggplot2 themes",
    "section": "Barbell",
    "text": "Barbell\nFor our last example with this data, we’re going to really highlight the Colt’s passing defense effectiveness without a blitz. A barbell plot is another combo of lines + points, where the line is a segment between the two measures of interest.\nOur first attempt is pretty straightforward, we’ll plot the segment between the points, then layer two geom_points(), one for each measure.\n\nInitial Barbell\n\nbarbell_first <- colt_df %>% \n  rename(pass_affected_rate = cov_rate) %>% \n  mutate(\n    color = str_replace(color, \"#91c390\", \"grey\"),\n    fill = str_replace(fill, \"#91c390\", \"grey\"),\n    tm = word(tm, -1)\n    ) %>% \n  ggplot(aes(x = blitz_pct, y = fct_reorder(tm, pass_affected_rate), \n             group = tm, color = color)) +\n  geom_segment(aes(xend = pass_affected_rate, yend = tm), size = 2) +\n  geom_point(size = 5, color = \"grey\") +\n  geom_point(aes(x = pass_affected_rate, y = tm), size = 5, color = \"black\") +\n  scale_color_identity()\n\nggsave(\"barbell_first.png\", barbell_first, height = 12, width = 8, units = \"in\", dpi = 300)\n\n\nTheme and context\nWe can add some more labels and context, along with our theme and a custom color placement to indicate the Colts as the outlier of interest.\n\nBarbell Theme\n\ncolt_colors <- colt_df %>% \n  arrange(cov_rate) %>% \n  mutate(color = str_replace(color, \"#91c390\", \"black\")) %>% \n  pull(color)\n\npass_label_df <- tibble(\n  x = c(20, 19.5),\n  tm = c(30, 25),\n  label = c(\"Blitz Rate\", \"Pass Affected<br>Rate\"),\n  color = c(\"grey\", \"black\")\n)\n\nex_barbell <- colt_df %>%\n  rename(pass_affected_rate = cov_rate) %>%\n  mutate(\n    color = str_replace(color, \"#91c390\", \"grey\"),\n    fill = str_replace(fill, \"#91c390\", \"grey\"),\n    tm = word(tm, -1)\n  ) %>%\n  ggplot(aes(x = blitz_pct, y = fct_reorder(tm, pass_affected_rate), \n             group = tm, color = color, fill = fill)) +\n  geom_segment(aes(xend = pass_affected_rate, yend = tm), size = 2) +\n  geom_point(size = 5, color = \"grey\") +\n  geom_point(aes(x = pass_affected_rate, y = tm), size = 5, color = \"black\") +\n  ggtext::geom_richtext(\n    data = pass_label_df,\n    aes(x = x, y = tm, label = label, color = color),\n    fill = \"#f0f0f0\",\n    label.color = NA,\n    # remove background and outline\n    label.padding = grid::unit(rep(0, 4), \"pt\"),\n    # remove padding\n    family = \"Chivo\",\n    hjust = 1,\n    fontface = \"bold\",\n    size = 5\n  ) +\n  annotate(\n    \"text\",\n    x = 10,\n    y = 1,\n    vjust = 10,\n    hjust = 0.4,\n    color = \"darkgrey\",\n    family = \"Chivo\",\n    label = \"Pass affected rate = (sacks + ints + passes defended)/pass att\"\n  ) +\n  scale_x_continuous(limits = c(10, 45), breaks = scales::pretty_breaks(n = 7)) +\n  scale_color_identity(aesthetics = c(\"fill\", \"color\")) +\n  coord_cartesian(clip = \"off\") +\n  labs(\n    x = \"<span style = 'color:grey;'>Blitz rate</span> vs Pass affected rate\",\n    y = \"\",\n    title = \"The Colts affect more passes with fewer rushers\",\n    subtitle = \"Data through Week 15 of the 2020 NFL season\",\n    caption = \"**Plot**: @thomas_mock | **Data**: PFR\"\n  ) +\n  theme_538() +\n  theme(\n    panel.grid.major.y = element_blank(),\n    axis.text.y = element_text(color = colt_colors, size = 18),\n    axis.title.x = element_markdown(),\n    plot.caption = element_markdown()\n  )\n\nWarning: Vectorized input to `element_text()` is not officially supported.\nResults may be unexpected or may change in future versions of ggplot2.\n\nggsave(\"barbell.png\", ex_barbell, height = 12, width = 8, units = \"in\", dpi = 300)"
  },
  {
    "objectID": "posts/2021-07-28-reminder-to-test-with-a-reprex/index.html",
    "href": "posts/2021-07-28-reminder-to-test-with-a-reprex/index.html",
    "title": "Reminder to test with a reprex",
    "section": "",
    "text": "It’s been a while since my last post, so I wanted to get back into the swing of things with a shorter article. My goal was to get a new one up on the blog before August 1st.\nAs such, I was working late on a much longer form article and as part of this I wanted to display some smoothed lines for several players on one plot. A sneak peek of some of this below:\nNow, I’ve been programming in R for quite some time, but for the life of me I couldn’t get my facets to align properly. This led to a bit of frustration as I “knew” what I was doing should be right but wasn’t returning the expected “correct” output.\nThis article walks through why I believe {reprex} driven testing is so useful for compartmentalizing a problem and getting at the specifics of why our expectation sometimes don’t match the output.\nLike most useful ideas, I’m far from the first person to think of it!\nThat’s a few folks who I have a great deal of respect for, and as usual they have great advice for us! (Write a reprex and you’ll likely solve the problem as you go)"
  },
  {
    "objectID": "posts/2021-07-28-reminder-to-test-with-a-reprex/index.html#whos-problem-is-this",
    "href": "posts/2021-07-28-reminder-to-test-with-a-reprex/index.html#whos-problem-is-this",
    "title": "Reminder to test with a reprex",
    "section": "Who’s problem is this?",
    "text": "Who’s problem is this?\nNow whenever I run into errors, mistakes, or unexpected outputs I ask myself:\n\nIs this a “Tom” problem? Or is this R’s fault?\n\n\n\nPrinciple skinner out of touch meme, with the text “Is it my code that is wrong?” and “No it must be an error with the forcats package” overlaid.\n\n\nThe short answer is that it’s almost always a “me” problem, as R is just diligently following the commands I gave to it. However, in some rare cases I do find a bug and can use the reprex testing I’ve done to quickly log a useful a bug report for the package developers.\nIf you haven’t run into the term “reprex” before, it is a:\n\n“minimal reproducible example”\n\nYou can read more about the {reprex} package on the package documentation site.\n\nIf you’re asking for R help, reporting a bug, or requesting a new feature, you’re more likely to succeed if you include a good reprex.\n\nThat quote is from the reprex docs, and I’ll add to it that a reprex can help with you solving your own problems BEFORE even submitting the bug request!"
  },
  {
    "objectID": "posts/2021-07-28-reminder-to-test-with-a-reprex/index.html#the-goal",
    "href": "posts/2021-07-28-reminder-to-test-with-a-reprex/index.html#the-goal",
    "title": "Reminder to test with a reprex",
    "section": "The Goal",
    "text": "The Goal\nWhile writing the article, I wanted to create a scatter plot, and facet the players by their respective QBR (Quarterback ratings) average scores. However, I kept getting the players to facet_wrap() by somewhat of an alphabetical order instead of in descending ranked order. This was a hint that my factor ordering via forcats was not being respected. I have included the “wrong” plot below.\n\n\nA 3x3 grid facetted by quarterback of the observation number on the X axis and the rolling max, min, and average on the Y-axis. The quarterbacks are facetted according to their alphabetical names.\n\n\nThis was of course frustrating, so I started doing some testing/troubleshooting of the complex plot as it was."
  },
  {
    "objectID": "posts/2021-07-28-reminder-to-test-with-a-reprex/index.html#initiate-testing",
    "href": "posts/2021-07-28-reminder-to-test-with-a-reprex/index.html#initiate-testing",
    "title": "Reminder to test with a reprex",
    "section": "Initiate testing",
    "text": "Initiate testing\nLet’s reproduce the initial problem. We’ll load the necessary packages, bring in the data, and generate the respective dataframes/plots as well. I’m intentionally leaving the code without comments and as a single code chunk as this is supposed to be a bit like a random code review. In retrospect the error is quite clear to me, but I was honestly stumped for a good chunk of time.\n\nlibrary(slider)\nlibrary(tidyverse)\nlibrary(espnscrapeR)\n\nall_qbr <- crossing(season = 2018:2020, week = 1:17) %>% \n  pmap_dfr(get_nfl_qbr)\n\nall_college_qbr <- 2018:2020 %>% \n  map_dfr(~get_college_qbr(.x, type = \"weekly\"))\n\ntest_data <- all_qbr %>%\n  select(player_id, qbr = qbr_total, team_abb, short_name) %>%\n  mutate(pure_avg = mean(qbr)) %>%\n  group_by(player_id) %>%\n  filter(n() >= 30) %>% \n  mutate(\n    short_name = fct_reorder(short_name, qbr, .fun= mean, .desc = TRUE),\n    grp_avg = mean(qbr, na.rm = TRUE),\n    diff_avg = qbr - pure_avg,\n    roll_mean = slide_dbl(qbr, mean, .before = 8L),\n    roll_max = slide_dbl(roll_mean, max, .before = Inf),\n    roll_min = slide_dbl(roll_mean, min, .before = Inf),\n    row = row_number()\n  ) %>% \n  ungroup()\n\ntest_plot <- test_data %>% \n  filter(grp_avg >= 62) %>% \n  ggplot(aes(x = row, y = roll_max)) +\n  geom_point(aes(y = qbr), alpha = 0.2) +\n  geom_step() +\n  geom_step(aes(y = roll_min), color = \"red\") +\n  geom_line(aes(y = roll_mean), color = \"blue\") +\n  geom_smooth(aes(y = qbr),method = \"loess\", size = 0.5, span = 0.35) +\n  facet_wrap(~factor(short_name)) +\n  coord_cartesian(ylim = c(0, 105), xlim = c(0, 50), expand = FALSE)\n\ntest_plot\n\n\n\nA 3x3 grid facetted by quarterback of the observation number on the X axis and the rolling max, min, and average on the Y-axis. The quarterbacks are facetted according to their alphabetical names.\n\n\nMaybe it’s a factor thing?\nMy initial thought is “it seems the factors are not being represented correctly”. Since I’m using forcats::fct_reorder(.f = short_name, .x = qbr, .fun = mean, .desc = TRUE) the Quarterback names should respect the “ranking” by their respective descending average QBR.\nHowever, what I was getting out in ggplot2 is ordered as below. It’s not in any real order!\n\ntest_data %>% \n  filter(grp_avg >= 62) %>% \n  distinct(short_name, grp_avg) %>% \n  arrange(short_name)\n\n# A tibble: 9 × 2\n  short_name        grp_avg\n  <fct>               <dbl>\n1 R. Wilson            66.4\n2 T. Brady             63.0\n3 D. Prescott          62.9\n4 D. Brees             71.4\n5 D. Watson            63.4\n6 P. Mahomes           77.2\n7 L. Jackson           68.4\n8 B. Roethlisberger    62.6\n9 A. Rodgers           62.1\n\n\nWhat I wanted, and how it “should” arrange like below:\n\ntest_data %>% \n  filter(grp_avg >= 62) %>% \n  mutate(short_name = fct_reorder(short_name, qbr, .fun = mean, .desc = TRUE)) %>% \n  distinct(short_name, grp_avg) %>% \n  arrange(short_name)\n\n# A tibble: 9 × 2\n  short_name        grp_avg\n  <fct>               <dbl>\n1 P. Mahomes           77.2\n2 D. Brees             71.4\n3 L. Jackson           68.4\n4 R. Wilson            66.4\n5 D. Watson            63.4\n6 T. Brady             63.0\n7 D. Prescott          62.9\n8 B. Roethlisberger    62.6\n9 A. Rodgers           62.1\n\n\nSo let’s take a look at the test_data object. The factors are simply “wrong”! We know we’re looking for “P. Mahomes” to always lead our rankings in this dataset. The results below are not in any “real” order!\n\ntest_data %>% \n  filter(grp_avg >= 62) %>% \n  distinct(short_name) %>% \n  arrange(short_name) %>% \n  pull() %>% \n  levels()\n\n [1] \"M. Ryan\"           \"M. Stafford\"       \"C. Newton\"        \n [4] \"A. Dalton\"         \"R. Tannehill\"      \"K. Cousins\"       \n [7] \"R. Wilson\"         \"D. Carr\"           \"T. Brady\"         \n[10] \"C. Wentz\"          \"D. Prescott\"       \"D. Brees\"         \n[13] \"M. Trubisky\"       \"J. Goff\"           \"B. Mayfield\"      \n[16] \"D. Watson\"         \"P. Mahomes\"        \"S. Darnold\"       \n[19] \"L. Jackson\"        \"K. Murray\"         \"J. Allen\"         \n[22] \"P. Rivers\"         \"B. Roethlisberger\" \"A. Rodgers\"       \n\n\nI thought to try to correct it manually. I could just get a vector of the quarterbacks according to the ranking and then apply it with factor(short_names, levels = qb_lvls). This gets us the “right” order of the names BUT it doesn’t really solve our underlying problem or tell us why it’s not working out as expected. This is a “bandaid” instead of a “cure” to my problem! If I did that I would never know if I had a wrong mental model, if there was an actual bug in ggplot2 or forcats (unlikely), or if I was simply coding it all wrong.\n\nqb_lvls <- test_data %>% \n  group_by(short_name) %>% \n  distinct(grp_avg) %>%\n  arrange(desc(grp_avg)) %>% \n  pull(short_name) %>% \n  as.character()\n\nqb_lvls\n\n [1] \"P. Mahomes\"        \"D. Brees\"          \"L. Jackson\"       \n [4] \"R. Wilson\"         \"D. Watson\"         \"T. Brady\"         \n [7] \"D. Prescott\"       \"B. Roethlisberger\" \"A. Rodgers\"       \n[10] \"M. Ryan\"           \"M. Stafford\"       \"J. Allen\"         \n[13] \"P. Rivers\"         \"K. Murray\"         \"R. Tannehill\"     \n[16] \"K. Cousins\"        \"B. Mayfield\"       \"D. Carr\"          \n[19] \"J. Goff\"           \"C. Wentz\"          \"M. Trubisky\"      \n[22] \"A. Dalton\"         \"C. Newton\"         \"S. Darnold\"       \n\n\nMake a reprex\nSo far, I dove into a few troubleshooting steps but it didn’t clarify what my underlying problem was. What I should have done was create a reprex or break the problem down into smaller pieces! I was about to ask for some help, so I wanted to generate a reprex to use as the “ask”.\nNow for the reprex, I don’t want to include data scraped from the internet as the data doesn’t really matter (and it requires a separate package - espnscrapeR). So let’s simulate data!\n\nlibrary(tidyverse)\n\nset.seed(20210728)\n\nsim_data <- crossing(\n  grp = letters[1:4],\n  series = 1:10\n) %>% \n  mutate(\n    val = rnorm(n = nrow(cur_data()), mean = 70, sd = 8)\n  )\n\nsim_data\n\n# A tibble: 40 × 3\n   grp   series   val\n   <chr>  <int> <dbl>\n 1 a          1  63.5\n 2 a          2  82.0\n 3 a          3  75.6\n 4 a          4  64.8\n 5 a          5  72.7\n 6 a          6  74.2\n 7 a          7  75.0\n 8 a          8  70.3\n 9 a          9  69.2\n10 a         10  69.7\n# … with 30 more rows\n\n\nWe also don’t need ALL the calculations we are doing, so let’s simplify it to just the minimal calculation:\n- a grouped average\n- an ordered factor according to that grouped average\n\nsim_plot_df <- sim_data %>% \n  group_by(grp) %>% \n  mutate(\n    grp_avg = mean(val, na.rm = TRUE),\n    grp_fct = fct_reorder(grp, val, .fun = mean, .desc = TRUE)\n  ) %>% \n  ungroup()\n\nsim_plot_df\n\n# A tibble: 40 × 5\n   grp   series   val grp_avg grp_fct\n   <chr>  <int> <dbl>   <dbl> <fct>  \n 1 a          1  63.5    71.7 a      \n 2 a          2  82.0    71.7 a      \n 3 a          3  75.6    71.7 a      \n 4 a          4  64.8    71.7 a      \n 5 a          5  72.7    71.7 a      \n 6 a          6  74.2    71.7 a      \n 7 a          7  75.0    71.7 a      \n 8 a          8  70.3    71.7 a      \n 9 a          9  69.2    71.7 a      \n10 a         10  69.7    71.7 a      \n# … with 30 more rows\n\n\nLet’s check what the order should be - looks like c > a > d > b\n\nsim_plot_df %>% \n  distinct(grp, grp_avg) %>% \n  arrange(desc(grp_avg))\n\n# A tibble: 4 × 2\n  grp   grp_avg\n  <chr>   <dbl>\n1 c        72.7\n2 a        71.7\n3 d        71.0\n4 b        67.4\n\n\nNow, let’s confirm what are the returned levels?\n\nsim_plot_df %>% \n  pull(grp_fct) %>% \n  levels()\n\n[1] \"a\" \"b\" \"c\" \"d\"\n\n\nOur reprex returned the “wrong” values! At this point, I thought I had legitimately found a bug…but I wanted to go one step further and check the plotting. I went ahead and added back in some complexity to check myself - specifically adding a horizontal line to indicate the group average and a label of the actual numeric group average on each facet.\nSTILL WRONG!\n\nsim_plot_df %>% \n  ggplot(aes(x = series, y = val)) +\n  geom_point() +\n  geom_hline(aes(yintercept = grp_avg), color = \"red\") +\n  geom_text(aes(x = 2.5, y = 100, label = round(grp_avg, digits = 1))) +\n  facet_wrap(~grp_fct, ncol = 4) \n\n\n\n\nLast step was to confirm I could get ggplot2 to return the expected behavior of c > a > d > b. I could get the “right” behavior by adding in the fct_reorder() across the overall data inside facet_wrap().\n\nsim_plot_df %>% \n  ggplot(aes(x = series, y = val)) +\n  geom_point() +\n  geom_smooth() +\n  geom_hline(aes(yintercept = grp_avg), color = \"red\") +\n  geom_text(aes(x = 2.5, y = 100, label = round(grp_avg, digits = 1))) +\n  facet_wrap(~fct_reorder(grp_fct, val, .fun = mean, .desc = TRUE), ncol = 4) \n\n`geom_smooth()` using method = 'loess' and formula 'y ~ x'\n\n\n\n\n\nAt this point the answer stared me right in the face!\n\nI could get the “right” behavior by adding in the fct_reorder() across the overall data inside facet_wrap().\n\nEmphasis there added on “overall data”. In my group_by + mutate I was applying a factor transformation WITHIN each group so each factor was basically a factor with only 1 level (the specific group), and when combined back into the dataframe it returned an overall factor with levels simply according to the order of the rows in the data.\nHere’s a peek at the initial reprex.\n\nsim_plot_df <- sim_data %>% \n  group_by(grp) %>% \n  mutate(\n    grp_avg = mean(val, na.rm = TRUE),\n    # this should be done BEFORE grouping\n    grp_fct = fct_reorder(grp, val, .fun = mean, .desc = TRUE)\n  ) %>% \n  ungroup()\n\nand now after I’ve moved the fct_reorder() ahead of the group_by().\n\nsim_plot_df_fixed <- sim_data %>% \n  # fct_reorder done BEFORE grouping\n  mutate(grp_fct = fct_reorder(grp, val, .fun = mean, .desc = TRUE)) %>% \n  group_by(grp) %>% \n  mutate(\n    grp_avg = mean(val, na.rm = TRUE)\n  ) %>% \n  ungroup()\n\nsim_plot_df_fixed %>% \n  ggplot(aes(x = series, y = val)) +\n  geom_point() +\n  geom_hline(aes(yintercept = grp_avg), color = \"red\") +\n  geom_text(aes(x = 2.5, y = 100, label = round(grp_avg, digits = 1))) +\n  facet_wrap(~fct_reorder(grp_fct, val, .fun = mean, .desc = TRUE), ncol = 4) \n\n\n\n\nBy breaking the problem down into the simplest version of itself, and carefully checking my assumptions as I went, I was able to get at the root of the problem.\nIn essence by preparing the reprex in preparation of asking for help, I was able to solve the problem.\nIn the words of Jenny Bryan:\n\nit’s basically the rubber duck in disguise\n\n\n\nA Giant floating yellow rubber duck in the ocean outside Hong Kong\n\n\n\nRubber duck debugging according to Wikipedia\n\nIn software engineering, rubber duck debugging is a method of debugging code. The name is a reference to a story in the book The Pragmatic Programmer in which a programmer would carry around a rubber duck and debug their code by forcing themselves to explain it, line-by-line, to the duck.\n\n\nSo go out, create your reprex, solve some of your own problems, and submit even better bug reports!\n\n\n\n\n\n\nExpand for Session Info\n\n\n\n\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.0 (2022-04-22)\n os       macOS Monterey 12.2.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       America/Chicago\n date     2022-04-28\n pandoc   2.18 @ /Applications/RStudio.app/Contents/MacOS/quarto/bin/tools/ (via rmarkdown)\n quarto   0.9.294 @ /usr/local/bin/quarto\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version date (UTC) lib source\n dplyr       * 1.0.8   2022-02-08 [1] CRAN (R 4.2.0)\n espnscrapeR * 0.6.5   2022-04-26 [1] Github (jthomasmock/espnscrapeR@084ce80)\n forcats     * 0.5.1   2021-01-27 [1] CRAN (R 4.2.0)\n ggplot2     * 3.3.5   2021-06-25 [1] CRAN (R 4.2.0)\n purrr       * 0.3.4   2020-04-17 [1] CRAN (R 4.2.0)\n readr       * 2.1.2   2022-01-30 [1] CRAN (R 4.2.0)\n sessioninfo * 1.2.2   2021-12-06 [1] CRAN (R 4.2.0)\n slider      * 0.2.2   2021-07-01 [1] CRAN (R 4.2.0)\n stringr     * 1.4.0   2019-02-10 [1] CRAN (R 4.2.0)\n tibble      * 3.1.6   2021-11-07 [1] CRAN (R 4.2.0)\n tidyr       * 1.2.0   2022-02-01 [1] CRAN (R 4.2.0)\n tidyverse   * 1.3.1   2021-04-15 [1] CRAN (R 4.2.0)\n\n [1] /Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/library\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "posts/2020-05-01-tidy-long-models/index.html",
    "href": "posts/2020-05-01-tidy-long-models/index.html",
    "title": "Flipping tibbles for many models",
    "section": "",
    "text": "The tidymodels package advocates for a nest-map-unnest workflow for running many models at once. While this typically is used for some type of group as seen in the tidymodels docs, we can also do it for running many models at once from a wide dataset.\nOur goal is to get all of the measures into a long form tibble so that we can fit all of the models at once, and plot it all at once.\n\nThis basic example is borrowed directly from the tidymodels docs.\nFirst you nest the data by a grouping variable to get list-columns of each split data/tibble.\n\nmtcars <- as_tibble(mtcars)  # to play nicely with list-cols\n\nnest_mtcars <- mtcars %>%\n  nest(data = c(-am)) \n\nnest_mtcars\n\n# A tibble: 2 × 2\n     am data              \n  <dbl> <list>            \n1     1 <tibble [13 × 10]>\n2     0 <tibble [19 × 10]>\n\n\nNow you can apply a lm() call w/ purrr::map() to each dataset, and then broom::tidy() the model output!\n\nnest_mtcars %>% \n  mutate(\n    fit = map(data, ~ lm(wt ~ mpg + qsec + gear, data = .x)),  # S3 list-col\n    tidied = map(fit, tidy)\n  ) %>% \n  unnest(tidied) %>% \n  select(-data, -fit)\n\n# A tibble: 8 × 6\n     am term        estimate std.error statistic  p.value\n  <dbl> <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1     1 (Intercept)   4.28      3.46      1.24   0.247   \n2     1 mpg          -0.101     0.0294   -3.43   0.00750 \n3     1 qsec          0.0398    0.151     0.264  0.798   \n4     1 gear         -0.0229    0.349    -0.0656 0.949   \n5     0 (Intercept)   4.92      1.40      3.52   0.00309 \n6     0 mpg          -0.192     0.0443   -4.33   0.000591\n7     0 qsec          0.0919    0.0983    0.935  0.365   \n8     0 gear          0.147     0.368     0.398  0.696   \n\n\nNow each of the model metrics for automatic vs manual transmissions (0 vs 1) is easy to work with! We’ll use a similar approach (nest-map-unnest) albeit with a slightly different data structure for our following analysis."
  },
  {
    "objectID": "posts/2020-05-01-tidy-long-models/index.html#pivot-the-data-longer",
    "href": "posts/2020-05-01-tidy-long-models/index.html#pivot-the-data-longer",
    "title": "Flipping tibbles for many models",
    "section": "Pivot the data longer",
    "text": "Pivot the data longer\nBecause we are looking to run all the models at once, we’ll need to take the data structure from wide to longer, so we can nest() the datasets by metric and run the model on each metric pair. By pivoting to long format we get our team-level data by season and metric with the corresponding value of each season.\n\nlong_off_stats <- all_off %>% \n  select(team, pass_att:sacks, season,-pass_long, -pass_comp) %>% \n  mutate(season2 = season + 1) %>% \n  pivot_longer(\n    cols = c(-team, -season, -season2), \n    names_to = \"metric\", \n    values_to = \"value\")\n\nlong_off_stats\n\n# A tibble: 7,512 × 5\n   team             season season2 metric            value\n   <chr>             <int>   <dbl> <chr>             <dbl>\n 1 RedskinsRedskins   2000    2001 pass_att        561    \n 2 RedskinsRedskins   2000    2001 pass_comp_pct     0.611\n 3 RedskinsRedskins   2000    2001 yds_att           6.9  \n 4 RedskinsRedskins   2000    2001 pass_yds       3892    \n 5 RedskinsRedskins   2000    2001 pass_td          18    \n 6 RedskinsRedskins   2000    2001 int              21    \n 7 RedskinsRedskins   2000    2001 pass_rating      77    \n 8 RedskinsRedskins   2000    2001 first_downs     185    \n 9 RedskinsRedskins   2000    2001 pass_first_pct    0.33 \n10 RedskinsRedskins   2000    2001 pass_20plus      43    \n# … with 7,502 more rows"
  },
  {
    "objectID": "posts/2020-05-01-tidy-long-models/index.html#join-the-data",
    "href": "posts/2020-05-01-tidy-long-models/index.html#join-the-data",
    "title": "Flipping tibbles for many models",
    "section": "Join the data",
    "text": "Join the data\nNext we need to join the data back into itself to get the matched value 1 (year) with value 2 (year + 1). The join renames value on the left-hand side (value.x) and the right-hand side (value.y). Technically we don’t need season or season 2 anymore, but I’ve kept them so we can do a quick visual check on the data. The numbers look good and are aligned properly!\n\njoin_years <- long_off_stats %>% \n    inner_join(long_off_stats, by = c(\"season2\" = \"season\", \"team\", \"metric\")) %>% \n    select(everything(), -season2.y)\n\njoin_years\n\n# A tibble: 7,116 × 6\n   team             season season2 metric          value.x  value.y\n   <chr>             <int>   <dbl> <chr>             <dbl>    <dbl>\n 1 RedskinsRedskins   2000    2001 pass_att        561      432    \n 2 RedskinsRedskins   2000    2001 pass_comp_pct     0.611    0.544\n 3 RedskinsRedskins   2000    2001 yds_att           6.9      6.3  \n 4 RedskinsRedskins   2000    2001 pass_yds       3892     2716    \n 5 RedskinsRedskins   2000    2001 pass_td          18       13    \n 6 RedskinsRedskins   2000    2001 int              21       13    \n 7 RedskinsRedskins   2000    2001 pass_rating      77       71.1  \n 8 RedskinsRedskins   2000    2001 first_downs     185      122    \n 9 RedskinsRedskins   2000    2001 pass_first_pct    0.33     0.282\n10 RedskinsRedskins   2000    2001 pass_20plus      43       31    \n# … with 7,106 more rows"
  },
  {
    "objectID": "posts/2020-05-01-tidy-long-models/index.html#nest-the-data",
    "href": "posts/2020-05-01-tidy-long-models/index.html#nest-the-data",
    "title": "Flipping tibbles for many models",
    "section": "Nest the Data",
    "text": "Nest the Data\nWe now need to nest the data, leaving metric out so that it is used as the group/label data. Now each of the metrics are separated into their own respective nested datasets!\n\nnest_off_data <- join_years %>% \n    nest(data = c(-metric))\n\nnest_off_data \n\n# A tibble: 12 × 2\n   metric         data              \n   <chr>          <list>            \n 1 pass_att       <tibble [593 × 5]>\n 2 pass_comp_pct  <tibble [593 × 5]>\n 3 yds_att        <tibble [593 × 5]>\n 4 pass_yds       <tibble [593 × 5]>\n 5 pass_td        <tibble [593 × 5]>\n 6 int            <tibble [593 × 5]>\n 7 pass_rating    <tibble [593 × 5]>\n 8 first_downs    <tibble [593 × 5]>\n 9 pass_first_pct <tibble [593 × 5]>\n10 pass_20plus    <tibble [593 × 5]>\n11 pass_40plus    <tibble [593 × 5]>\n12 sacks          <tibble [593 × 5]>"
  },
  {
    "objectID": "posts/2020-05-01-tidy-long-models/index.html#fit-the-models",
    "href": "posts/2020-05-01-tidy-long-models/index.html#fit-the-models",
    "title": "Flipping tibbles for many models",
    "section": "Fit the models",
    "text": "Fit the models\nNow let’s fit the models and tidy the outputs with broom::glance(). We now have the raw fit and the tidy output as list-column tibbles! We’re really just interested in r.squared for this example, so we’ll unnest() the data in the next step to get that out by metric.\n\ntidy_off_models <- nest_off_data %>% \n    mutate(\n      fit = map(data, ~ lm(value.y ~ value.x, data = .x)),\n      tidy_output = map(fit, glance)\n    )\n\ntidy_off_models\n\n# A tibble: 12 × 4\n   metric         data               fit    tidy_output      \n   <chr>          <list>             <list> <list>           \n 1 pass_att       <tibble [593 × 5]> <lm>   <tibble [1 × 12]>\n 2 pass_comp_pct  <tibble [593 × 5]> <lm>   <tibble [1 × 12]>\n 3 yds_att        <tibble [593 × 5]> <lm>   <tibble [1 × 12]>\n 4 pass_yds       <tibble [593 × 5]> <lm>   <tibble [1 × 12]>\n 5 pass_td        <tibble [593 × 5]> <lm>   <tibble [1 × 12]>\n 6 int            <tibble [593 × 5]> <lm>   <tibble [1 × 12]>\n 7 pass_rating    <tibble [593 × 5]> <lm>   <tibble [1 × 12]>\n 8 first_downs    <tibble [593 × 5]> <lm>   <tibble [1 × 12]>\n 9 pass_first_pct <tibble [593 × 5]> <lm>   <tibble [1 × 12]>\n10 pass_20plus    <tibble [593 × 5]> <lm>   <tibble [1 × 12]>\n11 pass_40plus    <tibble [593 × 5]> <lm>   <tibble [1 × 12]>\n12 sacks          <tibble [593 × 5]> <lm>   <tibble [1 × 12]>"
  },
  {
    "objectID": "posts/2020-05-01-tidy-long-models/index.html#unnest-the-model-metrics",
    "href": "posts/2020-05-01-tidy-long-models/index.html#unnest-the-model-metrics",
    "title": "Flipping tibbles for many models",
    "section": "Unnest the model metrics",
    "text": "Unnest the model metrics\nNow we have a few options - we can use unnest_wider() to get ALL the model metrics, but again that’s overkill for our example.\n\ntidy_off_models %>% \n    unnest_wider(tidy_output)\n\n# A tibble: 12 × 15\n   metric      data     fit   r.squared adj.r.squared   sigma statistic  p.value\n   <chr>       <list>   <lis>     <dbl>         <dbl>   <dbl>     <dbl>    <dbl>\n 1 pass_att    <tibble> <lm>     0.181         0.180  5.36e+1     131.  1.85e-27\n 2 pass_comp_… <tibble> <lm>     0.290         0.289  3.59e-2     242.  5.93e-46\n 3 yds_att     <tibble> <lm>     0.176         0.175  6.65e-1     127.  9.69e-27\n 4 pass_yds    <tibble> <lm>     0.306         0.305  4.93e+2     261.  7.20e-49\n 5 pass_td     <tibble> <lm>     0.180         0.178  6.63e+0     130.  2.77e-27\n 6 int         <tibble> <lm>     0.0623        0.0607 4.81e+0      39.3 7.06e-10\n 7 pass_rating <tibble> <lm>     0.233         0.232  1.04e+1     179.  6.61e-36\n 8 first_downs <tibble> <lm>     0.308         0.307  2.55e+1     263.  3.50e-49\n 9 pass_first… <tibble> <lm>     0.225         0.224  3.31e-2     172.  1.23e-34\n10 pass_20plus <tibble> <lm>     0.133         0.131  9.92e+0      90.3 5.03e-20\n11 pass_40plus <tibble> <lm>     0.0518        0.0502 3.51e+0      32.3 2.10e- 8\n12 sacks       <tibble> <lm>     0.121         0.119  1.01e+1      81.1 2.98e-18\n# … with 7 more variables: df <dbl>, logLik <dbl>, AIC <dbl>, BIC <dbl>,\n#   deviance <dbl>, df.residual <int>, nobs <int>\n\n\nInstead we’ll use tidyr::hoist() which pulls specific columns from nested data. In this case, we are extracting just the r.squared values for each respective metric and then arranging by r.squared. Full details of unnest vs hoist can be found at tidyr site.\n\noff_lm_output <- tidy_off_models %>% \n    hoist(tidy_output, r.squared = \"r.squared\") %>% \n    arrange(desc(r.squared))\n\noff_lm_output\n\n# A tibble: 12 × 5\n   metric         data               fit    r.squared tidy_output      \n   <chr>          <list>             <list>     <dbl> <list>           \n 1 first_downs    <tibble [593 × 5]> <lm>      0.308  <tibble [1 × 11]>\n 2 pass_yds       <tibble [593 × 5]> <lm>      0.306  <tibble [1 × 11]>\n 3 pass_comp_pct  <tibble [593 × 5]> <lm>      0.290  <tibble [1 × 11]>\n 4 pass_rating    <tibble [593 × 5]> <lm>      0.233  <tibble [1 × 11]>\n 5 pass_first_pct <tibble [593 × 5]> <lm>      0.225  <tibble [1 × 11]>\n 6 pass_att       <tibble [593 × 5]> <lm>      0.181  <tibble [1 × 11]>\n 7 pass_td        <tibble [593 × 5]> <lm>      0.180  <tibble [1 × 11]>\n 8 yds_att        <tibble [593 × 5]> <lm>      0.176  <tibble [1 × 11]>\n 9 pass_20plus    <tibble [593 × 5]> <lm>      0.133  <tibble [1 × 11]>\n10 sacks          <tibble [593 × 5]> <lm>      0.121  <tibble [1 × 11]>\n11 int            <tibble [593 × 5]> <lm>      0.0623 <tibble [1 × 11]>\n12 pass_40plus    <tibble [593 × 5]> <lm>      0.0518 <tibble [1 × 11]>\n\n\nGet just the good bits\nSo we just want the r.squared and metric values, plus a label we can use for ggplot down the road. Boom we have the final output!\n\noff_stability <- off_lm_output %>% \n  select(metric, r.squared) %>% \n  mutate(metric_label = glue::glue(\"{metric} (R^2 = {round(r.squared, 3)})\"))\n\noff_stability\n\n# A tibble: 12 × 3\n   metric         r.squared metric_label                \n   <chr>              <dbl> <glue>                      \n 1 first_downs       0.308  first_downs (R^2 = 0.308)   \n 2 pass_yds          0.306  pass_yds (R^2 = 0.306)      \n 3 pass_comp_pct     0.290  pass_comp_pct (R^2 = 0.29)  \n 4 pass_rating       0.233  pass_rating (R^2 = 0.233)   \n 5 pass_first_pct    0.225  pass_first_pct (R^2 = 0.225)\n 6 pass_att          0.181  pass_att (R^2 = 0.181)      \n 7 pass_td           0.180  pass_td (R^2 = 0.18)        \n 8 yds_att           0.176  yds_att (R^2 = 0.176)       \n 9 pass_20plus       0.133  pass_20plus (R^2 = 0.133)   \n10 sacks             0.121  sacks (R^2 = 0.121)         \n11 int               0.0623 int (R^2 = 0.062)           \n12 pass_40plus       0.0518 pass_40plus (R^2 = 0.052)"
  },
  {
    "objectID": "posts/2020-10-31-embedding-custom-features-in-gt-tables/index.html",
    "href": "posts/2020-10-31-embedding-custom-features-in-gt-tables/index.html",
    "title": "Embedding custom HTML in gt tables",
    "section": "",
    "text": "More HTML!\nSo that’s cool to see where things can be changed, but let’s walk through a bit more engaging example. Here we’re going to merge some columns for the Player’s last name + team.\n\nex_tab <- nfl_qbr %>% \n  select(rank, name_last, team, qbr_total, qb_plays, pass, run) %>% \n  gt() \n\nex_tab %>%\n  cols_merge(\n    columns = vars(name_last, team)\n  )\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\nrank\n      name_last\n      qbr_total\n      qb_plays\n      pass\n      run\n    \n\n\n1\nRodgers Packers\n79.8\n608\n98.4\n9.3\n\n\n2\nMahomes Chiefs\n78.1\n710\n116.1\n19.1\n\n\n3\nAllen Bills\n76.6\n729\n112.1\n13.0\n\n\n4\nTannehill Titans\n72.6\n594\n68.2\n22.1\n\n\n5\nFitzpatrick Dolphins\n70.9\n324\n41.6\n5.6\n\n\n6\nBrees Saints\n68.3\n428\n62.5\n1.0\n\n\n7\nJackson Ravens\n67.3\n585\n50.9\n30.8\n\n\n8\nWilson Seahawks\n67.1\n716\n88.6\n9.1\n\n\n9\nBrady Buccaneers\n66.0\n681\n90.4\n-3.1\n\n\n10\nMayfield Browns\n65.5\n597\n76.9\n3.3\n\n\n\n\n\n\nThis saves us some space since we’re dropping a column, but isn’t the prettiest thing. Let’s use an anonymous function and text_transform to change the styling of our player’s name/team with <span style> along with small caps, different font colors and sizes.\n\nex_tab %>%\n  cols_merge(\n    columns = vars(name_last, team)\n  ) %>% \n  text_transform(\n    locations = cells_body(\n      columns = vars(name_last)\n    ),\n    fn = function(x){\n      name <- word(x, 1)\n      team <- word(x, -1)\n      glue::glue(\n        \"<div><span style='font-weight:bold;font-variant:small-caps;font-size:14px'>{name}</div>\n        <div><span style ='font-weight:bold;color:grey;font-size:10px'>{team}</span></div>\"\n      )\n    }\n  )\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\nrank\n      name_last\n      qbr_total\n      qb_plays\n      pass\n      run\n    \n\n\n1\n\nRodgers\nPackers\n\n79.8\n608\n98.4\n9.3\n\n\n2\n\nMahomes\nChiefs\n\n78.1\n710\n116.1\n19.1\n\n\n3\n\nAllen\nBills\n\n76.6\n729\n112.1\n13.0\n\n\n4\n\nTannehill\nTitans\n\n72.6\n594\n68.2\n22.1\n\n\n5\n\nFitzpatrick\nDolphins\n\n70.9\n324\n41.6\n5.6\n\n\n6\n\nBrees\nSaints\n\n68.3\n428\n62.5\n1.0\n\n\n7\n\nJackson\nRavens\n\n67.3\n585\n50.9\n30.8\n\n\n8\n\nWilson\nSeahawks\n\n67.1\n716\n88.6\n9.1\n\n\n9\n\nBrady\nBuccaneers\n\n66.0\n681\n90.4\n-3.1\n\n\n10\n\nMayfield\nBrowns\n\n65.5\n597\n76.9\n3.3\n\n\n\n\n\n\nThis is starting to look better! However, since we stacked it, the rows are very tall, a bit too tall in my opinion. We can use line-height inside the <div> now to decrease the vertical space between our words.\n\nex_tab %>%\n  cols_merge(\n    columns = vars(name_last, team)\n  ) %>% \n  text_transform(\n    locations = cells_body(\n      columns = vars(name_last)\n    ),\n    fn = function(x){\n      name <- word(x, 1)\n      team <- word(x, -1)\n      glue::glue(\n        \"<div style='line-height:10px'><span style='font-weight:bold;font-variant:small-caps;font-size:14px'>{name}</div>\n        <div style='line-height:12px'><span style ='font-weight:bold;color:grey;font-size:10px'>{team}</span></div>\"\n      )\n    }\n  ) %>% \n  tab_options(\n    data_row.padding = px(5),\n  )\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\nrank\n      name_last\n      qbr_total\n      qb_plays\n      pass\n      run\n    \n\n\n1\n\nRodgers\nPackers\n\n79.8\n608\n98.4\n9.3\n\n\n2\n\nMahomes\nChiefs\n\n78.1\n710\n116.1\n19.1\n\n\n3\n\nAllen\nBills\n\n76.6\n729\n112.1\n13.0\n\n\n4\n\nTannehill\nTitans\n\n72.6\n594\n68.2\n22.1\n\n\n5\n\nFitzpatrick\nDolphins\n\n70.9\n324\n41.6\n5.6\n\n\n6\n\nBrees\nSaints\n\n68.3\n428\n62.5\n1.0\n\n\n7\n\nJackson\nRavens\n\n67.3\n585\n50.9\n30.8\n\n\n8\n\nWilson\nSeahawks\n\n67.1\n716\n88.6\n9.1\n\n\n9\n\nBrady\nBuccaneers\n\n66.0\n681\n90.4\n-3.1\n\n\n10\n\nMayfield\nBrowns\n\n65.5\n597\n76.9\n3.3\n\n\n\n\n\n\nWhile we did that ALL within gt, we could also have made similar changes by writing some HTML with functions inside mutate ahead of sending it to gt!\n\n# function to incorporate player name + team\ncombine_word <- function(name, team){\n      glue::glue(\n        \"<div style='line-height:10px'><span style='font-weight:bold;font-variant:small-caps;font-size:14px'>{name}</div>\n        <div style='line-height:12px'><span style ='font-weight:bold;color:grey;font-size:10px'>{team}</span></div>\"\n      )\n    }\n\nnfl_qbr %>% \n  select(rank, name_short, team, qbr_total, qb_plays, pass, run) %>% \n  mutate(\n    combo = combine_word(name_short, team),\n    combo = map(combo, gt::html)\n    ) %>% \n  select(rank, combo, everything(), -name_short, -team) %>% \n  gt() %>% \n  cols_align(\n    align = \"left\",\n    columns = vars(combo)\n  ) %>% \n  tab_options(\n    data_row.padding = px(5)\n  )\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\nrank\n      combo\n      qbr_total\n      qb_plays\n      pass\n      run\n    \n\n\n1\n\nA. Rodgers\nPackers\n\n79.8\n608\n98.4\n9.3\n\n\n2\n\nP. Mahomes\nChiefs\n\n78.1\n710\n116.1\n19.1\n\n\n3\n\nJ. Allen\nBills\n\n76.6\n729\n112.1\n13.0\n\n\n4\n\nR. Tannehill\nTitans\n\n72.6\n594\n68.2\n22.1\n\n\n5\n\nR. Fitzpatrick\nDolphins\n\n70.9\n324\n41.6\n5.6\n\n\n6\n\nD. Brees\nSaints\n\n68.3\n428\n62.5\n1.0\n\n\n7\n\nL. Jackson\nRavens\n\n67.3\n585\n50.9\n30.8\n\n\n8\n\nR. Wilson\nSeahawks\n\n67.1\n716\n88.6\n9.1\n\n\n9\n\nT. Brady\nBuccaneers\n\n66.0\n681\n90.4\n-3.1\n\n\n10\n\nB. Mayfield\nBrowns\n\n65.5\n597\n76.9\n3.3\n\n\n\n\n\n\nSo that’s really cool and allows you to do some creative things with HTML-based content. What else can we do with HTML?\n\nkableExtra integration\nThe fantastic kableExtra package has some sparkline-esque graphing capabilities that export as SVG, meaning they can be integrated into HTML.\nNote that while I love gt, kableExtra is again a great package in it’s own right and has more mature LaTeX integration today. If you REALLY have to use PDF/LaTex, it’s a great choice today.\nkableExtra approaches inline plots with the spec_plot() family of functions.\n\nkableExtra example\nHere’s a quick example from kableExtra, which can be adapted to work in gt, mainly incorporating an inline boxplot into the table.\n\nlibrary(kableExtra)\nlibrary(gt)\nlibrary(tidyverse)\n\nkableExtra method, adapted from the great guide by Hao Zhu.\n\n# first split the data by cylinders\nmpg_list <- split(mtcars$mpg, mtcars$cyl)\n\nmpg_list\n\n$`4`\n [1] 22.8 24.4 22.8 32.4 30.4 33.9 21.5 27.3 26.0 30.4 21.4\n\n$`6`\n[1] 21.0 21.0 21.4 18.1 19.2 17.8 19.7\n\n$`8`\n [1] 18.7 14.3 16.4 17.3 15.2 10.4 10.4 14.7 15.5 15.2 13.3 19.2 15.8 15.0\n\n# pipe the \ndata.frame(\n  cyl = c(4,6,8),\n  boxplot = \"\"\n  ) %>% \n  kbl(booktabs = TRUE) %>%\n  kable_paper(full_width = FALSE) %>%\n  column_spec(2, image = spec_boxplot(mpg_list, width = 300, height = 70))\n\n\n\n\n cyl \n    boxplot \n  \n\n\n 4 \n     \n\n  \n\n 6 \n     \n\n  \n\n 8 \n     \n\n  \n\n\n\n\n\ngt + kableExtra\n\nWe can adapt a similar idea for gt, here we are using mutate calls ahead of time to prep the data. Here we are going to keep all the data in a pipe, rather than having to split it and reference a dataset external to our table. We can essentially nest the same mpg column by group, keeping it in a single tibble this time. As an aside, note that you can embed ANY ggplot into gt with gt::ggplot_image(), but the ggplot_image() method is quite a bit slower as of today. If you need the full power of ggplot it’s totally worth it, but if you’re just adding sparklines I’m a big fan of kableExtra::spec_plot().\n\nmtcars %>% \n  group_by(cyl) %>% \n  summarize(data = list(mpg), .groups = \"drop\")\n\n# A tibble: 3 × 2\n    cyl data      \n  <dbl> <list>    \n1     4 <dbl [11]>\n2     6 <dbl [7]> \n3     8 <dbl [14]>\n\n\nThen we can create a range to set baselines for MPG, and then use kableExtra::spec_plot() to embed an inline sparkline. Note we have to use purrr::map() here to apply the function iteratively across each row.\n\nmpg_rng <- range(mtcars$mpg)\n\nmtcars %>% \n  group_by(cyl) %>% \n  summarize(data = list(mpg), .groups = \"drop\") %>% \n  mutate(\n    plot = map(data, ~spec_plot(.x, ylim = mpg_rng, same_lim = TRUE, width = 300, height = 70)),\n    plot = map(plot, \"svg_text\"),\n    plot = map(plot, gt::html)\n    ) %>% \n  select(-data) %>% \n  gt()\n\n\n\n\n\n\ncyl\n      plot\n    \n\n\n4\n\n\n\n\n\n6\n\n\n\n\n\n8\n\n\n\n\n\n\n\n\n\nNow that I’ve showed that it’s possible, what are we actually doing? kableExtra::spec_plot() creates a plot in base R, and then returns it as either svg or pdf, which means it can be compatible with either HTML or LaTeX. Remember the mpg_list we created by splitting the mpg column into a list of vectors by cyl?\n\nmpg_list %>% str()\n\nList of 3\n $ 4: num [1:11] 22.8 24.4 22.8 32.4 30.4 33.9 21.5 27.3 26 30.4 ...\n $ 6: num [1:7] 21 21 21.4 18.1 19.2 17.8 19.7\n $ 8: num [1:14] 18.7 14.3 16.4 17.3 15.2 10.4 10.4 14.7 15.5 15.2 ...\n\n\nWe can create plots for each cyl and then pull the cyl == 4 plot and look at it’s structure.\n\nspec_plot(mpg_list) %>% \n  pluck(\"4\") %>% \n  str()\n\nList of 7\n $ path    : chr(0) \n $ dev     : chr \"svg\"\n $ type    : chr \"line\"\n $ width   : num 200\n $ height  : num 50\n $ res     : num 300\n $ svg_text: chr \"<?xml version=\\\"1.0\\\" encoding=\\\"UTF-8\\\"?>\\n<svg xmlns=\\\"http://www.w3.org/2000/svg\\\" xmlns:xlink=\\\"http://www.\"| __truncated__\n - attr(*, \"class\")= chr [1:2] \"kableExtraInlinePlots\" \"list\"\n\n\nWe see that it returns a list object, with mostly metadata about what parameters were passed to the function. The part we really want is the svg_text since that has the xml code to generate our inline plot. We can pull out the svg_text list item from our list of lists by calling map(\"svg_text\"). Now we can see each of the svg-plots, one for each cylinder group!\n\nspec_plot(mpg_list) %>% \n  map(\"svg_text\") %>% \n  str()\n\nList of 3\n $ 4: chr \"<?xml version=\\\"1.0\\\" encoding=\\\"UTF-8\\\"?>\\n<svg xmlns=\\\"http://www.w3.org/2000/svg\\\" xmlns:xlink=\\\"http://www.\"| __truncated__\n $ 6: chr \"<?xml version=\\\"1.0\\\" encoding=\\\"UTF-8\\\"?>\\n<svg xmlns=\\\"http://www.w3.org/2000/svg\\\" xmlns:xlink=\\\"http://www.\"| __truncated__\n $ 8: chr \"<?xml version=\\\"1.0\\\" encoding=\\\"UTF-8\\\"?>\\n<svg xmlns=\\\"http://www.w3.org/2000/svg\\\" xmlns:xlink=\\\"http://www.\"| __truncated__\n\n\nSo now that we have the specific item of interest we need to let gt “know” to treat this as HTML and not just a random character string. We can call map() one more time and apply the gt::html() function to each svg plot.\n\nspec_plot(mpg_list) %>% \n  map(\"svg_text\") %>% \n  map(gt::html) %>% \n  str()\n\nList of 3\n $ 4: 'html' chr \"<?xml version=\\\"1.0\\\" encoding=\\\"UTF-8\\\"?>\\n<svg xmlns=\\\"http://www.w3.org/2000/svg\\\" xmlns:xlink=\\\"http://www.\"| __truncated__\n  ..- attr(*, \"html\")= logi TRUE\n $ 6: 'html' chr \"<?xml version=\\\"1.0\\\" encoding=\\\"UTF-8\\\"?>\\n<svg xmlns=\\\"http://www.w3.org/2000/svg\\\" xmlns:xlink=\\\"http://www.\"| __truncated__\n  ..- attr(*, \"html\")= logi TRUE\n $ 8: 'html' chr \"<?xml version=\\\"1.0\\\" encoding=\\\"UTF-8\\\"?>\\n<svg xmlns=\\\"http://www.w3.org/2000/svg\\\" xmlns:xlink=\\\"http://www.\"| __truncated__\n  ..- attr(*, \"html\")= logi TRUE\n\n\nAnd that’s why the following code works:\n- Group by cylinder\n- Summarize down to a list-column of the respective MPG column by cylinder\n- Create the spec_plot object\n- Extract the svg_text\n- Recognize the svg_text as HTML\n- gt takes the HTML and parses it\n\nmtcars %>% \n  group_by(cyl) %>% \n  summarize(data = list(mpg), .groups = \"drop\") %>% \n  mutate(\n    plot = map(data, ~spec_plot(.x, ylim = mpg_rng, same_lim = TRUE, width = 300, height = 70)),\n    plot = map(plot, \"svg_text\"),\n    plot = map(plot, gt::html)\n    ) %>% \n  select(-data) %>% \n  gt()\n\n\n\n\n\n\ncyl\n      plot\n    \n\n\n4\n\n\n\n\n\n6\n\n\n\n\n\n8\n\n\n\n\n\n\n\n\n\nDo it all in gt\n\nWhile that works just fine, it assumes that you create the content ahead of time, before incorporating it into gt. However, you can also approach it from within gt itself.\nFor the next one, I have a more general function to use.\nThe custom function gt_plot():\n- Takes the table data from gt\n- You specify a specific column\n- You specify external data to plot\n- Specify what type of plot\n- Optionally pass additional arguments to spec_plot with ...\n\ngt_plot <- function(table_data, column, plot_data, plot_fun, ...){\n  text_transform(\n    table_data,\n    # note the use of {{}} here - this is tidy eval\n    # that allows you to indicate specific columns\n    locations = cells_body(columns = vars({{column}})),\n    fn = function(x){\n      plot <- map(plot_data, plot_fun, width = 300, height = 70, same_lim = TRUE, ...)\n      plot_svg <- map(plot, \"svg_text\")\n      map(plot_svg, gt::html)\n    }\n  )\n}\n\nNote that again, my table “data” is pretty minimal, and I’ve got the data externally as our mpg_list object we created earlier.\n\nmpg_list %>% str()\n\nList of 3\n $ 4: num [1:11] 22.8 24.4 22.8 32.4 30.4 33.9 21.5 27.3 26 30.4 ...\n $ 6: num [1:7] 21 21 21.4 18.1 19.2 17.8 19.7\n $ 8: num [1:14] 18.7 14.3 16.4 17.3 15.2 10.4 10.4 14.7 15.5 15.2 ...\n\n\n\ntibble(cyl = c(4,6,8), boxplot = \"\") %>% \n  gt() %>% \n  gt_plot(\n    column = boxplot,  # column to create plot in \n    plot_data = mpg_list, # external data to reference\n    plot_fun = spec_boxplot,  # which plot fun\n    lim = mpg_rng # range applied\n    )\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\ncyl\n      boxplot\n    \n\n\n4\n\n\n\n\n\n6\n\n\n\n\n\n8\n\n\n\n\n\n\n\n\n\nWe can quickly switch from a boxplot to a sparkline, just by changing the plot_fun argument to spec_plot. Also since I passed ellipses (...) to the spec_plot() function we can also use some additional arguments to change the line-color to black, and make the max/min points to be a bit larger.\n\ntibble(cyl = c(4,6,8), boxplot = \"\") %>% \n  gt() %>% \n  gt_plot(\n    column = boxplot,  # column to create plot in \n    plot_data = mpg_list, # external data to reference\n    plot_fun = spec_plot,  # which plot fun\n    ylim = mpg_rng, # range applied,\n    col = \"black\", # change color of line\n    cex = 5 # change size of points\n    )\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\ncyl\n      boxplot\n    \n\n\n4\n\n\n\n\n\n6\n\n\n\n\n\n8\n\n\n\n\n\n\n\n\n\nThis works with all the kableExtra inline plot functions! Note that we are just varying the ylim on the line/points 1 vs 2, where the mpg_line1/mpg_points1 share a common y-axis, and line2/points2 have their own y-axis.\n\ntibble(\n  cyl = c(4,6,8), \n  boxplot = \"\", mpg_hist = \"\", mpg_line1 = \"\", \n  mpg_line2 = \"\", mpg_points1 = \"\", \n  mpg_points2 = \"\", mpg_poly = \"\"\n  ) %>% \n  gt() %>% \n  gt_plot(column = boxplot, plot_data = mpg_list, plot_fun = spec_boxplot, lim = mpg_rng) %>% \n  gt_plot(column = mpg_hist, plot_data = mpg_list, plot_fun = spec_hist, lim = mpg_rng) %>% \n  gt_plot(column = mpg_line1, plot_data = mpg_list, plot_fun = spec_plot, ylim = mpg_rng) %>% \n  gt_plot(column = mpg_line2, plot_data = mpg_list, plot_fun = spec_plot) %>% \n  gt_plot(column = mpg_points1, plot_data = mpg_list, plot_fun = spec_plot, type = \"p\", ylim = mpg_rng, cex = 4) %>% \n  gt_plot(column = mpg_points2, plot_data = mpg_list, plot_fun = spec_plot, type = \"p\", cex = 4) %>% \n  gt_plot(column = mpg_poly, plot_data = mpg_list, plot_fun = spec_plot, polymin = 5, ylim = mpg_rng)\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\ncyl\n      boxplot\n      mpg_hist\n      mpg_line1\n      mpg_line2\n      mpg_points1\n      mpg_points2\n      mpg_poly\n    \n\n\n4\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n6\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n8\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUse a single source of data\nOK so we now have a function, but we’re referencing an external data object, rather than data within the “table” itself - not ideal!\nCan we just use our group_by + summarize as list from before without any changes? (Spoiler = nope)\n\n# doesn't work\nmtcars %>% \n  group_by(cyl) %>% \n  summarize(data = list(mpg), .groups = \"drop\") %>% \n  gt() %>% \n  text_transform(\n    locations = cells_body(columns = vars(data)),\n    fn = function(x){\n    plot = map(x, ~spec_plot(.x, ylim = mpg_rng, same_lim = TRUE, width = 300, height = 70))\n    plot = map(plot, \"svg_text\")\n    plot = map(plot, gt::html)\n    }\n  ) \n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\nWarning in xy.coords(x, y, xlabel, ylabel, log): NAs introduced by coercion\n\n\nWarning in which.min(y): NAs introduced by coercion\n\n\nWarning in which.max(y): NAs introduced by coercion\n\n\nWarning in xy.coords(x, y, xlabel, ylabel, log): NAs introduced by coercion\n\n\nWarning in which.min(y): NAs introduced by coercion\n\n\nWarning in which.max(y): NAs introduced by coercion\n\n\nWarning in xy.coords(x, y, xlabel, ylabel, log): NAs introduced by coercion\n\n\nWarning in which.min(y): NAs introduced by coercion\n\n\nWarning in which.max(y): NAs introduced by coercion\n\n\n\n\n\n\n\ncyl\n      data\n    \n\n\n4\n\n\n\n\n\n6\n\n\n\n\n\n8\n\n\n\n\n\n\n\n\n\nNope - but it does give us a decent error message!\n1: In xy.coords(x, y, xlabel, ylabel, log) : NAs introduced by coercion\n2: In which.min(y) : NAs introduced by coercion\n3: In which.max(y) : NAs introduced by coercion\nThere seems to be a type conversion - NAs are being returned where we expect numeric data to create the x-y coordinates for the plot. Let’s dive a bit closer into what happens when we call text_transform(). I’m calling str() inside our text_transform() now to expose what the data itself looks like.\n\n# doesn't work\nmtcars %>% \n  group_by(cyl) %>% \n  summarize(mpg_data = list(mpg), .groups = \"drop\") %>% \n  gt() %>% \n  text_transform(\n    locations = cells_body(columns = vars(mpg_data)),\n    fn = function(x){\n      str(x)\n    })\n\nList of 3\n $ : chr \"22.8, 24.4, 22.8, 32.4, 30.4, 33.9, 21.5, 27.3, 26.0, 30.4, 21.4\"\n $ : chr \"21.0, 21.0, 21.4, 18.1, 19.2, 17.8, 19.7\"\n $ : chr \"18.7, 14.3, 16.4, 17.3, 15.2, 10.4, 10.4, 14.7, 15.5, 15.2, 13.3, 19.2, 15.8, 15.0\"\nError: Assigned data `*vtmp*` must be compatible with existing data.\nx Existing data has 3 rows.\nx Assigned data has 0 rows.\nℹ Only vectors of size 1 are recycled.\nThis tells us something interesting! It’s combined all the vectors into a character string separated by commas. No wonder our graph can’t understand its xy coords, it is passed as one long text string!\nNow if we’re tricky, we can get at the guts of gt since it’s just a list object. There’s quite a bit there inside the gt object, but the first list item is arguably the most important! We have the raw data as _data!\n\nmtcars %>% \n  group_by(cyl) %>% \n  summarize(mpg_data = list(mpg), .groups = \"drop\") %>% \n  gt() %>% \n  str(max.level = 1)\n\nList of 16\n $ _data        : tibble [3 × 2] (S3: tbl_df/tbl/data.frame)\n $ _boxhead     : tibble [2 × 6] (S3: tbl_df/tbl/data.frame)\n $ _stub_df     : tibble [3 × 5] (S3: tbl_df/tbl/data.frame)\n $ _row_groups  : chr(0) \n $ _heading     :List of 2\n $ _spanners    : tibble [0 × 6] (S3: tbl_df/tbl/data.frame)\n $ _stubhead    :List of 1\n $ _footnotes   : tibble [0 × 7] (S3: tbl_df/tbl/data.frame)\n $ _source_notes: list()\n $ _formats     : list()\n $ _styles      : tibble [0 × 7] (S3: tbl_df/tbl/data.frame)\n $ _summary     : list()\n $ _options     : tibble [156 × 5] (S3: tbl_df/tbl/data.frame)\n $ _transforms  : list()\n $ _locale      :List of 1\n $ _has_built   : logi FALSE\n - attr(*, \"class\")= chr [1:2] \"gt_tbl\" \"list\"\n\n\nWe can pluck() the raw underlying data itself from gt, extract the mpg_data column, and could work with it in our function.\n\nmtcars %>% \n  group_by(cyl) %>% \n  summarize(mpg_data = list(as.double(mpg)), .groups = \"drop\") %>% \n  gt() %>% \n  pluck(\"_data\", \"mpg_data\") %>% \n  str()\n\nList of 3\n $ : num [1:11] 22.8 24.4 22.8 32.4 30.4 33.9 21.5 27.3 26 30.4 ...\n $ : num [1:7] 21 21 21.4 18.1 19.2 17.8 19.7\n $ : num [1:14] 18.7 14.3 16.4 17.3 15.2 10.4 10.4 14.7 15.5 15.2 ...\n\n\nSo let’s try it out! Remember, we’re using pluck() to get the dataframe from gt’s list object, and then pulling out the mpg_data column from it.\n\n# works now\nmtcars %>% \n  group_by(cyl) %>% \n  summarize(mpg_data = list(mpg), .groups = \"drop\") %>% \n  gt() %>% \n  text_transform(\n    locations = cells_body(columns = vars(mpg_data)),\n    fn = function(x){\n      data_in = pluck(., \"_data\", \"mpg_data\")\n      plot = map(data_in, ~spec_plot(.x, ylim = mpg_rng, same_lim = TRUE, width = 300, height = 70))\n      plot = map_chr(plot, \"svg_text\")\n    })\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\ncyl\n      mpg_data\n    \n\n\n4\n\n\n\n\n\n6\n\n\n\n\n\n8\n\n\n\n\n\n\n\n\n\nThat worked beautifully!\nAn alternative that doesn’t require going into the gt object itself and coerces the character string back into numeric. This is a bit clunkier, but totally possible.\n\n# WORKS\nmtcars %>%\n  group_by(cyl) %>%\n  summarize(mpg_data = list(as.double(mpg)), .groups = \"drop\") %>%\n  gt() %>%\n  text_transform(\n    locations = cells_body(columns = vars(mpg_data)),\n    fn = function(x) {\n      # split the strings at each comma\n      split_data <- str_split(x, \", \")\n      # convert to type double\n      data <- map(split_data, as.double)\n      # create the plot\n      plot <- map(data, ~ spec_plot(.x, ylim = mpg_rng, same_lim = TRUE, width = 300, height = 70))\n      # extract the svg item\n      map(plot, \"svg_text\")\n    }\n  )\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\ncyl\n      mpg_data\n    \n\n\n4\n\n\n\n\n\n6\n\n\n\n\n\n8\n\n\n\n\n\n\n\n\n\nOk so we’ve shown that it’s possible to do that either way, so let’s rewrite our function!\n\ngt_plot <- function(table_data, plot_col, data_col, plot_fun, ...){\n  # save the data extract ahead of time \n  # to be used in our anonymous function below\n  data_in = pluck(table_data, \"_data\", data_col)\n\n  text_transform(\n    table_data,\n    # note the use of {{}} here - this is tidy eval\n    # that allows you to indicate specific columns\n    locations = cells_body(columns = vars({{plot_col}})),\n    fn = function(x){\n      plot <- map(data_in, plot_fun, width = 300, height = 70, same_lim = FALSE, ...)\n      plot_svg <- map(plot, \"svg_text\")\n      map(plot_svg, gt::html)\n    }\n  )\n}\n\nThis function will now work exactly as expected with the grouped list data columns!\n\n# works!\nmtcars %>% \n  group_by(cyl) %>% \n  summarize(mpg_data = list(mpg), .groups = \"drop\") %>% \n  gt() %>% \n  # note you can leave mpg_data unquoted for the tidyeval\n  # but have to quote mpg_data for the pluck\n  gt_plot(mpg_data, \"mpg_data\", plot_fun = spec_plot)\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\ncyl\n      mpg_data\n    \n\n\n4\n\n\n\n\n\n6\n\n\n\n\n\n8\n\n\n\n\n\n\n\n\n\nInteractive sparklines\n\nSo the embedded sparklines as shown above are fantastic, quick and robust, but they’re static. Since we’re focusing on HTML content, why don’t we also see if we can get javascript enabled interactivity?\nQuick example of this working below, but note you need to call sparkline(0) somewhere ahead of time in your RMarkdown doc to load the javascript library dependency. Also, if you try to view this interactively it will look like it failed and didn’t pass anything through, but it will work when the RMarkdown is knit and the JavaScript can be called properly.\n\ntibble(\n  var = c(\"mpg\", \"wt\"),\n  sparkline1 = \"\",\n  sparkline2 = \"\",\n  box = \"\"\n) %>% \n  gt() %>% \n  text_transform(\n    locations = cells_body(vars(sparkline1)),\n    fn = function(x){\n      sparkline <- map(list(mtcars$mpg, mtcars$wt), ~spk_chr(values = .x, chartRangeMin = 0))\n      map(sparkline, gt::html)\n    }\n  ) %>% \n  text_transform(\n    locations = cells_body(vars(sparkline2)),\n    fn = function(x){\n      sparkline <- map(list(mtcars$mpg, mtcars$wt), ~spk_chr(values = .x, type = \"bar\", chartRangeMin = 0))\n      map(sparkline, gt::html)\n    }\n  ) %>% \n  text_transform(\n    locations = cells_body(vars(box)),\n    fn = function(x){\n      sparkline <- map(list(mtcars$mpg, mtcars$wt), ~spk_chr(values = .x, type = \"box\", chartRangeMin = 0))\n      map(sparkline, gt::html)\n    }\n  )\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\nvar\n      sparkline1\n      sparkline2\n      box\n    \n\n\nmpg\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nwt\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhile we’re likely to only be using this in a table once per each , I do want to try and create a function so that we don’t have to re-write these each time and could potentially roll it into a package.\n\ngt_spark <- function(table_data, plot_col, data_col){\n  # save the data extract ahead of time \n  # to be used in our anonymous function below\n  data_in = pluck(table_data, \"_data\", data_col)\n  \n  text_transform(\n    table_data,\n    # note the use of {{}} here - this is tidy eval\n    # that allows you to indicate specific columns\n    locations = cells_body(columns = vars({{plot_col}})),\n    fn = function(x){\n      sparkline_plot <- map(\n        data_in, \n        ~spk_chr(values = .x, chartRangeMin = 0)\n        )\n      \n      map(sparkline_plot, gt::html)\n    }\n  )\n}\n\nWe can then apply the function to work very succinctly, referencing only the internal list-column data.\n\n# works!\nmtcars %>% \n  group_by(cyl) %>% \n  summarize(mpg_data = list(mpg), .groups = \"drop\") %>% \n  gt() %>% \n  # note you can leave mpg_data unquoted for the tidyeval\n  # but have to quote mpg_data for the pluck\n  gt_spark(mpg_data, \"mpg_data\")\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\ncyl\n      mpg_data\n    \n\n\n4\n\n\n\n\n\n\n6\n\n\n\n\n\n\n8\n\n\n\n\n\n\n\n\n\n\nForest\nYou can also make forest-plot like tables in gt, note that this code is taken essentially verbatim from kableExtra’s documentation, just adapted to work in gt.\n\ncoef_table <- data.frame(\n  Variables = c(\"var 1\", \"var 2\", \"var 3\"),\n  Coefficients = c(1.6, 0.2, -2.0),\n  Conf.Lower = c(1.3, -0.4, -2.5),\n  Conf.Higher = c(1.9, 0.6, -1.4)\n) \n\ntibble(\n  Variable = coef_table$Variables,\n) %>%\n  mutate(\n    image = spec_pointrange(\n      x = coef_table$Coefficients, \n      xmin = coef_table$Conf.Lower, \n      xmax = coef_table$Conf.Higher, \n      vline = 0,\n      width = 250,\n      cex = .75,\n      col = \"black\",\n      pch = 16\n      )\n    ) %>% \n  mutate(\n    image = map(image, \"svg_text\"),\n    image = map(image, ~gt::html(as.character(.x)))\n  ) %>% \n  gt()\n\n\n\n\n\n\nVariable\n      image\n    \n\n\nvar 1\n\n\n\n\n\nvar 2\n\n\n\n\n\nvar 3\n\n\n\n\n\n\n\n\n\nWe can show a bit more robust example from a recent question by Silvia Canelón - @spcanelon\nCode to generate fake data\n\ncoef_table <- tibble(\n  group = c(\n    \"\",\n    rep(\"Sex\", 2),\n    rep(\"Age\", 4),\n    rep(\"Body-Mass index\", 2),\n    rep(\"Race\", 3),\n    rep(\"Baseline statin treatment\", 2),\n    rep(\"Intensity of statin treatment\", 2),\n    rep(\"Metabolic disease\", 3),\n    rep(\"Renal function\", 3)\n  ),\n  subgroup = c(\n    \"All Patients\",\n    \"Male\", \"Female\",\n    \"<65 yr\", \">= 65 yr\", \"<75 yr\", \">=75 yr\",\n    \"<=Median\", \">Median\",\n    \"White\", \"Black\", \"Other\",\n    \"Yes\", \"No\",\n    \"High\", \"Not high\",\n    \"Diabetes\", \"Metabolic syndrome\", \"Neither\",\n    \"Normal\", \"Mild impairment\", \"Moderate impairment\"\n  ),\n  Inclisiran = c(\n    781, 535,246,297,484,638,143,394,387,653,110,18,701,80,538,243,371,195,215,395,269,113\n  ),\n  Placebo = c(\n    780,548,232,333,447,649,131,385,394,685,87,8,692,88,546,234,331,207,242,410,260,107\n  ),\n  coefficients = c(-60,-55,-68,-58,-55,-57,-58,-55,-48,-58,-57,-49,-44,-58,-55,-57,-54,-52,-54,-53, -54,-52)\n  ) %>% \n  mutate(\n    conf_range = runif(22, min = 5, max = 10),\n    conf_lower = coefficients - conf_range,\n    conf_higher = coefficients + conf_range\n  ) %>%\n  mutate(\n    image = spec_pointrange(\n      x = coefficients, \n      xmin = conf_lower, \n      xmax = conf_higher, \n      same_lim = TRUE,\n      lim = c(-100, 25),\n      vline = 0,\n      width = 550,\n      cex = .75,\n      col = \"black\"\n      )\n    )\n\nHere’s the code to create a quick table with a zero-indicated line, and some randomly generated “variation”.\n\ncoef_table %>% \n  select(-coefficients, -contains(\"conf\")) %>% \n  mutate(\n    image = map(image, \"svg_text\"),\n    image = map(image, ~gt::html(as.character(.x)))\n  ) %>% \n  select(group:Placebo, pct_diff = image) %>% \n  gt(\n    groupname_col = \"group\",\n    rowname_col = \"subgroup\"\n  ) %>% \n  opt_row_striping() %>% \n  tab_options(\n    data_row.padding = px(3)\n  )\n\n\n\n\n\n\n\n      Inclisiran\n      Placebo\n      pct_diff\n    \n\n\n\n    \n\nAll Patients\n781\n780\n\n\n\n\n\nSex\n    \n\nMale\n535\n548\n\n\n\n\n\nFemale\n246\n232\n\n\n\n\n\nAge\n    \n\n<65 yr\n297\n333\n\n\n\n\n\n>= 65 yr\n484\n447\n\n\n\n\n\n<75 yr\n638\n649\n\n\n\n\n\n>=75 yr\n143\n131\n\n\n\n\n\nBody-Mass index\n    \n\n<=Median\n394\n385\n\n\n\n\n\n>Median\n387\n394\n\n\n\n\n\nRace\n    \n\nWhite\n653\n685\n\n\n\n\n\nBlack\n110\n87\n\n\n\n\n\nOther\n18\n8\n\n\n\n\n\nBaseline statin treatment\n    \n\nYes\n701\n692\n\n\n\n\n\nNo\n80\n88\n\n\n\n\n\nIntensity of statin treatment\n    \n\nHigh\n538\n546\n\n\n\n\n\nNot high\n243\n234\n\n\n\n\n\nMetabolic disease\n    \n\nDiabetes\n371\n331\n\n\n\n\n\nMetabolic syndrome\n195\n207\n\n\n\n\n\nNeither\n215\n242\n\n\n\n\n\nRenal function\n    \n\nNormal\n395\n410\n\n\n\n\n\nMild impairment\n269\n260\n\n\n\n\n\nModerate impairment\n113\n107\n\n\n\n\n\n\n\n\n\nMore custom HTML work\nFor the next section, I’ll be showing some functions that are mostly adapted from Greg Lin’s fantastic examples for the reactable package Cookbook. I love reactable, but want to show how some of the same ideas can translate in to mostly static tables as well. Note that some of the tags$, div, etc are from the htmltools package, and you can generally write your own HTML by hand if you wanted.\nFunction to add tooltip to a table column label\n\nlibrary(htmltools)\n\n# Add tooltip to column labels\nwith_tooltip <- function(value, tooltip) {\n  tags$abbr(style = \"text-decoration: underline; text-decoration-style: solid; cursor: question; color: blue\",\n            title = tooltip, value)\n}\n\n\nFunction that creates a star rating scale from 0-5\n\n# note you could use ANY font-awesome logo\n# https://fontawesome.com/cheatsheet\nrating_stars <- function(rating, max_rating = 5) {\n  rounded_rating <- floor(rating + 0.5)  # always round up\n  stars <- lapply(seq_len(max_rating), function(i) {\n    if (i <= rounded_rating) fontawesome::fa(\"star\", fill= \"orange\") else fontawesome::fa(\"star\", fill= \"grey\")\n  })\n  label <- sprintf(\"%s out of %s\", rating, max_rating)\n  div_out <- div(title = label, \"aria-label\" = label, role = \"img\", stars)\n  \n  as.character(div_out) %>% \n    gt::html()\n}\n\n\nfontawesome package for inline icons\n\nrank_chg <- function(change_dir){\n  if (change_dir == \"increase\") {\n    logo_out <- fontawesome::fa(\"arrow-up\", fill = \"blue\")\n  } else if (change_dir == \"decrease\"){\n    logo_out <- fontawesome::fa(\"arrow-down\", fill = \"red\")\n  }\n  \n  logo_out %>% \n    as.character() %>% \n    gt::html()\n  \n}\n\n\nCreate a “badge” style label with a specific color, and round edges.\n\nadd_cyl_color <- function(cyl){\n      add_color <- if (cyl == 4) {\n        \"background: hsl(116, 60%, 90%); color: hsl(116, 30%, 25%);\"\n      } else if (cyl == 6) {\n        \"background: hsl(230, 70%, 90%); color: hsl(230, 45%, 30%);\"\n      } else if (cyl == 8) {\n        \"background: hsl(350, 70%, 90%); color: hsl(350, 45%, 30%);\"\n      }\n      div_out <- htmltools::div(\n        style = paste(\n          \"display: inline-block; padding: 2px 12px; border-radius: 15px; font-weight: 600; font-size: 12px;\",\n          add_color\n          ),\n        paste(cyl, \"Cylinders\")\n      )\n      \n      as.character(div_out) %>% \n        gt::html()\n}\n\n\nExample of a inline bar chart made purely with HTML\n\nbar_chart <- function(value, color = \"red\"){\n    \n    glue::glue(\"<span style=\\\"display: inline-block; direction: ltr; border-radius: 4px; padding-right: 2px; background-color: {color}; color: {color}; width: {value}%\\\"> &nbsp; </span>\") %>% \n    as.character() %>% \n    gt::html()\n}\n\n\nAll of these examples can be used in one example table! I’ve also added a HTML example of a hyperlink for the “data source” which links to the gt page for HTML content 😄. So now we have:\n- Tooltips\n- Embedded icons/font-awesome logos\n- Badges + colors\n- HTML-only bar charts\n- Hyperlinks\n- Expandable Tabke Key as “Details” with a HTML <details> tag\n\nset.seed(377)\n  \nmtcars %>% \n  tibble() %>% \n  select(1:4) %>% \n  sample_n(size = 6) %>% \n  mutate(\n    rank_change = sample(c(\"increase\", \"decrease\"), size = 6, replace = TRUE),\n    rank_change = map(rank_change, rank_chg)\n  ) %>% \n  mutate(\n    rating = sample(1:5, size = 6, replace = TRUE),\n    rating = map(rating, rating_stars)\n    ) %>% \n  mutate(\n    cylinder = map(cyl, add_cyl_color)\n  ) %>% \n  mutate(\n    mpg_plot = mpg/max(mpg) * 100,\n    mpg_plot = map(mpg_plot, ~bar_chart(value = .x, color = \"lightblue\"))\n    ) %>% \n  gt() %>% \n  cols_align(\n    align = \"left\",\n    columns = vars(mpg_plot)\n  ) %>% \n  cols_label(\n    mpg = gt::html(as.character(with_tooltip(\"MPG\", \"Miles per Gallon\")))\n  ) %>% \n  tab_source_note(\n    source_note = html(\n      htmltools::tags$a(\n        href = \"https://gt.rstudio.com/reference/md.html\", \n        target = \"_blank\", \n        \"Data Source\"\n        ) %>% \n        as.character()\n      )\n    ) %>% \n  tab_source_note(\n    source_note = html(\n      \"<details><h3 style='font-face:bold'>Table Key</h3><div>MPG: Miles Per Gallon</div><div>Cyl: Cylinders</div><div>disp: Displacement</div><div>hp: Horsepower</div><div>rank_change: Rank Change</div><div>rating: Rating</div></details>\"\n    )\n  ) %>% \n  tab_options(\n    data_row.padding = px(5)\n  )\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\nMPG\n      cyl\n      disp\n      hp\n      rank_change\n      rating\n      cylinder\n      mpg_plot\n    \n\n\n15.5\n8\n318.0\n150\n\n\n  \n\n8 Cylinders\n   \n\n\n14.3\n8\n360.0\n245\n\n\n  \n\n8 Cylinders\n   \n\n\n21.0\n6\n160.0\n110\n\n\n  \n\n6 Cylinders\n   \n\n\n10.4\n8\n472.0\n205\n\n\n  \n\n8 Cylinders\n   \n\n\n26.0\n4\n120.3\n91\n\n\n  \n\n4 Cylinders\n   \n\n\n15.0\n8\n301.0\n335\n\n\n  \n\n8 Cylinders\n   \n\n\n\n\nData Source\n    \n\nTable Key\nMPG: Miles Per Gallon\nCyl: Cylinders\ndisp: Displacement\nhp: Horsepower\nrank_change: Rank Change\nrating: Rating\n    \n\n\n\n\n\nPut it all together\nLet’s put all the things we’ve learned together into a publication-quality table, we’ll collect some QBR data to use.\n\n# use espnscrapeR to get NFL standings + QBR ratings\nnfl_qbr <- get_nfl_qbr(2020)\n\nScraping QBR totals for 2020!\n\nnfl_standings <- get_nfl_standings(2020)\n\nReturning 2020\n\n# also get weekly for embedded plot\nqbr_weekly <- crossing(season = 2020, week = 1:8) %>%\n  pmap_dfr(.f = get_nfl_qbr)\n\nScraping weekly QBR for week 1 of 2020!\n\n\nScraping weekly QBR for week 2 of 2020!\n\n\nScraping weekly QBR for week 3 of 2020!\n\n\nScraping weekly QBR for week 4 of 2020!\n\n\nScraping weekly QBR for week 5 of 2020!\n\n\nScraping weekly QBR for week 6 of 2020!\n\n\nScraping weekly QBR for week 7 of 2020!\n\n\nScraping weekly QBR for week 8 of 2020!\n\n\nThen we’ll summarise the data to prep for an embedded plot, and join together our NFL standings, QBR, and weekly QBR.\nData Prep\n\nqbr_match <- qbr_weekly %>%\n  filter(name_short %in% unique(nfl_qbr$name_short)) %>%\n  group_by(name_short, team) %>%\n  summarise(qbr_weekly = list(qbr_total), .groups = \"drop\",\n            qbr = mean(qbr_total),\n            qbr_sd = sd(qbr_total),\n            plays = sum(qb_plays),\n            pass = mean(pass),\n            run = mean(run),\n            head = unique(headshot_href),\n            n = n()) %>%\n  arrange(desc(qbr)) %>% \n  filter(n >= 7)\n\n# clean up the data a bit and combine\ntab_df <- qbr_match %>% \n  left_join(nfl_standings, by = c(\"team\" = \"team_name\")) %>%\n  select(name_short, team, head, qbr_weekly:run, wins, losses, pts_for) %>%\n  mutate(wl = glue(\"{wins}-{losses}\")) %>%\n  select(-wins, -losses)\ntab_df\n\n# A tibble: 23 × 11\n   name_short   team    head  qbr_weekly   qbr qbr_sd plays  pass    run pts_for\n   <chr>        <chr>   <chr> <list>     <dbl>  <dbl> <dbl> <dbl>  <dbl>   <dbl>\n 1 R. Wilson    Seahaw… http… <dbl [7]>   77.0   9.57   328  7.43  1.17      459\n 2 A. Rodgers   Packers http… <dbl [7]>   73.2  29.9    285  6.3   0.586     509\n 3 P. Mahomes   Chiefs  http… <dbl [8]>   72.1  20.8    347  7.22  1.29      473\n 4 D. Brees     Saints  http… <dbl [7]>   70.1  13.1    280  6.31  0.171     482\n 5 J. Allen     Bills   http… <dbl [8]>   69.9  20.9    362  6.64  1.21      501\n 6 R. Tannehill Titans  http… <dbl [7]>   68.8  20.3    284  5.81  1.13      491\n 7 D. Carr      Raiders http… <dbl [7]>   66.2  19.9    284  5.69  0.357     434\n 8 M. Ryan      Falcons http… <dbl [8]>   64.9  28.3    370  5.54  0.662     396\n 9 K. Murray    Cardin… http… <dbl [7]>   64.2  20.8    340  3.81  2.69      410\n10 T. Brady     Buccan… http… <dbl [8]>   62.2  25.9    349  5.88 -0.262     492\n# … with 13 more rows, and 1 more variable: wl <glue>\n\n# calc rank change\nqbr_rnk_chg <- qbr_weekly %>% \n  mutate(game_week = as.integer(game_week)) %>% \n  group_by(name_short) %>% \n  mutate(mean_qbr = mean(qbr_total)) %>% \n  ungroup() %>% \n  select(game_week, rank, name_short, qbr_total, mean_qbr) %>% \n  filter(game_week != max(game_week)) %>% \n  filter(name_short %in% nfl_qbr$name_short) %>%\n  group_by(name_short) %>%\n  summarize(prev_qbr = mean(qbr_total), mean_qbr = unique(mean_qbr)) %>% \n  mutate(\n    prev_week = rank(-prev_qbr),\n    rank = rank(-mean_qbr)\n    ) %>% \n  mutate(rank_chg = prev_week-rank) %>% \n  ungroup() %>% \n  arrange(desc(mean_qbr)) %>% \n  select(name_short, qbr = mean_qbr, rank_chg, rank)\n\nqbr_rnk_chg\n\n# A tibble: 35 × 4\n   name_short       qbr rank_chg  rank\n   <chr>          <dbl>    <dbl> <dbl>\n 1 R. Wilson       77.0        0     1\n 2 A. Rodgers      73.2        1     2\n 3 P. Mahomes      72.1        5     3\n 4 D. Prescott     71.5        1     4\n 5 D. Brees        70.1        1     5\n 6 J. Allen        69.9       -4     6\n 7 R. Tannehill    68.8       -3     7\n 8 J. Herbert      68.7        3     8\n 9 K. Allen        68.2        0     9\n10 R. Fitzpatrick  67.6        0    10\n# … with 25 more rows\n\n\nWe can then combine the player name, team, and win-loss record into one set of “data” presented with some HTML formatting.\nCode for Name/Team/Record Combo\n\ncombine_word <- function(name, team, wl){\n      glue::glue(\n        \"<div style='line-height:10px'><span style='font-weight:bold;font-variant:small-caps;font-size:14px'>{name}</div>\n        <div style='line-height:12px'><span style ='font-weight:bold;color:grey;font-size:10px'>{team}&nbsp;&nbsp;{wl}</span></div>\"\n      )\n    }\n\ncombo_df <- tab_df %>% \n  left_join(qbr_rnk_chg, by = c(\"name_short\", \"qbr\")) %>%\n  select(rank, rank_chg, name_short:wl) %>% \n  mutate(\n    rank = row_number(),\n    combo = combine_word(name_short, team, wl),\n    combo = map(combo, gt::html)\n    ) %>% \n  select(rank, rank_chg, head, combo, qbr, qbr_weekly, plays, pts_for)\n\ncombo_df\n\n# A tibble: 23 × 8\n    rank rank_chg head                     combo    qbr qbr_weekly plays pts_for\n   <int>    <dbl> <chr>                    <list> <dbl> <list>     <dbl>   <dbl>\n 1     1        0 https://a.espncdn.com/i… <html>  77.0 <dbl [7]>    328     459\n 2     2        1 https://a.espncdn.com/i… <html>  73.2 <dbl [7]>    285     509\n 3     3        5 https://a.espncdn.com/i… <html>  72.1 <dbl [8]>    347     473\n 4     4        1 https://a.espncdn.com/i… <html>  70.1 <dbl [7]>    280     482\n 5     5       -4 https://a.espncdn.com/i… <html>  69.9 <dbl [8]>    362     501\n 6     6       -3 https://a.espncdn.com/i… <html>  68.8 <dbl [7]>    284     491\n 7     7       -4 https://a.espncdn.com/i… <html>  66.2 <dbl [7]>    284     434\n 8     8        5 https://a.espncdn.com/i… <html>  64.9 <dbl [8]>    370     396\n 9     9        0 https://a.espncdn.com/i… <html>  64.2 <dbl [7]>    340     410\n10    10        6 https://a.espncdn.com/i… <html>  62.2 <dbl [8]>    349     492\n# … with 13 more rows\n\n\nTable Code\n\nfinal_table <- combo_df %>% \n  gt() %>% \n  cols_align(\n    align = \"left\",\n    columns = vars(combo)\n  ) %>% \n  tab_options(\n    data_row.padding = px(2)\n  ) %>% \n  text_transform(\n    locations = cells_body(columns = vars(head)),\n    fn = function(x){\n      gt::web_image(x)\n    }\n  ) %>% \n  text_transform(\n    locations = cells_body(columns = vars(rank_chg)),\n    fn = function(x){\n      \n      rank_chg <- as.integer(x)\n      \n      choose_logo <-function(x){\n        if (x == 0){\n        gt::html(fontawesome::fa(\"equals\", fill = \"grey\"))\n      } else if (x > 0){\n         gt::html(glue::glue(\"<span style='color:#1134A6;font-face:bold;font-size:10px;'>{x}</span>\"), fontawesome::fa(\"arrow-up\", fill = \"#1134A6\"))\n      } else if (x < 0) {\n        gt::html(glue::glue(\"<span style='color:#DA2A2A;font-face:bold;font-size:10px;'>{x}</span>\"), fontawesome::fa(\"arrow-down\", fill = \"#DA2A2A\"))\n      }\n      } \n      \n      map(rank_chg, choose_logo)\n    \n    }\n  ) %>% \n  fmt_number(\n    columns = vars(qbr), \n    decimals = 1\n    ) %>% \n  tab_style(\n    style = cell_text(weight = \"bold\"),\n    locations = cells_column_labels(TRUE)\n  ) %>% \n  cols_label(\n    rank = \"RK\",\n    combo = \"\",\n    head = \"QB\",\n    qbr = \"QBR\",\n    plays = \"PLAYS\",\n    pts_for = \"PF\",\n    qbr_weekly = \"WEEKLY\",\n    rank_chg = \"\"\n  ) %>% \n  gt_spark(qbr_weekly, \"qbr_weekly\") %>%\n  espnscrapeR::gt_theme_espn() %>% \n  tab_source_note(\n    source_note = gt::html(\n      htmltools::tags$a(\n        href = \"https://www.espn.com/nfl/qbr\", \n        target = \"_blank\", \n        \"Data: ESPN\"\n        ) %>% \n        as.character()\n      )\n    ) %>% \n  cols_align(\n    \"left\",\n    columns = vars(qbr_weekly)\n  ) %>% \n  cols_width(\n    vars(rank) ~ px(25),\n    vars(rank_chg) ~ px(35),\n    vars(head) ~ px(50),\n    vars(combo) ~ px(115),\n    vars(qbr) ~ px(35),\n    vars(plays) ~ px(35),\n    vars(pts_for) ~ px(35),\n    vars(qbr_weekly) ~ px(75)\n  ) %>% \n  tab_header(\n    title = gt::html(\"<h3>NFL QBR through Week 8</h3>\")\n  ) %>% \n  tab_options(\n    table.width = px(480),\n    data_row.padding = px(4)\n  )\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\nWarning: `columns = TRUE` has been deprecated in gt 0.3.0:\n* please use `columns = everything()` instead\n\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\nfinal_table\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNFL QBR through Week 8\n    \n\nRK\n      \n      QB\n      \n      QBR\n      WEEKLY\n      PLAYS\n      PF\n    \n\n\n1\n\n\n\nR. Wilson\nSeahawks  12-4\n\n77.0\n\n\n\n\n328\n459\n\n\n2\n\n1 \n\n\n\nA. Rodgers\nPackers  13-3\n\n73.2\n\n\n\n\n285\n509\n\n\n3\n\n5 \n\n\n\nP. Mahomes\nChiefs  14-2\n\n72.1\n\n\n\n\n347\n473\n\n\n4\n\n1 \n\n\n\nD. Brees\nSaints  12-4\n\n70.1\n\n\n\n\n280\n482\n\n\n5\n\n-4 \n\n\n\nJ. Allen\nBills  13-3\n\n69.9\n\n\n\n\n362\n501\n\n\n6\n\n-3 \n\n\n\nR. Tannehill\nTitans  11-5\n\n68.8\n\n\n\n\n284\n491\n\n\n7\n\n-4 \n\n\n\nD. Carr\nRaiders  8-8\n\n66.2\n\n\n\n\n284\n434\n\n\n8\n\n5 \n\n\n\nM. Ryan\nFalcons  4-12\n\n64.9\n\n\n\n\n370\n396\n\n\n9\n\n\n\nK. Murray\nCardinals  8-8\n\n64.2\n\n\n\n\n340\n410\n\n\n10\n\n6 \n\n\n\nT. Brady\nBuccaneers  11-5\n\n62.2\n\n\n\n\n349\n492\n\n\n11\n\n3 \n\n\n\nD. Watson\nTexans  4-12\n\n60.8\n\n\n\n\n305\n384\n\n\n12\n\n-1 \n\n\n\nB. Mayfield\nBrowns  11-5\n\n58.6\n\n\n\n\n271\n408\n\n\n13\n\n\n\nT. Bridgewater\nPanthers  5-11\n\n58.5\n\n\n\n\n329\n350\n\n\n14\n\n-7 \n\n\n\nL. Jackson\nRavens  11-5\n\n58.2\n\n\n\n\n282\n468\n\n\n15\n\n-5 \n\n\n\nM. Stafford\nLions  5-11\n\n58.2\n\n\n\n\n295\n377\n\n\n16\n\n1 \n\n\n\nP. Rivers\nColts  11-5\n\n57.4\n\n\n\n\n256\n451\n\n\n17\n\n-7 \n\n\n\nJ. Goff\nRams  10-6\n\n56.2\n\n\n\n\n328\n372\n\n\n18\n\n-2 \n\n\n\nD. Jones\nGiants  6-10\n\n55.6\n\n\n\n\n346\n280\n\n\n19\n\n\n\nB. Roethlisberger\nSteelers  12-4\n\n52.1\n\n\n\n\n283\n416\n\n\n20\n\n1 \n\n\n\nJ. Burrow\nBengals  4-11\n\n50.4\n\n\n\n\n426\n311\n\n\n21\n\n4 \n\n\n\nK. Cousins\nVikings  7-9\n\n46.9\n\n\n\n\n232\n430\n\n\n22\n\n-4 \n\n\n\nC. Wentz\nEagles  4-11\n\n46.1\n\n\n\n\n407\n334\n\n\n23\n\n-1 \n\n\n\nG. Minshew\nJaguars  1-15\n\n44.3\n\n\n\n\n331\n306\n\n\n\nData: ESPN\n    \n\n\n\n\nSo that’s all for now, but hopefully having this “cheatsheet” lets you go even further with all the possible creations you can make with a lot of gt and a little bit of HTML!\n\n\n\n\n\n\n\nExpand for Session Info\n\n\n\n\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.0 (2022-04-22)\n os       macOS Monterey 12.2.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       America/Chicago\n date     2022-04-28\n pandoc   2.18 @ /Applications/RStudio.app/Contents/MacOS/quarto/bin/tools/ (via rmarkdown)\n quarto   0.9.294 @ /usr/local/bin/quarto\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version    date (UTC) lib source\n dplyr       * 1.0.8      2022-02-08 [1] CRAN (R 4.2.0)\n espnscrapeR * 0.6.5      2022-04-26 [1] Github (jthomasmock/espnscrapeR@084ce80)\n forcats     * 0.5.1      2021-01-27 [1] CRAN (R 4.2.0)\n formattable * 0.2.1      2021-01-07 [1] CRAN (R 4.2.0)\n ggplot2     * 3.3.5      2021-06-25 [1] CRAN (R 4.2.0)\n glue        * 1.6.2      2022-02-24 [1] CRAN (R 4.2.0)\n gt          * 0.5.0.9000 2022-04-27 [1] Github (rstudio/gt@0d4c83d)\n htmltools   * 0.5.2      2021-08-25 [1] CRAN (R 4.2.0)\n kableExtra  * 1.3.4      2021-02-20 [1] CRAN (R 4.2.0)\n purrr       * 0.3.4      2020-04-17 [1] CRAN (R 4.2.0)\n readr       * 2.1.2      2022-01-30 [1] CRAN (R 4.2.0)\n sessioninfo * 1.2.2      2021-12-06 [1] CRAN (R 4.2.0)\n sparkline   * 2.0        2016-11-12 [1] CRAN (R 4.2.0)\n stringr     * 1.4.0      2019-02-10 [1] CRAN (R 4.2.0)\n tibble      * 3.1.6      2021-11-07 [1] CRAN (R 4.2.0)\n tidyr       * 1.2.0      2022-02-01 [1] CRAN (R 4.2.0)\n tidyverse   * 1.3.1      2021-04-15 [1] CRAN (R 4.2.0)\n\n [1] /Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/library\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "posts/2018-12-10-a-gentle-guide-to-tidy-statistics-in-r/index.html",
    "href": "posts/2018-12-10-a-gentle-guide-to-tidy-statistics-in-r/index.html",
    "title": "A Gentle Guide to Tidy Statistics in R",
    "section": "",
    "text": "While data analysis in R can seem intimidating, we will explore how to use it effectively and clearly!"
  },
  {
    "objectID": "posts/2018-12-10-a-gentle-guide-to-tidy-statistics-in-r/index.html#introduction",
    "href": "posts/2018-12-10-a-gentle-guide-to-tidy-statistics-in-r/index.html#introduction",
    "title": "A Gentle Guide to Tidy Statistics in R",
    "section": "Introduction",
    "text": "Introduction\nAfter a great discussion started by Jesse Maegan (@kiersi) on Twitter, I decided to post a workthrough of some (fake) experimental treatment data. These data correspond to a new (fake) research drug called AD-x37, a theoretical drug that has been shown to have beneficial outcomes on cognitive decline in mouse models of Alzheimer’s disease. In the current experiment we will be statistically testing whether the drug was effective in reducing cognitive impairment in dementia patients. See the data HERE.\nWe will be using MMSE (mini-mental status exam) scores to assess the degree of cognitive impairment. In a real clinical trial, many other variables would be recorded, but for the sake of a straightforward but multi-variate example we will stick to just MMSE.\n\n\nSource: Folstein et al, 1975, J Psychiatr Res 12:189–198\n\n\nWe will be working through loading, plotting, analyzing, and saving the outputs of our analysis through the tidyverse, an “opinionated collection of R packages” designed for data analysis. We will limit dependence to two packages: tidyverse and broomwhile using base R for the rest. These two packages dramatically improve the data analysis workflow in my opinion. While other stats-heavy packages provide additional statistical testing, base R has a decent ability to perform statistical analyses out of the box. I will use knitr::kable to generate some html tables for a markdown document, but it is not necessary for the workflow.\nAdditionally, I will be uploading the Excel Sheet used in this example, so that you can re-create the workflow on your own. You can simply copy-paste the code seen here and it will run in R. If you would rather see the entire workflow in an R-Markdown document, please see here. R Markdown is a document created inside R that allows you to write code, execute it inline, and write comments/notes as you go. You could think of it like being able to write R code inside a basic Word document (but it can do a lot more than that!).\nAlthough you may not be interested in the dataset I have provided, this hopefully provides a clear workflow for you to swap in your data of interest and accomplish a basic analysis!\nLoad the tidyverse, broom, and knitr\nUsing the library function we will load the tidyverse. If you have never installed it before you can also use the install.packages(\"tidyverse\") call to install it for the first time. This package includes ggplot2 (graphs), dplyr/tidyr (summary statistics, data manipulation), and readxl (reading excel files) as well as the pipe %>%which will make our code much more readable! We will also load the broom package to tidy up some of our statistical outputs. Lastly we will load knitr for making nice html tables via knitr::kable, but not necessary for simply saving the outputs to Excel.\n\n# Load libraries\nlibrary(tidyverse)\nlibrary(broom)\nlibrary(knitr)\nlibrary(readxl)\n\nThis will output some message about the packages being loaded and any conflicts of function calls.\nLoading the data\nWhile I am calling readxl::read_xlsx you could also simply use read_xlsx, but in the interest of transparency, I will be using the full call to begin. The concept of calling a function with the use of :: is important as some packages have conflicts in functions, for example multiple packages include the function select and summarize. As such, we can clarify from which package we want R to call our function from, so package::function ! To read more about the concept of “namespace” when calling functions, please look here.\nreadxl is unfortunately a funny case, as installing the tidyverse installs readxl, but readxl is not loaded when loading the tidyverse via a library call. As such we must either load readxl like any other package or call both the package and the name as in readxl::read_xlsx. readxl allows us to read .xls, .xlsx files into R. Alternatively, you could convert your Excel sheet into .csv, which can be read by read_csv(). By using the glimpse function from dplyr we can see how the variables were imported, as well as the first few rows.\n\n\n\n\n\nRows: 600\nColumns: 5\n$ age            <dbl> 80, 85, 82, 80, 83, 79, 82, 79, 80, 79, 80, 79, 81, 83,…\n$ sex            <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0…\n$ health_status  <chr> \"Healthy\", \"Healthy\", \"Healthy\", \"Healthy\", \"Healthy\", …\n$ drug_treatment <chr> \"Placebo\", \"Placebo\", \"Placebo\", \"Placebo\", \"Placebo\", …\n$ mmse           <dbl> 24.78988, 24.88192, 25.10903, 24.92636, 23.38845, 24.11…\n\n\n\nWe can collect some information about the dataset now. Namely, we have our 3 categorical/factor variables: sex, health_status, and drug_treatment and 1 dependent variable (DV): mmse. We also have age, but importantly it is recorded as a discrete number instead of as a factor (eg as 85 years, instead of old). Thus we can look at age, but we will not use it as a factor in our ANOVA.\nChecking the data distribution\nWe will use our first ggplot2call to create a graph showing the distribution of age. To break down what we are doing, we need to call ggplot, tell it what data to use, and use the aes or aesthetic call to assign the x coordinate. We then add a + which tells ggplot to include the next line of code. The geom_density tells R that we want to make create a density distribution layer and we want to fillit with a blue color! For more info about ggplot2 please go HERE or here.\n\n\n\n\n\n\nThe graph shows us that age really only goes from 79–85 years, and that there is really not any age over or underrepresented. We can confirm the age ranges by a dplyr::summarize call or by calling range in base R. As a slight aside, we can now talk about using the pipe or %>%. The pipe passes the results or data from the left of it to the right. For more info about the pipe, please see here.\nWe can read the following code as take raw_df and then summarize it by taking the min and max of the age variable. Now because we started with raw_df R understands we want to take the column age from this dataframe.\n\n\n# A tibble: 1 × 2\n    min   max\n  <dbl> <dbl>\n1    79    85\n\n\nAlternatively we could use the base R range function, which requires the use of $ . The dollar sign indicates that R should use the age column from raw_df. Both of these functions give us the same results, the minimum number and maximum number.\n\n\n[1] 79 85\n\n\nFor more information about using these two syntaxes look here or for cheat sheets look here.\nWhat about the experimental variables levels?\nNow while I am very aware of the variables in this dataframe, you might not be without exploring it! To quickly determine drug_treatment groups, health_status groups and how they interact we can do a table call. By calling it on both drug_treatment and health_status, we get a nice table breaking down how many rows are in each of the variable groups.\n\ntable(raw_df$drug_treatment, raw_df$health_status)\n\n           \n            Alzheimer's Healthy\n  High Dose         100     100\n  Low dose          100     100\n  Placebo           100     100\n\n\n\nAlternatively we can do the same thing in dplyr with the following code.\n\nraw_df %>% \n  group_by(drug_treatment, health_status) %>% \n  count()\n\n# A tibble: 6 × 3\n# Groups:   drug_treatment, health_status [6]\n  drug_treatment health_status     n\n  <chr>          <chr>         <int>\n1 High Dose      Alzheimer's     100\n2 High Dose      Healthy         100\n3 Low dose       Alzheimer's     100\n4 Low dose       Healthy         100\n5 Placebo        Alzheimer's     100\n6 Placebo        Healthy         100\n\n\nNow we know the levels of our variables of interest, and that there are 100 patients per overall treatment group!\nData exploration of dependent variable\nBefore running our summary statistics we can actually visualize the range, central tendency and quartiles via a geom_boxplot call.\n\nggplot(data = raw_df, # add the data\n       aes(x = drug_treatment, y = mmse, # set x, y coordinates\n           color = drug_treatment)) +    # color by treatment\n  geom_boxplot() +\n  facet_grid(~health_status) # create panes base on health status\n\n\n\n\n\n\n\n\nWe have split the data into separate graph facets (or panes) for healthy and Alzheimer’s patients, as well as into groups within each facet by drug treatment. This graph tells us a few things of interest for later. It definitely looks like we have an effect with our (fake) awesome drug! Let’s explore that with descriptive statistics.\nWhile this is an exploratory graph and we don’t necessarily want to “tweak” it to perfection, we can take note that our drug treatment should be ordered Placebo < Low dose < High Dose and we should have Healthy patients presented first, and Alzheimer’s patients second. This is something we can fix in our next section!\nSummary Statistics\nWe are looking to generate the mean and standard error for mmse scores, this is useful as a measure of central tendency, and for creating our final publication graphs. We have our categorical variables of sex, drug treatment, and health status. However going back to our glimpse call from earlier, we can see that the data is not ‘coded’ properly. Namely, sex is a dbl (number), without a descriptive name, and health_status/drug_treatment are chr (characters)! These need to be converted into factors!\n\n\nRows: 600\nColumns: 5\n$ age            <dbl> 80, 85, 82, 80, 83, 79, 82, 79, 80, 79, 80, 79, 81, 83,…\n$ sex            <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0…\n$ health_status  <chr> \"Healthy\", \"Healthy\", \"Healthy\", \"Healthy\", \"Healthy\", …\n$ drug_treatment <chr> \"Placebo\", \"Placebo\", \"Placebo\", \"Placebo\", \"Placebo\", …\n$ mmse           <dbl> 24.78988, 24.88192, 25.10903, 24.92636, 23.38845, 24.11…\n\n\n\nWe can use the dplyr::mutate function to tell R we want to change (mutate) the rows within a variable of interest. So we will take the data in the sex, drug_treatment, and health_status columns and convert them from either just numbers or characters into a factor variable! dplyr::mutate can also perform math, and many other interesting things. For more information please see here.\nWe will use the mutate function and the base R factor function to convert our variables into the proper factors, and give them labels (for sex) or reorder the levels of the factors.\nWe need to be REALLY careful to type the labels EXACTLY as they appear in the column or it will replace those misspelled with a NA. For example, did you notice that High Dose has a capital “D” while Low dose has a lower case “d”?\n\nsum_df <- raw_df %>% \n            mutate(\n              sex = factor(sex, \n                  labels = c(\"Male\", \"Female\")),\n              drug_treatment =  factor(drug_treatment, \n                  levels = c(\"Placebo\", \"Low dose\", \"High Dose\")),\n              health_status = factor(health_status, \n                  levels = c(\"Healthy\", \"Alzheimer's\"))\n              )\nglimpse(sum_df)\n\nAs powerful as R is, it needs explicit and accurate code input to accomplish the end goals. As such, if we had typed “High dose” it would give an NA, while “High Dose” outputs correctly. We now see age and mmse as dbl (numerics) and sex, health_status, and drug_treatment as factors.\n\n\nRows: 600\nColumns: 5\n$ age            <dbl> 80, 85, 82, 80, 83, 79, 82, 79, 80, 79, 80, 79, 81, 83,…\n$ sex            <fct> Male, Male, Male, Male, Male, Male, Male, Male, Female,…\n$ health_status  <fct> Healthy, Healthy, Healthy, Healthy, Healthy, Healthy, H…\n$ drug_treatment <fct> Placebo, Placebo, Placebo, Placebo, Placebo, Placebo, P…\n$ mmse           <dbl> 24.78988, 24.88192, 25.10903, 24.92636, 23.38845, 24.11…\n\n\nNow that everything is coded properly, we can calculate our mean and standard error (se = standard deviation/square root of number of samples)! We will use the dplyr::group_by to tell R which factors we want to… group by! Then we will create named summaries by first calling dplyr::summarize and then specifying which summaries we want with mmse_mean and mmse_seand the number of samples n(). Lastly we will ungroup, which removes the group_by code from the dataframe.\n\nsum_df <- sum_df %>%   \n  group_by(sex, health_status, drug_treatment) %>%  \n  summarize(mmse_mean = mean(mmse),   \n            mmse_se = sd(mmse)/sqrt(n()),\n            n_samples = n()) %>%\n  ungroup() # ungrouping variable is a good habit to prevent errors\n\n`summarise()` has grouped output by 'sex', 'health_status'. You can override\nusing the `.groups` argument.\n\n\n\nNow we have a nicely formatted dataframe that can be saved to Excel, or used in graphing. We need to indicate what data we are writing (sum_df) and what we want the resulting file to be named (“adx37_sum_stats.csv”).\n\n# code to save the table into a .csv Excel file\nwrite.csv(sum_df, \"adx37_sum_stats.csv\")\n\nSummary graph\nBy calling a ggplot function we can generate a preliminary summary graph.\n\nggplot(data = sum_df, # add the data\n       aes(x = drug_treatment,  #set x, y coordinates\n           y = mmse_mean,\n           group = drug_treatment,  # group by treatment\n           color = drug_treatment)) +    # color by treatment\n  geom_point(size = 3) + \n  facet_grid(sex~health_status) # create facets by sex and status\n\n\n\n\nWe can now see that the graph is properly sorted by drug treatment and by health status. We still have some work to do on the final graph, but let’s move on to the ANOVAs first!\nThe ANOVA finally!\nWe will be prepping a dataframe for analysis via ANOVA. We need to again make sure we have our factors as factors via mutate, and in the correct order. This is necessary for the ANOVA/post-hoc testing to work, and to make the post-hocs and the ANOVA outputs easier to read.\n\n\nRows: 600\nColumns: 5\n$ age            <dbl> 80, 85, 82, 80, 83, 79, 82, 79, 80, 79, 80, 79, 81, 83,…\n$ sex            <fct> Male, Male, Male, Male, Male, Male, Male, Male, Female,…\n$ health_status  <fct> Healthy, Healthy, Healthy, Healthy, Healthy, Healthy, H…\n$ drug_treatment <fct> Placebo, Placebo, Placebo, Placebo, Placebo, Placebo, P…\n$ mmse           <dbl> 24.78988, 24.88192, 25.10903, 24.92636, 23.38845, 24.11…\n\n\n\nThat gets our dataframe into working status!\nCalling the ANOVA is a done via the aov function. The basic syntax is shown via pseudocode below. We put the dependent variable first (mmse in our case), then a ~ then the independent variable we want to test. Lastly we specify what data to use.\n\n\n\nWe can add our real data set via the code below, but because we have 3 independent variables we have a choice to make. We can simply look for main effects by adding a + in between each of our variables, or we can look for both main effects and interactions by adding a * between each variable. Make sure to not replace the + or * with commas, as that will lead to an error.\n\n\n\n\n\n\n\n\n\n\nBy assigning the ANOVA to the ad_aov object, we can then call summary on it to look at the results of the ANOVA.\n\n\n                                  Df Sum Sq Mean Sq  F value Pr(>F)    \nsex                                1      0       0    0.047  0.828    \ndrug_treatment                     2   3601    1801  909.213 <2e-16 ***\nhealth_status                      1  10789   10789 5447.953 <2e-16 ***\nsex:drug_treatment                 2      8       4    2.070  0.127    \nsex:health_status                  1      5       5    2.448  0.118    \ndrug_treatment:health_status       2   2842    1421  717.584 <2e-16 ***\nsex:drug_treatment:health_status   2      5       2    1.213  0.298    \nResiduals                        588   1164       2                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThe summary gives us the degrees of freedom, sum of squares, mean squares, F value, and the p value. I added a bold emphasis on the <2e -16, these p values are so small that R switches to scientific notation. So we see significant main effects of drug treatment, health status, and an interaction of drug treatment by health status. We can interpret that Alzheimer’s patients had different cognitive scores than healthy, and that drug treatment had an effect on cognitive scores. Importantly, sex was not a significant factor, as p = 0.828. Variables being scored as significant or non-significant can both be important!\nWe can also use broom::tidy to clean up the results of the ANOVA and put them into a dataframe. This is useful for storage, or for automation of some analysis for future ANOVAs.\n\n\n\nHowever, we don’t know the direction of differences, or where exactly the differences were Was it just the high dose? Low dose? Both? We need follow-up post hoc tests to determine these answers!\nPost-hocs > Post-docs (academia jokes < dad jokes)\nWe have multiple ways of looking at post-hocs. I will show two in this section.\nFor the pairwise, we need to use the $ to select columns from each of the dataframes and look at the interaction via :. Our first pairwise has NO correction for multiple comparisons, and is comparable to a unprotected Fisher’s-LSD post-hoc. This is not stringent at all, and given the amount of comparisons we have it is advisable to either move forward with a p.adjusting Bonferonni correction (change p.adj = “none” to p.adj = “bonf”) or the Tukey post-hoc test seen in the next example. You can see that this method is a little jumbled to read due to the dataset$column method and the need for : in between each interaction. We can read this as we want pairwise.t.test for the interaction of sex by drug_treatment by health_status, which gives us every iteration of these factors against the other.\n\n\n\nAdditionally, we need to extract the matrix of p values and save to an Excel file for future use.\nWe do this by simply wrapping our ad_last posthoc with broom::tidy.\n\n\n# A tibble: 6 × 3\n  group1                    group2                     p.value\n  <chr>                     <chr>                        <dbl>\n1 Male:Placebo:Alzheimer's  Male:Placebo:Healthy     1.25e-199\n2 Male:Low dose:Healthy     Male:Placebo:Healthy     9.84e-  1\n3 Male:Low dose:Healthy     Male:Placebo:Alzheimer's 8.68e-198\n4 Male:Low dose:Alzheimer's Male:Placebo:Healthy     8.01e-157\n5 Male:Low dose:Alzheimer's Male:Placebo:Alzheimer's 1.37e- 18\n6 Male:Low dose:Alzheimer's Male:Low dose:Healthy    3.23e-155\n\n\n\n\n\n\nThe Tukey post-hoc is a little cleaner to call, and is preferable to the unadjusted pairwise t-test. Notice we also are already wrapping the Tukey results in broom::tidy to save as a tidy dataframe! The TukeyHSD call incorporates the results of the ANOVA call, and is preferable to the previous method.\nThe following code can be read as we want a Tukey post-hoc test on the results of our ad_aov ANOVA across the interactions of sex by drug_treatment by health_status. Notice the quotation marks around ‘sex:drug_treatment:health_status’ and the : in between each variable. These are necessary to tell R how we want the Tukey to be run! Once this is done, R then runs tidy on it to make it into a nice dataframe similar to our previous pairwise test. We can then save the results to Excel!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\ncontrast\nnull.value\nestimate\nconf.low\nconf.high\nadj.p.value\n\n\n\nsex:drug_treatment:health_status\nFemale:Placebo:Healthy-Male:Placebo:Healthy\n0\n0.0111117\n-0.9140819\n0.9363052\n1.0000000\n\n\nsex:drug_treatment:health_status\nMale:Low dose:Healthy-Male:Placebo:Healthy\n0\n0.0056692\n-0.9000907\n0.9114291\n1.0000000\n\n\nsex:drug_treatment:health_status\nFemale:Low dose:Healthy-Male:Placebo:Healthy\n0\n0.0403184\n-0.8748132\n0.9554500\n1.0000000\n\n\nsex:drug_treatment:health_status\nMale:High Dose:Healthy-Male:Placebo:Healthy\n0\n0.7762410\n-0.1295189\n1.6820009\n0.1775310\n\n\nsex:drug_treatment:health_status\nFemale:High Dose:Healthy-Male:Placebo:Healthy\n0\n0.4360609\n-0.4790707\n1.3511925\n0.9213646\n\n\nsex:drug_treatment:health_status\nMale:Placebo:Alzheimer’s-Male:Placebo:Healthy\n0\n-12.8040144\n-13.7053250\n-11.9027038\n0.0000000\n\n\n\n\n\nPublication Graph\nNow that we have generated our ANOVAs and post-hocs, and saved them to Excel for storage, we can start making a publication-grade graph!\nggplot2 graphs allow for extreme customization, some of the additions I make to this graph are a personal choice, and as such I would recommend discussion with a mentor or experienced member in your field. Bar graphs are ubiquitous in my field, and while I think plotting as a boxplot would tell more about the data, I will initially start with a bar graph.\nOur goal is to plot the means, standard errors, and indicate significance where it occurs. Rather than relying on a package to label significance, I will be handmaking a custom dataframe with the tribble function. There are alternatives to doing it this way, but I can easily control what happens with this method, and it is explicitly apparent what the dataframe contains. The basics of tribble are shown in the below example. We assign columns with the ~ and then explicitly write out what we want in each row of the columns.\n\n\n# A tibble: 3 × 2\n  colA   colB\n  <chr> <dbl>\n1 a         1\n2 b         2\n3 c         3\n\n\nAnd here is our actual code for making the custom dataframe.\n\n\n\nNow that we have this data frame, we can use it in a geom_text call to label our bars with significance labels as indicated by a *.\nHere is what the final publication graph looks like in ggplot2 code. You’ll notice I assigned it to g1 rather than just calling it directly. This means I will have to call g1 to view the graph, but I can save it now! To read what we are doing, I am calling the initial ggplot call as before, but adding an error bar layer, a bar graph layer, separating into panes for sex and health_status, switching to an alternate appearance (theme_bw), setting the colors manually, making minor adjustments via theme, adding the * for indication of significance, and lastly altering the axis labels while adding a figure caption.\n\n\n\nSaving is done via the ggsave function, where we will need to name the resulting file with surrounding “ “, tell R which ggplot object we want (g1), and indicate the size via height, width, and units. Don’t forget to save the graph with a dpi call to make it nice and crisp!\n\n\n\nAnd the final graph!\n\n\n\n\n\n\nI think it would be a disservice to say you can learn ggplot by simply recreating my example. As such, I would like to point you in the direction of the R for Data Science textbook, as well as the Modern Dive ebook. These free ebooks have a tremendous amount of information that may be beyond what you need to accomplish today, but would serve you well in your future endeavors. Their chapters on data visualization are very helpful for getting started in R plotting!"
  },
  {
    "objectID": "posts/2018-12-10-a-gentle-guide-to-tidy-statistics-in-r/index.html#thank-you",
    "href": "posts/2018-12-10-a-gentle-guide-to-tidy-statistics-in-r/index.html#thank-you",
    "title": "A Gentle Guide to Tidy Statistics in R",
    "section": "Thank you",
    "text": "Thank you\nIf you have made it this far, good for you! I hope this was helpful and if you have any questions, I would recommend reaching out on Twitter via the #rstats or #r4ds hashtag, or you can find me @thomas_mock on twitter.\nAdditionally, Jesse Maegan has a R for Data Science Slack channel where you can learn and ask questions as you work through the R for Data Science text, read all about it here!. R Studio (caretakers of the Tidyverse) hosts their own forums.\n\n\n\n\n\n\nExpand for Session Info\n\n\n\n\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.0 (2022-04-22)\n os       macOS Monterey 12.2.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       America/Chicago\n date     2022-06-17\n pandoc   2.18 @ /Applications/RStudio.app/Contents/MacOS/quarto/bin/tools/ (via rmarkdown)\n quarto   0.9.577 @ /usr/local/bin/quarto\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version date (UTC) lib source\n broom       * 0.8.0   2022-04-13 [1] CRAN (R 4.2.0)\n dplyr       * 1.0.9   2022-04-28 [1] CRAN (R 4.2.0)\n forcats     * 0.5.1   2021-01-27 [1] CRAN (R 4.2.0)\n ggplot2     * 3.3.6   2022-05-03 [1] CRAN (R 4.2.0)\n here        * 1.0.1   2020-12-13 [1] CRAN (R 4.2.0)\n knitr       * 1.38.3  2022-04-26 [1] Github (yihui/knitr@87e5d8e)\n purrr       * 0.3.4   2020-04-17 [1] CRAN (R 4.2.0)\n readr       * 2.1.2   2022-01-30 [1] CRAN (R 4.2.0)\n readxl      * 1.4.0   2022-03-28 [1] CRAN (R 4.2.0)\n sessioninfo * 1.2.2   2021-12-06 [1] CRAN (R 4.2.0)\n stringr     * 1.4.0   2019-02-10 [1] CRAN (R 4.2.0)\n tibble      * 3.1.7   2022-05-03 [1] CRAN (R 4.2.0)\n tidyr       * 1.2.0   2022-02-01 [1] CRAN (R 4.2.0)\n tidyverse   * 1.3.1   2021-04-15 [1] CRAN (R 4.2.0)\n\n [1] /Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/library\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "posts/2022-06-13-gtextras-cran/index.html",
    "href": "posts/2022-06-13-gtextras-cran/index.html",
    "title": "Beautiful tables in R with gtExtras",
    "section": "",
    "text": "I’m very excited to have the first release of gtExtras available on CRAN!\nThe goal of gtExtras is to provide opinionated helper functions to assist in creating beautiful and functional tables with gt.\nThe functions are generally wrappers around boilerplate table-making code or adding opinionated functions like data journalism inspired table themes and inline graphics. The gt package is amazing, make sure to go read the official documentation.\nFor installation:"
  },
  {
    "objectID": "posts/2022-06-13-gtextras-cran/index.html#using-gtextras",
    "href": "posts/2022-06-13-gtextras-cran/index.html#using-gtextras",
    "title": "Beautiful tables in R with gtExtras",
    "section": "Using gtExtras\n",
    "text": "Using gtExtras\n\nOverall, there are a lot of available functions in gtExtras:\n\nlength(ls.str('package:gtExtras', mode='function'))\n\n[1] 65\n\n\nYou can read about each of the functions in the function reference.\nOverall, there are four families of functions in gtExtras:\n\nThemes: 7 themes that style almost every element of a gt table, built off of data journalism-styled tables\nUtilities: Helper functions for aligning/padding numbers, adding fontawesome icons, images, highlighting, dividers, styling by group, creating two tables or two column layouts, extracting ordered data from a gt table internals, or generating a random dataset for reprex\n\nPlotting: 12 plotting functions for inline sparklines, win-loss charts, distributions (density/histogram), percentiles, dot + bar, bar charts, confidence intervals, or summarizing an entire dataframe!\nColors: 3 functions, a palette for “Hulk” style scale (purple/green), coloring rows with good defaults from paletteer, or adding a “color box” along with the cell value\n\nAlso see the Plotting with gtExtras article for more examples of combining tables and graphics together.\nA subset of functions are included below, or see the full function reference.\nImportantly, gtExtras is not at all a replacement for gt, but rather is almost a “cookbook” where common or repeated function calls are grouped into their own respective functions. At a technical level, gtExtras is literally just gt functions under the hood and I’ll highlight a few examples of how to do the same thing in each package.\nLoad libraries\n\nlibrary(tidyverse)\nlibrary(gt)\nlibrary(gtExtras)\n\nThemes\nThe package includes seven different themes, and 3 examples are the gt_theme_538() styled after FiveThirtyEight style tables, the gt_theme_espn() styled after ESPN style tables, and the gt_theme_nytimes() styled after The New York Times tables.\n\nhead(mtcars) %>%\n  gt() %>% \n  gt_theme_538() %>% \n  tab_header(title = \"Table styled like the FiveThirtyEight\")\n\n\n\n\n\n\nTable styled like the FiveThirtyEight\n    \n\nmpg\n      cyl\n      disp\n      hp\n      drat\n      wt\n      qsec\n      vs\n      am\n      gear\n      carb\n    \n\n\n21.0\n6\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\n21.0\n6\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\n22.8\n4\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\n21.4\n6\n258\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\n18.7\n8\n360\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\n18.1\n6\n225\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\n\n\n\n\n\nhead(mtcars) %>%\n  gt() %>% \n  gt_theme_guardian() %>% \n  tab_header(title = \"Table styled like the Guardian\")\n\n\n\n\n\n\nTable styled like the Guardian\n    \n\nmpg\n      cyl\n      disp\n      hp\n      drat\n      wt\n      qsec\n      vs\n      am\n      gear\n      carb\n    \n\n\n21.0\n6\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\n21.0\n6\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\n22.8\n4\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\n21.4\n6\n258\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\n18.7\n8\n360\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\n18.1\n6\n225\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\n\n\n\n\n\nhead(mtcars) %>% \n  gt() %>% \n  gt_theme_nytimes() %>% \n  tab_header(title = \"Table styled like the NY Times\")\n\n\n\n\n\n\nTable styled like the NY Times\n    \n\nmpg\n      cyl\n      disp\n      hp\n      drat\n      wt\n      qsec\n      vs\n      am\n      gear\n      carb\n    \n\n\n21.0\n6\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\n21.0\n6\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\n22.8\n4\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\n21.4\n6\n258\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\n18.7\n8\n360\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\n18.1\n6\n225\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\n\n\n\n\nThere are also themes that are bit more specific or somewhat “tongue in cheek”:\n\nhead(mtcars) %>% \n  gt() %>% \n  gt_theme_excel() %>% \n  tab_header(title = \"Table styled like Excel\")\n\n\n\n\n\n\nTable styled like Excel\n    \n\nmpg\n      cyl\n      disp\n      hp\n      drat\n      wt\n      qsec\n      vs\n      am\n      gear\n      carb\n    \n\n\n21.0\n6\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\n21.0\n6\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\n22.8\n4\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\n21.4\n6\n258\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\n18.7\n8\n360\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\n18.1\n6\n225\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\n\n\n\n\n\nhead(mtcars) %>% \n  gt() %>% \n  gt_theme_dot_matrix() %>% \n  tab_header(title = \"Table styled like a dot matrix printer\")\n\n\n\n\n\n\nTable styled like a dot matrix printer\n    \n\nmpg\n      cyl\n      disp\n      hp\n      drat\n      wt\n      qsec\n      vs\n      am\n      gear\n      carb\n    \n\n\n21.0\n6\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\n21.0\n6\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\n22.8\n4\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\n21.4\n6\n258\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\n18.7\n8\n360\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\n18.1\n6\n225\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\n\n\n\n\nIf you wanted to write your own gt_theme_YOURTHEME() function, you could do this with something like the below:\n\nmy_theme <- function(gt_object, ...){\n  gt_object %>%\n    tab_options(\n      column_labels.background.color = \"black\",\n      heading.align = \"left\",\n      ...\n    ) %>%\n    tab_style(\n      style = cell_text(color = \"red\", size = px(32)),\n      locations = cells_title(\"title\")\n    )\n}\n\n\nhead(mtcars) %>%\n  gt() %>%\n  my_theme() %>%\n  tab_header(\"My own custom theme!\")\n\n\n\n\n\n\nMy own custom theme!\n    \n\nmpg\n      cyl\n      disp\n      hp\n      drat\n      wt\n      qsec\n      vs\n      am\n      gear\n      carb\n    \n\n\n21.0\n6\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\n21.0\n6\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\n22.8\n4\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\n21.4\n6\n258\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\n18.7\n8\n360\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\n18.1\n6\n225\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\n\n\n\n\nHulk data_color\nThis is an opinionated diverging color palette. It diverges from low to high as purple to green. It is a good alternative to a red-green diverging palette as a color-blind friendly palette. The specific colors come from colorbrewer2.\nBasic usage below, where a specific column is passed.\n\n# basic use\nhead(mtcars) %>%\n  gt::gt() %>%\n  gt_hulk_col_numeric(mpg)\n\n\n\n\n\n\nmpg\n      cyl\n      disp\n      hp\n      drat\n      wt\n      qsec\n      vs\n      am\n      gear\n      carb\n    \n\n\n21.0\n6\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\n21.0\n6\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\n22.8\n4\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\n21.4\n6\n258\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\n18.7\n8\n360\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\n18.1\n6\n225\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\n\n\n\n\nTrim provides a tighter range of purple/green so the colors are less pronounced.\n\nhead(mtcars) %>%\n  gt::gt() %>%\n  # trim gives smaller range of colors\n  # so the green and purples are not as dark\n  gt_hulk_col_numeric(mpg:disp, trim = TRUE) \n\n\n\n\n\n\nmpg\n      cyl\n      disp\n      hp\n      drat\n      wt\n      qsec\n      vs\n      am\n      gear\n      carb\n    \n\n\n21.0\n6\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\n21.0\n6\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\n22.8\n4\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\n21.4\n6\n258\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\n18.7\n8\n360\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\n18.1\n6\n225\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\n\n\n\n\nReverse makes higher values represented by purple and lower by green. The default is to have high = green, low = purple.\n\n# option to reverse the color palette\n# so that purple is higher\nhead(mtcars) %>%\n  gt::gt() %>%\n  # reverse = green for low, purple for high\n  gt_hulk_col_numeric(mpg:disp, reverse = TRUE) \n\n\n\n\n\n\nmpg\n      cyl\n      disp\n      hp\n      drat\n      wt\n      qsec\n      vs\n      am\n      gear\n      carb\n    \n\n\n21.0\n6\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\n21.0\n6\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\n22.8\n4\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\n21.4\n6\n258\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\n18.7\n8\n360\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\n18.1\n6\n225\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\n\n\n\n\ngt_color_rows()\nThe gt_color_rows() function is a more generic, thin boilerplate wrapper around gt::data_color(). A quick example of gt::data_color() is below.\nUsing named colors or hex colors is very simple!\n\nhead(mtcars) %>% \n  gt() %>% \n  gt::data_color(\n    columns = mpg:disp, colors = c(\"white\", \"red\")\n  )\n\n\n\n\n\n\nmpg\n      cyl\n      disp\n      hp\n      drat\n      wt\n      qsec\n      vs\n      am\n      gear\n      carb\n    \n\n\n21.0\n6\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\n21.0\n6\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\n22.8\n4\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\n21.4\n6\n258\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\n18.7\n8\n360\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\n18.1\n6\n225\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\n\n\n\n\nSome complexity arises when wanting to use a color palette with tighter control. The code below is good but requires you to write out a lot of your own control.\n\ncolor_fn <- scales::col_numeric(\n    domain = NULL,\n  palette = as.character(\n    paletteer::paletteer_d(\n      palette = \"ggsci::red_material\" ,\n      type = \"continuous\"))\n  )\n\nhead(mtcars) %>% \n  gt() %>% \n  gt::data_color(columns = mpg:disp, colors = color_fn)\n\n\n\n\n\n\nmpg\n      cyl\n      disp\n      hp\n      drat\n      wt\n      qsec\n      vs\n      am\n      gear\n      carb\n    \n\n\n21.0\n6\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\n21.0\n6\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\n22.8\n4\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\n21.4\n6\n258\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\n18.7\n8\n360\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\n18.1\n6\n225\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\n\n\n\n\ngtExtras::gt_color_rows() simple to use but provides rich color choices thanks to the native inclusion of paletteer::paletteer_d(). This can provide 100s of discrete (ie categorical) or continuous color palettes.\nNote that it is very close to the color_fn from above but throws a warning if domain is NULL since that will use range within EACH column rather than a shared range ACROSS columns.\n\n# basic use\nmtcars %>%\n  head() %>%\n  gt() %>%\n  gt_color_rows(mpg:disp)\n\nWarning: Domain not specified, defaulting to observed range within each\nspecified column.\n\n\n\n\n\n\n\nmpg\n      cyl\n      disp\n      hp\n      drat\n      wt\n      qsec\n      vs\n      am\n      gear\n      carb\n    \n\n\n21.0\n6\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\n21.0\n6\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\n22.8\n4\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\n21.4\n6\n258\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\n18.7\n8\n360\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\n18.1\n6\n225\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\n\n\n\n\nYou can change the specific palette with palette = \"package_name::palette_name\"\n\n# recognizes all of the dynamic palettes from paletteer\nmtcars %>%\n  head() %>%\n  gt() %>%\n  gt_color_rows(mpg:disp, palette = \"ggsci::blue_material\")\n\nWarning: Domain not specified, defaulting to observed range within each\nspecified column.\n\n\n\n\n\n\n\nmpg\n      cyl\n      disp\n      hp\n      drat\n      wt\n      qsec\n      vs\n      am\n      gear\n      carb\n    \n\n\n21.0\n6\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\n21.0\n6\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\n22.8\n4\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\n21.4\n6\n258\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\n18.7\n8\n360\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\n18.1\n6\n225\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\n\n\n\n\nYou can also use custom-defined palettes with named colors in R or hex color values however, this has minimal value over gt::data_color(). The main difference would be ability to specify a domain and throwing a warning without it.\n\nmtcars %>%\n  head() %>%\n  gt() %>%\n  gt_color_rows(mpg:disp, palette = c(\"white\", \"green\"))\n\nWarning: Domain not specified, defaulting to observed range within each\nspecified column.\n\n\n\n\n\n\n\nmpg\n      cyl\n      disp\n      hp\n      drat\n      wt\n      qsec\n      vs\n      am\n      gear\n      carb\n    \n\n\n21.0\n6\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\n21.0\n6\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\n22.8\n4\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\n21.4\n6\n258\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\n18.7\n8\n360\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\n18.1\n6\n225\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\n\n\n\n    # could also use palette = c(\"#ffffff\", \"##00FF00\")\n\ngt-native example gives you basically the same result.\n\nmtcars %>%\n  head() %>%\n  gt() %>%\n  gt::data_color(mpg:disp, colors = c(\"white\", \"green\"))\n\n\n\n\n\n\nmpg\n      cyl\n      disp\n      hp\n      drat\n      wt\n      qsec\n      vs\n      am\n      gear\n      carb\n    \n\n\n21.0\n6\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\n21.0\n6\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\n22.8\n4\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\n21.4\n6\n258\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\n18.7\n8\n360\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\n18.1\n6\n225\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\n\n\n\n\nLastly, you can also provide categorical or discrete data to be colored.\n\n# provide type = \"discrete\"\nmtcars %>%\n  head() %>%\n  gt() %>%\n  gt_color_rows(\n    cyl, \n    palette = \"ggthemes::colorblind\", \n    # note that you can manually define range like c(4, 6, 8)\n    domain = range(mtcars$cyl),\n    pal_type = \"discrete\"\n   )\n\n\n\n\n\n\nmpg\n      cyl\n      disp\n      hp\n      drat\n      wt\n      qsec\n      vs\n      am\n      gear\n      carb\n    \n\n\n21.0\n6\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\n21.0\n6\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\n22.8\n4\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\n21.4\n6\n258\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\n18.7\n8\n360\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\n18.1\n6\n225\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\n\n\n\n\nAgain, this function is an example of something that is easily possible with gt but would require a good chunk of repeated boilerplate code.\ngt_highlight_rows()\nThis provides the ability to highlight and optionally bold entire rows within an existing gt table. Basic use defaults to a light-blue highlight which can be changed with the fill argument.\n\nhead_car <- head(mtcars[,1:5]) %>% \n  tibble::rownames_to_column(\"car\")\n\ngt(head_car) %>% \n  gt_highlight_rows(rows = 2, font_weight = \"normal\") \n\n\n\n\n\n\ncar\n      mpg\n      cyl\n      disp\n      hp\n      drat\n    \n\n\nMazda RX4\n21.0\n6\n160\n110\n3.90\n\n\nMazda RX4 Wag\n21.0\n6\n160\n110\n3.90\n\n\nDatsun 710\n22.8\n4\n108\n93\n3.85\n\n\nHornet 4 Drive\n21.4\n6\n258\n110\n3.08\n\n\nHornet Sportabout\n18.7\n8\n360\n175\n3.15\n\n\nValiant\n18.1\n6\n225\n105\n2.76\n\n\n\n\n\n\nYou can optionally specify a target column with target_col that will be bold, while the rest of the row’s text will be default weight.\n\ngt(head_car) %>% \n  gt_highlight_rows(\n    rows = 5, \n    fill = \"lightgrey\",\n    bold_target_only = TRUE,\n    target_col = car\n    )\n\n\n\n\n\n\ncar\n      mpg\n      cyl\n      disp\n      hp\n      drat\n    \n\n\nMazda RX4\n21.0\n6\n160\n110\n3.90\n\n\nMazda RX4 Wag\n21.0\n6\n160\n110\n3.90\n\n\nDatsun 710\n22.8\n4\n108\n93\n3.85\n\n\nHornet 4 Drive\n21.4\n6\n258\n110\n3.08\n\n\nHornet Sportabout\n18.7\n8\n360\n175\n3.15\n\n\nValiant\n18.1\n6\n225\n105\n2.76\n\n\n\n\n\n\nAnd because gtExtras is just using gt::tab_style() under the hood, it also accepts logical statements for specific rows.\n\ngt(head_car) %>% \n  gt_highlight_rows(\n    rows = drat == 3.08,# a logic statement\n    fill = \"lightgrey\",\n    bold_target_only = TRUE,\n    target_col = car\n    )\n\n\n\n\n\n\ncar\n      mpg\n      cyl\n      disp\n      hp\n      drat\n    \n\n\nMazda RX4\n21.0\n6\n160\n110\n3.90\n\n\nMazda RX4 Wag\n21.0\n6\n160\n110\n3.90\n\n\nDatsun 710\n22.8\n4\n108\n93\n3.85\n\n\nHornet 4 Drive\n21.4\n6\n258\n110\n3.08\n\n\nHornet Sportabout\n18.7\n8\n360\n175\n3.15\n\n\nValiant\n18.1\n6\n225\n105\n2.76\n\n\n\n\n\n\nThe equivalent gt code - again, easy to figure out but some repeated calls.\n\ngt(head_car) %>%\n  tab_style(\n    style = cell_fill(color = \"lightgrey\"), \n    locations = cells_body(everything(), rows = drat == 3.08)\n    ) %>%\n  tab_style(\n    style = cell_text(weight = \"bold\"),\n    locations = cells_body(car, rows = drat == 3.08)\n  )\n\n\n\n\n\n\ncar\n      mpg\n      cyl\n      disp\n      hp\n      drat\n    \n\n\nMazda RX4\n21.0\n6\n160\n110\n3.90\n\n\nMazda RX4 Wag\n21.0\n6\n160\n110\n3.90\n\n\nDatsun 710\n22.8\n4\n108\n93\n3.85\n\n\nHornet 4 Drive\n21.4\n6\n258\n110\n3.08\n\n\nHornet Sportabout\n18.7\n8\n360\n175\n3.15\n\n\nValiant\n18.1\n6\n225\n105\n2.76"
  },
  {
    "objectID": "posts/2022-06-13-gtextras-cran/index.html#plotting-in-gt-with-gtextras",
    "href": "posts/2022-06-13-gtextras-cran/index.html#plotting-in-gt-with-gtextras",
    "title": "Beautiful tables in R with gtExtras",
    "section": "Plotting in gt with gtExtras\n",
    "text": "Plotting in gt with gtExtras\n\nAs we get into plotting with gt the complexity really ramps up internally, as you’re wrapping gt + ggplot2 code internally.\nNote that if you just want to create ggplot2 plots and embed them in gt, you can use gt::ggplot_image()! That gives you full and separate control of the two items, ie just use ggplot2 and use gt separately.\n\nplot_object <-\n  ggplot(\n    data = gtcars,\n    aes(x = hp, y = trq, size = msrp)\n  ) +\n  geom_point(color = \"blue\") +\n  theme(legend.position = \"none\")\n\ndplyr::tibble(\n  text = \"Here is a ggplot:\",\n  ggplot = NA\n) %>%\n  gt() %>%\n  text_transform(\n    locations = cells_body(columns = ggplot),\n    fn = function(x) {\n      plot_object %>%\n        ggplot_image(height = px(200))\n    }\n  )\n\n\n\n\n\n\ntext\n      ggplot\n    \n\nHere is a ggplot:\n\n\n\n\n\n\nHowever, with the plotting functions in gtExtras, I’ve made some opinionated choices as to the output style/size/options - taking away some of your creativity for a simple to use user interface.\nA side effect of these gtExtras functions is that almost exclusively they require you to pass datasets with list columns. These are easy enough to create!\n\nmtcars %>%\n   dplyr::group_by(cyl) %>%\n   # must end up with list of data for each row in the input dataframe\n   dplyr::summarize(mpg_data = list(mpg), .groups = \"drop\")\n\n# A tibble: 3 × 2\n    cyl mpg_data  \n  <dbl> <list>    \n1     4 <dbl [11]>\n2     6 <dbl [7]> \n3     8 <dbl [14]>\n\n\ngt_sparkline()\nA typical sparkline for your table!\n\nmtcars %>%\n   dplyr::group_by(cyl) %>%\n   # must end up with list of data for each row in the input dataframe\n   dplyr::summarize(mpg_data = list(mpg), .groups = \"drop\") %>%\n   gt() %>%\n   gt_plt_sparkline(mpg_data)\n\n\n\n\n\n\ncyl\n      mpg_data\n    \n\n\n4\n\n21.4\n\n\n\n6\n\n19.7\n\n\n\n8\n\n15.0\n\n\n\n\n\n\n\ngt_plt_dist()\nIf you’d rather plot some distributions, you could use gt_plt_dist(). This functions defaults to an inline density plot, but accepts a type = \"boxplot\", \"histogram\", \"rug_strip\" or \"density\".\n\nmtcars %>%\n   dplyr::group_by(cyl) %>%\n   # must end up with list of data for each row in the input dataframe\n   dplyr::summarize(mpg_data = list(mpg), .groups = \"drop\") %>%\n   gt() %>%\n   gt_plt_dist(mpg_data)\n\n\n\n\n\n\ncyl\n      mpg_data\n    \n\n\n4\n\n\n\n\n\n6\n\n\n\n\n\n8\n\n\n\n\n\n\n\n\n\ngt_bar_plot()\nThe gt_bar_plot function takes an existing gt_tbl object and adds horizontal barplots via native HTML. This is a wrapper around raw HTML strings, gt::text_transform() and gt::cols_align(). Note that values default to being normalized to the percent of the maximum observed value in the specified column. You can turn this off if the values already represent a percentage value representing 0-100.\n\nmtcars %>%\n  head() %>%\n  dplyr::select(cyl, mpg) %>%\n  dplyr::mutate(mpg_pct_max = round(mpg/max(mpg) * 100, digits = 2),\n                mpg_scaled = mpg/max(mpg) * 100) %>%\n  dplyr::mutate(mpg_unscaled = mpg) %>%\n  gt() %>%\n  gt_plt_bar_pct(column = mpg_scaled, scaled = TRUE) %>%\n  gt_plt_bar_pct(column = mpg_unscaled, scaled = FALSE, fill = \"blue\", background = \"lightblue\") %>%\n  cols_align(\"center\", contains(\"scale\")) %>%\n  cols_width(4 ~ px(125),\n             5 ~ px(125))\n\n\n\n\n\n\n\n\n\n\n\n\n\ncyl\n      mpg\n      mpg_pct_max\n      mpg_scaled\n      mpg_unscaled\n    \n\n\n6\n21.0\n92.11\n\n\n\n\n6\n21.0\n92.11\n\n\n\n\n4\n22.8\n100.00\n\n\n\n\n6\n21.4\n93.86\n\n\n\n\n8\n18.7\n82.02\n\n\n\n\n6\n18.1\n79.39\n\n\n\n\n\n\n\n\ngt_merge_stack()\nThe gt_merge_stack() function takes an existing gt table and merges column 1 and column 2, stacking column 1’s text on top of column 2’s. Top text is in all caps with black bold text, while the lower text is smaller and dark grey.\nNote that team_nick has the team nickname over the team’s division.\n\nteam_df <- readRDS(url(\"https://github.com/nflverse/nflfastR-data/raw/master/teams_colors_logos.rds\"))\n\nteam_df %>%\n  dplyr::select(team_nick, team_abbr, team_conf, team_division, team_wordmark) %>%\n  head(8) %>%\n  gt(groupname_col = \"team_conf\") %>%\n  gt_merge_stack(col1 = team_nick, col2 = team_division) %>%\n  gt_img_rows(team_wordmark)\n\n\n\n\n\n\nteam_nick\n      team_abbr\n      team_wordmark\n    \n\n\nNFC\n    \n\n\nCardinals\nNFC West\n\nARI\n\n\n\n\nFalcons\nNFC South\n\nATL\n\n\n\n\nPanthers\nAFC North\n\nCAR\n\n\n\n\nBears\nAFC East\n\nCHI\n\n\n\nAFC\n    \n\n\nRavens\nNFC South\n\nBAL\n\n\n\n\nBills\nNFC North\n\nBUF\n\n\n\n\nBengals\nAFC North\n\nCIN\n\n\n\n\nBrowns\nAFC North\n\nCLE\n\n\n\n\n\n\n\ngt_plt_winloss()\nThis function takes a list-column of win loss values (ie, 0=loss, 0.5 = tie, 1 = win) and ouputs an inline plot representing the win/loss squares with blue = win, red = loss, grey = tie. Points are also also redundantly coded with height, where wins are highest, ties are middle, and losses are at the bottom.\nThe example below generates an example dataset and then embeds a plot.\n\ncreate_input_df <- function(repeats = 3){\n  \n  input_df <- dplyr::tibble(\n    team = c(\"A1\", \"B2\", \"C3\", \"C4\"),\n    Wins = c(3, 2, 1, 1),\n    Losses = c(2, 3, 2, 4),\n    Ties = c(0, 0, 2, 0),\n    outcomes = list(\n      c(1, .5, 0) %>% rep(each = repeats),\n      c(0, 1, 0.5) %>% rep(each = repeats),\n      c(0, 0.5, 1) %>% rep(each = repeats),\n      c(0.5, 1, 0) %>% rep(each = repeats)\n    )\n  )\n  \n  input_df\n  \n}\n\ncreate_input_df(5) %>% \n  dplyr::glimpse()\n\nRows: 4\nColumns: 5\n$ team     <chr> \"A1\", \"B2\", \"C3\", \"C4\"\n$ Wins     <dbl> 3, 2, 1, 1\n$ Losses   <dbl> 2, 3, 2, 4\n$ Ties     <dbl> 0, 0, 2, 0\n$ outcomes <list> <1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.0, 0.0, …\n\n\nNow that we have way to quickly generate example data, we can show the ability to incrementally add the win/losses.\nStarting with 3 games. Please ignore the Wins/Loss/Ties columns, as they are simply placeholders. I am iterating the length of the outcomes list row.\n\ncreate_input_df(1) %>% \n  gt() %>% \n  gt_plt_winloss(outcomes, max_wins = 15) %>% \n  tab_options(data_row.padding = px(2))\n\n\n\n\n\n\nteam\n      Wins\n      Losses\n      Ties\n      outcomes\n    \n\n\nA1\n3\n2\n0\n\n\n\n\n\nB2\n2\n3\n0\n\n\n\n\n\nC3\n1\n2\n2\n\n\n\n\n\nC4\n1\n4\n0\n\n\n\n\n\n\n\n\n\nAnd moving to 12 games, we can see that the scale is unchanged, and “empty” points are replaced with outcomes once the values are present in the data.\n\ncreate_input_df(4) %>% \n  gt() %>% \n  gt_plt_winloss(outcomes, max_wins = 15) %>% \n  tab_options(data_row.padding = px(2))\n\n\n\n\n\n\nteam\n      Wins\n      Losses\n      Ties\n      outcomes\n    \n\n\nA1\n3\n2\n0\n\n\n\n\n\nB2\n2\n3\n0\n\n\n\n\n\nC3\n1\n2\n2\n\n\n\n\n\nC4\n1\n4\n0\n\n\n\n\n\n\n\n\n\nYou can also switch over to ‘squares’ instead of ‘pills’ by changing the type argument.\n\ncreate_input_df(4) %>% \n  gt() %>% \n  gt_plt_winloss(outcomes, max_wins = 15, type = \"square\") %>% \n  tab_options(data_row.padding = px(2))\n\n\n\n\n\n\nteam\n      Wins\n      Losses\n      Ties\n      outcomes\n    \n\n\nA1\n3\n2\n0\n\n\n\n\n\nB2\n2\n3\n0\n\n\n\n\n\nC3\n1\n2\n2\n\n\n\n\n\nC4\n1\n4\n0\n\n\n\n\n\n\n\n\n\nA more realistic use case is seen below with data from nflreadr:\n\nCreating dataset\n\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(nflreadr)\n\ngames_df <- nflreadr::load_schedules() %>% \n  filter(season == 2020, game_type == \"REG\") %>% \n  select(game_id, team_home = home_team, team_away = away_team, result, week) %>% \n  pivot_longer(contains('team'), names_to = 'home_away', values_to = 'team', names_prefix = 'team_') %>% \n  mutate(\n    result = ifelse(home_away == 'home', result, -result),\n    win = ifelse(result == 0 , 0.5, ifelse(result > 0, 1, 0))\n  ) %>% \n  select(week, team, win) %>% \n  mutate(\n    team = case_when(\n      team == 'STL' ~ 'LA',\n      team == 'OAK' ~ 'LV',\n      team == 'SD' ~ 'LAC',\n      T ~ team\n    )\n  )\n\nteam_df <- nflreadr::load_teams() %>% \n  select(team_wordmark, team_abbr, team_conf, team_division)\n\njoined_df <- games_df %>% \n  group_by(team) %>% \n  summarise(\n    Wins = length(win[win==1]),\n    Losses = length(win[win==0]),\n    outcomes = list(win), .groups = \"drop\") %>% \n  left_join(team_df, by = c(\"team\" = \"team_abbr\")) %>% \n  select(team_wordmark, team_conf, team_division, Wins:outcomes)\n\nfinal_df <- joined_df %>% \n  filter(team_conf == \"AFC\") %>% \n  group_by(team_division) %>% \n  arrange(desc(Wins)) %>% \n  ungroup() %>% \n  arrange(team_division)\n\n\nfinal_df %>% \n  gt(groupname_col = \"team_division\") %>%\n  gt_plt_winloss(outcomes, max_wins = 16) %>% \n  gt_img_rows(columns = team_wordmark) %>% \n  gt_theme_538() %>% \n  tab_header(title = \"2020 Results by Division for the AFC\")\n\n\n\n\n\n\n2020 Results by Division for the AFC\n    \n\nteam_wordmark\n      team_conf\n      Wins\n      Losses\n      outcomes\n    \n\n\nAFC East\n    \n\n\nAFC\n13\n3\n\n\n\n\n\n\nAFC\n10\n6\n\n\n\n\n\n\nAFC\n7\n9\n\n\n\n\n\n\nAFC\n2\n14\n\n\n\n\n\nAFC North\n    \n\n\nAFC\n12\n4\n\n\n\n\n\n\nAFC\n11\n5\n\n\n\n\n\n\nAFC\n11\n5\n\n\n\n\n\n\nAFC\n4\n11\n\n\n\n\n\nAFC South\n    \n\n\nAFC\n11\n5\n\n\n\n\n\n\nAFC\n11\n5\n\n\n\n\n\n\nAFC\n4\n12\n\n\n\n\n\n\nAFC\n1\n15\n\n\n\n\n\nAFC West\n    \n\n\nAFC\n14\n2\n\n\n\n\n\n\nAFC\n8\n8\n\n\n\n\n\n\nAFC\n7\n9\n\n\n\n\n\n\nAFC\n5\n11"
  },
  {
    "objectID": "posts/2022-06-13-gtextras-cran/index.html#closing",
    "href": "posts/2022-06-13-gtextras-cran/index.html#closing",
    "title": "Beautiful tables in R with gtExtras",
    "section": "Closing",
    "text": "Closing\nSo that has been a brief overview of some of the possibilities of gtExtras - so go out, use gt, bring in gtExtras when you’d like to extend some of the work you’re doing and let me know if you enjoy the package!\n\n\n\n\n\n\nExpand for Session Info\n\n\n\n\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.0 (2022-04-22)\n os       macOS Monterey 12.2.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       America/Chicago\n date     2022-06-13\n pandoc   2.18 @ /Applications/RStudio.app/Contents/MacOS/quarto/bin/tools/ (via rmarkdown)\n quarto   0.9.577 @ /usr/local/bin/quarto\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version  date (UTC) lib source\n dplyr       * 1.0.9    2022-04-28 [1] CRAN (R 4.2.0)\n forcats     * 0.5.1    2021-01-27 [1] CRAN (R 4.2.0)\n ggplot2     * 3.3.6    2022-05-03 [1] CRAN (R 4.2.0)\n gt          * 0.6.0    2022-05-24 [1] CRAN (R 4.2.0)\n gtExtras    * 0.4.0    2022-06-09 [1] CRAN (R 4.2.0)\n nflreadr    * 1.2.0.12 2022-06-02 [1] Github (nflverse/nflreadr@94e3400)\n purrr       * 0.3.4    2020-04-17 [1] CRAN (R 4.2.0)\n readr       * 2.1.2    2022-01-30 [1] CRAN (R 4.2.0)\n sessioninfo * 1.2.2    2021-12-06 [1] CRAN (R 4.2.0)\n stringr     * 1.4.0    2019-02-10 [1] CRAN (R 4.2.0)\n tibble      * 3.1.7    2022-05-03 [1] CRAN (R 4.2.0)\n tidyr       * 1.2.0    2022-02-01 [1] CRAN (R 4.2.0)\n tidyverse   * 1.3.1    2021-04-15 [1] CRAN (R 4.2.0)\n\n [1] /Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/library\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "posts/2020-05-29-client-side-interactivity-do-more-with-crosstalk/index.html",
    "href": "posts/2020-05-29-client-side-interactivity-do-more-with-crosstalk/index.html",
    "title": "Client-side interactivity - do more with Crosstalk",
    "section": "",
    "text": "Greg Lin, the author of reactable recently added support for crosstalk to the package! This is great, because it allows you to do many things:\n\nAdd client-side interactivity\n\neg Shiny-lite without a server!\n\n\n\nCombine interactivity between multiple HTML Widgets\n\nHave a interactive plot interact with an interactive table\n\n\n\nPass client-side interactions back to a Shiny runtime\n\nWe’ll continue on our example use-cases of interactive tables w/ reactable, but now add in a bit of crosstalk to show how this can be useful.\nMy previous posts on:\n- reactable - How to guide for interactive tables\n- gt - How to guide for static tables"
  },
  {
    "objectID": "posts/2020-05-29-client-side-interactivity-do-more-with-crosstalk/index.html#prep-the-data",
    "href": "posts/2020-05-29-client-side-interactivity-do-more-with-crosstalk/index.html#prep-the-data",
    "title": "Client-side interactivity - do more with Crosstalk",
    "section": "Prep the data",
    "text": "Prep the data\nLet’s read in our data - however note that this is long-format, so it’s not ideal for our summary table. We’ll tidyr::pivot_wider() in the next step and use some new dplyr features!\nHowever we can see that we have:\n- a passer\n- a draft round variable (round)\n- total touchdowns thrown (n)\n- total touchdowns thrown (total)\n- the ratio of touchdowns thrown per round relative to the total touchdowns normalized to each passer (ratio).\n\nlibrary(htmltools)\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──\n\n\n✔ ggplot2 3.3.5     ✔ purrr   0.3.4\n✔ tibble  3.1.6     ✔ dplyr   1.0.8\n✔ tidyr   1.2.0     ✔ stringr 1.4.0\n✔ readr   2.1.2     ✔ forcats 0.5.1\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(reactable)\n\n# read in our summary data\nsummary_qbs <- readr::read_rds(\"summary_qbs.rds\")\n\nglimpse(summary_qbs)\n\nRows: 96\nColumns: 5\n$ passer <chr> \"Aaron Rodgers\", \"Aaron Rodgers\", \"Aaron Rodgers\", \"Aaron Rodge…\n$ rnd    <fct> Rnd 1, Rnd 2, Rnd 3, Rnd 4, Rnd 5, Rnd 6, Rnd 7, Undrafted, Rnd…\n$ n      <int> 1, 191, 82, 5, 23, 6, 24, 32, 69, 31, 101, 35, 17, 77, 3, 32, 6…\n$ total  <int> 364, 364, 364, 364, 364, 364, 364, 364, 365, 365, 365, 365, 365…\n$ ratio  <dbl> 0.002747253, 0.524725275, 0.225274725, 0.013736264, 0.063186813…\n\n\nWe’ll use tidyr::unnest_wider() to widen this data where each passer/QB get their own row and the round of their receivers get their own column. This is ready to go into it’s own table!\n\n# make the data wider\nwide_qbs <- summary_qbs %>% \n  # drop total TDs\n  select(passer, rnd, ratio) %>% \n  # round the ratio (we don't need 8 digits of accuracy)\n  mutate(ratio = round(ratio, digits = 3)) %>% \n  # Move rnd and ratio to wide-form data\n  pivot_wider(\n    names_from = rnd, \n    values_from = ratio\n    ) %>% \n  group_by(passer) %>% \n  mutate(\n    # Createa a top 3 rounds var\n    `Rnds 1-3` = `Rnd 1`+ `Rnd 2` + `Rnd 3`, \n    # this is a dplyr 1.0 feature\n    # place the new column before Undrafted - new to dplyr 1.0\n    .before = Undrafted) %>% \n  ungroup() # always ungroup!\n\nwide_qbs %>% \n  glimpse()\n\nRows: 12\nColumns: 10\n$ passer     <chr> \"Aaron Rodgers\", \"Ben Roethlisberger\", \"Carson Palmer\", \"Dr…\n$ `Rnd 1`    <dbl> 0.003, 0.189, 0.196, 0.190, 0.358, 0.514, 0.406, 0.547, 0.1…\n$ `Rnd 2`    <dbl> 0.525, 0.085, 0.227, 0.112, 0.212, 0.000, 0.196, 0.030, 0.1…\n$ `Rnd 3`    <dbl> 0.225, 0.277, 0.221, 0.152, 0.098, 0.168, 0.100, 0.076, 0.0…\n$ `Rnd 4`    <dbl> 0.014, 0.096, 0.012, 0.042, 0.040, 0.112, 0.025, 0.132, 0.1…\n$ `Rnd 5`    <dbl> 0.063, 0.047, 0.081, 0.029, 0.064, 0.022, 0.085, 0.020, 0.0…\n$ `Rnd 6`    <dbl> 0.016, 0.211, 0.025, 0.004, 0.042, 0.012, 0.075, 0.043, 0.0…\n$ `Rnd 7`    <dbl> 0.066, 0.008, 0.146, 0.141, 0.019, 0.028, 0.000, 0.004, 0.0…\n$ `Rnds 1-3` <dbl> 0.753, 0.551, 0.644, 0.454, 0.668, 0.682, 0.702, 0.653, 0.3…\n$ Undrafted  <dbl> 0.088, 0.088, 0.090, 0.331, 0.167, 0.143, 0.114, 0.148, 0.4…"
  },
  {
    "objectID": "posts/2020-05-29-client-side-interactivity-do-more-with-crosstalk/index.html#create-a-color-palette",
    "href": "posts/2020-05-29-client-side-interactivity-do-more-with-crosstalk/index.html#create-a-color-palette",
    "title": "Client-side interactivity - do more with Crosstalk",
    "section": "Create a color palette",
    "text": "Create a color palette\nWe’ll create a color palette function using viridis.\n\n# create a color function\nvir_scale_col <- function(x) rgb(colorRamp(c(viridis::viridis_pal(begin = 0.5, end = 1)(10) %>% rev()))(x), maxColorValue = 255)\n\n# min val of ratio\nqb_min <- summary_qbs %>% \n  summarize(min = min(ratio)) %>% \n  pull(min)\n\n# max value of ratio\nqb_max <- summary_qbs %>% \n  filter(rnd %in% c(\"Rnd 1\", \"Rnd 2\", \"Rnd 3\")) %>% \n  group_by(passer) %>% \n  summarize(sum = sum(ratio)) %>% \n  summarize(max = max(sum) + 0.01) %>% \n  pull(max)\n\n# show the range from min to max\nseq(from = qb_min, to = qb_max, length.out = 9) %>% \n  vir_scale_col() %>% scales::show_col()"
  },
  {
    "objectID": "posts/2020-05-29-client-side-interactivity-do-more-with-crosstalk/index.html#create-the-table",
    "href": "posts/2020-05-29-client-side-interactivity-do-more-with-crosstalk/index.html#create-the-table",
    "title": "Client-side interactivity - do more with Crosstalk",
    "section": "Create the table",
    "text": "Create the table\nNow we can create the table - here is the basic table that gets us most of the way!\nI’ve added comments to the code so you can see what the arguments do.\n\n\ntable_out <- wide_qbs %>% \n  reactable(\n    pagination = FALSE, # all one page\n    searchable = TRUE,  # add a search bar\n    striped = TRUE,  # add stripes\n    highlight = TRUE, # highlight on hover\n    compact = TRUE, # compact the table\n    fullWidth = FALSE, # don't fill the page\n    defaultSortOrder = \"desc\", # default to descending order sort\n    defaultSorted = c(\"Rnd 1\"), # default to sorting by Rnd 1 val\n    # apply our color function across numeric values\n    defaultColDef = colDef(\n      style = function(value) {\n        if (!is.numeric(value)) return()\n        normalized <- value/0.756\n        color <- vir_scale_col(normalized)\n        list(background = color, fontWeight = \"bold\")\n      },\n      # convert to percent for numeric\n      format = colFormat(percent = TRUE, digits = 1),\n      # default to 80px wide\n      minWidth = 80\n    )\n    )\n\ntable_out\n\n\n\n\n\n\n\nWe’ll add in a few fonts (locally this time, instead of from Google), add some additional styling, and then I’m happy with this as an output table. Feel free to compare to what round of receivers QBs are throwing to, and you have filtering via the search bar.\nWhile Aaron Rodgers hasn’t thrown hardly any passes to 1st Rounders - he actually leads this group in passes thrown to 1st, 2nd and 3rd rounders! The story can change a bit based on how you choose the data/cutoff. However, there’s a bit more to this story that is missing from the below table.\n\n\ntable_out <- wide_qbs %>%\n  reactable(\n    pagination = FALSE, # all one page\n    searchable = TRUE, # add a search bar\n    striped = TRUE, # add stripes\n    highlight = TRUE, # highlight on hover\n    compact = TRUE, # compact the table\n    fullWidth = FALSE, # don't fill the page\n    defaultSortOrder = \"desc\", # default to descending order sort\n    defaultSorted = c(\"Rnd 1\"), # default to sorting by Rnd 1 val\n    # apply our color function across numeric values\n    defaultColDef = colDef(\n      style = function(value) {\n        if (!is.numeric(value)) return()\n        normalized <- value / 0.756\n        color <- vir_scale_col(normalized)\n        list(background = color, fontWeight = \"bold\")\n      },\n      # convert to percent for numeric\n      format = colFormat(percent = TRUE, digits = 1),\n      # default to 80px wide\n      minWidth = 80\n    ),\n    ### Additions made below ###\n    ############################\n\n    # change specific columns from default\n    columns = list(\n      passer = colDef(\n        name = \"QB\", # change display name\n        minWidth = 150, # widen the column\n        # highlight Aaron Rodgers\n        style = function(value) {\n          weight_name <- if (value == \"Aaron Rodgers\") {\n            800\n          } else if (value != \"Aaron Rodgers\") {\n            500\n          }\n          list(fontWeight = weight_name, fontFamily = \"Lato\")\n        }\n      ),\n      Undrafted = colDef(\n        name = \"UDFA\"\n      )\n    ),\n    theme = reactableTheme(\n      # set a default theme for font across table\n      style = list(fontFamily = \"Fira Mono\")\n    )\n  )\n\n# Note I'm using htmltools to build up these div containers\n# for better web display as I'm using RMarkdown to build up a webpage.\ndiv(\n  h2(\"Percent of Touchdowns thrown to players by draft round\"),\n  h3(\"Normalized to each passer's total passing touchdowns\"),\n  table_out,\n  \"Table: @thomas_mock | Data: pro-football-reference.com\"\n)\n\n\n\nPercent of Touchdowns thrown to players by draft round\nNormalized to each passer's total passing touchdowns\n\n\nTable: @thomas_mock | Data: pro-football-reference.com\n\n\n\n\n\nThis table shows us a lot - Rodgers actually has thrown the most passes to 2nd Round receivers of any of these QBs, and the most passes to 1st, 2nd or 3rd Round receivers, along with the fewest passes to undrafted receivers! Not quite, the same storyline. An additional consideration - where in the overall draft were the players catching passes taken?\nSpoiler - most of Rodger’s receivers were actually top 4-5 WRs in their respective draft classes."
  },
  {
    "objectID": "posts/2020-05-29-client-side-interactivity-do-more-with-crosstalk/index.html#crosstalk-add-ons",
    "href": "posts/2020-05-29-client-side-interactivity-do-more-with-crosstalk/index.html#crosstalk-add-ons",
    "title": "Client-side interactivity - do more with Crosstalk",
    "section": "\ncrosstalk add ons",
    "text": "crosstalk add ons\nSo that table is interactive, but it’s all sorting. What about all the special crosstalk features?\nWe can align some filters and the table together with bootstrap columns (similar to setting up shiny structure). These come along with loading crosstalk. Note that this is because I’m working in a traditional RMarkdown to build this distill website, and if I were using something like flexdashboard, it has alternate and more robust methods of aligning various plots, tables, control boxes, etc.\nAlso! Note that because I’m using the shared data across multiple areas, if I filter at any stage it will effect ALL the shared data tables. So if you play with the example below, make sure to reset all the settings before continuing on.\n\n\n\n# bootstrap columns\nh3(\"Interactive QB Table with Filtering\")\n\n\nInteractive QB Table with Filtering\n\nbscols(\n  # bootstrap is built off a 12 wide grid system,\n  # so we have 1/6 and 5/6 width below\n  widths = c(2, 10),\n  list(\n    # Create shiny-esque filters\n    # Note that we are defining:\n    # a name for the filter\n    # a display name for the filter\n    # a shared data object\n    # and a column of interest (w/ a ~)\n    filter_checkbox(\"type\", \"Round\", wr_data, ~rnd),\n    filter_slider(\"tds\", \"Total TDs\", wr_data, ~n, width = \"100%\"),\n    filter_slider(\"pos_rank\", \"Pos Rank\", wr_data, ~pos_rank, width = \"100%\"),\n    filter_select(\"qb\", \"Quarterback\", wr_data, ~passer)\n  ),\n  # add our table next to the filters\n  wr_table\n)\n\n\n\n\n\n\nRound\n\n\n\nRnd 1\n\n\n\n\nRnd 2\n\n\n\n\nRnd 3\n\n\n\n\nRnd 4\n\n\n\n\nRnd 5\n\n\n\n\nRnd 6\n\n\n\n\nRnd 7\n\n\n\n\nUDFA\n\n\n\n\n\n\nTotal TDs\n\n\n\nPos Rank\n\n\n\nQuarterback\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThat’s it! No setting up shiny, no server, you get all this filtering for free! Now there’s still a spectrum where shiny adds a LOT of value - namely, I want to do more custom work and need to execute additional R code!"
  },
  {
    "objectID": "posts/2020-05-29-client-side-interactivity-do-more-with-crosstalk/index.html#additional-crosstalk-features",
    "href": "posts/2020-05-29-client-side-interactivity-do-more-with-crosstalk/index.html#additional-crosstalk-features",
    "title": "Client-side interactivity - do more with Crosstalk",
    "section": "Additional crosstalk features",
    "text": "Additional crosstalk features\nNow while the table-level filtering is nice, you can also communicate between various crosstalk enabled widgets, including plotly graphs, reactable, DT, and leaflet.\nThis is a rather minimal example as far as plotly, but you can see some of the interaction across the 3 levels (filters, plotly, reactable). The main additions I have for plotly are adding specific hover text.\nAs a fun exploration - try filtering Pos Rank to 1-5 - Rodgers has 7 receivers in this category.\n\n\nlibrary(plotly)\n\n\nAttaching package: 'plotly'\n\n\nThe following object is masked from 'package:ggplot2':\n\n    last_plot\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\nThe following object is masked from 'package:graphics':\n\n    layout\n\n# add a div so that the various components get bound together\ndiv(\n  h3(\"Compare and filter WR touchdowns by QB, Round, or Draft Position\"),\n  h4(\"Filter by: round drafted, total TDs, positional rank drafted, or QB\"),\n  # use bootstrap columns for the crosstalk stuff\n  bscols(\n  # bootstrap is built off a 12 wide grid system,\n  # so we have 1/6 and 5/6 width below\n  widths = c(2, 10),\n  list(\n    # Create shiny-esque filters\n    filter_checkbox(\"type\", \"Round\", wr_data, ~rnd),\n    filter_slider(\"tds\", \"Total TDs\", wr_data, ~n, width = \"100%\"),\n    filter_slider(\"pos_rank\", \"Pos Rank\", wr_data, ~pos_rank, width = \"100%\"),\n    filter_select(\"qb\", \"Quarterback\", wr_data, ~passer)\n  ),\n  # add our table next to the filters\n  plot_ly(wr_data, y = ~passer, x = ~n, \n          color = ~passer, text = ~scorer_receiver) %>% \n  add_bars(width = 1,\n           # Add specific text to hover\n           hovertemplate = \"%{text}<br>%{x} TDs\") %>% \n    # reverse the Y axis\n    layout(yaxis = list(autorange = \"reversed\"))\n),\nwr_table,\n\"Graphic: @thomas_mock | Data: Pro-football-reference.com\"\n)\n\n\n\nCompare and filter WR touchdowns by QB, Round, or Draft Position\nFilter by: round drafted, total TDs, positional rank drafted, or QB\n\n\n\n\nRound\n\n\n\nRnd 1\n\n\n\n\nRnd 2\n\n\n\n\nRnd 3\n\n\n\n\nRnd 4\n\n\n\n\nRnd 5\n\n\n\n\nRnd 6\n\n\n\n\nRnd 7\n\n\n\n\nUDFA\n\n\n\n\n\n\nTotal TDs\n\n\n\nPos Rank\n\n\n\nQuarterback\n\n\n\n\n\n\n\n\n\n\n\n\n\nGraphic: @thomas_mock | Data: Pro-football-reference.com\n\n\n\n\n\nSo overall - we’re able to do some exploration of the data at specific filters very easily and without having to setup or do a lot of extra work.\nFollowup\nThis can be further extended to shiny - where some of the interaction can happen at the level of the client (ie JavaScript) and other portions can be pushed down to R (shiny) or even a database backend (ie SQL).\nHopefully this gives you an additional picture as to WHY interactive tables and/or client-side interactivity can help expand your ability to share details in R.\nThat’s out of scope for today, but reading material at:\n- Free plotly R book\n- crosstalk + Shiny website\n\n\n\n\n\n\nExpand for Session Info\n\n\n\n\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.0 (2022-04-22)\n os       macOS Monterey 12.2.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       America/Chicago\n date     2022-04-28\n pandoc   2.18 @ /Applications/RStudio.app/Contents/MacOS/quarto/bin/tools/ (via rmarkdown)\n quarto   0.9.294 @ /usr/local/bin/quarto\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version date (UTC) lib source\n crosstalk   * 1.2.0   2021-11-04 [1] CRAN (R 4.2.0)\n dplyr       * 1.0.8   2022-02-08 [1] CRAN (R 4.2.0)\n forcats     * 0.5.1   2021-01-27 [1] CRAN (R 4.2.0)\n ggplot2     * 3.3.5   2021-06-25 [1] CRAN (R 4.2.0)\n htmltools   * 0.5.2   2021-08-25 [1] CRAN (R 4.2.0)\n plotly      * 4.10.0  2021-10-09 [1] CRAN (R 4.2.0)\n purrr       * 0.3.4   2020-04-17 [1] CRAN (R 4.2.0)\n reactable   * 0.2.3   2020-10-04 [1] CRAN (R 4.2.0)\n readr       * 2.1.2   2022-01-30 [1] CRAN (R 4.2.0)\n sessioninfo * 1.2.2   2021-12-06 [1] CRAN (R 4.2.0)\n stringr     * 1.4.0   2019-02-10 [1] CRAN (R 4.2.0)\n tibble      * 3.1.6   2021-11-07 [1] CRAN (R 4.2.0)\n tidyr       * 1.2.0   2022-02-01 [1] CRAN (R 4.2.0)\n tidyverse   * 1.3.1   2021-04-15 [1] CRAN (R 4.2.0)\n\n [1] /Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/library\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "posts/2020-12-13-extracting-json-from-websites-and-public-apis-with-r/index.html",
    "href": "posts/2020-12-13-extracting-json-from-websites-and-public-apis-with-r/index.html",
    "title": "Extracting JSON data from websites and public APIs with R",
    "section": "",
    "text": "I’ve covered some strategies for parsing JSON with a few methods in base R and/or tidyverse in a previous blog post. I’d like to go one step up in the chain, and talk about pulling raw data/JSON from sites. While having a direct link to JSON is common, in some situations where you’re scraping JavaScript fed by APIs the raw data source is not always as easy to find.\nI have three examples for today:\n- FiveThirtyEight 2020 NFL Predictions\n- ESPN Win Percentage/play-by-play (embedded JSON)\n- ESPN Public API\n\nMost of these JSON data sources are intended to be used with JavaScript methods, and have not been oriented to a “flat” data style. This means the JSON has lots of separations of the data for a specific use/purpose inside the site, and efficient singular representations of each data in JSON storage as opposed to normalized data with repeats in a dataframe. While extreme detail is out of scope for this blogpost, JSON is structured as a “collection of name/value pairs” or a “an ordered list of values”. This means it is typically represented in R as repeated lists of list elements, where the list elements can be named lists, vectors, dataframes, or character strings.\nAlternatively typically data for analysis is usually most useful as a normalized rectangle eg a dataframe/tibble. “Under the hood a data frame is a list of equal length vectors” per Advanced R.\nOne step further is tidy data which is essentially “3rd normal form”. Hadley goes into more detail in his “Tidy Data” publication. The takeaway here is that web designers are optimizing for their extremely focused interactive JavaScript apps and websites, as opposed to novel analyses that we often want to work with. This is often why there are quite a few steps to “rectangle” a JSON."
  },
  {
    "objectID": "posts/2020-12-13-extracting-json-from-websites-and-public-apis-with-r/index.html#rvest",
    "href": "posts/2020-12-13-extracting-json-from-websites-and-public-apis-with-r/index.html#rvest",
    "title": "Extracting JSON data from websites and public APIs with R",
    "section": "rvest",
    "text": "rvest\nWe can try our classical rvest based approach to scrape the HTML content and get back a table. However, the side effect of this is we’re returning the literal data with units, some combined columns, and other formatting. You’ll notice that all the columns show up as character and this introduces a lot of other work we’d have to do to “clean” the data.\n\nlibrary(xml2)\nlibrary(rvest)\n\nurl_538 <- \"https://projects.fivethirtyeight.com/2020-nfl-predictions/\"\n\nraw_538_html <- read_html(url_538)\n\nraw_538_table <- raw_538_html %>% \n  html_node(\"#standings-table\") %>% \n  html_table(fill = TRUE) %>% \n  janitor::clean_names() %>% \n  tibble()\n\nraw_538_table %>% glimpse()\n\nRows: 36\nColumns: 12\n$ x                 <chr> \"\", \"\", \"\", \"elo with top qbelo rating\", \"1734\", \"17…\n$ x_2               <chr> \"\", \"\", \"\", \"1-week change\", \"+34\", \"\", \"\", \"\", \"\", …\n$ x_3               <chr> \"\", \"\", \"\", \"current qb adj.\", \"\", \"\", \"\", \"\", \"\", \"…\n$ x_4               <chr> \"\", \"playoff chances\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"…\n$ x_5               <chr> \"playoff chances\", \"playoff chances\", \"\", \"team\", \"B…\n$ x_6               <chr> \"playoff chances\", \"playoff chances\", \"\", \"division\"…\n$ playoff_chances   <chr> \"playoff chances\", \"playoff chances\", \"\", \"make div.…\n$ playoff_chances_2 <chr> \"playoff chances\", NA, \"\", \"make conf. champ\", \"✓\", …\n$ playoff_chances_3 <chr> NA, NA, \"\", \"make super bowl\", \"✓\", \"✓\", \"—\", \"—\", \"…\n$ playoff_chances_4 <chr> NA, NA, \"\", \"win super bowl\", \"✓\", \"—\", \"—\", \"—\", \"—…\n$ x_7               <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ x_8               <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …"
  },
  {
    "objectID": "posts/2020-12-13-extracting-json-from-websites-and-public-apis-with-r/index.html#inspect-network",
    "href": "posts/2020-12-13-extracting-json-from-websites-and-public-apis-with-r/index.html#inspect-network",
    "title": "Extracting JSON data from websites and public APIs with R",
    "section": "Inspect + Network",
    "text": "Inspect + Network\nAlternatively, we can Right Click + inspect the site, go to the Network tab, reload the site and see what sources are loaded. Again, FiveThirtyEight is very kind and essentially just loads the JSON as data.json.\nI have screenshots below of each item, and the below is a short video of the entire process.\n\n\nNetwork Tab\nNetwork Tab Reloaded\nNetwork Tab Data\n\n\n\nWe can click over to the Network Tab after inspecting the site\n\n\n\n\n\n\n\nWe need to reload the web page to find sources\n\n\n\n\n\n\n\nWe can examine specific elements by clicking on them, which then shows us JSON!\n\n\n\n\n\n\n\n\n\n\nIn our browser inspect, we can see the structure, and that it has some info about games, QBs, and forecasts. This looks like the right dataset! You can right click on data.json and open it in a new page. The url is https://projects.fivethirtyeight.com/2020-nfl-predictions/data.json, and note that we can adjust the year to get older or current data. So https://projects.fivethirtyeight.com/2019-nfl-predictions/data.json returns the data for 2019, and you can go all the way back to 2016! 2015 also exists, but with a different JSON structure, and AFAIK they don’t have data before 2015.\nRead the JSON\nNow that we have a JSON source, we can read it into R with jsonlite. By using the RStudio viewer or listviewer::jsonedit() we can take a look at what the overall structure of the JSON.\n\nlibrary(jsonlite)\n\nraw_538_json <- fromJSON(\"https://projects.fivethirtyeight.com/2020-nfl-predictions/data.json\", simplifyVector = FALSE)\n\nraw_538_json %>% str(max.level = 1)\n\nList of 9\n $ archie                :List of 24\n $ clinches              :List of 114\n $ distances             :List of 32\n $ games                 :List of 269\n $ pageconfig            :List of 20\n $ playoff_qb_adjustments:List of 32\n $ qbs                   :List of 87\n $ urls                  :List of 2\n $ weekly_forecasts      :List of 2\n\n\nDon’t forget that the RStudio Viewer also gives you the ability to export the base R code to access a specific component of the JSON!\n\n\nScreenshot of RStudio Viewer\n\n\nWhich gives us the following code:\nraw_538_json[[\"weekly_forecasts\"]][[\"forecasts\"]][[1]][[\"types\"]][[\"elo\"]][[1]]\n\nex_538_data <- raw_538_json[[\"weekly_forecasts\"]][[\"forecasts\"]][[1]][[\"types\"]][[\"elo\"]][[1]]\n\nex_538_data %>% str()\n\nList of 29\n $ conference           : chr \"NFC\"\n $ current_losses       : int 9\n $ current_ties         : int 0\n $ current_wins         : int 7\n $ division             : chr \"NFC North\"\n $ elo                  : num 1489\n $ losses               : int 9\n $ make_conference_champ: int 0\n $ make_divisional_round: int 0\n $ make_playoffs        : int 0\n $ make_superbowl       : int 0\n $ name                 : chr \"MIN\"\n $ point_diff           : int -45\n $ points_allowed       : int 475\n $ points_scored        : int 430\n $ rating               : num 1481\n $ rating_current       : num 1502\n $ rating_top           : num 1502\n $ seed_1               : int 0\n $ seed_2               : int 0\n $ seed_3               : int 0\n $ seed_4               : int 0\n $ seed_5               : int 0\n $ seed_6               : int 0\n $ seed_7               : int 0\n $ ties                 : int 0\n $ win_division         : int 0\n $ win_superbowl        : int 0\n $ wins                 : int 7\n\n\nWe can also play around with listviewer.\n\nraw_538_json %>% \n  listviewer::jsonedit()\n\n\n\n\n\n\nSince these are unique list elements, we can turn it into a dataframe! This is the current projection for Minnesota.\n\ndata.frame(ex_538_data) %>% glimpse()\n\nRows: 1\nColumns: 29\n$ conference            <chr> \"NFC\"\n$ current_losses        <int> 9\n$ current_ties          <int> 0\n$ current_wins          <int> 7\n$ division              <chr> \"NFC North\"\n$ elo                   <dbl> 1489.284\n$ losses                <int> 9\n$ make_conference_champ <int> 0\n$ make_divisional_round <int> 0\n$ make_playoffs         <int> 0\n$ make_superbowl        <int> 0\n$ name                  <chr> \"MIN\"\n$ point_diff            <int> -45\n$ points_allowed        <int> 475\n$ points_scored         <int> 430\n$ rating                <dbl> 1480.954\n$ rating_current        <dbl> 1501.583\n$ rating_top            <dbl> 1501.583\n$ seed_1                <int> 0\n$ seed_2                <int> 0\n$ seed_3                <int> 0\n$ seed_4                <int> 0\n$ seed_5                <int> 0\n$ seed_6                <int> 0\n$ seed_7                <int> 0\n$ ties                  <int> 0\n$ win_division          <int> 0\n$ win_superbowl         <int> 0\n$ wins                  <int> 7"
  },
  {
    "objectID": "posts/2020-12-13-extracting-json-from-websites-and-public-apis-with-r/index.html#parse-the-json",
    "href": "posts/2020-12-13-extracting-json-from-websites-and-public-apis-with-r/index.html#parse-the-json",
    "title": "Extracting JSON data from websites and public APIs with R",
    "section": "Parse the JSON",
    "text": "Parse the JSON\nOk so we’ve found at least one set of data that is pretty dataframe ready, let’s clean it all up in bulk! I’m most interested in the weekly_forecasts data, so let’s start there.\n\nraw_538_json$weekly_forecasts %>% str(max.level = 1)\n\nList of 2\n $ last_updated: chr \"2021-02-08T03:15:55.357Z\"\n $ forecasts   :List of 22\n\n\nOk so last_updated is good to know, but not something I need right now. Let’s go one step deeper into forecasts.\n\nraw_538_json$weekly_forecasts$forecasts %>% str(max.level = 1)\n\nList of 22\n $ :List of 3\n $ :List of 3\n $ :List of 3\n $ :List of 3\n $ :List of 3\n $ :List of 3\n $ :List of 3\n $ :List of 3\n $ :List of 3\n $ :List of 3\n $ :List of 3\n $ :List of 3\n $ :List of 3\n $ :List of 3\n $ :List of 3\n $ :List of 3\n $ :List of 3\n $ :List of 3\n $ :List of 3\n $ :List of 3\n $ :List of 3\n $ :List of 3\n\n\nOk now we have a list of 14 lists. This may seem not helpful, BUT remember that as of 2020-12-12, we are in Week 14 of the NFL season! So this is likely 1 list for each of the weekly forecasts, which makes sense as we are in weekly_forecasts$forecasts!\nAt this point, I think I’m at the right data, so I’m going to take the list and put it in a tibble via tibble::enframe().\n\nraw_538_json$weekly_forecasts$forecasts %>% \n  enframe()\n\n# A tibble: 22 × 2\n    name value           \n   <int> <list>          \n 1     1 <named list [3]>\n 2     2 <named list [3]>\n 3     3 <named list [3]>\n 4     4 <named list [3]>\n 5     5 <named list [3]>\n 6     6 <named list [3]>\n 7     7 <named list [3]>\n 8     8 <named list [3]>\n 9     9 <named list [3]>\n10    10 <named list [3]>\n# … with 12 more rows\n\n\nWe need to separate the list items out, so we can try unnest_auto() to see if tidyr can parse the correct structure. Note that unnest_auto works and tells us we could have used unnest_wider().\n\nraw_538_json$weekly_forecasts$forecasts %>% \n  enframe() %>% \n  unnest_auto(value)\n\nUsing `unnest_wider(value)`; elements have 3 names in common\n\n\n# A tibble: 22 × 4\n    name last_updated              week types           \n   <int> <chr>                    <int> <list>          \n 1     1 2021-02-08T03:15:55.357Z    21 <named list [2]>\n 2     2 2021-01-25T03:10:04.809Z    20 <named list [2]>\n 3     3 2021-01-22T19:28:01.278Z    19 <named list [2]>\n 4     4 2021-01-15T01:25:55.192Z    18 <named list [2]>\n 5     5 2021-01-09T16:38:13.126Z    17 <named list [2]>\n 6     6 2021-01-03T16:03:42.517Z    16 <named list [2]>\n 7     7 2020-12-24T01:32:05.045Z    15 <named list [2]>\n 8     8 2020-12-16T14:13:49.344Z    14 <named list [2]>\n 9     9 2020-12-10T16:21:56.731Z    13 <named list [2]>\n10    10 2020-12-06T15:29:51.523Z    12 <named list [2]>\n# … with 12 more rows\n\n\nWe can keep going on the types list column! Note that as unnest_auto() tells us “what” to do, I’m going to replace it with the appropriate function.\n\nraw_538_json$weekly_forecasts$forecasts %>% \n  enframe() %>% \n  unnest_wider(value) %>% # changed per recommendation\n  unnest_auto(types)\n\nUsing `unnest_wider(types)`; elements have 2 names in common\n\n\n# A tibble: 22 × 5\n    name last_updated              week elo         rating     \n   <int> <chr>                    <int> <list>      <list>     \n 1     1 2021-02-08T03:15:55.357Z    21 <list [32]> <list [32]>\n 2     2 2021-01-25T03:10:04.809Z    20 <list [32]> <list [32]>\n 3     3 2021-01-22T19:28:01.278Z    19 <list [32]> <list [32]>\n 4     4 2021-01-15T01:25:55.192Z    18 <list [32]> <list [32]>\n 5     5 2021-01-09T16:38:13.126Z    17 <list [32]> <list [32]>\n 6     6 2021-01-03T16:03:42.517Z    16 <list [32]> <list [32]>\n 7     7 2020-12-24T01:32:05.045Z    15 <list [32]> <list [32]>\n 8     8 2020-12-16T14:13:49.344Z    14 <list [32]> <list [32]>\n 9     9 2020-12-10T16:21:56.731Z    13 <list [32]> <list [32]>\n10    10 2020-12-06T15:29:51.523Z    12 <list [32]> <list [32]>\n# … with 12 more rows\n\n\nWe now have a list of 32 x 14 weeks. There are 32 teams so we’re most likely at the appropriate depth and can go longer vs wider now. We can also see that name/week don’t align so let’s drop name, and we can use unchop() to increase the length of the data for elo and rating at the same time.\n\nraw_538_json$weekly_forecasts$forecasts %>% \n  enframe() %>% \n  unnest_wider(value) %>% \n  unnest_wider(types) %>% # Changed per recommendation\n  unchop(cols = c(elo, rating)) %>% \n  select(-name)\n\n# A tibble: 704 × 4\n   last_updated              week elo               rating           \n   <chr>                    <int> <list>            <list>           \n 1 2021-02-08T03:15:55.357Z    21 <named list [29]> <named list [29]>\n 2 2021-02-08T03:15:55.357Z    21 <named list [29]> <named list [29]>\n 3 2021-02-08T03:15:55.357Z    21 <named list [29]> <named list [29]>\n 4 2021-02-08T03:15:55.357Z    21 <named list [29]> <named list [29]>\n 5 2021-02-08T03:15:55.357Z    21 <named list [29]> <named list [29]>\n 6 2021-02-08T03:15:55.357Z    21 <named list [29]> <named list [29]>\n 7 2021-02-08T03:15:55.357Z    21 <named list [29]> <named list [29]>\n 8 2021-02-08T03:15:55.357Z    21 <named list [29]> <named list [29]>\n 9 2021-02-08T03:15:55.357Z    21 <named list [29]> <named list [29]>\n10 2021-02-08T03:15:55.357Z    21 <named list [29]> <named list [29]>\n# … with 694 more rows\n\n\nWe now have 14 weeks x 32 teams (448 rows), along with last_updated, week, elo and rating data. We can use unnest_auto() on the elo column to see what’s the next step. Rating is duplicated so there’s been name repair to avoid duplicated names. We get the following warning that tells us this has occurred.\n\n* rating -> rating...18* rating -> rating...32\n\nYou’ll see that I’ve done unnest_auto() on both elo and rating...32 (the renamed rating list column). If you look closely at the names, we can also see that there is duplication of the names for MANY of the columns. A tricky part is that elo/rating each have a LOT of overlap, and are most appropriate as separate data frames that could be stacked if desired.\n\nelo_raw <- raw_538_json$weekly_forecasts$forecasts %>% \n  enframe() %>% \n  unnest_wider(value) %>% \n  unnest_wider(types) %>% # Changed per recommendation\n  unchop(cols = c(elo, rating)) %>% \n  select(-name) %>% \n  unnest_auto(elo) %>% \n  unnest_auto(rating...32)\n\nUsing `unnest_wider(elo)`; elements have 29 names in common\n\n\nNew names:\nUsing `unnest_wider(rating...32)`; elements have 29 names in common\nNew names:\n• `rating` -> `rating...18`\n• `rating` -> `rating...32`\n\nelo_raw %>% \n  names()\n\n [1] \"last_updated\"               \"week\"                      \n [3] \"conference...3\"             \"current_losses...4\"        \n [5] \"current_ties...5\"           \"current_wins...6\"          \n [7] \"division...7\"               \"elo...8\"                   \n [9] \"losses...9\"                 \"make_conference_champ...10\"\n[11] \"make_divisional_round...11\" \"make_playoffs...12\"        \n[13] \"make_superbowl...13\"        \"name...14\"                 \n[15] \"point_diff...15\"            \"points_allowed...16\"       \n[17] \"points_scored...17\"         \"rating...18\"               \n[19] \"rating_current...19\"        \"rating_top...20\"           \n[21] \"seed_1...21\"                \"seed_2...22\"               \n[23] \"seed_3...23\"                \"seed_4...24\"               \n[25] \"seed_5...25\"                \"seed_6...26\"               \n[27] \"seed_7...27\"                \"ties...28\"                 \n[29] \"win_division...29\"          \"win_superbowl...30\"        \n[31] \"wins...31\"                  \"conference...32\"           \n[33] \"current_losses...33\"        \"current_ties...34\"         \n[35] \"current_wins...35\"          \"division...36\"             \n[37] \"elo...37\"                   \"losses...38\"               \n[39] \"make_conference_champ...39\" \"make_divisional_round...40\"\n[41] \"make_playoffs...41\"         \"make_superbowl...42\"       \n[43] \"name...43\"                  \"point_diff...44\"           \n[45] \"points_allowed...45\"        \"points_scored...46\"        \n[47] \"rating...47\"                \"rating_current...48\"       \n[49] \"rating_top...49\"            \"seed_1...50\"               \n[51] \"seed_2...51\"                \"seed_3...52\"               \n[53] \"seed_4...53\"                \"seed_5...54\"               \n[55] \"seed_6...55\"                \"seed_7...56\"               \n[57] \"ties...57\"                  \"win_division...58\"         \n[59] \"win_superbowl...59\"         \"wins...60\"                 \n\n\nLet’s try this again, with the knowledge that elo and rating should be treated separately for now. Since they have the same names, we can also combine the data by stacking (bind_rows()). I have added a new column so that we can differentiate between the two datasets (ELO vs Rating).\n\nweekly_raw <- raw_538_json$weekly_forecasts$forecasts %>% \n  enframe() %>% \n  unnest_wider(value) %>% \n  unnest_wider(types) %>% \n  select(-name) %>%\n  unchop(cols = c(elo, rating))\n\nweekly_elo <- weekly_raw %>% \n  select(-rating) %>% \n  unnest_wider(elo) %>% \n  mutate(measure = \"ELO\", .after = last_updated)\n\nweekly_rating <- weekly_raw %>% \n  select(-elo) %>% \n  unnest_wider(rating) %>% \n  mutate(measure = \"Rating\", .after = last_updated)\n\n# confirm same names\nall.equal(\n  names(weekly_elo),\n  names(weekly_rating)\n)\n\n[1] TRUE\n\nweekly_forecasts <- bind_rows(weekly_elo, weekly_rating)\n\nweekly_forecasts %>% glimpse()\n\nRows: 1,408\nColumns: 32\n$ last_updated          <chr> \"2021-02-08T03:15:55.357Z\", \"2021-02-08T03:15:55…\n$ measure               <chr> \"ELO\", \"ELO\", \"ELO\", \"ELO\", \"ELO\", \"ELO\", \"ELO\",…\n$ week                  <int> 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, …\n$ conference            <chr> \"NFC\", \"AFC\", \"NFC\", \"NFC\", \"NFC\", \"AFC\", \"AFC\",…\n$ current_losses        <int> 9, 6, 10, 12, 11, 11, 14, 11, 6, 10, 6, 5, 10, 9…\n$ current_ties          <int> 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ current_wins          <int> 7, 10, 7, 4, 5, 4, 2, 5, 12, 6, 11, 13, 6, 7, 15…\n$ division              <chr> \"NFC North\", \"AFC East\", \"NFC East\", \"NFC South\"…\n$ elo                   <dbl> 1489.284, 1545.820, 1442.351, 1474.240, 1333.468…\n$ losses                <dbl> 9, 6, 9, 12, 11, 11, 14, 11, 5, 10, 5, 4, 10, 9,…\n$ make_conference_champ <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, …\n$ make_divisional_round <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, …\n$ make_playoffs         <dbl> 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, …\n$ make_superbowl        <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ name                  <chr> \"MIN\", \"MIA\", \"WSH\", \"ATL\", \"DET\", \"CIN\", \"NYJ\",…\n$ point_diff            <dbl> -45, 66, 6, -18, -142, -113, -214, -123, 165, -7…\n$ points_allowed        <dbl> 475, 338, 329, 414, 519, 424, 457, 446, 303, 357…\n$ points_scored         <dbl> 430, 404, 335, 396, 377, 311, 243, 323, 468, 280…\n$ rating                <dbl> 1480.954, 1565.307, 1446.254, 1449.242, 1340.178…\n$ rating_current        <dbl> 1501.583, 1529.565, 1462.552, 1448.424, 1338.309…\n$ rating_top            <dbl> 1501.583, 1529.565, 1462.552, 1448.424, 1338.309…\n$ seed_1                <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ seed_2                <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, …\n$ seed_3                <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, …\n$ seed_4                <dbl> 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, …\n$ seed_5                <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, …\n$ seed_6                <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ seed_7                <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ ties                  <dbl> 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ win_division          <dbl> 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, …\n$ win_superbowl         <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ wins                  <dbl> 7, 10, 7, 4, 5, 4, 2, 5, 11, 6, 11, 12, 6, 7, 13…"
  },
  {
    "objectID": "posts/2020-12-13-extracting-json-from-websites-and-public-apis-with-r/index.html#create-a-function",
    "href": "posts/2020-12-13-extracting-json-from-websites-and-public-apis-with-r/index.html#create-a-function",
    "title": "Extracting JSON data from websites and public APIs with R",
    "section": "Create a Function",
    "text": "Create a Function\nFinally, we can combine the techniques we showed above as a function (and I’ve added it to espnscrapeR). Now we can use this to get data throughout the current season OR get info from past seasons (2015 and beyond). Again, note that 2015 has a different JSON structure but the core forecasts portion is still the same.\n\nget_weekly_forecast <- function(season) {\n  \n  # Fill URL and read in JSON\n  raw_url <- glue::glue(\"https://projects.fivethirtyeight.com/{season}-nfl-predictions/data.json\")\n  raw_json <- fromJSON(raw_url, simplifyVector = FALSE)\n  \n  # get the two datasets\n  weekly_raw <- raw_538_json$weekly_forecasts$forecasts %>%\n    enframe() %>%\n    unnest_wider(value) %>%\n    unnest_wider(types) %>%\n    select(-name) %>%\n    unchop(cols = c(elo, rating))\n  \n  # get ELO\n  weekly_elo <- weekly_raw %>%\n    select(-rating) %>%\n    unnest_wider(elo) %>%\n    mutate(measure = \"ELO\", .after = last_updated)\n  # get Rating\n  weekly_rating <- weekly_raw %>%\n    select(-elo) %>%\n    unnest_wider(rating) %>%\n    mutate(measure = \"Rating\", .after = last_updated)\n  # combine\n  bind_rows(weekly_elo, weekly_rating)\n}\n\nget_weekly_forecast(2015) %>% \n  glimpse()\n\nRows: 1,408\nColumns: 32\n$ last_updated          <chr> \"2021-02-08T03:15:55.357Z\", \"2021-02-08T03:15:55…\n$ measure               <chr> \"ELO\", \"ELO\", \"ELO\", \"ELO\", \"ELO\", \"ELO\", \"ELO\",…\n$ week                  <int> 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, …\n$ conference            <chr> \"NFC\", \"AFC\", \"NFC\", \"NFC\", \"NFC\", \"AFC\", \"AFC\",…\n$ current_losses        <int> 9, 6, 10, 12, 11, 11, 14, 11, 6, 10, 6, 5, 10, 9…\n$ current_ties          <int> 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ current_wins          <int> 7, 10, 7, 4, 5, 4, 2, 5, 12, 6, 11, 13, 6, 7, 15…\n$ division              <chr> \"NFC North\", \"AFC East\", \"NFC East\", \"NFC South\"…\n$ elo                   <dbl> 1489.284, 1545.820, 1442.351, 1474.240, 1333.468…\n$ losses                <dbl> 9, 6, 9, 12, 11, 11, 14, 11, 5, 10, 5, 4, 10, 9,…\n$ make_conference_champ <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, …\n$ make_divisional_round <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, …\n$ make_playoffs         <dbl> 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, …\n$ make_superbowl        <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ name                  <chr> \"MIN\", \"MIA\", \"WSH\", \"ATL\", \"DET\", \"CIN\", \"NYJ\",…\n$ point_diff            <dbl> -45, 66, 6, -18, -142, -113, -214, -123, 165, -7…\n$ points_allowed        <dbl> 475, 338, 329, 414, 519, 424, 457, 446, 303, 357…\n$ points_scored         <dbl> 430, 404, 335, 396, 377, 311, 243, 323, 468, 280…\n$ rating                <dbl> 1480.954, 1565.307, 1446.254, 1449.242, 1340.178…\n$ rating_current        <dbl> 1501.583, 1529.565, 1462.552, 1448.424, 1338.309…\n$ rating_top            <dbl> 1501.583, 1529.565, 1462.552, 1448.424, 1338.309…\n$ seed_1                <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ seed_2                <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, …\n$ seed_3                <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, …\n$ seed_4                <dbl> 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, …\n$ seed_5                <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, …\n$ seed_6                <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ seed_7                <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ ties                  <dbl> 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ win_division          <dbl> 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, …\n$ win_superbowl         <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ wins                  <dbl> 7, 10, 7, 4, 5, 4, 2, 5, 11, 6, 11, 12, 6, 7, 13…"
  },
  {
    "objectID": "posts/2020-12-13-extracting-json-from-websites-and-public-apis-with-r/index.html#qb-playoff-adjustment-values",
    "href": "posts/2020-12-13-extracting-json-from-websites-and-public-apis-with-r/index.html#qb-playoff-adjustment-values",
    "title": "Extracting JSON data from websites and public APIs with R",
    "section": "QB playoff adjustment values",
    "text": "QB playoff adjustment values\n\nqb_playoff_adj <- raw_538_json$playoff_qb_adjustments %>% \n  enframe() %>% \n  unnest_wider(value)\n\n\nOutput\n\nqb_playoff_adj\n\n# A tibble: 32 × 4\n    name team   week  qb_adj\n   <int> <chr> <int>   <dbl>\n 1     1 ARI      21  17.3  \n 2     2 ATL      21  -0.819\n 3     3 BAL      21  -2.72 \n 4     4 BUF      21  33.1  \n 5     5 CAR      21   4.26 \n 6     6 CHI      21  19.2  \n 7     7 CIN      21 -84.5  \n 8     8 CLE      21  16.9  \n 9     9 DAL      21 -60.9  \n10    10 DEN      21  15.3  \n# … with 22 more rows"
  },
  {
    "objectID": "posts/2020-12-13-extracting-json-from-websites-and-public-apis-with-r/index.html#games-data",
    "href": "posts/2020-12-13-extracting-json-from-websites-and-public-apis-with-r/index.html#games-data",
    "title": "Extracting JSON data from websites and public APIs with R",
    "section": "Games Data",
    "text": "Games Data\nThis one is interesting, it’s got ELO change as a result of win/loss along with the spread and ratings.\n\ngames_df <- raw_538_json$games %>% \n  enframe() %>% \n  unnest_auto(value) %>% \n  select(-name)\n\nUsing `unnest_wider(value)`; elements have 40 names in common\n\n\n\nOutput\n\ngames_df\n\n# A tibble: 269 × 40\n        id date  datetime  week status team1 team2 neutral playoff score1 score2\n     <int> <chr> <chr>    <int> <chr>  <chr> <chr> <lgl>   <chr>    <int>  <int>\n 1  4.01e8 2020… 2020-09…     1 post   KC    HOU   FALSE   <NA>        34     20\n 2  4.01e8 2020… 2020-09…     1 post   DET   CHI   FALSE   <NA>        23     27\n 3  4.01e8 2020… 2020-09…     1 post   BAL   CLE   FALSE   <NA>        38      6\n 4  4.01e8 2020… 2020-09…     1 post   MIN   GB    FALSE   <NA>        34     43\n 5  4.01e8 2020… 2020-09…     1 post   JAX   IND   FALSE   <NA>        27     20\n 6  4.01e8 2020… 2020-09…     1 post   NE    MIA   FALSE   <NA>        21     11\n 7  4.01e8 2020… 2020-09…     1 post   BUF   NYJ   FALSE   <NA>        27     17\n 8  4.01e8 2020… 2020-09…     1 post   CAR   OAK   FALSE   <NA>        30     34\n 9  4.01e8 2020… 2020-09…     1 post   WSH   PHI   FALSE   <NA>        27     17\n10  4.01e8 2020… 2020-09…     1 post   ATL   SEA   FALSE   <NA>        25     38\n# … with 259 more rows, and 29 more variables: overtime <lgl>, elo1_pre <dbl>,\n#   elo2_pre <dbl>, elo_spread <dbl>, elo_prob1 <dbl>, elo_prob2 <dbl>,\n#   elo1_post <dbl>, elo2_post <dbl>, rating1_pre <dbl>, rating2_pre <dbl>,\n#   rating_spread <dbl>, rating_prob1 <dbl>, rating_prob2 <dbl>,\n#   rating1_post <dbl>, rating2_post <dbl>, bettable <lgl>, outcome <dbl>,\n#   qb_adj1 <dbl>, qb_adj2 <dbl>, rest_adj1 <int>, rest_adj2 <int>,\n#   dist_adj <dbl>, rating1_top_qb <dbl>, rating2_top_qb <dbl>, …"
  },
  {
    "objectID": "posts/2020-12-13-extracting-json-from-websites-and-public-apis-with-r/index.html#distances",
    "href": "posts/2020-12-13-extracting-json-from-websites-and-public-apis-with-r/index.html#distances",
    "title": "Extracting JSON data from websites and public APIs with R",
    "section": "Distances",
    "text": "Distances\nThis data has the distances for each team to other locations/stadiums.\n\ndistance_df <- raw_538_json$distances %>% \n  enframe() %>% \n  unnest_wider(value) %>% \n  unnest_longer(distances)\n\n\nOutput\n\ndistance_df\n\n# A tibble: 1,024 × 6\n    name team    lat   lon distances distances_id\n   <int> <chr> <dbl> <dbl>     <dbl> <chr>       \n 1     1 TEN    36.2 -86.8        0  TEN         \n 2     1 TEN    36.2 -86.8      758. NYG         \n 3     1 TEN    36.2 -86.8      471. PIT         \n 4     1 TEN    36.2 -86.8      339. CAR         \n 5     1 TEN    36.2 -86.8      595. BAL         \n 6     1 TEN    36.2 -86.8      619. TB          \n 7     1 TEN    36.2 -86.8      251. IND         \n 8     1 TEN    36.2 -86.8      698. MIN         \n 9     1 TEN    36.2 -86.8     1454. ARI         \n10     1 TEN    36.2 -86.8      634. DAL         \n# … with 1,014 more rows"
  },
  {
    "objectID": "posts/2020-12-13-extracting-json-from-websites-and-public-apis-with-r/index.html#qb-adjustment",
    "href": "posts/2020-12-13-extracting-json-from-websites-and-public-apis-with-r/index.html#qb-adjustment",
    "title": "Extracting JSON data from websites and public APIs with R",
    "section": "QB Adjustment",
    "text": "QB Adjustment\nI believe this is the in-season QB adjustment for each team.\n\nqb_adj <- raw_538_json$qbs %>% \n  enframe() %>% \n  select(-name) %>% \n  unnest_wider(value)\n\n\nOutput\n\nqb_adj\n\n# A tibble: 87 × 6\n    api_id name            team  priority elo_value starts\n     <int> <chr>           <chr>    <int>     <int>  <int>\n 1 3040206 Chris Streveler ARI          2         0      1\n 2 4035003 Jacob Eason     IND          3        58      1\n 3 3124900 Jake Luton      JAX          3        20      1\n 4 3915436 Steven Montez   WSH          3         0      1\n 5 4241479 Tua Tagovailoa  MIA          1       128      1\n 6 4038941 Justin Herbert  LAC          1       200      1\n 7 4040715 Jalen Hurts     PHI          1       120      1\n 8 3895785 Ben DiNucci     DAL          3         6      1\n 9 4036378 Jordan Love     GB           3       102      1\n10   12471 Chase Daniel    DET          2        33      1\n# … with 77 more rows"
  },
  {
    "objectID": "posts/2020-12-13-extracting-json-from-websites-and-public-apis-with-r/index.html#get-the-data",
    "href": "posts/2020-12-13-extracting-json-from-websites-and-public-apis-with-r/index.html#get-the-data",
    "title": "Extracting JSON data from websites and public APIs with R",
    "section": "Get the data",
    "text": "Get the data\nLet’s use an example from a pretty wild swing in Win Percentage from Week 13 of the 2020 NFL season. The Vikings and Jaguars went to overtime, with a lot of back and forth. Since there is an interactive data visualization, I’m assuming the JSON data is present there as well.\n\n\nIf we try our previous trick from FiveThirtyEight and the Inspect -> Network we get a total of… about 300 different requests! None of them appear big enough to be the “right” data. We’re expecting 4-5 Mb of data.\n\n\nAnother trick is to look for embedded JSON in the site itself. The basic representation of JSON is [{name: item}], so let’s try looking for [{ as the start of a JSON structure.\nInside the Google Chrome Dev tools we can search and find a few JSON files, including one inside some JavaScript called espn.gamepackage.probability! There’s a good amount of data there, but we need to extract it from the raw HTML. This JSON is inside a <script> object, so let’s parse the HTML and get script nodes.\n\n\n\nespn_url <-glue::glue(\"https://www.espn.com/nfl/game?gameId=401220303\")\n\nraw_espn_html <- espn_url %>%\n    read_html()\n\nraw_espn_html %>%\n    html_nodes(\"script\") \n\n{xml_nodeset (27)}\n [1] <script type=\"application/ld+json\">\\n\\t{\\n\\t\\t\"@context\": \"https://schem ...\n [2] <script type=\"text/javascript\" src=\"https://dcf.espn.com/TWDC-DTCI/prod/ ...\n [3] <script type=\"text/javascript\">\\n;(function(){\\n\\nfunction rc(a){for(var ...\n [4] <script src=\"https://secure.espn.com/core/format/modules/head/i18n?editi ...\n [5] <script src=\"https://a.espncdn.com/redesign/0.591.3/js/espn-head.js\"></s ...\n [6] <script>\\n\\t\\t\\tif (espn && espn.geoRedirect){\\n\\t\\t\\t\\tespn.geoRedirect ...\n [7] <script>\\n\\tvar espn = espn || {};\\n\\tespn.isOneSite = false;\\n\\tespn.bu ...\n [8] <script src=\"https://a.espncdn.com/redesign/0.591.3/node_modules/espn-la ...\n [9] <script type=\"text/javascript\">\\n\\t(function () {\\n\\t\\tvar featureGating ...\n[10] <script>\\n\\t\\twindow.googletag = window.googletag || {};\\n\\n\\t\\t(functio ...\n[11] <script type=\"text/javascript\">\\n\\tif( typeof s_omni === \"undefined\" ) w ...\n[12] <script type=\"text/javascript\" src=\"https://a.espncdn.com/prod/scripts/a ...\n[13] <script>\\n\\t// Picture element HTML shim|v it for old IE (pairs with Pic ...\n[14] <script type=\"text/javascript\">\\n\\t\\t\\tvar abtestData = {};\\n\\t\\t\\t\\n\\t\\ ...\n[15] <script type=\"text/javascript\">\\n\\t\\tvar espn = espn || {};\\n\\t\\tespn.na ...\n[16] <script type=\"text/javascript\">\\n\\n    var __dataLayer = window.__dataLa ...\n[17] <script>\\n\\tvar espn_ui = window.espn_ui || {};\\n\\tespn_ui.staticRef = \" ...\n[18] <script src=\"https://a.espncdn.com/redesign/0.591.3/js/espn-critical.js\" ...\n[19] <script type=\"text/javascript\">\\n\\t\\t\\tvar espn = espn || {};\\n\\n\\t\\t\\t/ ...\n[20] <script type=\"text/javascript\">jQuery.subscribe('espn.defer.end', functi ...\n...\n\n\nBig oof. There’s 27 scripts here and just parsing through the start of the script as they are in XML is not helpful…So let’s get the raw text from each of these nodes and see if we can find the espn.gamepackage.probability element which we’re looking for!\n\nraw_espn_text <- raw_espn_html %>%\n  html_nodes(\"script\") %>% \n  html_text()\n\nraw_espn_text %>% \n  str_which(\"espn.gamepackage.probability\")\n\n[1] 23\n\n\nOk! So we’re looking for the 23rd node, I’m going to hide the output inside an expandable tag, as it’s a long output!\n\nexample_embed_json <- raw_espn_html %>%\n    html_nodes(\"script\") %>% \n    .[23] %>%\n    html_text()\n\n\nExample Embed JSON\n\nexample_embed_json\n\n[1] \"\\n\\t\\t\\t\\t(function($) {\\n\\t\\t\\t\\t\\tvar espn = window.espn || {},\\n\\t\\t\\t\\t\\t\\tDTCpackages = window.DTCpackages || [];\\n\\n\\t\\t\\t\\t\\tespn.gamepackage = espn.gamepackage || {};\\n\\t\\t\\t\\t\\tespn.gamepackage.gameId = \\\"401220303\\\";\\n\\t\\t\\t\\t\\tespn.gamepackage.type = \\\"game\\\";\\n\\t\\t\\t\\t\\tespn.gamepackage.timestamp = \\\"2020-12-06T18:00Z\\\";\\n\\t\\t\\t\\t\\tespn.gamepackage.status = \\\"post\\\";\\n\\t\\t\\t\\t\\tespn.gamepackage.league = \\\"nfl\\\";\\n\\t\\t\\t\\t\\tespn.gamepackage.leagueId = 28;\\n\\t\\t\\t\\t\\tespn.gamepackage.sport = \\\"football\\\";\\n\\t\\t\\t\\t\\tespn.gamepackage.network = \\\"CBS\\\";\\n\\t\\t\\t\\t\\tespn.gamepackage.awayTeamName = \\\"jacksonville-jaguars\\\";\\n\\t\\t\\t\\t\\tespn.gamepackage.homeTeamName = \\\"minnesota-vikings\\\";\\n\\t\\t\\t\\t\\tespn.gamepackage.awayTeamId = \\\"30\\\";\\n\\t\\t\\t\\t\\tespn.gamepackage.homeTeamId = \\\"16\\\";\\n\\t\\t\\t\\t\\tespn.gamepackage.awayTeamColor = \\\"00839C\\\";\\n\\t\\t\\t\\t\\tespn.gamepackage.homeTeamColor = \\\"240A67\\\";\\n\\t\\t\\t\\t\\tespn.gamepackage.showGamebreak = true;\\n\\t\\t\\t\\t\\tespn.gamepackage.supportsHeadshots = true\\n\\t\\t\\t\\t\\tespn.gamepackage.playByPlaySource = \\\"full\\\";\\n\\t\\t\\t\\t\\tespn.gamepackage.numPeriods = null;\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\n\\t\\t\\t\\t\\t\\n\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\tespn.gamepackage.probability = espn.gamepackage.probability || {};\\n\\t\\t\\t\\t\\t\\tespn.gamepackage.probability.data = [{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":1},\\\"homeScore\\\":0,\\\"awayScore\\\":0,\\\"start\\\":{\\\"distance\\\":0,\\\"yardLine\\\":35,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":0,\\\"yardsToEndzone\\\":65},\\\"text\\\":\\\"D.Bailey kicks 65 yards from MIN 35 to end zone, Touchback.\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"15:00\\\"},\\\"type\\\":{\\\"id\\\":\\\"53\\\",\\\"text\\\":\\\"Kickoff\\\",\\\"abbreviation\\\":\\\"K\\\"}},\\\"homeWinPercentage\\\":0.828,\\\"playId\\\":\\\"40122030340\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":1},\\\"homeScore\\\":0,\\\"awayScore\\\":0,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 10\\\",\\\"possessionText\\\":\\\"JAX 25\\\",\\\"downDistanceText\\\":\\\"1st & 10 at JAX 25\\\",\\\"distance\\\":10,\\\"yardLine\\\":75,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":75},\\\"text\\\":\\\"(15:00) M.Glennon pass deep middle to J.O'Shaughnessy to JAX 49 for 24 yards (A.Harris; E.Wilson).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"15:00\\\"},\\\"type\\\":{\\\"id\\\":\\\"24\\\",\\\"text\\\":\\\"Pass Reception\\\",\\\"abbreviation\\\":\\\"REC\\\"}},\\\"homeWinPercentage\\\":0.807,\\\"playId\\\":\\\"40122030355\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":1},\\\"homeScore\\\":0,\\\"awayScore\\\":0,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 10\\\",\\\"possessionText\\\":\\\"JAX 49\\\",\\\"downDistanceText\\\":\\\"1st & 10 at JAX 49\\\",\\\"distance\\\":10,\\\"yardLine\\\":51,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":51},\\\"text\\\":\\\"(14:25) (Shotgun) M.Glennon pass short right to J.Robinson pushed ob at MIN 43 for 8 yards (T.Dye).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"14:25\\\"},\\\"type\\\":{\\\"id\\\":\\\"24\\\",\\\"text\\\":\\\"Pass Reception\\\",\\\"abbreviation\\\":\\\"REC\\\"}},\\\"homeWinPercentage\\\":0.796,\\\"playId\\\":\\\"40122030379\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":1},\\\"homeScore\\\":0,\\\"awayScore\\\":0,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"2nd & 2\\\",\\\"possessionText\\\":\\\"MIN 43\\\",\\\"downDistanceText\\\":\\\"2nd & 2 at MIN 43\\\",\\\"distance\\\":2,\\\"yardLine\\\":43,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":2,\\\"yardsToEndzone\\\":43},\\\"text\\\":\\\"(13:54) J.Robinson left guard to MIN 34 for 9 yards (T.Davis; E.Wilson).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"13:54\\\"},\\\"type\\\":{\\\"id\\\":\\\"5\\\",\\\"text\\\":\\\"Rush\\\",\\\"abbreviation\\\":\\\"RUSH\\\"}},\\\"homeWinPercentage\\\":0.785,\\\"playId\\\":\\\"401220303108\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":1},\\\"homeScore\\\":0,\\\"awayScore\\\":0,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 10\\\",\\\"possessionText\\\":\\\"MIN 34\\\",\\\"downDistanceText\\\":\\\"1st & 10 at MIN 34\\\",\\\"distance\\\":10,\\\"yardLine\\\":34,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":34},\\\"text\\\":\\\"(13:21) J.Robinson left end to MIN 28 for 6 yards (A.Harris; S.Stephen).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"13:21\\\"},\\\"type\\\":{\\\"id\\\":\\\"5\\\",\\\"text\\\":\\\"Rush\\\",\\\"abbreviation\\\":\\\"RUSH\\\"}},\\\"homeWinPercentage\\\":0.777,\\\"playId\\\":\\\"401220303129\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":1},\\\"homeScore\\\":0,\\\"awayScore\\\":6,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"2nd & 4\\\",\\\"possessionText\\\":\\\"MIN 28\\\",\\\"downDistanceText\\\":\\\"2nd & 4 at MIN 28\\\",\\\"distance\\\":4,\\\"yardLine\\\":28,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":2,\\\"yardsToEndzone\\\":28},\\\"text\\\":\\\"Laviska Shenault Jr. 28 Yd pass from Mike Glennon (Chase McLaughlin PAT failed)\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"12:33\\\"},\\\"type\\\":{\\\"id\\\":\\\"67\\\",\\\"text\\\":\\\"Passing Touchdown\\\",\\\"abbreviation\\\":\\\"TD\\\"}},\\\"homeWinPercentage\\\":0.742,\\\"playId\\\":\\\"401220303150\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":1},\\\"homeScore\\\":0,\\\"awayScore\\\":6,\\\"start\\\":{\\\"distance\\\":0,\\\"yardLine\\\":-4,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":0,\\\"yardsToEndzone\\\":65},\\\"text\\\":\\\"L.Cooke kicks 69 yards from JAX 35 to MIN -4. A.Abdullah to MIN 21 for 25 yards (S.Quarterman).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"12:33\\\"},\\\"type\\\":{\\\"id\\\":\\\"12\\\",\\\"text\\\":\\\"Kickoff Return (Offense)\\\"}},\\\"homeWinPercentage\\\":0.741,\\\"playId\\\":\\\"401220303191\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":1},\\\"homeScore\\\":0,\\\"awayScore\\\":6,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 10\\\",\\\"possessionText\\\":\\\"MIN 21\\\",\\\"downDistanceText\\\":\\\"1st & 10 at MIN 21\\\",\\\"distance\\\":10,\\\"yardLine\\\":21,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":79},\\\"text\\\":\\\"(12:28) K.Cousins pass short left to A.Thielen pushed ob at MIN 29 for 8 yards (T.Herndon). PENALTY on JAX-M.Jack, Defensive Holding, 5 yards, enforced at MIN 21 - No Play.\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"12:28\\\"},\\\"type\\\":{\\\"id\\\":\\\"24\\\",\\\"text\\\":\\\"Pass Reception\\\",\\\"abbreviation\\\":\\\"REC\\\"}},\\\"homeWinPercentage\\\":0.747,\\\"playId\\\":\\\"401220303213\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":1},\\\"homeScore\\\":0,\\\"awayScore\\\":6,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 10\\\",\\\"possessionText\\\":\\\"MIN 26\\\",\\\"downDistanceText\\\":\\\"1st & 10 at MIN 26\\\",\\\"distance\\\":10,\\\"yardLine\\\":26,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":74},\\\"text\\\":\\\"(12:11) (Shotgun) K.Cousins pass incomplete deep right to A.Thielen.\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"12:11\\\"},\\\"type\\\":{\\\"id\\\":\\\"3\\\",\\\"text\\\":\\\"Pass Incompletion\\\"}},\\\"homeWinPercentage\\\":0.719,\\\"playId\\\":\\\"401220303257\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":1},\\\"homeScore\\\":0,\\\"awayScore\\\":6,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"2nd & 10\\\",\\\"possessionText\\\":\\\"MIN 26\\\",\\\"downDistanceText\\\":\\\"2nd & 10 at MIN 26\\\",\\\"distance\\\":10,\\\"yardLine\\\":26,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":2,\\\"yardsToEndzone\\\":74},\\\"text\\\":\\\"(12:06) D.Cook right tackle to MIN 33 for 7 yards (M.Jack).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"12:06\\\"},\\\"type\\\":{\\\"id\\\":\\\"5\\\",\\\"text\\\":\\\"Rush\\\",\\\"abbreviation\\\":\\\"RUSH\\\"}},\\\"homeWinPercentage\\\":0.731,\\\"playId\\\":\\\"401220303279\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":1},\\\"homeScore\\\":0,\\\"awayScore\\\":6,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"3rd & 3\\\",\\\"possessionText\\\":\\\"MIN 33\\\",\\\"downDistanceText\\\":\\\"3rd & 3 at MIN 33\\\",\\\"distance\\\":3,\\\"yardLine\\\":33,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":3,\\\"yardsToEndzone\\\":67},\\\"text\\\":\\\"(11:27) (Shotgun) K.Cousins pass incomplete short right to D.Cook.\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"11:27\\\"},\\\"type\\\":{\\\"id\\\":\\\"3\\\",\\\"text\\\":\\\"Pass Incompletion\\\"}},\\\"homeWinPercentage\\\":0.683,\\\"playId\\\":\\\"401220303300\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":1},\\\"homeScore\\\":0,\\\"awayScore\\\":6,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"4th & 3\\\",\\\"possessionText\\\":\\\"MIN 33\\\",\\\"downDistanceText\\\":\\\"4th & 3 at MIN 33\\\",\\\"distance\\\":3,\\\"yardLine\\\":33,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":4,\\\"yardsToEndzone\\\":67},\\\"text\\\":\\\"(11:23) B.Colquitt punts 50 yards to JAX 17, Center-A.DePaola. K.Cole Sr. to JAX 30 for 13 yards (T.Conklin).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"11:23\\\"},\\\"type\\\":{\\\"id\\\":\\\"52\\\",\\\"text\\\":\\\"Punt\\\",\\\"abbreviation\\\":\\\"PUNT\\\"}},\\\"homeWinPercentage\\\":0.699,\\\"playId\\\":\\\"401220303322\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":1},\\\"homeScore\\\":0,\\\"awayScore\\\":6,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 10\\\",\\\"possessionText\\\":\\\"JAX 30\\\",\\\"downDistanceText\\\":\\\"1st & 10 at JAX 30\\\",\\\"distance\\\":10,\\\"yardLine\\\":70,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":70},\\\"text\\\":\\\"(11:11) J.Robinson left guard to JAX 34 for 4 yards (T.Dye).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"11:11\\\"},\\\"type\\\":{\\\"id\\\":\\\"5\\\",\\\"text\\\":\\\"Rush\\\",\\\"abbreviation\\\":\\\"RUSH\\\"}},\\\"homeWinPercentage\\\":0.693,\\\"playId\\\":\\\"401220303347\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":1},\\\"homeScore\\\":0,\\\"awayScore\\\":6,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"2nd & 6\\\",\\\"possessionText\\\":\\\"JAX 34\\\",\\\"downDistanceText\\\":\\\"2nd & 6 at JAX 34\\\",\\\"distance\\\":6,\\\"yardLine\\\":66,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":2,\\\"yardsToEndzone\\\":66},\\\"text\\\":\\\"(10:41) (Shotgun) J.Robinson left end to JAX 38 for 4 yards (T.Davis; J.Johnson).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"10:41\\\"},\\\"type\\\":{\\\"id\\\":\\\"5\\\",\\\"text\\\":\\\"Rush\\\",\\\"abbreviation\\\":\\\"RUSH\\\"}},\\\"homeWinPercentage\\\":0.685,\\\"playId\\\":\\\"401220303368\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":1},\\\"homeScore\\\":0,\\\"awayScore\\\":6,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"3rd & 2\\\",\\\"possessionText\\\":\\\"JAX 38\\\",\\\"downDistanceText\\\":\\\"3rd & 2 at JAX 38\\\",\\\"distance\\\":2,\\\"yardLine\\\":62,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":3,\\\"yardsToEndzone\\\":62},\\\"text\\\":\\\"(10:04) (Shotgun) M.Glennon pass short right to T.Eifert to JAX 44 for 6 yards (J.Gladney).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"10:04\\\"},\\\"type\\\":{\\\"id\\\":\\\"24\\\",\\\"text\\\":\\\"Pass Reception\\\",\\\"abbreviation\\\":\\\"REC\\\"}},\\\"homeWinPercentage\\\":0.653,\\\"playId\\\":\\\"401220303389\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":1},\\\"homeScore\\\":0,\\\"awayScore\\\":6,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 10\\\",\\\"possessionText\\\":\\\"JAX 44\\\",\\\"downDistanceText\\\":\\\"1st & 10 at JAX 44\\\",\\\"distance\\\":10,\\\"yardLine\\\":56,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":56},\\\"text\\\":\\\"(9:29) J.Robinson left tackle to MIN 47 for 9 yards (E.Wilson).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"9:29\\\"},\\\"type\\\":{\\\"id\\\":\\\"5\\\",\\\"text\\\":\\\"Rush\\\",\\\"abbreviation\\\":\\\"RUSH\\\"}},\\\"homeWinPercentage\\\":0.629,\\\"playId\\\":\\\"401220303413\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":1},\\\"homeScore\\\":0,\\\"awayScore\\\":6,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"2nd & 1\\\",\\\"possessionText\\\":\\\"MIN 47\\\",\\\"downDistanceText\\\":\\\"2nd & 1 at MIN 47\\\",\\\"distance\\\":1,\\\"yardLine\\\":47,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":2,\\\"yardsToEndzone\\\":47},\\\"text\\\":\\\"(8:48) M.Glennon pass short middle to J.O'Shaughnessy to MIN 40 for 7 yards (T.Dye).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"8:48\\\"},\\\"type\\\":{\\\"id\\\":\\\"24\\\",\\\"text\\\":\\\"Pass Reception\\\",\\\"abbreviation\\\":\\\"REC\\\"}},\\\"homeWinPercentage\\\":0.62,\\\"playId\\\":\\\"401220303434\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":1},\\\"homeScore\\\":0,\\\"awayScore\\\":6,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 10\\\",\\\"possessionText\\\":\\\"MIN 40\\\",\\\"downDistanceText\\\":\\\"1st & 10 at MIN 40\\\",\\\"distance\\\":10,\\\"yardLine\\\":40,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":40},\\\"text\\\":\\\"(8:06) (Shotgun) M.Glennon pass deep left to C.Johnson to MIN 6 for 34 yards (H.Smith) [J.Holmes].\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"8:06\\\"},\\\"type\\\":{\\\"id\\\":\\\"24\\\",\\\"text\\\":\\\"Pass Reception\\\",\\\"abbreviation\\\":\\\"REC\\\"}},\\\"homeWinPercentage\\\":0.688,\\\"playId\\\":\\\"401220303458\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":1},\\\"homeScore\\\":0,\\\"awayScore\\\":6,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & Goal\\\",\\\"possessionText\\\":\\\"MIN 6\\\",\\\"downDistanceText\\\":\\\"1st & Goal at MIN 6\\\",\\\"distance\\\":6,\\\"yardLine\\\":6,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":6},\\\"text\\\":\\\"(7:28) (Shotgun) M.Glennon pass short right to J.Robinson to MIN 5 for 1 yard (T.Dye).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"7:26\\\"},\\\"type\\\":{\\\"id\\\":\\\"24\\\",\\\"text\\\":\\\"Pass Reception\\\",\\\"abbreviation\\\":\\\"REC\\\"}},\\\"homeWinPercentage\\\":0.523,\\\"playId\\\":\\\"401220303482\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":1},\\\"homeScore\\\":0,\\\"awayScore\\\":6,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"2nd & Goal\\\",\\\"possessionText\\\":\\\"MIN 5\\\",\\\"downDistanceText\\\":\\\"2nd & Goal at MIN 5\\\",\\\"distance\\\":5,\\\"yardLine\\\":5,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":2,\\\"yardsToEndzone\\\":5},\\\"text\\\":\\\"(6:52) (Shotgun) J.Robinson up the middle to MIN 4 for 1 yard (E.Yarbrough; J.Gladney).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"6:52\\\"},\\\"type\\\":{\\\"id\\\":\\\"5\\\",\\\"text\\\":\\\"Rush\\\",\\\"abbreviation\\\":\\\"RUSH\\\"}},\\\"homeWinPercentage\\\":0.578,\\\"playId\\\":\\\"401220303506\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":1},\\\"homeScore\\\":0,\\\"awayScore\\\":6,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"3rd & Goal\\\",\\\"possessionText\\\":\\\"MIN 4\\\",\\\"downDistanceText\\\":\\\"3rd & Goal at MIN 4\\\",\\\"distance\\\":4,\\\"yardLine\\\":4,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":3,\\\"yardsToEndzone\\\":4},\\\"text\\\":\\\"(6:12) (Shotgun) M.Glennon pass incomplete short left to K.Cole Sr..\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"6:12\\\"},\\\"type\\\":{\\\"id\\\":\\\"3\\\",\\\"text\\\":\\\"Pass Incompletion\\\"}},\\\"homeWinPercentage\\\":0.621,\\\"playId\\\":\\\"401220303527\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":1},\\\"homeScore\\\":0,\\\"awayScore\\\":9,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"4th & Goal\\\",\\\"possessionText\\\":\\\"MIN 4\\\",\\\"downDistanceText\\\":\\\"4th & Goal at MIN 4\\\",\\\"distance\\\":4,\\\"yardLine\\\":4,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":4,\\\"yardsToEndzone\\\":4},\\\"text\\\":\\\"Chase McLaughlin 22 Yd Field Goal\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"6:04\\\"},\\\"type\\\":{\\\"id\\\":\\\"59\\\",\\\"text\\\":\\\"Field Goal Good\\\",\\\"abbreviation\\\":\\\"FG\\\"}},\\\"homeWinPercentage\\\":0.619,\\\"playId\\\":\\\"401220303549\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":1},\\\"homeScore\\\":0,\\\"awayScore\\\":9,\\\"start\\\":{\\\"distance\\\":0,\\\"yardLine\\\":65,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":0,\\\"yardsToEndzone\\\":65},\\\"text\\\":\\\"L.Cooke kicks 65 yards from JAX 35 to end zone, Touchback.\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"6:04\\\"},\\\"type\\\":{\\\"id\\\":\\\"53\\\",\\\"text\\\":\\\"Kickoff\\\",\\\"abbreviation\\\":\\\"K\\\"}},\\\"homeWinPercentage\\\":0.624,\\\"playId\\\":\\\"401220303568\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":1},\\\"homeScore\\\":0,\\\"awayScore\\\":9,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 10\\\",\\\"possessionText\\\":\\\"MIN 25\\\",\\\"downDistanceText\\\":\\\"1st & 10 at MIN 25\\\",\\\"distance\\\":10,\\\"yardLine\\\":25,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":75},\\\"text\\\":\\\"(6:04) D.Cook left end to MIN 31 for 6 yards (J.Schobert).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"6:04\\\"},\\\"type\\\":{\\\"id\\\":\\\"5\\\",\\\"text\\\":\\\"Rush\\\",\\\"abbreviation\\\":\\\"RUSH\\\"}},\\\"homeWinPercentage\\\":0.625,\\\"playId\\\":\\\"401220303583\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":1},\\\"homeScore\\\":0,\\\"awayScore\\\":9,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"2nd & 4\\\",\\\"possessionText\\\":\\\"MIN 31\\\",\\\"downDistanceText\\\":\\\"2nd & 4 at MIN 31\\\",\\\"distance\\\":4,\\\"yardLine\\\":31,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":2,\\\"yardsToEndzone\\\":69},\\\"text\\\":\\\"(5:28) K.Cousins pass short left to J.Jefferson to MIN 36 for 5 yards (T.Herndon).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"5:28\\\"},\\\"type\\\":{\\\"id\\\":\\\"24\\\",\\\"text\\\":\\\"Pass Reception\\\",\\\"abbreviation\\\":\\\"REC\\\"}},\\\"homeWinPercentage\\\":0.636,\\\"playId\\\":\\\"401220303604\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":1},\\\"homeScore\\\":0,\\\"awayScore\\\":9,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 10\\\",\\\"possessionText\\\":\\\"MIN 36\\\",\\\"downDistanceText\\\":\\\"1st & 10 at MIN 36\\\",\\\"distance\\\":10,\\\"yardLine\\\":36,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":64},\\\"text\\\":\\\"(4:53) J.Jefferson right end pushed ob at MIN 38 for 2 yards (M.Jack).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"4:53\\\"},\\\"type\\\":{\\\"id\\\":\\\"5\\\",\\\"text\\\":\\\"Rush\\\",\\\"abbreviation\\\":\\\"RUSH\\\"}},\\\"homeWinPercentage\\\":0.553,\\\"playId\\\":\\\"401220303628\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":1},\\\"homeScore\\\":0,\\\"awayScore\\\":9,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"2nd & 8\\\",\\\"possessionText\\\":\\\"MIN 38\\\",\\\"downDistanceText\\\":\\\"2nd & 8 at MIN 38\\\",\\\"distance\\\":8,\\\"yardLine\\\":38,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":2,\\\"yardsToEndzone\\\":62},\\\"text\\\":\\\"(4:17) D.Cook left end to MIN 35 for -3 yards (T.Herndon).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"4:17\\\"},\\\"type\\\":{\\\"id\\\":\\\"5\\\",\\\"text\\\":\\\"Rush\\\",\\\"abbreviation\\\":\\\"RUSH\\\"}},\\\"homeWinPercentage\\\":0.572,\\\"playId\\\":\\\"401220303649\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":1},\\\"homeScore\\\":0,\\\"awayScore\\\":9,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"3rd & 11\\\",\\\"possessionText\\\":\\\"MIN 35\\\",\\\"downDistanceText\\\":\\\"3rd & 11 at MIN 35\\\",\\\"distance\\\":11,\\\"yardLine\\\":35,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":3,\\\"yardsToEndzone\\\":65},\\\"text\\\":\\\"(3:36) (Shotgun) K.Cousins sacked at MIN 30 for -5 yards (D.Smoot).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"3:36\\\"},\\\"type\\\":{\\\"id\\\":\\\"7\\\",\\\"text\\\":\\\"Sack\\\"}},\\\"homeWinPercentage\\\":0.464,\\\"playId\\\":\\\"401220303670\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":1},\\\"homeScore\\\":0,\\\"awayScore\\\":9,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"4th & 16\\\",\\\"possessionText\\\":\\\"MIN 30\\\",\\\"downDistanceText\\\":\\\"4th & 16 at MIN 30\\\",\\\"distance\\\":16,\\\"yardLine\\\":30,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":4,\\\"yardsToEndzone\\\":70},\\\"text\\\":\\\"(3:08) B.Colquitt punts 49 yards to JAX 21, Center-A.DePaola. K.Cole Sr. to JAX 25 for 4 yards (R.Connelly). PENALTY on JAX-J.Giles-Harris, Offensive Holding, 10 yards, enforced at JAX 21.\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"3:08\\\"},\\\"type\\\":{\\\"id\\\":\\\"52\\\",\\\"text\\\":\\\"Punt\\\",\\\"abbreviation\\\":\\\"PUNT\\\"}},\\\"homeWinPercentage\\\":0.565,\\\"playId\\\":\\\"401220303689\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":1},\\\"homeScore\\\":0,\\\"awayScore\\\":9,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 10\\\",\\\"possessionText\\\":\\\"JAX 11\\\",\\\"downDistanceText\\\":\\\"1st & 10 at JAX 11\\\",\\\"distance\\\":10,\\\"yardLine\\\":89,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":89},\\\"text\\\":\\\"(2:56) L.Shenault Jr. left end to JAX 24 for 13 yards (T.Davis).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"2:56\\\"},\\\"type\\\":{\\\"id\\\":\\\"5\\\",\\\"text\\\":\\\"Rush\\\",\\\"abbreviation\\\":\\\"RUSH\\\"}},\\\"homeWinPercentage\\\":0.537,\\\"playId\\\":\\\"401220303731\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":1},\\\"homeScore\\\":0,\\\"awayScore\\\":9,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 10\\\",\\\"possessionText\\\":\\\"JAX 24\\\",\\\"downDistanceText\\\":\\\"1st & 10 at JAX 24\\\",\\\"distance\\\":10,\\\"yardLine\\\":76,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":76},\\\"text\\\":\\\"(2:17) J.Robinson up the middle to JAX 28 for 4 yards (H.Mata'afa; T.Davis).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"2:17\\\"},\\\"type\\\":{\\\"id\\\":\\\"5\\\",\\\"text\\\":\\\"Rush\\\",\\\"abbreviation\\\":\\\"RUSH\\\"}},\\\"homeWinPercentage\\\":0.547,\\\"playId\\\":\\\"401220303752\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":1},\\\"homeScore\\\":0,\\\"awayScore\\\":9,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"2nd & 6\\\",\\\"possessionText\\\":\\\"JAX 28\\\",\\\"downDistanceText\\\":\\\"2nd & 6 at JAX 28\\\",\\\"distance\\\":6,\\\"yardLine\\\":72,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":2,\\\"yardsToEndzone\\\":72},\\\"text\\\":\\\"(1:41) M.Glennon pass short right to J.O'Shaughnessy to JAX 32 for 4 yards (J.Gladney).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"1:41\\\"},\\\"type\\\":{\\\"id\\\":\\\"24\\\",\\\"text\\\":\\\"Pass Reception\\\",\\\"abbreviation\\\":\\\"REC\\\"}},\\\"homeWinPercentage\\\":0.536,\\\"playId\\\":\\\"401220303773\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":1},\\\"homeScore\\\":0,\\\"awayScore\\\":9,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"3rd & 2\\\",\\\"possessionText\\\":\\\"JAX 32\\\",\\\"downDistanceText\\\":\\\"3rd & 2 at JAX 32\\\",\\\"distance\\\":2,\\\"yardLine\\\":68,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":3,\\\"yardsToEndzone\\\":68},\\\"text\\\":\\\"(:59) (Shotgun) PENALTY on JAX-J.Robinson, False Start, 5 yards, enforced at JAX 32 - No Play.\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"0:59\\\"},\\\"type\\\":{\\\"id\\\":\\\"8\\\",\\\"text\\\":\\\"Penalty\\\",\\\"abbreviation\\\":\\\"PEN\\\"}},\\\"homeWinPercentage\\\":0.559,\\\"playId\\\":\\\"401220303797\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":1},\\\"homeScore\\\":0,\\\"awayScore\\\":9,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"3rd & 7\\\",\\\"possessionText\\\":\\\"JAX 27\\\",\\\"downDistanceText\\\":\\\"3rd & 7 at JAX 27\\\",\\\"distance\\\":7,\\\"yardLine\\\":73,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":3,\\\"yardsToEndzone\\\":73},\\\"text\\\":\\\"(:38) (Shotgun) M.Glennon pass incomplete short right to D.Chark Jr..\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"0:38\\\"},\\\"type\\\":{\\\"id\\\":\\\"3\\\",\\\"text\\\":\\\"Pass Incompletion\\\"}},\\\"homeWinPercentage\\\":0.591,\\\"playId\\\":\\\"401220303820\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":1},\\\"homeScore\\\":0,\\\"awayScore\\\":9,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"4th & 7\\\",\\\"possessionText\\\":\\\"JAX 27\\\",\\\"downDistanceText\\\":\\\"4th & 7 at JAX 27\\\",\\\"distance\\\":7,\\\"yardLine\\\":73,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":4,\\\"yardsToEndzone\\\":73},\\\"text\\\":\\\"(:33) L.Cooke punts 59 yards to MIN 14, Center-R.Matiscik. K.Osborn to MIN 21 for 7 yards (D.Ogunbowale).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"0:33\\\"},\\\"type\\\":{\\\"id\\\":\\\"52\\\",\\\"text\\\":\\\"Punt\\\",\\\"abbreviation\\\":\\\"PUNT\\\"}},\\\"homeWinPercentage\\\":0.567,\\\"playId\\\":\\\"401220303842\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":1},\\\"homeScore\\\":0,\\\"awayScore\\\":9,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 10\\\",\\\"possessionText\\\":\\\"MIN 21\\\",\\\"downDistanceText\\\":\\\"1st & 10 at MIN 21\\\",\\\"distance\\\":10,\\\"yardLine\\\":21,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":79},\\\"text\\\":\\\"(:22) K.Cousins pass short right to J.Jefferson to MIN 28 for 7 yards (J.Jones).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"0:22\\\"},\\\"type\\\":{\\\"id\\\":\\\"24\\\",\\\"text\\\":\\\"Pass Reception\\\",\\\"abbreviation\\\":\\\"REC\\\"}},\\\"homeWinPercentage\\\":0.577,\\\"playId\\\":\\\"401220303867\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":1},\\\"homeScore\\\":0,\\\"awayScore\\\":9,\\\"start\\\":{\\\"distance\\\":0,\\\"yardLine\\\":0,\\\"down\\\":2,\\\"yardsToEndzone\\\":72},\\\"text\\\":\\\"END QUARTER 1\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"0:00\\\"},\\\"type\\\":{\\\"id\\\":\\\"2\\\",\\\"text\\\":\\\"End Period\\\",\\\"abbreviation\\\":\\\"EP\\\"}},\\\"homeWinPercentage\\\":0.574,\\\"playId\\\":\\\"401220303891\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":2},\\\"homeScore\\\":0,\\\"awayScore\\\":9,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"2nd & 3\\\",\\\"possessionText\\\":\\\"MIN 28\\\",\\\"downDistanceText\\\":\\\"2nd & 3 at MIN 28\\\",\\\"distance\\\":3,\\\"yardLine\\\":28,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":2,\\\"yardsToEndzone\\\":72},\\\"text\\\":\\\"(15:00) D.Cook left end to MIN 29 for 1 yard (M.Jack; D.Costin).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"15:00\\\"},\\\"type\\\":{\\\"id\\\":\\\"5\\\",\\\"text\\\":\\\"Rush\\\",\\\"abbreviation\\\":\\\"RUSH\\\"}},\\\"homeWinPercentage\\\":0.559,\\\"playId\\\":\\\"401220303910\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":2},\\\"homeScore\\\":0,\\\"awayScore\\\":9,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"3rd & 2\\\",\\\"possessionText\\\":\\\"MIN 29\\\",\\\"downDistanceText\\\":\\\"3rd & 2 at MIN 29\\\",\\\"distance\\\":2,\\\"yardLine\\\":29,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":3,\\\"yardsToEndzone\\\":71},\\\"text\\\":\\\"(14:22) (Shotgun) K.Cousins pass incomplete short right to A.Thielen (G.Mabin).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"14:22\\\"},\\\"type\\\":{\\\"id\\\":\\\"3\\\",\\\"text\\\":\\\"Pass Incompletion\\\"}},\\\"homeWinPercentage\\\":0.489,\\\"playId\\\":\\\"401220303931\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":2},\\\"homeScore\\\":0,\\\"awayScore\\\":9,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"4th & 2\\\",\\\"possessionText\\\":\\\"MIN 29\\\",\\\"downDistanceText\\\":\\\"4th & 2 at MIN 29\\\",\\\"distance\\\":2,\\\"yardLine\\\":29,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":4,\\\"yardsToEndzone\\\":71},\\\"text\\\":\\\"(14:17) B.Colquitt punts 46 yards to JAX 25, Center-A.DePaola, downed by MIN-K.Boyd.\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"14:17\\\"},\\\"type\\\":{\\\"id\\\":\\\"52\\\",\\\"text\\\":\\\"Punt\\\",\\\"abbreviation\\\":\\\"PUNT\\\"}},\\\"homeWinPercentage\\\":0.5,\\\"playId\\\":\\\"401220303953\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":2},\\\"homeScore\\\":0,\\\"awayScore\\\":9,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 10\\\",\\\"possessionText\\\":\\\"JAX 25\\\",\\\"downDistanceText\\\":\\\"1st & 10 at JAX 25\\\",\\\"distance\\\":10,\\\"yardLine\\\":75,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":75},\\\"text\\\":\\\"(14:06) J.Robinson left guard to JAX 28 for 3 yards (T.Davis; J.Johnson).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"14:06\\\"},\\\"type\\\":{\\\"id\\\":\\\"5\\\",\\\"text\\\":\\\"Rush\\\",\\\"abbreviation\\\":\\\"RUSH\\\"}},\\\"homeWinPercentage\\\":0.493,\\\"playId\\\":\\\"401220303972\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":2},\\\"homeScore\\\":0,\\\"awayScore\\\":9,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"2nd & 7\\\",\\\"possessionText\\\":\\\"JAX 28\\\",\\\"downDistanceText\\\":\\\"2nd & 7 at JAX 28\\\",\\\"distance\\\":7,\\\"yardLine\\\":72,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":2,\\\"yardsToEndzone\\\":72},\\\"text\\\":\\\"(13:27) (Shotgun) M.Glennon pass short left to L.Shenault Jr. to JAX 35 for 7 yards (H.Smith; E.Wilson).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"13:27\\\"},\\\"type\\\":{\\\"id\\\":\\\"24\\\",\\\"text\\\":\\\"Pass Reception\\\",\\\"abbreviation\\\":\\\"REC\\\"}},\\\"homeWinPercentage\\\":0.474,\\\"playId\\\":\\\"401220303993\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":2},\\\"homeScore\\\":0,\\\"awayScore\\\":9,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 10\\\",\\\"possessionText\\\":\\\"JAX 35\\\",\\\"downDistanceText\\\":\\\"1st & 10 at JAX 35\\\",\\\"distance\\\":10,\\\"yardLine\\\":65,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":65},\\\"text\\\":\\\"(12:50) M.Glennon pass incomplete deep left to D.Chark Jr..\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"12:50\\\"},\\\"type\\\":{\\\"id\\\":\\\"3\\\",\\\"text\\\":\\\"Pass Incompletion\\\"}},\\\"homeWinPercentage\\\":0.507,\\\"playId\\\":\\\"4012203031017\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":2},\\\"homeScore\\\":0,\\\"awayScore\\\":9,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"2nd & 10\\\",\\\"possessionText\\\":\\\"JAX 35\\\",\\\"downDistanceText\\\":\\\"2nd & 10 at JAX 35\\\",\\\"distance\\\":10,\\\"yardLine\\\":65,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":2,\\\"yardsToEndzone\\\":65},\\\"text\\\":\\\"(12:44) (Shotgun) M.Glennon pass short right to C.Johnson to JAX 41 for 6 yards (H.Smith).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"12:44\\\"},\\\"type\\\":{\\\"id\\\":\\\"24\\\",\\\"text\\\":\\\"Pass Reception\\\",\\\"abbreviation\\\":\\\"REC\\\"}},\\\"homeWinPercentage\\\":0.519,\\\"playId\\\":\\\"4012203031039\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":2},\\\"homeScore\\\":0,\\\"awayScore\\\":9,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"3rd & 4\\\",\\\"possessionText\\\":\\\"JAX 41\\\",\\\"downDistanceText\\\":\\\"3rd & 4 at JAX 41\\\",\\\"distance\\\":4,\\\"yardLine\\\":59,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":3,\\\"yardsToEndzone\\\":59},\\\"text\\\":\\\"(12:03) (Shotgun) M.Glennon pass short left to T.Eifert to JAX 47 for 6 yards (C.Jones).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"12:03\\\"},\\\"type\\\":{\\\"id\\\":\\\"24\\\",\\\"text\\\":\\\"Pass Reception\\\",\\\"abbreviation\\\":\\\"REC\\\"}},\\\"homeWinPercentage\\\":0.439,\\\"playId\\\":\\\"4012203031063\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":2},\\\"homeScore\\\":0,\\\"awayScore\\\":9,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 10\\\",\\\"possessionText\\\":\\\"JAX 47\\\",\\\"downDistanceText\\\":\\\"1st & 10 at JAX 47\\\",\\\"distance\\\":10,\\\"yardLine\\\":53,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":53},\\\"text\\\":\\\"(11:24) J.Robinson right end to 50 for 3 yards (T.Davis; A.Watts).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"11:24\\\"},\\\"type\\\":{\\\"id\\\":\\\"5\\\",\\\"text\\\":\\\"Rush\\\",\\\"abbreviation\\\":\\\"RUSH\\\"}},\\\"homeWinPercentage\\\":0.458,\\\"playId\\\":\\\"4012203031087\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":2},\\\"homeScore\\\":0,\\\"awayScore\\\":9,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"2nd & 7\\\",\\\"possessionText\\\":\\\"50\\\",\\\"downDistanceText\\\":\\\"2nd & 7 at 50\\\",\\\"distance\\\":7,\\\"yardLine\\\":50,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":2,\\\"yardsToEndzone\\\":50},\\\"text\\\":\\\"(10:43) (Shotgun) L.Shenault Jr. right end to MIN 33 for 17 yards (A.Harris).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"10:43\\\"},\\\"type\\\":{\\\"id\\\":\\\"5\\\",\\\"text\\\":\\\"Rush\\\",\\\"abbreviation\\\":\\\"RUSH\\\"}},\\\"homeWinPercentage\\\":0.388,\\\"playId\\\":\\\"4012203031108\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":2},\\\"homeScore\\\":0,\\\"awayScore\\\":9,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 10\\\",\\\"possessionText\\\":\\\"MIN 33\\\",\\\"downDistanceText\\\":\\\"1st & 10 at MIN 33\\\",\\\"distance\\\":10,\\\"yardLine\\\":33,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":33},\\\"text\\\":\\\"(10:02) PENALTY on JAX-J.Taylor, False Start, 5 yards, enforced at MIN 33 - No Play.\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"10:02\\\"},\\\"type\\\":{\\\"id\\\":\\\"8\\\",\\\"text\\\":\\\"Penalty\\\",\\\"abbreviation\\\":\\\"PEN\\\"}},\\\"homeWinPercentage\\\":0.444,\\\"playId\\\":\\\"4012203031132\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":2},\\\"homeScore\\\":0,\\\"awayScore\\\":9,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 15\\\",\\\"possessionText\\\":\\\"MIN 38\\\",\\\"downDistanceText\\\":\\\"1st & 15 at MIN 38\\\",\\\"distance\\\":15,\\\"yardLine\\\":38,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":38},\\\"text\\\":\\\"(9:38) (Shotgun) D.Ogunbowale left end to MIN 34 for 4 yards (E.Yarbrough).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"9:38\\\"},\\\"type\\\":{\\\"id\\\":\\\"5\\\",\\\"text\\\":\\\"Rush\\\",\\\"abbreviation\\\":\\\"RUSH\\\"}},\\\"homeWinPercentage\\\":0.419,\\\"playId\\\":\\\"4012203031159\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":2},\\\"homeScore\\\":0,\\\"awayScore\\\":9,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"2nd & 11\\\",\\\"possessionText\\\":\\\"MIN 34\\\",\\\"downDistanceText\\\":\\\"2nd & 11 at MIN 34\\\",\\\"distance\\\":11,\\\"yardLine\\\":34,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":2,\\\"yardsToEndzone\\\":34},\\\"text\\\":\\\"(8:58) (Shotgun) M.Glennon pass incomplete short left to D.Ogunbowale.\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"8:58\\\"},\\\"type\\\":{\\\"id\\\":\\\"3\\\",\\\"text\\\":\\\"Pass Incompletion\\\"}},\\\"homeWinPercentage\\\":0.427,\\\"playId\\\":\\\"4012203031181\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":2},\\\"homeScore\\\":0,\\\"awayScore\\\":9,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"3rd & 11\\\",\\\"possessionText\\\":\\\"MIN 34\\\",\\\"downDistanceText\\\":\\\"3rd & 11 at MIN 34\\\",\\\"distance\\\":11,\\\"yardLine\\\":34,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":3,\\\"yardsToEndzone\\\":34},\\\"text\\\":\\\"(8:55) (Shotgun) M.Glennon pass short right to T.Eifert to MIN 21 for 13 yards (E.Wilson).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"8:55\\\"},\\\"type\\\":{\\\"id\\\":\\\"24\\\",\\\"text\\\":\\\"Pass Reception\\\",\\\"abbreviation\\\":\\\"REC\\\"}},\\\"homeWinPercentage\\\":0.486,\\\"playId\\\":\\\"4012203031203\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":2},\\\"homeScore\\\":0,\\\"awayScore\\\":9,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 10\\\",\\\"possessionText\\\":\\\"MIN 21\\\",\\\"downDistanceText\\\":\\\"1st & 10 at MIN 21\\\",\\\"distance\\\":10,\\\"yardLine\\\":21,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":21},\\\"text\\\":\\\"(8:16) (Shotgun) J.Robinson right tackle to MIN 16 for 5 yards (C.Jones; A.Harris). PENALTY on JAX-L.Shenault Jr., Illegal Shift, 5 yards, enforced at MIN 21 - No Play.\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"8:16\\\"},\\\"type\\\":{\\\"id\\\":\\\"5\\\",\\\"text\\\":\\\"Rush\\\",\\\"abbreviation\\\":\\\"RUSH\\\"}},\\\"homeWinPercentage\\\":0.386,\\\"playId\\\":\\\"4012203031227\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":2},\\\"homeScore\\\":0,\\\"awayScore\\\":9,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 15\\\",\\\"possessionText\\\":\\\"MIN 26\\\",\\\"downDistanceText\\\":\\\"1st & 15 at MIN 26\\\",\\\"distance\\\":15,\\\"yardLine\\\":26,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":26},\\\"text\\\":\\\"(7:46) (Shotgun) M.Glennon pass short left intended for E.Saubert INTERCEPTED by C.Dantzler at MIN 22. C.Dantzler to MIN 22 for no gain (E.Saubert).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"7:46\\\"},\\\"type\\\":{\\\"id\\\":\\\"26\\\",\\\"text\\\":\\\"Pass Interception Return\\\",\\\"abbreviation\\\":\\\"INTR\\\"}},\\\"homeWinPercentage\\\":0.495,\\\"playId\\\":\\\"4012203031259\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":2},\\\"homeScore\\\":0,\\\"awayScore\\\":9,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 10\\\",\\\"possessionText\\\":\\\"MIN 22\\\",\\\"downDistanceText\\\":\\\"1st & 10 at MIN 22\\\",\\\"distance\\\":10,\\\"yardLine\\\":22,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":78},\\\"text\\\":\\\"(7:40) D.Cook left tackle to MIN 26 for 4 yards (J.Jones).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"7:40\\\"},\\\"type\\\":{\\\"id\\\":\\\"5\\\",\\\"text\\\":\\\"Rush\\\",\\\"abbreviation\\\":\\\"RUSH\\\"}},\\\"homeWinPercentage\\\":0.502,\\\"playId\\\":\\\"4012203031285\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":2},\\\"homeScore\\\":0,\\\"awayScore\\\":9,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"2nd & 6\\\",\\\"possessionText\\\":\\\"MIN 26\\\",\\\"downDistanceText\\\":\\\"2nd & 6 at MIN 26\\\",\\\"distance\\\":6,\\\"yardLine\\\":26,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":2,\\\"yardsToEndzone\\\":74},\\\"text\\\":\\\"(7:12) K.Cousins pass short right to A.Thielen pushed ob at MIN 40 for 14 yards (G.Mabin).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"7:12\\\"},\\\"type\\\":{\\\"id\\\":\\\"24\\\",\\\"text\\\":\\\"Pass Reception\\\",\\\"abbreviation\\\":\\\"REC\\\"}},\\\"homeWinPercentage\\\":0.524,\\\"playId\\\":\\\"4012203031306\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":2},\\\"homeScore\\\":0,\\\"awayScore\\\":9,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 10\\\",\\\"possessionText\\\":\\\"MIN 40\\\",\\\"downDistanceText\\\":\\\"1st & 10 at MIN 40\\\",\\\"distance\\\":10,\\\"yardLine\\\":40,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":60},\\\"text\\\":\\\"(6:41) D.Cook right tackle to MIN 44 for 4 yards (D.Costin; J.Giles-Harris).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"6:41\\\"},\\\"type\\\":{\\\"id\\\":\\\"5\\\",\\\"text\\\":\\\"Rush\\\",\\\"abbreviation\\\":\\\"RUSH\\\"}},\\\"homeWinPercentage\\\":0.507,\\\"playId\\\":\\\"4012203031335\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":2},\\\"homeScore\\\":0,\\\"awayScore\\\":9,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"2nd & 6\\\",\\\"possessionText\\\":\\\"MIN 44\\\",\\\"downDistanceText\\\":\\\"2nd & 6 at MIN 44\\\",\\\"distance\\\":6,\\\"yardLine\\\":44,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":2,\\\"yardsToEndzone\\\":56},\\\"text\\\":\\\"(6:07) K.Cousins pass short right to D.Cook to JAX 45 for 11 yards (J.Giles-Harris).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"6:07\\\"},\\\"type\\\":{\\\"id\\\":\\\"24\\\",\\\"text\\\":\\\"Pass Reception\\\",\\\"abbreviation\\\":\\\"REC\\\"}},\\\"homeWinPercentage\\\":0.542,\\\"playId\\\":\\\"4012203031356\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":2},\\\"homeScore\\\":0,\\\"awayScore\\\":9,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 10\\\",\\\"possessionText\\\":\\\"JAX 45\\\",\\\"downDistanceText\\\":\\\"1st & 10 at JAX 45\\\",\\\"distance\\\":10,\\\"yardLine\\\":55,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":45},\\\"text\\\":\\\"(5:27) K.Cousins scrambles left end to JAX 35 for 10 yards (G.Mabin).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"5:27\\\"},\\\"type\\\":{\\\"id\\\":\\\"5\\\",\\\"text\\\":\\\"Rush\\\",\\\"abbreviation\\\":\\\"RUSH\\\"}},\\\"homeWinPercentage\\\":0.556,\\\"playId\\\":\\\"4012203031380\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":2},\\\"homeScore\\\":0,\\\"awayScore\\\":9,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 10\\\",\\\"possessionText\\\":\\\"JAX 35\\\",\\\"downDistanceText\\\":\\\"1st & 10 at JAX 35\\\",\\\"distance\\\":10,\\\"yardLine\\\":65,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":35},\\\"text\\\":\\\"(4:47) K.Cousins pass short right to A.Thielen pushed ob at JAX 23 for 12 yards (G.Mabin).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"4:47\\\"},\\\"type\\\":{\\\"id\\\":\\\"24\\\",\\\"text\\\":\\\"Pass Reception\\\",\\\"abbreviation\\\":\\\"REC\\\"}},\\\"homeWinPercentage\\\":0.58,\\\"playId\\\":\\\"4012203031401\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":2},\\\"homeScore\\\":0,\\\"awayScore\\\":9,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 10\\\",\\\"possessionText\\\":\\\"JAX 23\\\",\\\"downDistanceText\\\":\\\"1st & 10 at JAX 23\\\",\\\"distance\\\":10,\\\"yardLine\\\":77,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":23},\\\"text\\\":\\\"(4:16) K.Cousins pass incomplete deep left to K.Rudolph [J.Giles-Harris].\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"4:16\\\"},\\\"type\\\":{\\\"id\\\":\\\"3\\\",\\\"text\\\":\\\"Pass Incompletion\\\"}},\\\"homeWinPercentage\\\":0.543,\\\"playId\\\":\\\"4012203031430\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":2},\\\"homeScore\\\":0,\\\"awayScore\\\":9,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"2nd & 10\\\",\\\"possessionText\\\":\\\"JAX 23\\\",\\\"downDistanceText\\\":\\\"2nd & 10 at JAX 23\\\",\\\"distance\\\":10,\\\"yardLine\\\":77,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":2,\\\"yardsToEndzone\\\":23},\\\"text\\\":\\\"(4:10) (Shotgun) K.Cousins pass short middle to D.Cook pushed ob at JAX 3 for 20 yards (M.Jack).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"4:10\\\"},\\\"type\\\":{\\\"id\\\":\\\"24\\\",\\\"text\\\":\\\"Pass Reception\\\",\\\"abbreviation\\\":\\\"REC\\\"}},\\\"homeWinPercentage\\\":0.485,\\\"playId\\\":\\\"4012203031452\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":2},\\\"homeScore\\\":0,\\\"awayScore\\\":9,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & Goal\\\",\\\"possessionText\\\":\\\"JAX 3\\\",\\\"downDistanceText\\\":\\\"1st & Goal at JAX 3\\\",\\\"distance\\\":3,\\\"yardLine\\\":97,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":3},\\\"text\\\":\\\"(3:37) D.Cook left tackle to JAX 3 for no gain (J.Jones; J.Giles-Harris).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"3:37\\\"},\\\"type\\\":{\\\"id\\\":\\\"5\\\",\\\"text\\\":\\\"Rush\\\",\\\"abbreviation\\\":\\\"RUSH\\\"}},\\\"homeWinPercentage\\\":0.61,\\\"playId\\\":\\\"4012203031476\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":2},\\\"homeScore\\\":6,\\\"awayScore\\\":9,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"2nd & Goal\\\",\\\"possessionText\\\":\\\"JAX 3\\\",\\\"downDistanceText\\\":\\\"2nd & Goal at JAX 3\\\",\\\"distance\\\":3,\\\"yardLine\\\":97,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":2,\\\"yardsToEndzone\\\":3},\\\"text\\\":\\\"Adam Thielen 3 Yd pass from Kirk Cousins (Dan Bailey PAT failed)\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"2:50\\\"},\\\"type\\\":{\\\"id\\\":\\\"67\\\",\\\"text\\\":\\\"Passing Touchdown\\\",\\\"abbreviation\\\":\\\"TD\\\"}},\\\"homeWinPercentage\\\":0.608,\\\"playId\\\":\\\"4012203031497\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":2},\\\"homeScore\\\":6,\\\"awayScore\\\":9,\\\"start\\\":{\\\"distance\\\":0,\\\"yardLine\\\":35,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":0,\\\"yardsToEndzone\\\":65},\\\"text\\\":\\\"D.Bailey kicks 65 yards from MIN 35 to end zone, Touchback.\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"2:50\\\"},\\\"type\\\":{\\\"id\\\":\\\"53\\\",\\\"text\\\":\\\"Kickoff\\\",\\\"abbreviation\\\":\\\"K\\\"}},\\\"homeWinPercentage\\\":0.601,\\\"playId\\\":\\\"4012203031538\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":2},\\\"homeScore\\\":6,\\\"awayScore\\\":9,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 10\\\",\\\"possessionText\\\":\\\"JAX 25\\\",\\\"downDistanceText\\\":\\\"1st & 10 at JAX 25\\\",\\\"distance\\\":10,\\\"yardLine\\\":75,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":75},\\\"text\\\":\\\"(2:50) (Shotgun) M.Glennon pass incomplete short middle to D.Ogunbowale [I.Odenigbo].\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"2:50\\\"},\\\"type\\\":{\\\"id\\\":\\\"3\\\",\\\"text\\\":\\\"Pass Incompletion\\\"}},\\\"homeWinPercentage\\\":0.635,\\\"playId\\\":\\\"4012203031553\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":2},\\\"homeScore\\\":6,\\\"awayScore\\\":9,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"2nd & 10\\\",\\\"possessionText\\\":\\\"JAX 25\\\",\\\"downDistanceText\\\":\\\"2nd & 10 at JAX 25\\\",\\\"distance\\\":10,\\\"yardLine\\\":75,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":2,\\\"yardsToEndzone\\\":75},\\\"text\\\":\\\"(2:46) (Shotgun) M.Glennon pass short right to J.Robinson to JAX 31 for 6 yards (T.Davis).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"2:46\\\"},\\\"type\\\":{\\\"id\\\":\\\"24\\\",\\\"text\\\":\\\"Pass Reception\\\",\\\"abbreviation\\\":\\\"REC\\\"}},\\\"homeWinPercentage\\\":0.62,\\\"playId\\\":\\\"4012203031575\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":2},\\\"homeScore\\\":6,\\\"awayScore\\\":9,\\\"start\\\":{\\\"distance\\\":4,\\\"yardLine\\\":69,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":3,\\\"yardsToEndzone\\\":69},\\\"text\\\":\\\"Two-Minute Warning\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"2:00\\\"},\\\"type\\\":{\\\"id\\\":\\\"75\\\",\\\"text\\\":\\\"Two-minute warning\\\",\\\"abbreviation\\\":\\\"2Min Warn\\\"}},\\\"homeWinPercentage\\\":0.616,\\\"playId\\\":\\\"4012203031599\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":2},\\\"homeScore\\\":6,\\\"awayScore\\\":9,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"3rd & 4\\\",\\\"possessionText\\\":\\\"JAX 31\\\",\\\"downDistanceText\\\":\\\"3rd & 4 at JAX 31\\\",\\\"distance\\\":4,\\\"yardLine\\\":69,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":3,\\\"yardsToEndzone\\\":69},\\\"text\\\":\\\"(2:00) (Shotgun) M.Glennon pass short left to L.Shenault Jr. to JAX 34 for 3 yards (I.Odenigbo; E.Wilson).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"2:00\\\"},\\\"type\\\":{\\\"id\\\":\\\"24\\\",\\\"text\\\":\\\"Pass Reception\\\",\\\"abbreviation\\\":\\\"REC\\\"}},\\\"homeWinPercentage\\\":0.657,\\\"playId\\\":\\\"4012203031622\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":2},\\\"homeScore\\\":6,\\\"awayScore\\\":9,\\\"start\\\":{\\\"distance\\\":1,\\\"yardLine\\\":66,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":4,\\\"yardsToEndzone\\\":66},\\\"text\\\":\\\"Timeout #1 by MIN at 01:54.\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"1:54\\\"},\\\"type\\\":{\\\"id\\\":\\\"21\\\",\\\"text\\\":\\\"Timeout\\\",\\\"abbreviation\\\":\\\"TO\\\"}},\\\"homeWinPercentage\\\":0.645,\\\"playId\\\":\\\"4012203031646\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":2},\\\"homeScore\\\":6,\\\"awayScore\\\":9,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"4th & 1\\\",\\\"possessionText\\\":\\\"JAX 34\\\",\\\"downDistanceText\\\":\\\"4th & 1 at JAX 34\\\",\\\"distance\\\":1,\\\"yardLine\\\":66,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":4,\\\"yardsToEndzone\\\":66},\\\"text\\\":\\\"(1:54) L.Cooke punts 48 yards to MIN 18, Center-R.Matiscik. K.Osborn to MIN 26 for 8 yards (B.Watson).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"1:54\\\"},\\\"type\\\":{\\\"id\\\":\\\"52\\\",\\\"text\\\":\\\"Punt\\\",\\\"abbreviation\\\":\\\"PUNT\\\"}},\\\"homeWinPercentage\\\":0.641,\\\"playId\\\":\\\"4012203031663\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":2},\\\"homeScore\\\":6,\\\"awayScore\\\":9,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 10\\\",\\\"possessionText\\\":\\\"MIN 26\\\",\\\"downDistanceText\\\":\\\"1st & 10 at MIN 26\\\",\\\"distance\\\":10,\\\"yardLine\\\":26,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":74},\\\"text\\\":\\\"(1:45) (Shotgun) D.Cook left guard to MIN 28 for 2 yards (J.Schobert; C.Reid).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"1:45\\\"},\\\"type\\\":{\\\"id\\\":\\\"5\\\",\\\"text\\\":\\\"Rush\\\",\\\"abbreviation\\\":\\\"RUSH\\\"}},\\\"homeWinPercentage\\\":0.618,\\\"playId\\\":\\\"4012203031688\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":2},\\\"homeScore\\\":6,\\\"awayScore\\\":9,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"2nd & 8\\\",\\\"possessionText\\\":\\\"MIN 28\\\",\\\"downDistanceText\\\":\\\"2nd & 8 at MIN 28\\\",\\\"distance\\\":8,\\\"yardLine\\\":28,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":2,\\\"yardsToEndzone\\\":72},\\\"text\\\":\\\"(1:28) (No Huddle, Shotgun) PENALTY on JAX-D.Smoot, Neutral Zone Infraction, 5 yards, enforced at MIN 28 - No Play.\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"1:28\\\"},\\\"type\\\":{\\\"id\\\":\\\"8\\\",\\\"text\\\":\\\"Penalty\\\",\\\"abbreviation\\\":\\\"PEN\\\"}},\\\"homeWinPercentage\\\":0.646,\\\"playId\\\":\\\"4012203031709\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":2},\\\"homeScore\\\":6,\\\"awayScore\\\":9,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"2nd & 3\\\",\\\"possessionText\\\":\\\"MIN 33\\\",\\\"downDistanceText\\\":\\\"2nd & 3 at MIN 33\\\",\\\"distance\\\":3,\\\"yardLine\\\":33,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":2,\\\"yardsToEndzone\\\":67},\\\"text\\\":\\\"(1:28) (Shotgun) K.Cousins pass short left to D.Cook to MIN 38 for 5 yards (T.Herndon) [A.Lynch].\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"1:28\\\"},\\\"type\\\":{\\\"id\\\":\\\"24\\\",\\\"text\\\":\\\"Pass Reception\\\",\\\"abbreviation\\\":\\\"REC\\\"}},\\\"homeWinPercentage\\\":0.652,\\\"playId\\\":\\\"4012203031732\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":2},\\\"homeScore\\\":6,\\\"awayScore\\\":9,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 10\\\",\\\"possessionText\\\":\\\"MIN 38\\\",\\\"downDistanceText\\\":\\\"1st & 10 at MIN 38\\\",\\\"distance\\\":10,\\\"yardLine\\\":38,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":62},\\\"text\\\":\\\"(1:14) (Shotgun) K.Cousins pass short left to D.Cook to MIN 39 for 1 yard (T.Herndon).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"1:14\\\"},\\\"type\\\":{\\\"id\\\":\\\"24\\\",\\\"text\\\":\\\"Pass Reception\\\",\\\"abbreviation\\\":\\\"REC\\\"}},\\\"homeWinPercentage\\\":0.63,\\\"playId\\\":\\\"4012203031756\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":2},\\\"homeScore\\\":6,\\\"awayScore\\\":9,\\\"start\\\":{\\\"distance\\\":9,\\\"yardLine\\\":39,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":2,\\\"yardsToEndzone\\\":61},\\\"text\\\":\\\"Timeout #2 by MIN at 01:05.\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"1:05\\\"},\\\"type\\\":{\\\"id\\\":\\\"21\\\",\\\"text\\\":\\\"Timeout\\\",\\\"abbreviation\\\":\\\"TO\\\"}},\\\"homeWinPercentage\\\":0.617,\\\"playId\\\":\\\"4012203031780\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":2},\\\"homeScore\\\":6,\\\"awayScore\\\":9,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"2nd & 9\\\",\\\"possessionText\\\":\\\"MIN 39\\\",\\\"downDistanceText\\\":\\\"2nd & 9 at MIN 39\\\",\\\"distance\\\":9,\\\"yardLine\\\":39,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":2,\\\"yardsToEndzone\\\":61},\\\"text\\\":\\\"(1:05) (Shotgun) PENALTY on MIN-T.Conklin, False Start, 5 yards, enforced at MIN 39 - No Play.\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"1:05\\\"},\\\"type\\\":{\\\"id\\\":\\\"8\\\",\\\"text\\\":\\\"Penalty\\\",\\\"abbreviation\\\":\\\"PEN\\\"}},\\\"homeWinPercentage\\\":0.593,\\\"playId\\\":\\\"4012203031797\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":2},\\\"homeScore\\\":6,\\\"awayScore\\\":9,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"2nd & 14\\\",\\\"possessionText\\\":\\\"MIN 34\\\",\\\"downDistanceText\\\":\\\"2nd & 14 at MIN 34\\\",\\\"distance\\\":14,\\\"yardLine\\\":34,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":2,\\\"yardsToEndzone\\\":66},\\\"text\\\":\\\"(1:05) (Shotgun) K.Cousins pass short left to C.Beebe pushed ob at MIN 39 for 5 yards (T.Herndon) [K.Chaisson].\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"1:05\\\"},\\\"type\\\":{\\\"id\\\":\\\"24\\\",\\\"text\\\":\\\"Pass Reception\\\",\\\"abbreviation\\\":\\\"REC\\\"}},\\\"homeWinPercentage\\\":0.603,\\\"playId\\\":\\\"4012203031820\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":2},\\\"homeScore\\\":6,\\\"awayScore\\\":9,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"3rd & 9\\\",\\\"possessionText\\\":\\\"MIN 39\\\",\\\"downDistanceText\\\":\\\"3rd & 9 at MIN 39\\\",\\\"distance\\\":9,\\\"yardLine\\\":39,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":3,\\\"yardsToEndzone\\\":61},\\\"text\\\":\\\"(1:00) (Shotgun) K.Cousins sacked at MIN 32 for -7 yards (J.Schobert).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"1:00\\\"},\\\"type\\\":{\\\"id\\\":\\\"7\\\",\\\"text\\\":\\\"Sack\\\"}},\\\"homeWinPercentage\\\":0.569,\\\"playId\\\":\\\"4012203031849\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":2},\\\"homeScore\\\":6,\\\"awayScore\\\":9,\\\"start\\\":{\\\"distance\\\":16,\\\"yardLine\\\":32,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":4,\\\"yardsToEndzone\\\":68},\\\"text\\\":\\\"Timeout #1 by JAX at 00:56.\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"0:56\\\"},\\\"type\\\":{\\\"id\\\":\\\"21\\\",\\\"text\\\":\\\"Timeout\\\",\\\"abbreviation\\\":\\\"TO\\\"}},\\\"homeWinPercentage\\\":0.579,\\\"playId\\\":\\\"4012203031868\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":2},\\\"homeScore\\\":6,\\\"awayScore\\\":9,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"4th & 16\\\",\\\"possessionText\\\":\\\"MIN 32\\\",\\\"downDistanceText\\\":\\\"4th & 16 at MIN 32\\\",\\\"distance\\\":16,\\\"yardLine\\\":32,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":4,\\\"yardsToEndzone\\\":68},\\\"text\\\":\\\"(:56) B.Colquitt punts 45 yards to JAX 23, Center-A.DePaola, fair catch by K.Cole Sr..\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"0:56\\\"},\\\"type\\\":{\\\"id\\\":\\\"52\\\",\\\"text\\\":\\\"Punt\\\",\\\"abbreviation\\\":\\\"PUNT\\\"}},\\\"homeWinPercentage\\\":0.587,\\\"playId\\\":\\\"4012203031885\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":2},\\\"homeScore\\\":6,\\\"awayScore\\\":9,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 10\\\",\\\"possessionText\\\":\\\"JAX 23\\\",\\\"downDistanceText\\\":\\\"1st & 10 at JAX 23\\\",\\\"distance\\\":10,\\\"yardLine\\\":77,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":77},\\\"text\\\":\\\"(:49) (Shotgun) M.Glennon pass short right to T.Eifert pushed ob at JAX 27 for 4 yards (C.Jones).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"0:49\\\"},\\\"type\\\":{\\\"id\\\":\\\"24\\\",\\\"text\\\":\\\"Pass Reception\\\",\\\"abbreviation\\\":\\\"REC\\\"}},\\\"homeWinPercentage\\\":0.695,\\\"playId\\\":\\\"4012203031904\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":2},\\\"homeScore\\\":6,\\\"awayScore\\\":9,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"2nd & 6\\\",\\\"possessionText\\\":\\\"JAX 27\\\",\\\"downDistanceText\\\":\\\"2nd & 6 at JAX 27\\\",\\\"distance\\\":6,\\\"yardLine\\\":73,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":2,\\\"yardsToEndzone\\\":73},\\\"text\\\":\\\"(:43) (Shotgun) M.Glennon pass short left to J.Robinson ran ob at JAX 32 for 5 yards (C.Dantzler).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"0:43\\\"},\\\"type\\\":{\\\"id\\\":\\\"24\\\",\\\"text\\\":\\\"Pass Reception\\\",\\\"abbreviation\\\":\\\"REC\\\"}},\\\"homeWinPercentage\\\":0.583,\\\"playId\\\":\\\"4012203031928\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":2},\\\"homeScore\\\":6,\\\"awayScore\\\":9,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"3rd & 1\\\",\\\"possessionText\\\":\\\"JAX 32\\\",\\\"downDistanceText\\\":\\\"3rd & 1 at JAX 32\\\",\\\"distance\\\":1,\\\"yardLine\\\":68,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":3,\\\"yardsToEndzone\\\":68},\\\"text\\\":\\\"(:35) (Shotgun) M.Glennon pass incomplete short middle to D.Chark Jr. (H.Smith).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"0:35\\\"},\\\"type\\\":{\\\"id\\\":\\\"3\\\",\\\"text\\\":\\\"Pass Incompletion\\\"}},\\\"homeWinPercentage\\\":0.62,\\\"playId\\\":\\\"4012203031957\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":2},\\\"homeScore\\\":6,\\\"awayScore\\\":9,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"4th & 1\\\",\\\"possessionText\\\":\\\"JAX 32\\\",\\\"downDistanceText\\\":\\\"4th & 1 at JAX 32\\\",\\\"distance\\\":1,\\\"yardLine\\\":68,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":4,\\\"yardsToEndzone\\\":68},\\\"text\\\":\\\"(:31) L.Cooke punts 47 yards to MIN 21, Center-R.Matiscik, downed by JAX.\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"0:31\\\"},\\\"type\\\":{\\\"id\\\":\\\"52\\\",\\\"text\\\":\\\"Punt\\\",\\\"abbreviation\\\":\\\"PUNT\\\"}},\\\"homeWinPercentage\\\":0.483,\\\"playId\\\":\\\"4012203031979\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":2},\\\"homeScore\\\":6,\\\"awayScore\\\":9,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 10\\\",\\\"possessionText\\\":\\\"MIN 21\\\",\\\"downDistanceText\\\":\\\"1st & 10 at MIN 21\\\",\\\"distance\\\":10,\\\"yardLine\\\":21,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":79},\\\"text\\\":\\\"(:18) K.Cousins pass incomplete short right to C.Beebe (A.Lynch).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"0:18\\\"},\\\"type\\\":{\\\"id\\\":\\\"3\\\",\\\"text\\\":\\\"Pass Incompletion\\\"}},\\\"homeWinPercentage\\\":0.601,\\\"playId\\\":\\\"4012203031999\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":2},\\\"homeScore\\\":6,\\\"awayScore\\\":9,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"2nd & 10\\\",\\\"possessionText\\\":\\\"MIN 21\\\",\\\"downDistanceText\\\":\\\"2nd & 10 at MIN 21\\\",\\\"distance\\\":10,\\\"yardLine\\\":21,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":2,\\\"yardsToEndzone\\\":79},\\\"text\\\":\\\"(:15) (Shotgun) A.Abdullah right guard to MIN 25 for 4 yards (C.Reid).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"0:15\\\"},\\\"type\\\":{\\\"id\\\":\\\"5\\\",\\\"text\\\":\\\"Rush\\\",\\\"abbreviation\\\":\\\"RUSH\\\"}},\\\"homeWinPercentage\\\":0.603,\\\"playId\\\":\\\"4012203032021\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":2},\\\"homeScore\\\":6,\\\"awayScore\\\":9,\\\"start\\\":{\\\"distance\\\":6,\\\"yardLine\\\":25,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":3,\\\"yardsToEndzone\\\":75},\\\"text\\\":\\\"Timeout #2 by JAX at 00:10.\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"0:10\\\"},\\\"type\\\":{\\\"id\\\":\\\"21\\\",\\\"text\\\":\\\"Timeout\\\",\\\"abbreviation\\\":\\\"TO\\\"}},\\\"homeWinPercentage\\\":0.606,\\\"playId\\\":\\\"4012203032042\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":2},\\\"homeScore\\\":6,\\\"awayScore\\\":9,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"3rd & 6\\\",\\\"possessionText\\\":\\\"MIN 25\\\",\\\"downDistanceText\\\":\\\"3rd & 6 at MIN 25\\\",\\\"distance\\\":6,\\\"yardLine\\\":25,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":3,\\\"yardsToEndzone\\\":75},\\\"text\\\":\\\"(:10) (Shotgun) A.Abdullah right tackle to MIN 32 for 7 yards (K.Chaisson).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"0:10\\\"},\\\"type\\\":{\\\"id\\\":\\\"5\\\",\\\"text\\\":\\\"Rush\\\",\\\"abbreviation\\\":\\\"RUSH\\\"}},\\\"homeWinPercentage\\\":0.531,\\\"playId\\\":\\\"4012203032059\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":2},\\\"homeScore\\\":6,\\\"awayScore\\\":9,\\\"start\\\":{\\\"distance\\\":0,\\\"yardLine\\\":0,\\\"down\\\":0,\\\"yardsToEndzone\\\":0},\\\"text\\\":\\\"END QUARTER 2\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"0:00\\\"},\\\"type\\\":{\\\"id\\\":\\\"65\\\",\\\"text\\\":\\\"End of Half\\\",\\\"abbreviation\\\":\\\"EH\\\"}},\\\"homeWinPercentage\\\":0.644,\\\"playId\\\":\\\"4012203032086\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":3},\\\"homeScore\\\":6,\\\"awayScore\\\":9,\\\"start\\\":{\\\"distance\\\":0,\\\"yardLine\\\":65,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":0,\\\"yardsToEndzone\\\":65},\\\"text\\\":\\\"L.Cooke kicks 50 yards from JAX 35 to MIN 15, out of bounds.\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"15:00\\\"},\\\"type\\\":{\\\"id\\\":\\\"53\\\",\\\"text\\\":\\\"Kickoff\\\",\\\"abbreviation\\\":\\\"K\\\"}},\\\"homeWinPercentage\\\":0.673,\\\"playId\\\":\\\"4012203032117\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":3},\\\"homeScore\\\":6,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 10\\\",\\\"possessionText\\\":\\\"MIN 40\\\",\\\"downDistanceText\\\":\\\"1st & 10 at MIN 40\\\",\\\"distance\\\":10,\\\"yardLine\\\":40,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":60},\\\"text\\\":\\\"Joe Schobert 43 Yrd Interception Return C.McLaughlin extra point is GOOD, Center-R.Matiscik, Holder-L.Cooke.\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"14:50\\\"},\\\"type\\\":{\\\"id\\\":\\\"36\\\",\\\"text\\\":\\\"Interception Return Touchdown\\\",\\\"abbreviation\\\":\\\"TD\\\"}},\\\"homeWinPercentage\\\":0.329,\\\"playId\\\":\\\"4012203032143\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":3},\\\"homeScore\\\":6,\\\"awayScore\\\":16,\\\"start\\\":{\\\"distance\\\":0,\\\"yardLine\\\":65,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":0,\\\"yardsToEndzone\\\":65},\\\"text\\\":\\\"L.Cooke kicks 65 yards from JAX 35 to end zone, Touchback.\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"14:50\\\"},\\\"type\\\":{\\\"id\\\":\\\"53\\\",\\\"text\\\":\\\"Kickoff\\\",\\\"abbreviation\\\":\\\"K\\\"}},\\\"homeWinPercentage\\\":0.335,\\\"playId\\\":\\\"4012203032186\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":3},\\\"homeScore\\\":6,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 10\\\",\\\"possessionText\\\":\\\"MIN 25\\\",\\\"downDistanceText\\\":\\\"1st & 10 at MIN 25\\\",\\\"distance\\\":10,\\\"yardLine\\\":25,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":75},\\\"text\\\":\\\"(14:50) D.Cook left tackle to MIN 26 for 1 yard (J.Schobert).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"14:50\\\"},\\\"type\\\":{\\\"id\\\":\\\"5\\\",\\\"text\\\":\\\"Rush\\\",\\\"abbreviation\\\":\\\"RUSH\\\"}},\\\"homeWinPercentage\\\":0.311,\\\"playId\\\":\\\"4012203032201\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":3},\\\"homeScore\\\":6,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"2nd & 9\\\",\\\"possessionText\\\":\\\"MIN 26\\\",\\\"downDistanceText\\\":\\\"2nd & 9 at MIN 26\\\",\\\"distance\\\":9,\\\"yardLine\\\":26,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":2,\\\"yardsToEndzone\\\":74},\\\"text\\\":\\\"(14:21) K.Cousins pass short right to D.Cook pushed ob at MIN 36 for 10 yards (M.Jack).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"14:21\\\"},\\\"type\\\":{\\\"id\\\":\\\"24\\\",\\\"text\\\":\\\"Pass Reception\\\",\\\"abbreviation\\\":\\\"REC\\\"}},\\\"homeWinPercentage\\\":0.311,\\\"playId\\\":\\\"4012203032222\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":3},\\\"homeScore\\\":6,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 10\\\",\\\"possessionText\\\":\\\"MIN 36\\\",\\\"downDistanceText\\\":\\\"1st & 10 at MIN 36\\\",\\\"distance\\\":10,\\\"yardLine\\\":36,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":64},\\\"text\\\":\\\"(13:49) D.Cook left end to MIN 36 for no gain (J.Schobert; D.Costin).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"13:49\\\"},\\\"type\\\":{\\\"id\\\":\\\"5\\\",\\\"text\\\":\\\"Rush\\\",\\\"abbreviation\\\":\\\"RUSH\\\"}},\\\"homeWinPercentage\\\":0.323,\\\"playId\\\":\\\"4012203032246\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":3},\\\"homeScore\\\":6,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"2nd & 10\\\",\\\"possessionText\\\":\\\"MIN 36\\\",\\\"downDistanceText\\\":\\\"2nd & 10 at MIN 36\\\",\\\"distance\\\":10,\\\"yardLine\\\":36,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":2,\\\"yardsToEndzone\\\":64},\\\"text\\\":\\\"(13:14) K.Cousins pass incomplete short right to D.Cook [J.Giles-Harris].\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"13:14\\\"},\\\"type\\\":{\\\"id\\\":\\\"3\\\",\\\"text\\\":\\\"Pass Incompletion\\\"}},\\\"homeWinPercentage\\\":0.299,\\\"playId\\\":\\\"4012203032267\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":3},\\\"homeScore\\\":6,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"3rd & 10\\\",\\\"possessionText\\\":\\\"MIN 36\\\",\\\"downDistanceText\\\":\\\"3rd & 10 at MIN 36\\\",\\\"distance\\\":10,\\\"yardLine\\\":36,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":3,\\\"yardsToEndzone\\\":64},\\\"text\\\":\\\"(13:10) (Shotgun) K.Cousins pass to A.Thielen to MIN 47 for 11 yards (L.Barcoo).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"13:10\\\"},\\\"type\\\":{\\\"id\\\":\\\"24\\\",\\\"text\\\":\\\"Pass Reception\\\",\\\"abbreviation\\\":\\\"REC\\\"}},\\\"homeWinPercentage\\\":0.363,\\\"playId\\\":\\\"4012203032289\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":3},\\\"homeScore\\\":6,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 10\\\",\\\"possessionText\\\":\\\"MIN 47\\\",\\\"downDistanceText\\\":\\\"1st & 10 at MIN 47\\\",\\\"distance\\\":10,\\\"yardLine\\\":47,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":53},\\\"text\\\":\\\"(12:32) M.Boone up the middle to 50 for 3 yards (A.Gotsis). PENALTY on MIN-B.O'Neill, Offensive Holding, 10 yards, enforced at MIN 47 - No Play.\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"12:32\\\"},\\\"type\\\":{\\\"id\\\":\\\"5\\\",\\\"text\\\":\\\"Rush\\\",\\\"abbreviation\\\":\\\"RUSH\\\"}},\\\"homeWinPercentage\\\":0.333,\\\"playId\\\":\\\"4012203032319\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":3},\\\"homeScore\\\":6,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 20\\\",\\\"possessionText\\\":\\\"MIN 37\\\",\\\"downDistanceText\\\":\\\"1st & 20 at MIN 37\\\",\\\"distance\\\":20,\\\"yardLine\\\":37,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":63},\\\"text\\\":\\\"(12:13) K.Cousins pass short right to J.Jefferson to MIN 48 for 11 yards (L.Barcoo).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"12:13\\\"},\\\"type\\\":{\\\"id\\\":\\\"24\\\",\\\"text\\\":\\\"Pass Reception\\\",\\\"abbreviation\\\":\\\"REC\\\"}},\\\"homeWinPercentage\\\":0.328,\\\"playId\\\":\\\"4012203032351\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":3},\\\"homeScore\\\":6,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"2nd & 9\\\",\\\"possessionText\\\":\\\"MIN 48\\\",\\\"downDistanceText\\\":\\\"2nd & 9 at MIN 48\\\",\\\"distance\\\":9,\\\"yardLine\\\":48,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":2,\\\"yardsToEndzone\\\":52},\\\"text\\\":\\\"(11:41) K.Cousins pass deep right to J.Jefferson pushed ob at JAX 12 for 40 yards (L.Barcoo). Penalty on JAX-L.Barcoo, Defensive Pass Interference, declined.\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"11:41\\\"},\\\"type\\\":{\\\"id\\\":\\\"24\\\",\\\"text\\\":\\\"Pass Reception\\\",\\\"abbreviation\\\":\\\"REC\\\"}},\\\"homeWinPercentage\\\":0.282,\\\"playId\\\":\\\"4012203032375\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":3},\\\"homeScore\\\":13,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 10\\\",\\\"possessionText\\\":\\\"JAX 12\\\",\\\"downDistanceText\\\":\\\"1st & 10 at JAX 12\\\",\\\"distance\\\":10,\\\"yardLine\\\":88,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":12},\\\"text\\\":\\\"C.J. Ham Pass From Kirk Cousins for 12 Yrds D.Bailey extra point is GOOD, Center-A.DePaola, Holder-B.Colquitt.\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"11:08\\\"},\\\"type\\\":{\\\"id\\\":\\\"67\\\",\\\"text\\\":\\\"Passing Touchdown\\\",\\\"abbreviation\\\":\\\"TD\\\"}},\\\"homeWinPercentage\\\":0.538,\\\"playId\\\":\\\"4012203032410\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":3},\\\"homeScore\\\":13,\\\"awayScore\\\":16,\\\"start\\\":{\\\"distance\\\":0,\\\"yardLine\\\":35,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":0,\\\"yardsToEndzone\\\":65},\\\"text\\\":\\\"D.Bailey kicks 65 yards from MIN 35 to end zone, Touchback.\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"11:08\\\"},\\\"type\\\":{\\\"id\\\":\\\"53\\\",\\\"text\\\":\\\"Kickoff\\\",\\\"abbreviation\\\":\\\"K\\\"}},\\\"homeWinPercentage\\\":0.531,\\\"playId\\\":\\\"4012203032451\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":3},\\\"homeScore\\\":13,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 10\\\",\\\"possessionText\\\":\\\"JAX 25\\\",\\\"downDistanceText\\\":\\\"1st & 10 at JAX 25\\\",\\\"distance\\\":10,\\\"yardLine\\\":75,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":75},\\\"text\\\":\\\"(11:08) J.Robinson right end pushed ob at JAX 30 for 5 yards (H.Smith).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"11:08\\\"},\\\"type\\\":{\\\"id\\\":\\\"5\\\",\\\"text\\\":\\\"Rush\\\",\\\"abbreviation\\\":\\\"RUSH\\\"}},\\\"homeWinPercentage\\\":0.521,\\\"playId\\\":\\\"4012203032466\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":3},\\\"homeScore\\\":13,\\\"awayScore\\\":16,\\\"start\\\":{\\\"distance\\\":5,\\\"yardLine\\\":70,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":2,\\\"yardsToEndzone\\\":70},\\\"text\\\":\\\"Timeout #1 by JAX at 10:28.\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"10:28\\\"},\\\"type\\\":{\\\"id\\\":\\\"21\\\",\\\"text\\\":\\\"Timeout\\\",\\\"abbreviation\\\":\\\"TO\\\"}},\\\"homeWinPercentage\\\":0.536,\\\"playId\\\":\\\"4012203032493\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":3},\\\"homeScore\\\":13,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"2nd & 5\\\",\\\"possessionText\\\":\\\"JAX 30\\\",\\\"downDistanceText\\\":\\\"2nd & 5 at JAX 30\\\",\\\"distance\\\":5,\\\"yardLine\\\":70,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":2,\\\"yardsToEndzone\\\":70},\\\"text\\\":\\\"(10:28) M.Glennon pass short right to J.Robinson to JAX 36 for 6 yards (K.Boyd).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"10:28\\\"},\\\"type\\\":{\\\"id\\\":\\\"24\\\",\\\"text\\\":\\\"Pass Reception\\\",\\\"abbreviation\\\":\\\"REC\\\"}},\\\"homeWinPercentage\\\":0.513,\\\"playId\\\":\\\"4012203032510\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":3},\\\"homeScore\\\":13,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 10\\\",\\\"possessionText\\\":\\\"JAX 36\\\",\\\"downDistanceText\\\":\\\"1st & 10 at JAX 36\\\",\\\"distance\\\":10,\\\"yardLine\\\":64,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":64},\\\"text\\\":\\\"(9:47) J.Robinson left end pushed ob at JAX 42 for 6 yards (C.Dantzler).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"9:47\\\"},\\\"type\\\":{\\\"id\\\":\\\"5\\\",\\\"text\\\":\\\"Rush\\\",\\\"abbreviation\\\":\\\"RUSH\\\"}},\\\"homeWinPercentage\\\":0.498,\\\"playId\\\":\\\"4012203032534\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":3},\\\"homeScore\\\":13,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"2nd & 4\\\",\\\"possessionText\\\":\\\"JAX 42\\\",\\\"downDistanceText\\\":\\\"2nd & 4 at JAX 42\\\",\\\"distance\\\":4,\\\"yardLine\\\":58,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":2,\\\"yardsToEndzone\\\":58},\\\"text\\\":\\\"(9:23) (Shotgun) M.Glennon pass short right to J.O'Shaughnessy to JAX 48 for 6 yards (E.Wilson; J.Gladney).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"9:23\\\"},\\\"type\\\":{\\\"id\\\":\\\"24\\\",\\\"text\\\":\\\"Pass Reception\\\",\\\"abbreviation\\\":\\\"REC\\\"}},\\\"homeWinPercentage\\\":0.475,\\\"playId\\\":\\\"4012203032566\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":3},\\\"homeScore\\\":13,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 10\\\",\\\"possessionText\\\":\\\"JAX 48\\\",\\\"downDistanceText\\\":\\\"1st & 10 at JAX 48\\\",\\\"distance\\\":10,\\\"yardLine\\\":52,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":52},\\\"text\\\":\\\"(8:47) J.Robinson up the middle to 50 for 2 yards (E.Yarbrough; S.Stephen).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"8:47\\\"},\\\"type\\\":{\\\"id\\\":\\\"5\\\",\\\"text\\\":\\\"Rush\\\",\\\"abbreviation\\\":\\\"RUSH\\\"}},\\\"homeWinPercentage\\\":0.552,\\\"playId\\\":\\\"4012203032590\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":3},\\\"homeScore\\\":13,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"2nd & 8\\\",\\\"possessionText\\\":\\\"50\\\",\\\"downDistanceText\\\":\\\"2nd & 8 at 50\\\",\\\"distance\\\":8,\\\"yardLine\\\":50,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":2,\\\"yardsToEndzone\\\":90},\\\"text\\\":\\\"(8:09) (Shotgun) M.Glennon pass incomplete deep right to C.Johnson.\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"8:09\\\"},\\\"type\\\":{\\\"id\\\":\\\"3\\\",\\\"text\\\":\\\"Pass Incompletion\\\"}},\\\"homeWinPercentage\\\":0.615,\\\"playId\\\":\\\"4012203032611\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":3},\\\"homeScore\\\":13,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"3rd & 8\\\",\\\"possessionText\\\":\\\"50\\\",\\\"downDistanceText\\\":\\\"3rd & 8 at 50\\\",\\\"distance\\\":8,\\\"yardLine\\\":50,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":3,\\\"yardsToEndzone\\\":50},\\\"text\\\":\\\"(8:04) (Shotgun) M.Glennon sacked at JAX 40 for -10 yards (sack split by H.Smith and H.Mata'afa).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"8:04\\\"},\\\"type\\\":{\\\"id\\\":\\\"7\\\",\\\"text\\\":\\\"Sack\\\"}},\\\"homeWinPercentage\\\":0.556,\\\"playId\\\":\\\"4012203032633\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":3},\\\"homeScore\\\":13,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"4th & 18\\\",\\\"possessionText\\\":\\\"JAX 40\\\",\\\"downDistanceText\\\":\\\"4th & 18 at JAX 40\\\",\\\"distance\\\":18,\\\"yardLine\\\":60,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":4,\\\"yardsToEndzone\\\":60},\\\"text\\\":\\\"(7:26) L.Cooke punts 60 yards to end zone, Center-R.Matiscik, Touchback. PENALTY on MIN-K.Boyd, Illegal Block Above the Waist, 10 yards, enforced at MIN 20.\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"7:26\\\"},\\\"type\\\":{\\\"id\\\":\\\"52\\\",\\\"text\\\":\\\"Punt\\\",\\\"abbreviation\\\":\\\"PUNT\\\"}},\\\"homeWinPercentage\\\":0.477,\\\"playId\\\":\\\"4012203032652\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":3},\\\"homeScore\\\":13,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 10\\\",\\\"possessionText\\\":\\\"MIN 10\\\",\\\"downDistanceText\\\":\\\"1st & 10 at MIN 10\\\",\\\"distance\\\":10,\\\"yardLine\\\":10,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":90},\\\"text\\\":\\\"(7:17) D.Cook right end pushed ob at MIN 20 for 10 yards (J.Jones).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"7:17\\\"},\\\"type\\\":{\\\"id\\\":\\\"5\\\",\\\"text\\\":\\\"Rush\\\",\\\"abbreviation\\\":\\\"RUSH\\\"}},\\\"homeWinPercentage\\\":0.544,\\\"playId\\\":\\\"4012203032680\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":3},\\\"homeScore\\\":13,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 10\\\",\\\"possessionText\\\":\\\"MIN 20\\\",\\\"downDistanceText\\\":\\\"1st & 10 at MIN 20\\\",\\\"distance\\\":10,\\\"yardLine\\\":20,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":80},\\\"text\\\":\\\"(6:50) K.Cousins pass short left to A.Thielen to MIN 29 for 9 yards (M.Jack).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"6:50\\\"},\\\"type\\\":{\\\"id\\\":\\\"24\\\",\\\"text\\\":\\\"Pass Reception\\\",\\\"abbreviation\\\":\\\"REC\\\"}},\\\"homeWinPercentage\\\":0.575,\\\"playId\\\":\\\"4012203032706\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":3},\\\"homeScore\\\":13,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"2nd & 1\\\",\\\"possessionText\\\":\\\"MIN 29\\\",\\\"downDistanceText\\\":\\\"2nd & 1 at MIN 29\\\",\\\"distance\\\":1,\\\"yardLine\\\":29,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":2,\\\"yardsToEndzone\\\":71},\\\"text\\\":\\\"(6:12) K.Cousins up the middle to MIN 31 for 2 yards (C.Reid).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"6:12\\\"},\\\"type\\\":{\\\"id\\\":\\\"5\\\",\\\"text\\\":\\\"Rush\\\",\\\"abbreviation\\\":\\\"RUSH\\\"}},\\\"homeWinPercentage\\\":0.561,\\\"playId\\\":\\\"4012203032730\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":3},\\\"homeScore\\\":13,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 10\\\",\\\"possessionText\\\":\\\"MIN 31\\\",\\\"downDistanceText\\\":\\\"1st & 10 at MIN 31\\\",\\\"distance\\\":10,\\\"yardLine\\\":31,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":69},\\\"text\\\":\\\"(5:38) K.Cousins pass incomplete deep left to J.Jefferson (T.Herndon) [J.Jones]. PENALTY on JAX-J.Jones, Roughing the Passer, 15 yards, enforced at MIN 31 - No Play.\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"5:38\\\"},\\\"type\\\":{\\\"id\\\":\\\"3\\\",\\\"text\\\":\\\"Pass Incompletion\\\"}},\\\"homeWinPercentage\\\":0.588,\\\"playId\\\":\\\"4012203032751\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":3},\\\"homeScore\\\":13,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 10\\\",\\\"possessionText\\\":\\\"MIN 46\\\",\\\"downDistanceText\\\":\\\"1st & 10 at MIN 46\\\",\\\"distance\\\":10,\\\"yardLine\\\":46,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":54},\\\"text\\\":\\\"(5:31) D.Cook left end to MIN 47 for 1 yard (J.Schobert).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"5:31\\\"},\\\"type\\\":{\\\"id\\\":\\\"5\\\",\\\"text\\\":\\\"Rush\\\",\\\"abbreviation\\\":\\\"RUSH\\\"}},\\\"homeWinPercentage\\\":0.559,\\\"playId\\\":\\\"4012203032784\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":3},\\\"homeScore\\\":13,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"2nd & 9\\\",\\\"possessionText\\\":\\\"MIN 47\\\",\\\"downDistanceText\\\":\\\"2nd & 9 at MIN 47\\\",\\\"distance\\\":9,\\\"yardLine\\\":47,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":2,\\\"yardsToEndzone\\\":53},\\\"text\\\":\\\"(4:58) K.Cousins pass incomplete short left to J.Jefferson (D.Costin) [J.Giles-Harris].\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"4:58\\\"},\\\"type\\\":{\\\"id\\\":\\\"3\\\",\\\"text\\\":\\\"Pass Incompletion\\\"}},\\\"homeWinPercentage\\\":0.534,\\\"playId\\\":\\\"4012203032805\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":3},\\\"homeScore\\\":13,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"3rd & 9\\\",\\\"possessionText\\\":\\\"MIN 47\\\",\\\"downDistanceText\\\":\\\"3rd & 9 at MIN 47\\\",\\\"distance\\\":9,\\\"yardLine\\\":47,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":3,\\\"yardsToEndzone\\\":53},\\\"text\\\":\\\"(4:53) (Shotgun) K.Cousins pass short middle to A.Thielen to JAX 41 for 12 yards (J.Jones) [D.Smoot].\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"4:53\\\"},\\\"type\\\":{\\\"id\\\":\\\"24\\\",\\\"text\\\":\\\"Pass Reception\\\",\\\"abbreviation\\\":\\\"REC\\\"}},\\\"homeWinPercentage\\\":0.477,\\\"playId\\\":\\\"4012203032827\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":3},\\\"homeScore\\\":13,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 10\\\",\\\"possessionText\\\":\\\"JAX 41\\\",\\\"downDistanceText\\\":\\\"1st & 10 at JAX 41\\\",\\\"distance\\\":10,\\\"yardLine\\\":59,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":41},\\\"text\\\":\\\"(4:14) D.Cook right end to JAX 38 for 3 yards (D.Costin; M.Jack).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"4:14\\\"},\\\"type\\\":{\\\"id\\\":\\\"5\\\",\\\"text\\\":\\\"Rush\\\",\\\"abbreviation\\\":\\\"RUSH\\\"}},\\\"homeWinPercentage\\\":0.592,\\\"playId\\\":\\\"4012203032851\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":3},\\\"homeScore\\\":13,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"2nd & 7\\\",\\\"possessionText\\\":\\\"JAX 38\\\",\\\"downDistanceText\\\":\\\"2nd & 7 at JAX 38\\\",\\\"distance\\\":7,\\\"yardLine\\\":62,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":2,\\\"yardsToEndzone\\\":38},\\\"text\\\":\\\"(3:40) K.Cousins pass incomplete deep right to J.Jefferson [A.Gotsis]. PENALTY on JAX-L.Barcoo, Defensive Pass Interference, 18 yards, enforced at JAX 38 - No Play.\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"3:40\\\"},\\\"type\\\":{\\\"id\\\":\\\"3\\\",\\\"text\\\":\\\"Pass Incompletion\\\"}},\\\"homeWinPercentage\\\":0.67,\\\"playId\\\":\\\"4012203032872\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":3},\\\"homeScore\\\":19,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 10\\\",\\\"possessionText\\\":\\\"JAX 20\\\",\\\"downDistanceText\\\":\\\"1st & 10 at JAX 20\\\",\\\"distance\\\":10,\\\"yardLine\\\":80,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":20},\\\"text\\\":\\\"Justin Jefferson 20 Yd pass from Kirk Cousins (Dan Bailey PAT failed)\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"3:27\\\"},\\\"type\\\":{\\\"id\\\":\\\"67\\\",\\\"text\\\":\\\"Passing Touchdown\\\",\\\"abbreviation\\\":\\\"TD\\\"}},\\\"homeWinPercentage\\\":0.729,\\\"playId\\\":\\\"4012203032905\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":3},\\\"homeScore\\\":19,\\\"awayScore\\\":16,\\\"start\\\":{\\\"distance\\\":0,\\\"yardLine\\\":35,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":0,\\\"yardsToEndzone\\\":65},\\\"text\\\":\\\"D.Bailey kicks 65 yards from MIN 35 to end zone, Touchback.\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"3:27\\\"},\\\"type\\\":{\\\"id\\\":\\\"53\\\",\\\"text\\\":\\\"Kickoff\\\",\\\"abbreviation\\\":\\\"K\\\"}},\\\"homeWinPercentage\\\":0.722,\\\"playId\\\":\\\"4012203032946\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":3},\\\"homeScore\\\":19,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 10\\\",\\\"possessionText\\\":\\\"JAX 25\\\",\\\"downDistanceText\\\":\\\"1st & 10 at JAX 25\\\",\\\"distance\\\":10,\\\"yardLine\\\":75,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":75},\\\"text\\\":\\\"(3:27) M.Glennon pass incomplete deep left to C.Johnson.\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"3:27\\\"},\\\"type\\\":{\\\"id\\\":\\\"3\\\",\\\"text\\\":\\\"Pass Incompletion\\\"}},\\\"homeWinPercentage\\\":0.749,\\\"playId\\\":\\\"4012203032961\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":3},\\\"homeScore\\\":19,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"2nd & 10\\\",\\\"possessionText\\\":\\\"JAX 25\\\",\\\"downDistanceText\\\":\\\"2nd & 10 at JAX 25\\\",\\\"distance\\\":10,\\\"yardLine\\\":75,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":2,\\\"yardsToEndzone\\\":75},\\\"text\\\":\\\"(3:22) (Shotgun) M.Glennon pass short right to C.Johnson to JAX 30 for 5 yards (K.Boyd).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"3:22\\\"},\\\"type\\\":{\\\"id\\\":\\\"24\\\",\\\"text\\\":\\\"Pass Reception\\\",\\\"abbreviation\\\":\\\"REC\\\"}},\\\"homeWinPercentage\\\":0.739,\\\"playId\\\":\\\"4012203032983\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":3},\\\"homeScore\\\":19,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"3rd & 5\\\",\\\"possessionText\\\":\\\"JAX 30\\\",\\\"downDistanceText\\\":\\\"3rd & 5 at JAX 30\\\",\\\"distance\\\":5,\\\"yardLine\\\":70,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":3,\\\"yardsToEndzone\\\":70},\\\"text\\\":\\\"(2:43) (Shotgun) M.Glennon scrambles right end to JAX 32 for 2 yards (J.Brailford). FUMBLES (J.Brailford), RECOVERED by MIN-J.Brailford at JAX 34.\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"2:43\\\"},\\\"type\\\":{\\\"id\\\":\\\"29\\\",\\\"text\\\":\\\"Fumble Recovery (Opponent)\\\"}},\\\"homeWinPercentage\\\":0.834,\\\"playId\\\":\\\"4012203033007\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":3},\\\"homeScore\\\":19,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 10\\\",\\\"possessionText\\\":\\\"JAX 34\\\",\\\"downDistanceText\\\":\\\"1st & 10 at JAX 34\\\",\\\"distance\\\":10,\\\"yardLine\\\":66,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":34},\\\"text\\\":\\\"(2:24) K.Cousins pass incomplete short right [A.Gotsis].\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"2:24\\\"},\\\"type\\\":{\\\"id\\\":\\\"3\\\",\\\"text\\\":\\\"Pass Incompletion\\\"}},\\\"homeWinPercentage\\\":0.813,\\\"playId\\\":\\\"4012203033044\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":3},\\\"homeScore\\\":19,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"2nd & 10\\\",\\\"possessionText\\\":\\\"JAX 34\\\",\\\"downDistanceText\\\":\\\"2nd & 10 at JAX 34\\\",\\\"distance\\\":10,\\\"yardLine\\\":66,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":2,\\\"yardsToEndzone\\\":34},\\\"text\\\":\\\"(2:19) D.Cook right end pushed ob at JAX 22 for 12 yards (J.Wilson).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"2:19\\\"},\\\"type\\\":{\\\"id\\\":\\\"5\\\",\\\"text\\\":\\\"Rush\\\",\\\"abbreviation\\\":\\\"RUSH\\\"}},\\\"homeWinPercentage\\\":0.726,\\\"playId\\\":\\\"4012203033066\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":3},\\\"homeScore\\\":19,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 10\\\",\\\"possessionText\\\":\\\"JAX 22\\\",\\\"downDistanceText\\\":\\\"1st & 10 at JAX 22\\\",\\\"distance\\\":10,\\\"yardLine\\\":78,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":22},\\\"text\\\":\\\"(1:50) K.Cousins pass short right to A.Thielen to JAX 17 for 5 yards (L.Barcoo).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"1:50\\\"},\\\"type\\\":{\\\"id\\\":\\\"24\\\",\\\"text\\\":\\\"Pass Reception\\\",\\\"abbreviation\\\":\\\"REC\\\"}},\\\"homeWinPercentage\\\":0.735,\\\"playId\\\":\\\"4012203033097\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":3},\\\"homeScore\\\":19,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"2nd & 5\\\",\\\"possessionText\\\":\\\"JAX 17\\\",\\\"downDistanceText\\\":\\\"2nd & 5 at JAX 17\\\",\\\"distance\\\":5,\\\"yardLine\\\":83,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":2,\\\"yardsToEndzone\\\":17},\\\"text\\\":\\\"(1:16) D.Cook left guard to JAX 11 for 6 yards (J.Giles-Harris).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"1:16\\\"},\\\"type\\\":{\\\"id\\\":\\\"5\\\",\\\"text\\\":\\\"Rush\\\",\\\"abbreviation\\\":\\\"RUSH\\\"}},\\\"homeWinPercentage\\\":0.882,\\\"playId\\\":\\\"4012203033121\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":3},\\\"homeScore\\\":19,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 10\\\",\\\"possessionText\\\":\\\"JAX 11\\\",\\\"downDistanceText\\\":\\\"1st & 10 at JAX 11\\\",\\\"distance\\\":10,\\\"yardLine\\\":89,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":11},\\\"text\\\":\\\"(:38) D.Cook up the middle to JAX 1 for 10 yards (J.Wilson; J.Schobert).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"0:38\\\"},\\\"type\\\":{\\\"id\\\":\\\"5\\\",\\\"text\\\":\\\"Rush\\\",\\\"abbreviation\\\":\\\"RUSH\\\"}},\\\"homeWinPercentage\\\":0.9,\\\"playId\\\":\\\"4012203033142\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":3},\\\"homeScore\\\":19,\\\"awayScore\\\":16,\\\"start\\\":{\\\"distance\\\":0,\\\"yardLine\\\":0,\\\"down\\\":1,\\\"yardsToEndzone\\\":1},\\\"text\\\":\\\"END QUARTER 3\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"0:00\\\"},\\\"type\\\":{\\\"id\\\":\\\"2\\\",\\\"text\\\":\\\"End Period\\\",\\\"abbreviation\\\":\\\"EP\\\"}},\\\"homeWinPercentage\\\":0.902,\\\"playId\\\":\\\"4012203033163\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":4},\\\"homeScore\\\":19,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & Goal\\\",\\\"possessionText\\\":\\\"JAX 1\\\",\\\"downDistanceText\\\":\\\"1st & Goal at JAX 1\\\",\\\"distance\\\":1,\\\"yardLine\\\":99,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":1},\\\"text\\\":\\\"(15:00) K.Cousins FUMBLES (Aborted) at JAX 4, RECOVERED by JAX-M.Jack at JAX 2.\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"15:00\\\"},\\\"type\\\":{\\\"id\\\":\\\"29\\\",\\\"text\\\":\\\"Fumble Recovery (Opponent)\\\"}},\\\"homeWinPercentage\\\":0.76,\\\"playId\\\":\\\"4012203033182\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":4},\\\"homeScore\\\":19,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 10\\\",\\\"possessionText\\\":\\\"JAX 2\\\",\\\"downDistanceText\\\":\\\"1st & 10 at JAX 2\\\",\\\"distance\\\":10,\\\"yardLine\\\":98,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":98},\\\"text\\\":\\\"(14:55) J.Robinson up the middle to JAX 5 for 3 yards (J.Gladney). MIN-J.Gladney was injured during the play. JAX-B.Linder was injured during the play.\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"14:55\\\"},\\\"type\\\":{\\\"id\\\":\\\"5\\\",\\\"text\\\":\\\"Rush\\\",\\\"abbreviation\\\":\\\"RUSH\\\"}},\\\"homeWinPercentage\\\":0.776,\\\"playId\\\":\\\"4012203033223\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":4},\\\"homeScore\\\":19,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"2nd & 7\\\",\\\"possessionText\\\":\\\"JAX 5\\\",\\\"downDistanceText\\\":\\\"2nd & 7 at JAX 5\\\",\\\"distance\\\":7,\\\"yardLine\\\":95,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":2,\\\"yardsToEndzone\\\":95},\\\"text\\\":\\\"(14:33) J.Robinson left end to JAX 4 for -1 yards (A.Harris). FUMBLES (A.Harris), RECOVERED by MIN-A.Harris at JAX 4. A.Harris to JAX 2 for 2 yards (E.Saubert). The Replay Official reviewed the fumble ruling, and the play was REVERSED. J.Robinson left end to JAX 4 for -1 yards (A.Harris).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"14:33\\\"},\\\"type\\\":{\\\"id\\\":\\\"5\\\",\\\"text\\\":\\\"Rush\\\",\\\"abbreviation\\\":\\\"RUSH\\\"}},\\\"homeWinPercentage\\\":0.797,\\\"playId\\\":\\\"4012203033257\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":4},\\\"homeScore\\\":21,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"3rd & 8\\\",\\\"possessionText\\\":\\\"JAX 4\\\",\\\"downDistanceText\\\":\\\"3rd & 8 at JAX 4\\\",\\\"distance\\\":8,\\\"yardLine\\\":96,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":3,\\\"yardsToEndzone\\\":96},\\\"text\\\":\\\"Ifeadi Odenigbo Safety\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"14:11\\\"},\\\"type\\\":{\\\"id\\\":\\\"20\\\",\\\"text\\\":\\\"Safety\\\",\\\"abbreviation\\\":\\\"SF\\\"}},\\\"homeWinPercentage\\\":0.887,\\\"playId\\\":\\\"4012203033335\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":4},\\\"homeScore\\\":21,\\\"awayScore\\\":16,\\\"start\\\":{\\\"distance\\\":0,\\\"yardLine\\\":24,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":0,\\\"yardsToEndzone\\\":80},\\\"text\\\":\\\"L.Cooke kicks 56 yards from JAX 20 to MIN 24. K.Osborn to MIN 38 for 14 yards (Q.Williams; D.Middleton).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"14:11\\\"},\\\"type\\\":{\\\"id\\\":\\\"12\\\",\\\"text\\\":\\\"Kickoff Return (Offense)\\\"}},\\\"homeWinPercentage\\\":0.851,\\\"playId\\\":\\\"4012203033354\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":4},\\\"homeScore\\\":21,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 10\\\",\\\"possessionText\\\":\\\"MIN 38\\\",\\\"downDistanceText\\\":\\\"1st & 10 at MIN 38\\\",\\\"distance\\\":10,\\\"yardLine\\\":38,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":62},\\\"text\\\":\\\"(14:05) D.Cook up the middle to MIN 41 for 3 yards (D.Smoot).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"14:05\\\"},\\\"type\\\":{\\\"id\\\":\\\"5\\\",\\\"text\\\":\\\"Rush\\\",\\\"abbreviation\\\":\\\"RUSH\\\"}},\\\"homeWinPercentage\\\":0.837,\\\"playId\\\":\\\"4012203033379\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":4},\\\"homeScore\\\":21,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"2nd & 7\\\",\\\"possessionText\\\":\\\"MIN 41\\\",\\\"downDistanceText\\\":\\\"2nd & 7 at MIN 41\\\",\\\"distance\\\":7,\\\"yardLine\\\":41,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":2,\\\"yardsToEndzone\\\":59},\\\"text\\\":\\\"(13:29) D.Cook up the middle to MIN 41 for no gain (M.Jack).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"13:29\\\"},\\\"type\\\":{\\\"id\\\":\\\"5\\\",\\\"text\\\":\\\"Rush\\\",\\\"abbreviation\\\":\\\"RUSH\\\"}},\\\"homeWinPercentage\\\":0.822,\\\"playId\\\":\\\"4012203033400\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":4},\\\"homeScore\\\":21,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"3rd & 7\\\",\\\"possessionText\\\":\\\"MIN 41\\\",\\\"downDistanceText\\\":\\\"3rd & 7 at MIN 41\\\",\\\"distance\\\":7,\\\"yardLine\\\":41,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":3,\\\"yardsToEndzone\\\":59},\\\"text\\\":\\\"(12:52) (Shotgun) K.Cousins pass short left to J.Jefferson to JAX 45 for 14 yards (J.Jones).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"12:52\\\"},\\\"type\\\":{\\\"id\\\":\\\"24\\\",\\\"text\\\":\\\"Pass Reception\\\",\\\"abbreviation\\\":\\\"REC\\\"}},\\\"homeWinPercentage\\\":0.877,\\\"playId\\\":\\\"4012203033421\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":4},\\\"homeScore\\\":21,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 10\\\",\\\"possessionText\\\":\\\"JAX 45\\\",\\\"downDistanceText\\\":\\\"1st & 10 at JAX 45\\\",\\\"distance\\\":10,\\\"yardLine\\\":55,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":45},\\\"text\\\":\\\"(12:14) D.Cook left guard to JAX 44 for 1 yard (K.Chaisson; M.Jack).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"12:14\\\"},\\\"type\\\":{\\\"id\\\":\\\"5\\\",\\\"text\\\":\\\"Rush\\\",\\\"abbreviation\\\":\\\"RUSH\\\"}},\\\"homeWinPercentage\\\":0.853,\\\"playId\\\":\\\"4012203033445\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":4},\\\"homeScore\\\":21,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"2nd & 9\\\",\\\"possessionText\\\":\\\"JAX 44\\\",\\\"downDistanceText\\\":\\\"2nd & 9 at JAX 44\\\",\\\"distance\\\":9,\\\"yardLine\\\":56,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":2,\\\"yardsToEndzone\\\":44},\\\"text\\\":\\\"(11:34) K.Cousins pass short left to J.Jefferson to JAX 40 for 4 yards (T.Herndon).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"11:34\\\"},\\\"type\\\":{\\\"id\\\":\\\"24\\\",\\\"text\\\":\\\"Pass Reception\\\",\\\"abbreviation\\\":\\\"REC\\\"}},\\\"homeWinPercentage\\\":0.858,\\\"playId\\\":\\\"4012203033466\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":4},\\\"homeScore\\\":21,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"3rd & 5\\\",\\\"possessionText\\\":\\\"JAX 40\\\",\\\"downDistanceText\\\":\\\"3rd & 5 at JAX 40\\\",\\\"distance\\\":5,\\\"yardLine\\\":60,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":3,\\\"yardsToEndzone\\\":40},\\\"text\\\":\\\"(10:50) (Shotgun) K.Cousins pass incomplete deep right to J.Jefferson.\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"10:50\\\"},\\\"type\\\":{\\\"id\\\":\\\"3\\\",\\\"text\\\":\\\"Pass Incompletion\\\"}},\\\"homeWinPercentage\\\":0.81,\\\"playId\\\":\\\"4012203033490\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":4},\\\"homeScore\\\":21,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"4th & 5\\\",\\\"possessionText\\\":\\\"JAX 40\\\",\\\"downDistanceText\\\":\\\"4th & 5 at JAX 40\\\",\\\"distance\\\":5,\\\"yardLine\\\":60,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":4,\\\"yardsToEndzone\\\":40},\\\"text\\\":\\\"(10:45) B.Colquitt punts 40 yards to end zone, Center-A.DePaola, Touchback.\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"10:45\\\"},\\\"type\\\":{\\\"id\\\":\\\"52\\\",\\\"text\\\":\\\"Punt\\\",\\\"abbreviation\\\":\\\"PUNT\\\"}},\\\"homeWinPercentage\\\":0.796,\\\"playId\\\":\\\"4012203033512\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":4},\\\"homeScore\\\":21,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 10\\\",\\\"possessionText\\\":\\\"JAX 20\\\",\\\"downDistanceText\\\":\\\"1st & 10 at JAX 20\\\",\\\"distance\\\":10,\\\"yardLine\\\":80,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":80},\\\"text\\\":\\\"(10:32) J.Robinson left end to JAX 22 for 2 yards (H.Hand).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"10:32\\\"},\\\"type\\\":{\\\"id\\\":\\\"5\\\",\\\"text\\\":\\\"Rush\\\",\\\"abbreviation\\\":\\\"RUSH\\\"}},\\\"homeWinPercentage\\\":0.813,\\\"playId\\\":\\\"4012203033529\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":4},\\\"homeScore\\\":21,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"2nd & 8\\\",\\\"possessionText\\\":\\\"JAX 22\\\",\\\"downDistanceText\\\":\\\"2nd & 8 at JAX 22\\\",\\\"distance\\\":8,\\\"yardLine\\\":78,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":2,\\\"yardsToEndzone\\\":78},\\\"text\\\":\\\"(9:58) (Shotgun) M.Glennon pass incomplete short middle to J.O'Shaughnessy (E.Wilson).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"9:58\\\"},\\\"type\\\":{\\\"id\\\":\\\"3\\\",\\\"text\\\":\\\"Pass Incompletion\\\"}},\\\"homeWinPercentage\\\":0.828,\\\"playId\\\":\\\"4012203033550\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":4},\\\"homeScore\\\":21,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"3rd & 8\\\",\\\"possessionText\\\":\\\"JAX 22\\\",\\\"downDistanceText\\\":\\\"3rd & 8 at JAX 22\\\",\\\"distance\\\":8,\\\"yardLine\\\":78,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":3,\\\"yardsToEndzone\\\":78},\\\"text\\\":\\\"(9:51) (Shotgun) M.Glennon pass short left to T.Eifert to JAX 28 for 6 yards (K.Boyd; T.Davis).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"9:51\\\"},\\\"type\\\":{\\\"id\\\":\\\"24\\\",\\\"text\\\":\\\"Pass Reception\\\",\\\"abbreviation\\\":\\\"REC\\\"}},\\\"homeWinPercentage\\\":0.848,\\\"playId\\\":\\\"4012203033572\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":4},\\\"homeScore\\\":21,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"4th & 2\\\",\\\"possessionText\\\":\\\"JAX 28\\\",\\\"downDistanceText\\\":\\\"4th & 2 at JAX 28\\\",\\\"distance\\\":2,\\\"yardLine\\\":72,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":4,\\\"yardsToEndzone\\\":72},\\\"text\\\":\\\"(9:13) L.Cooke punts 44 yards to MIN 28, Center-R.Matiscik. K.Osborn to MIN 34 for 6 yards (Q.Williams; R.Matiscik). FUMBLES (Q.Williams), and recovers at MIN 34.\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"9:13\\\"},\\\"type\\\":{\\\"id\\\":\\\"52\\\",\\\"text\\\":\\\"Punt\\\",\\\"abbreviation\\\":\\\"PUNT\\\"}},\\\"homeWinPercentage\\\":0.66,\\\"playId\\\":\\\"4012203033596\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":4},\\\"homeScore\\\":21,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 10\\\",\\\"possessionText\\\":\\\"MIN 34\\\",\\\"downDistanceText\\\":\\\"1st & 10 at MIN 34\\\",\\\"distance\\\":10,\\\"yardLine\\\":34,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":66},\\\"text\\\":\\\"(9:02) D.Cook up the middle to MIN 35 for 1 yard (D.Ekuale).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"9:02\\\"},\\\"type\\\":{\\\"id\\\":\\\"5\\\",\\\"text\\\":\\\"Rush\\\",\\\"abbreviation\\\":\\\"RUSH\\\"}},\\\"homeWinPercentage\\\":0.664,\\\"playId\\\":\\\"4012203033637\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":4},\\\"homeScore\\\":21,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"2nd & 9\\\",\\\"possessionText\\\":\\\"MIN 35\\\",\\\"downDistanceText\\\":\\\"2nd & 9 at MIN 35\\\",\\\"distance\\\":9,\\\"yardLine\\\":35,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":2,\\\"yardsToEndzone\\\":65},\\\"text\\\":\\\"(8:23) K.Cousins sacked at MIN 26 for -9 yards (D.Ekuale).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"8:23\\\"},\\\"type\\\":{\\\"id\\\":\\\"7\\\",\\\"text\\\":\\\"Sack\\\"}},\\\"homeWinPercentage\\\":0.771,\\\"playId\\\":\\\"4012203033658\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":4},\\\"homeScore\\\":21,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"3rd & 18\\\",\\\"possessionText\\\":\\\"MIN 26\\\",\\\"downDistanceText\\\":\\\"3rd & 18 at MIN 26\\\",\\\"distance\\\":18,\\\"yardLine\\\":26,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":3,\\\"yardsToEndzone\\\":74},\\\"text\\\":\\\"(7:41) (Shotgun) D.Cook up the middle to MIN 33 for 7 yards (A.Lynch).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"7:41\\\"},\\\"type\\\":{\\\"id\\\":\\\"5\\\",\\\"text\\\":\\\"Rush\\\",\\\"abbreviation\\\":\\\"RUSH\\\"}},\\\"homeWinPercentage\\\":0.774,\\\"playId\\\":\\\"4012203033677\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":4},\\\"homeScore\\\":21,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"4th & 11\\\",\\\"possessionText\\\":\\\"MIN 33\\\",\\\"downDistanceText\\\":\\\"4th & 11 at MIN 33\\\",\\\"distance\\\":11,\\\"yardLine\\\":33,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":4,\\\"yardsToEndzone\\\":67},\\\"text\\\":\\\"(7:08) B.Colquitt punts 49 yards to JAX 18, Center-A.DePaola, fair catch by K.Cole Sr..\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"7:08\\\"},\\\"type\\\":{\\\"id\\\":\\\"52\\\",\\\"text\\\":\\\"Punt\\\",\\\"abbreviation\\\":\\\"PUNT\\\"}},\\\"homeWinPercentage\\\":0.802,\\\"playId\\\":\\\"4012203033698\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":4},\\\"homeScore\\\":21,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 10\\\",\\\"possessionText\\\":\\\"JAX 18\\\",\\\"downDistanceText\\\":\\\"1st & 10 at JAX 18\\\",\\\"distance\\\":10,\\\"yardLine\\\":82,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":82},\\\"text\\\":\\\"(7:01) M.Glennon pass deep left to D.Chark Jr. to JAX 37 for 19 yards (K.Boyd; E.Wilson).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"7:01\\\"},\\\"type\\\":{\\\"id\\\":\\\"24\\\",\\\"text\\\":\\\"Pass Reception\\\",\\\"abbreviation\\\":\\\"REC\\\"}},\\\"homeWinPercentage\\\":0.757,\\\"playId\\\":\\\"4012203033726\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":4},\\\"homeScore\\\":21,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 10\\\",\\\"possessionText\\\":\\\"JAX 37\\\",\\\"downDistanceText\\\":\\\"1st & 10 at JAX 37\\\",\\\"distance\\\":10,\\\"yardLine\\\":63,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":63},\\\"text\\\":\\\"(6:26) M.Glennon scrambles up the middle to JAX 41 for 4 yards (E.Wilson).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"6:26\\\"},\\\"type\\\":{\\\"id\\\":\\\"5\\\",\\\"text\\\":\\\"Rush\\\",\\\"abbreviation\\\":\\\"RUSH\\\"}},\\\"homeWinPercentage\\\":0.769,\\\"playId\\\":\\\"4012203033750\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":4},\\\"homeScore\\\":21,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"2nd & 6\\\",\\\"possessionText\\\":\\\"JAX 41\\\",\\\"downDistanceText\\\":\\\"2nd & 6 at JAX 41\\\",\\\"distance\\\":6,\\\"yardLine\\\":59,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":2,\\\"yardsToEndzone\\\":59},\\\"text\\\":\\\"(5:39) M.Glennon pass short right to C.Conley to JAX 45 for 4 yards (C.Dantzler). FUMBLES (C.Dantzler), RECOVERED by MIN-C.Dantzler at JAX 44. C.Dantzler to JAX 44 for no gain (J.O'Shaughnessy).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"5:39\\\"},\\\"type\\\":{\\\"id\\\":\\\"29\\\",\\\"text\\\":\\\"Fumble Recovery (Opponent)\\\"}},\\\"homeWinPercentage\\\":0.902,\\\"playId\\\":\\\"4012203033771\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":4},\\\"homeScore\\\":21,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 10\\\",\\\"possessionText\\\":\\\"JAX 44\\\",\\\"downDistanceText\\\":\\\"1st & 10 at JAX 44\\\",\\\"distance\\\":10,\\\"yardLine\\\":56,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":44},\\\"text\\\":\\\"(5:29) K.Cousins pass short right to J.Jefferson to JAX 33 for 11 yards (T.Herndon).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"5:29\\\"},\\\"type\\\":{\\\"id\\\":\\\"24\\\",\\\"text\\\":\\\"Pass Reception\\\",\\\"abbreviation\\\":\\\"REC\\\"}},\\\"homeWinPercentage\\\":0.923,\\\"playId\\\":\\\"4012203033811\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":4},\\\"homeScore\\\":21,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 10\\\",\\\"possessionText\\\":\\\"JAX 33\\\",\\\"downDistanceText\\\":\\\"1st & 10 at JAX 33\\\",\\\"distance\\\":10,\\\"yardLine\\\":67,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":33},\\\"text\\\":\\\"(4:49) D.Cook left tackle to JAX 30 for 3 yards (J.Schobert; M.Jack).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"4:49\\\"},\\\"type\\\":{\\\"id\\\":\\\"5\\\",\\\"text\\\":\\\"Rush\\\",\\\"abbreviation\\\":\\\"RUSH\\\"}},\\\"homeWinPercentage\\\":0.922,\\\"playId\\\":\\\"4012203033835\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":4},\\\"homeScore\\\":21,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"2nd & 7\\\",\\\"possessionText\\\":\\\"JAX 30\\\",\\\"downDistanceText\\\":\\\"2nd & 7 at JAX 30\\\",\\\"distance\\\":7,\\\"yardLine\\\":70,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":2,\\\"yardsToEndzone\\\":30},\\\"text\\\":\\\"(4:08) K.Cousins pass incomplete short right [J.Giles-Harris].\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"4:08\\\"},\\\"type\\\":{\\\"id\\\":\\\"3\\\",\\\"text\\\":\\\"Pass Incompletion\\\"}},\\\"homeWinPercentage\\\":0.916,\\\"playId\\\":\\\"4012203033856\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":4},\\\"homeScore\\\":21,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"3rd & 7\\\",\\\"possessionText\\\":\\\"JAX 30\\\",\\\"downDistanceText\\\":\\\"3rd & 7 at JAX 30\\\",\\\"distance\\\":7,\\\"yardLine\\\":70,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":3,\\\"yardsToEndzone\\\":15},\\\"text\\\":\\\"(4:01) (Shotgun) K.Cousins pass incomplete deep left to J.Jefferson (T.Herndon) [J.Schobert].\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"4:01\\\"},\\\"type\\\":{\\\"id\\\":\\\"3\\\",\\\"text\\\":\\\"Pass Incompletion\\\"}},\\\"homeWinPercentage\\\":0.776,\\\"playId\\\":\\\"4012203033878\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":4},\\\"homeScore\\\":24,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"4th & 7\\\",\\\"possessionText\\\":\\\"JAX 30\\\",\\\"downDistanceText\\\":\\\"4th & 7 at JAX 30\\\",\\\"distance\\\":7,\\\"yardLine\\\":70,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":4,\\\"yardsToEndzone\\\":30},\\\"text\\\":\\\"Dan Bailey 48 Yd Field Goal\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"3:50\\\"},\\\"type\\\":{\\\"id\\\":\\\"59\\\",\\\"text\\\":\\\"Field Goal Good\\\",\\\"abbreviation\\\":\\\"FG\\\"}},\\\"homeWinPercentage\\\":0.94,\\\"playId\\\":\\\"4012203033900\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":4},\\\"homeScore\\\":24,\\\"awayScore\\\":16,\\\"start\\\":{\\\"distance\\\":0,\\\"yardLine\\\":35,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":0,\\\"yardsToEndzone\\\":65},\\\"text\\\":\\\"D.Bailey kicks 65 yards from MIN 35 to end zone, Touchback.\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"3:50\\\"},\\\"type\\\":{\\\"id\\\":\\\"53\\\",\\\"text\\\":\\\"Kickoff\\\",\\\"abbreviation\\\":\\\"K\\\"}},\\\"homeWinPercentage\\\":0.936,\\\"playId\\\":\\\"4012203033919\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":4},\\\"homeScore\\\":24,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 10\\\",\\\"possessionText\\\":\\\"JAX 25\\\",\\\"downDistanceText\\\":\\\"1st & 10 at JAX 25\\\",\\\"distance\\\":10,\\\"yardLine\\\":75,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":75},\\\"text\\\":\\\"(3:50) (Shotgun) M.Glennon pass short middle to K.Cole Sr. to JAX 32 for 7 yards (E.Wilson).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"3:50\\\"},\\\"type\\\":{\\\"id\\\":\\\"24\\\",\\\"text\\\":\\\"Pass Reception\\\",\\\"abbreviation\\\":\\\"REC\\\"}},\\\"homeWinPercentage\\\":0.919,\\\"playId\\\":\\\"4012203033934\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":4},\\\"homeScore\\\":24,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"2nd & 3\\\",\\\"possessionText\\\":\\\"JAX 32\\\",\\\"downDistanceText\\\":\\\"2nd & 3 at JAX 32\\\",\\\"distance\\\":3,\\\"yardLine\\\":68,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":2,\\\"yardsToEndzone\\\":68},\\\"text\\\":\\\"(3:29) (No Huddle, Shotgun) M.Glennon pass short left to J.Robinson to JAX 36 for 4 yards (E.Wilson; A.Harris).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"3:29\\\"},\\\"type\\\":{\\\"id\\\":\\\"24\\\",\\\"text\\\":\\\"Pass Reception\\\",\\\"abbreviation\\\":\\\"REC\\\"}},\\\"homeWinPercentage\\\":0.918,\\\"playId\\\":\\\"4012203033958\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":4},\\\"homeScore\\\":24,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 10\\\",\\\"possessionText\\\":\\\"JAX 36\\\",\\\"downDistanceText\\\":\\\"1st & 10 at JAX 36\\\",\\\"distance\\\":10,\\\"yardLine\\\":64,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":64},\\\"text\\\":\\\"(2:56) (No Huddle, Shotgun) M.Glennon pass short right to T.Eifert to JAX 46 for 10 yards (C.Dantzler; T.Davis).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"2:56\\\"},\\\"type\\\":{\\\"id\\\":\\\"24\\\",\\\"text\\\":\\\"Pass Reception\\\",\\\"abbreviation\\\":\\\"REC\\\"}},\\\"homeWinPercentage\\\":0.905,\\\"playId\\\":\\\"4012203033982\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":4},\\\"homeScore\\\":24,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 10\\\",\\\"possessionText\\\":\\\"JAX 46\\\",\\\"downDistanceText\\\":\\\"1st & 10 at JAX 46\\\",\\\"distance\\\":10,\\\"yardLine\\\":54,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":54},\\\"text\\\":\\\"(2:29) (No Huddle, Shotgun) M.Glennon pass incomplete deep right to D.Chark Jr..\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"2:29\\\"},\\\"type\\\":{\\\"id\\\":\\\"3\\\",\\\"text\\\":\\\"Pass Incompletion\\\"}},\\\"homeWinPercentage\\\":0.928,\\\"playId\\\":\\\"4012203034006\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":4},\\\"homeScore\\\":24,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"2nd & 10\\\",\\\"possessionText\\\":\\\"JAX 46\\\",\\\"downDistanceText\\\":\\\"2nd & 10 at JAX 46\\\",\\\"distance\\\":10,\\\"yardLine\\\":54,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":2,\\\"yardsToEndzone\\\":54},\\\"text\\\":\\\"(2:23) (Shotgun) M.Glennon pass short left to C.Conley to MIN 45 for 9 yards (T.Davis; K.Boyd).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"2:23\\\"},\\\"type\\\":{\\\"id\\\":\\\"24\\\",\\\"text\\\":\\\"Pass Reception\\\",\\\"abbreviation\\\":\\\"REC\\\"}},\\\"homeWinPercentage\\\":0.887,\\\"playId\\\":\\\"4012203034028\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":4},\\\"homeScore\\\":24,\\\"awayScore\\\":16,\\\"start\\\":{\\\"distance\\\":1,\\\"yardLine\\\":45,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":3,\\\"yardsToEndzone\\\":45},\\\"text\\\":\\\"Two-Minute Warning\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"2:00\\\"},\\\"type\\\":{\\\"id\\\":\\\"75\\\",\\\"text\\\":\\\"Two-minute warning\\\",\\\"abbreviation\\\":\\\"2Min Warn\\\"}},\\\"homeWinPercentage\\\":0.9,\\\"playId\\\":\\\"4012203034052\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":4},\\\"homeScore\\\":24,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"3rd & 1\\\",\\\"possessionText\\\":\\\"MIN 45\\\",\\\"downDistanceText\\\":\\\"3rd & 1 at MIN 45\\\",\\\"distance\\\":1,\\\"yardLine\\\":45,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":3,\\\"yardsToEndzone\\\":45},\\\"text\\\":\\\"(2:00) PENALTY on JAX-J.Taylor, False Start, 5 yards, enforced at MIN 45 - No Play.\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"2:00\\\"},\\\"type\\\":{\\\"id\\\":\\\"8\\\",\\\"text\\\":\\\"Penalty\\\",\\\"abbreviation\\\":\\\"PEN\\\"}},\\\"homeWinPercentage\\\":0.932,\\\"playId\\\":\\\"4012203034069\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":4},\\\"homeScore\\\":24,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"3rd & 6\\\",\\\"possessionText\\\":\\\"50\\\",\\\"downDistanceText\\\":\\\"3rd & 6 at 50\\\",\\\"distance\\\":6,\\\"yardLine\\\":50,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":3,\\\"yardsToEndzone\\\":50},\\\"text\\\":\\\"(2:00) (Shotgun) M.Glennon pass deep left to D.Chark Jr. pushed ob at MIN 28 for 22 yards (H.Hand).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"2:00\\\"},\\\"type\\\":{\\\"id\\\":\\\"24\\\",\\\"text\\\":\\\"Pass Reception\\\",\\\"abbreviation\\\":\\\"REC\\\"}},\\\"homeWinPercentage\\\":0.977,\\\"playId\\\":\\\"4012203034092\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":4},\\\"homeScore\\\":24,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 10\\\",\\\"possessionText\\\":\\\"MIN 28\\\",\\\"downDistanceText\\\":\\\"1st & 10 at MIN 28\\\",\\\"distance\\\":10,\\\"yardLine\\\":28,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":28},\\\"text\\\":\\\"(1:53) (Shotgun) M.Glennon scrambles left end ran ob at MIN 25 for 3 yards (H.Mata'afa).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"1:53\\\"},\\\"type\\\":{\\\"id\\\":\\\"5\\\",\\\"text\\\":\\\"Rush\\\",\\\"abbreviation\\\":\\\"RUSH\\\"}},\\\"homeWinPercentage\\\":0.881,\\\"playId\\\":\\\"4012203034116\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":4},\\\"homeScore\\\":24,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"2nd & 7\\\",\\\"possessionText\\\":\\\"MIN 25\\\",\\\"downDistanceText\\\":\\\"2nd & 7 at MIN 25\\\",\\\"distance\\\":7,\\\"yardLine\\\":25,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":2,\\\"yardsToEndzone\\\":25},\\\"text\\\":\\\"(1:46) (Shotgun) M.Glennon pass deep right to C.Johnson to MIN 4 for 21 yards (H.Smith).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"1:46\\\"},\\\"type\\\":{\\\"id\\\":\\\"24\\\",\\\"text\\\":\\\"Pass Reception\\\",\\\"abbreviation\\\":\\\"REC\\\"}},\\\"homeWinPercentage\\\":0.771,\\\"playId\\\":\\\"4012203034142\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":4},\\\"homeScore\\\":24,\\\"awayScore\\\":16,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & Goal\\\",\\\"possessionText\\\":\\\"MIN 4\\\",\\\"downDistanceText\\\":\\\"1st & Goal at MIN 4\\\",\\\"distance\\\":4,\\\"yardLine\\\":4,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":4},\\\"text\\\":\\\"(1:18) (No Huddle, Shotgun) D.Ogunbowale up the middle to MIN 1 for 3 yards (J.Brailford).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"1:18\\\"},\\\"type\\\":{\\\"id\\\":\\\"5\\\",\\\"text\\\":\\\"Rush\\\",\\\"abbreviation\\\":\\\"RUSH\\\"}},\\\"homeWinPercentage\\\":0.766,\\\"playId\\\":\\\"4012203034166\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":4},\\\"homeScore\\\":24,\\\"awayScore\\\":16,\\\"start\\\":{\\\"distance\\\":1,\\\"yardLine\\\":1,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":2,\\\"yardsToEndzone\\\":1},\\\"text\\\":\\\"Timeout #1 by MIN at 01:12.\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"1:12\\\"},\\\"type\\\":{\\\"id\\\":\\\"21\\\",\\\"text\\\":\\\"Timeout\\\",\\\"abbreviation\\\":\\\"TO\\\"}},\\\"homeWinPercentage\\\":0.77,\\\"playId\\\":\\\"4012203034187\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":4},\\\"homeScore\\\":24,\\\"awayScore\\\":24,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"2nd & Goal\\\",\\\"possessionText\\\":\\\"MIN 1\\\",\\\"downDistanceText\\\":\\\"2nd & Goal at MIN 1\\\",\\\"distance\\\":1,\\\"yardLine\\\":1,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":2,\\\"yardsToEndzone\\\":1},\\\"text\\\":\\\"James Robinson 1 Yard Rush (Pass formation) TWO-POINT CONVERSION ATTEMPT. M.Glennon pass to C.Johnson is complete. ATTEMPT SUCCEEDS.\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"1:08\\\"},\\\"type\\\":{\\\"id\\\":\\\"68\\\",\\\"text\\\":\\\"Rushing Touchdown\\\",\\\"abbreviation\\\":\\\"TD\\\"}},\\\"homeWinPercentage\\\":0.521,\\\"playId\\\":\\\"4012203034204\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":4},\\\"homeScore\\\":24,\\\"awayScore\\\":24,\\\"start\\\":{\\\"distance\\\":0,\\\"yardLine\\\":65,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":0,\\\"yardsToEndzone\\\":65},\\\"text\\\":\\\"L.Cooke kicks 65 yards from JAX 35 to end zone, Touchback.\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"1:08\\\"},\\\"type\\\":{\\\"id\\\":\\\"53\\\",\\\"text\\\":\\\"Kickoff\\\",\\\"abbreviation\\\":\\\"K\\\"}},\\\"homeWinPercentage\\\":0.551,\\\"playId\\\":\\\"4012203034263\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":4},\\\"homeScore\\\":24,\\\"awayScore\\\":24,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 10\\\",\\\"possessionText\\\":\\\"MIN 25\\\",\\\"downDistanceText\\\":\\\"1st & 10 at MIN 25\\\",\\\"distance\\\":10,\\\"yardLine\\\":25,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":75},\\\"text\\\":\\\"(1:08) (Shotgun) D.Cook right end pushed ob at MIN 29 for 4 yards (J.Scott; J.Schobert).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"1:08\\\"},\\\"type\\\":{\\\"id\\\":\\\"5\\\",\\\"text\\\":\\\"Rush\\\",\\\"abbreviation\\\":\\\"RUSH\\\"}},\\\"homeWinPercentage\\\":0.414,\\\"playId\\\":\\\"4012203034278\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":4},\\\"homeScore\\\":24,\\\"awayScore\\\":24,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"2nd & 6\\\",\\\"possessionText\\\":\\\"MIN 29\\\",\\\"downDistanceText\\\":\\\"2nd & 6 at MIN 29\\\",\\\"distance\\\":6,\\\"yardLine\\\":29,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":2,\\\"yardsToEndzone\\\":71},\\\"text\\\":\\\"(1:03) (Shotgun) K.Cousins pass short left to C.Beebe pushed ob at MIN 34 for 5 yards (T.Herndon).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"1:03\\\"},\\\"type\\\":{\\\"id\\\":\\\"24\\\",\\\"text\\\":\\\"Pass Reception\\\",\\\"abbreviation\\\":\\\"REC\\\"}},\\\"homeWinPercentage\\\":0.442,\\\"playId\\\":\\\"4012203034299\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":4},\\\"homeScore\\\":24,\\\"awayScore\\\":24,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"3rd & 1\\\",\\\"possessionText\\\":\\\"MIN 34\\\",\\\"downDistanceText\\\":\\\"3rd & 1 at MIN 34\\\",\\\"distance\\\":1,\\\"yardLine\\\":34,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":3,\\\"yardsToEndzone\\\":66},\\\"text\\\":\\\"(:58) (Shotgun) D.Cook up the middle to MIN 40 for 6 yards (J.Wilson).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"0:58\\\"},\\\"type\\\":{\\\"id\\\":\\\"5\\\",\\\"text\\\":\\\"Rush\\\",\\\"abbreviation\\\":\\\"RUSH\\\"}},\\\"homeWinPercentage\\\":0.643,\\\"playId\\\":\\\"4012203034323\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":4},\\\"homeScore\\\":24,\\\"awayScore\\\":24,\\\"start\\\":{\\\"distance\\\":10,\\\"yardLine\\\":40,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":60},\\\"text\\\":\\\"Timeout #2 by MIN at 00:53.\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"0:53\\\"},\\\"type\\\":{\\\"id\\\":\\\"21\\\",\\\"text\\\":\\\"Timeout\\\",\\\"abbreviation\\\":\\\"TO\\\"}},\\\"homeWinPercentage\\\":0.618,\\\"playId\\\":\\\"4012203034350\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":4},\\\"homeScore\\\":24,\\\"awayScore\\\":24,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 10\\\",\\\"possessionText\\\":\\\"MIN 40\\\",\\\"downDistanceText\\\":\\\"1st & 10 at MIN 40\\\",\\\"distance\\\":10,\\\"yardLine\\\":40,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":60},\\\"text\\\":\\\"(:53) (Shotgun) K.Cousins pass short middle to A.Abdullah to JAX 42 for 18 yards (J.Scott).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"0:53\\\"},\\\"type\\\":{\\\"id\\\":\\\"24\\\",\\\"text\\\":\\\"Pass Reception\\\",\\\"abbreviation\\\":\\\"REC\\\"}},\\\"homeWinPercentage\\\":0.737,\\\"playId\\\":\\\"4012203034367\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":4},\\\"homeScore\\\":24,\\\"awayScore\\\":24,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 10\\\",\\\"possessionText\\\":\\\"JAX 42\\\",\\\"downDistanceText\\\":\\\"1st & 10 at JAX 42\\\",\\\"distance\\\":10,\\\"yardLine\\\":58,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":42},\\\"text\\\":\\\"(:34) (No Huddle, Shotgun) K.Cousins pass incomplete short left [K.Chaisson].\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"0:34\\\"},\\\"type\\\":{\\\"id\\\":\\\"3\\\",\\\"text\\\":\\\"Pass Incompletion\\\"}},\\\"homeWinPercentage\\\":0.64,\\\"playId\\\":\\\"4012203034391\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":4},\\\"homeScore\\\":24,\\\"awayScore\\\":24,\\\"start\\\":{\\\"distance\\\":10,\\\"yardLine\\\":58,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":2,\\\"yardsToEndzone\\\":42},\\\"text\\\":\\\"Timeout #3 by JAX at 00:29.\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"0:29\\\"},\\\"type\\\":{\\\"id\\\":\\\"21\\\",\\\"text\\\":\\\"Timeout\\\",\\\"abbreviation\\\":\\\"TO\\\"}},\\\"homeWinPercentage\\\":0.642,\\\"playId\\\":\\\"4012203034413\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":4},\\\"homeScore\\\":24,\\\"awayScore\\\":24,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"2nd & 10\\\",\\\"possessionText\\\":\\\"JAX 42\\\",\\\"downDistanceText\\\":\\\"2nd & 10 at JAX 42\\\",\\\"distance\\\":10,\\\"yardLine\\\":58,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":2,\\\"yardsToEndzone\\\":42},\\\"text\\\":\\\"(:29) (Shotgun) K.Cousins pass short right to J.Jefferson to JAX 33 for 9 yards (L.Barcoo).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"0:29\\\"},\\\"type\\\":{\\\"id\\\":\\\"24\\\",\\\"text\\\":\\\"Pass Reception\\\",\\\"abbreviation\\\":\\\"REC\\\"}},\\\"homeWinPercentage\\\":0.835,\\\"playId\\\":\\\"4012203034430\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":4},\\\"homeScore\\\":24,\\\"awayScore\\\":24,\\\"start\\\":{\\\"distance\\\":1,\\\"yardLine\\\":67,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":3,\\\"yardsToEndzone\\\":33},\\\"text\\\":\\\"Timeout #3 by MIN at 00:23.\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"0:23\\\"},\\\"type\\\":{\\\"id\\\":\\\"21\\\",\\\"text\\\":\\\"Timeout\\\",\\\"abbreviation\\\":\\\"TO\\\"}},\\\"homeWinPercentage\\\":0.812,\\\"playId\\\":\\\"4012203034454\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":4},\\\"homeScore\\\":24,\\\"awayScore\\\":24,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"3rd & 1\\\",\\\"possessionText\\\":\\\"JAX 33\\\",\\\"downDistanceText\\\":\\\"3rd & 1 at JAX 33\\\",\\\"distance\\\":1,\\\"yardLine\\\":67,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":3,\\\"yardsToEndzone\\\":33},\\\"text\\\":\\\"(:23) (Shotgun) K.Cousins pass incomplete deep right to A.Thielen (L.Barcoo).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"0:23\\\"},\\\"type\\\":{\\\"id\\\":\\\"3\\\",\\\"text\\\":\\\"Pass Incompletion\\\"}},\\\"homeWinPercentage\\\":0.706,\\\"playId\\\":\\\"4012203034471\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":4},\\\"homeScore\\\":24,\\\"awayScore\\\":24,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"4th & 1\\\",\\\"possessionText\\\":\\\"JAX 33\\\",\\\"downDistanceText\\\":\\\"4th & 1 at JAX 33\\\",\\\"distance\\\":1,\\\"yardLine\\\":67,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":4,\\\"yardsToEndzone\\\":33},\\\"text\\\":\\\"(:18) D.Bailey 51 yard field goal is No Good, Wide Left, Center-A.DePaola, Holder-B.Colquitt.\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"0:18\\\"},\\\"type\\\":{\\\"id\\\":\\\"60\\\",\\\"text\\\":\\\"Field Goal Missed\\\",\\\"abbreviation\\\":\\\"FGM\\\"}},\\\"homeWinPercentage\\\":0.494,\\\"playId\\\":\\\"4012203034493\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":4},\\\"homeScore\\\":24,\\\"awayScore\\\":24,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 10\\\",\\\"possessionText\\\":\\\"JAX 41\\\",\\\"downDistanceText\\\":\\\"1st & 10 at JAX 41\\\",\\\"distance\\\":10,\\\"yardLine\\\":59,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":59},\\\"text\\\":\\\"(:13) (Shotgun) J.Robinson up the middle to MIN 44 for 15 yards (T.Davis).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"0:13\\\"},\\\"type\\\":{\\\"id\\\":\\\"5\\\",\\\"text\\\":\\\"Rush\\\",\\\"abbreviation\\\":\\\"RUSH\\\"}},\\\"homeWinPercentage\\\":0.452,\\\"playId\\\":\\\"4012203034525\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":4},\\\"homeScore\\\":24,\\\"awayScore\\\":24,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 10\\\",\\\"possessionText\\\":\\\"MIN 44\\\",\\\"downDistanceText\\\":\\\"1st & 10 at MIN 44\\\",\\\"distance\\\":10,\\\"yardLine\\\":44,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":85},\\\"text\\\":\\\"(:02) M.Glennon spiked the ball to stop the clock.\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"0:01\\\"},\\\"type\\\":{\\\"id\\\":\\\"3\\\",\\\"text\\\":\\\"Pass Incompletion\\\"}},\\\"homeWinPercentage\\\":0.5,\\\"playId\\\":\\\"4012203034546\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":4},\\\"homeScore\\\":24,\\\"awayScore\\\":24,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"2nd & 10\\\",\\\"possessionText\\\":\\\"MIN 44\\\",\\\"downDistanceText\\\":\\\"2nd & 10 at MIN 44\\\",\\\"distance\\\":10,\\\"yardLine\\\":44,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":2,\\\"yardsToEndzone\\\":44},\\\"text\\\":\\\"(:01) C.McLaughlin 62 yard field goal is No Good, Short, Center-R.Matiscik, Holder-L.Cooke.\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"0:01\\\"},\\\"type\\\":{\\\"id\\\":\\\"60\\\",\\\"text\\\":\\\"Field Goal Missed\\\",\\\"abbreviation\\\":\\\"FGM\\\"}},\\\"homeWinPercentage\\\":0.502,\\\"playId\\\":\\\"4012203034568\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"period\\\":{\\\"number\\\":4},\\\"homeScore\\\":24,\\\"awayScore\\\":24,\\\"start\\\":{\\\"distance\\\":0,\\\"yardLine\\\":0,\\\"down\\\":0,\\\"yardsToEndzone\\\":0},\\\"text\\\":\\\"END QUARTER 4\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"0:00\\\"},\\\"type\\\":{\\\"id\\\":\\\"79\\\",\\\"text\\\":\\\"End of Regulation\\\",\\\"abbreviation\\\":\\\"ER\\\"}},\\\"homeWinPercentage\\\":0.5,\\\"playId\\\":\\\"4012203034588\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"overtimePlayCount\\\":1,\\\"period\\\":{\\\"number\\\":5},\\\"homeScore\\\":24,\\\"awayScore\\\":24,\\\"start\\\":{\\\"distance\\\":0,\\\"yardLine\\\":0,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":0,\\\"yardsToEndzone\\\":65},\\\"text\\\":\\\"L.Cooke kicks 65 yards from JAX 35 to MIN 0. A.Abdullah to MIN 24 for 24 yards (S.Quarterman; N.Cottrell).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"10:00\\\"},\\\"type\\\":{\\\"id\\\":\\\"12\\\",\\\"text\\\":\\\"Kickoff Return (Offense)\\\"}},\\\"homeWinPercentage\\\":0.546,\\\"playId\\\":\\\"4012203034607\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"overtimePlayCount\\\":2,\\\"period\\\":{\\\"number\\\":5},\\\"homeScore\\\":24,\\\"awayScore\\\":24,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 10\\\",\\\"possessionText\\\":\\\"MIN 24\\\",\\\"downDistanceText\\\":\\\"1st & 10 at MIN 24\\\",\\\"distance\\\":10,\\\"yardLine\\\":24,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":76},\\\"text\\\":\\\"(9:56) K.Cousins sacked at MIN 15 for -9 yards (D.Smoot).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"9:56\\\"},\\\"type\\\":{\\\"id\\\":\\\"7\\\",\\\"text\\\":\\\"Sack\\\"}},\\\"homeWinPercentage\\\":0.348,\\\"playId\\\":\\\"4012203034629\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"overtimePlayCount\\\":3,\\\"period\\\":{\\\"number\\\":5},\\\"homeScore\\\":24,\\\"awayScore\\\":24,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"2nd & 19\\\",\\\"possessionText\\\":\\\"MIN 15\\\",\\\"downDistanceText\\\":\\\"2nd & 19 at MIN 15\\\",\\\"distance\\\":19,\\\"yardLine\\\":15,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":2,\\\"yardsToEndzone\\\":85},\\\"text\\\":\\\"(9:17) (Shotgun) K.Cousins pass incomplete short middle to K.Rudolph (J.Schobert).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"9:17\\\"},\\\"type\\\":{\\\"id\\\":\\\"3\\\",\\\"text\\\":\\\"Pass Incompletion\\\"}},\\\"homeWinPercentage\\\":0.325,\\\"playId\\\":\\\"4012203034648\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"overtimePlayCount\\\":4,\\\"period\\\":{\\\"number\\\":5},\\\"homeScore\\\":24,\\\"awayScore\\\":24,\\\"start\\\":{\\\"distance\\\":19,\\\"yardLine\\\":15,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":3,\\\"yardsToEndzone\\\":85},\\\"text\\\":\\\"Timeout #1 by MIN at 09:13.\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"9:13\\\"},\\\"type\\\":{\\\"id\\\":\\\"21\\\",\\\"text\\\":\\\"Timeout\\\",\\\"abbreviation\\\":\\\"TO\\\"}},\\\"homeWinPercentage\\\":0.325,\\\"playId\\\":\\\"4012203034670\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"overtimePlayCount\\\":5,\\\"period\\\":{\\\"number\\\":5},\\\"homeScore\\\":24,\\\"awayScore\\\":24,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"3rd & 19\\\",\\\"possessionText\\\":\\\"MIN 15\\\",\\\"downDistanceText\\\":\\\"3rd & 19 at MIN 15\\\",\\\"distance\\\":19,\\\"yardLine\\\":15,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":3,\\\"yardsToEndzone\\\":85},\\\"text\\\":\\\"(9:13) (Shotgun) K.Cousins pass deep left to J.Jefferson to JAX 38 for 47 yards (J.Wilson) [C.Reid]. PENALTY on MIN-J.Jefferson, Offensive Pass Interference, 7 yards, enforced at MIN 15 - No Play.\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"9:13\\\"},\\\"type\\\":{\\\"id\\\":\\\"24\\\",\\\"text\\\":\\\"Pass Reception\\\",\\\"abbreviation\\\":\\\"REC\\\"}},\\\"homeWinPercentage\\\":0.255,\\\"playId\\\":\\\"4012203034687\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"overtimePlayCount\\\":6,\\\"period\\\":{\\\"number\\\":5},\\\"homeScore\\\":24,\\\"awayScore\\\":24,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"3rd & 26\\\",\\\"possessionText\\\":\\\"MIN 8\\\",\\\"downDistanceText\\\":\\\"3rd & 26 at MIN 8\\\",\\\"distance\\\":26,\\\"yardLine\\\":8,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":3,\\\"yardsToEndzone\\\":92},\\\"text\\\":\\\"(8:52) (Shotgun) K.Cousins pass short right to D.Cook to MIN 20 for 12 yards (J.Scott).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"8:52\\\"},\\\"type\\\":{\\\"id\\\":\\\"24\\\",\\\"text\\\":\\\"Pass Reception\\\",\\\"abbreviation\\\":\\\"REC\\\"}},\\\"homeWinPercentage\\\":0.083,\\\"playId\\\":\\\"4012203034722\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"overtimePlayCount\\\":7,\\\"period\\\":{\\\"number\\\":5},\\\"homeScore\\\":24,\\\"awayScore\\\":24,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"4th & 14\\\",\\\"possessionText\\\":\\\"MIN 20\\\",\\\"downDistanceText\\\":\\\"4th & 14 at MIN 20\\\",\\\"distance\\\":14,\\\"yardLine\\\":20,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":4,\\\"yardsToEndzone\\\":80},\\\"text\\\":\\\"(8:16) B.Colquitt punts 52 yards to JAX 28, Center-A.DePaola. K.Cole Sr. to JAX 29 for 1 yard (D.Chisena). PENALTY on JAX-B.Watson, Offensive Holding, 10 yards, enforced at JAX 28.\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"8:16\\\"},\\\"type\\\":{\\\"id\\\":\\\"52\\\",\\\"text\\\":\\\"Punt\\\",\\\"abbreviation\\\":\\\"PUNT\\\"}},\\\"homeWinPercentage\\\":0.52,\\\"playId\\\":\\\"4012203034746\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"overtimePlayCount\\\":8,\\\"period\\\":{\\\"number\\\":5},\\\"homeScore\\\":24,\\\"awayScore\\\":24,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 10\\\",\\\"possessionText\\\":\\\"JAX 18\\\",\\\"downDistanceText\\\":\\\"1st & 10 at JAX 18\\\",\\\"distance\\\":10,\\\"yardLine\\\":82,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":82},\\\"text\\\":\\\"(8:06) M.Glennon pass incomplete short right to J.O'Shaughnessy (A.Harris).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"8:06\\\"},\\\"type\\\":{\\\"id\\\":\\\"3\\\",\\\"text\\\":\\\"Pass Incompletion\\\"}},\\\"homeWinPercentage\\\":0.593,\\\"playId\\\":\\\"4012203034782\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"overtimePlayCount\\\":9,\\\"period\\\":{\\\"number\\\":5},\\\"homeScore\\\":24,\\\"awayScore\\\":24,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"2nd & 10\\\",\\\"possessionText\\\":\\\"JAX 18\\\",\\\"downDistanceText\\\":\\\"2nd & 10 at JAX 18\\\",\\\"distance\\\":10,\\\"yardLine\\\":82,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":2,\\\"yardsToEndzone\\\":82},\\\"text\\\":\\\"(8:01) J.Robinson left end to JAX 20 for 2 yards (K.Boyd; H.Hand).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"8:01\\\"},\\\"type\\\":{\\\"id\\\":\\\"5\\\",\\\"text\\\":\\\"Rush\\\",\\\"abbreviation\\\":\\\"RUSH\\\"}},\\\"homeWinPercentage\\\":0.597,\\\"playId\\\":\\\"4012203034804\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"overtimePlayCount\\\":10,\\\"period\\\":{\\\"number\\\":5},\\\"homeScore\\\":24,\\\"awayScore\\\":24,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"3rd & 8\\\",\\\"possessionText\\\":\\\"JAX 20\\\",\\\"downDistanceText\\\":\\\"3rd & 8 at JAX 20\\\",\\\"distance\\\":8,\\\"yardLine\\\":80,\\\"team\\\":{\\\"id\\\":\\\"30\\\"},\\\"down\\\":3,\\\"yardsToEndzone\\\":80},\\\"text\\\":\\\"(7:19) (Shotgun) M.Glennon pass deep middle intended for D.Chark Jr. INTERCEPTED by H.Smith [I.Odenigbo] at JAX 46. H.Smith to JAX 46 for no gain (D.Chark Jr.).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"7:19\\\"},\\\"type\\\":{\\\"id\\\":\\\"26\\\",\\\"text\\\":\\\"Pass Interception Return\\\",\\\"abbreviation\\\":\\\"INTR\\\"}},\\\"homeWinPercentage\\\":0.764,\\\"playId\\\":\\\"4012203034825\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"overtimePlayCount\\\":11,\\\"period\\\":{\\\"number\\\":5},\\\"homeScore\\\":24,\\\"awayScore\\\":24,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 10\\\",\\\"possessionText\\\":\\\"JAX 46\\\",\\\"downDistanceText\\\":\\\"1st & 10 at JAX 46\\\",\\\"distance\\\":10,\\\"yardLine\\\":54,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":46},\\\"text\\\":\\\"(7:13) K.Cousins pass short left to A.Thielen to JAX 37 for 9 yards (J.Wilson).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"7:13\\\"},\\\"type\\\":{\\\"id\\\":\\\"24\\\",\\\"text\\\":\\\"Pass Reception\\\",\\\"abbreviation\\\":\\\"REC\\\"}},\\\"homeWinPercentage\\\":0.793,\\\"playId\\\":\\\"4012203034851\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"overtimePlayCount\\\":12,\\\"period\\\":{\\\"number\\\":5},\\\"homeScore\\\":24,\\\"awayScore\\\":24,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"2nd & 1\\\",\\\"possessionText\\\":\\\"JAX 37\\\",\\\"downDistanceText\\\":\\\"2nd & 1 at JAX 37\\\",\\\"distance\\\":1,\\\"yardLine\\\":63,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":2,\\\"yardsToEndzone\\\":37},\\\"text\\\":\\\"(6:41) K.Cousins pass incomplete short right to T.Conklin (J.Jones). PENALTY on MIN-J.Jefferson, Offensive Offside, 5 yards, enforced at JAX 37 - No Play.\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"6:41\\\"},\\\"type\\\":{\\\"id\\\":\\\"3\\\",\\\"text\\\":\\\"Pass Incompletion\\\"}},\\\"homeWinPercentage\\\":0.719,\\\"playId\\\":\\\"4012203034875\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"overtimePlayCount\\\":13,\\\"period\\\":{\\\"number\\\":5},\\\"homeScore\\\":24,\\\"awayScore\\\":24,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"2nd & 6\\\",\\\"possessionText\\\":\\\"JAX 42\\\",\\\"downDistanceText\\\":\\\"2nd & 6 at JAX 42\\\",\\\"distance\\\":6,\\\"yardLine\\\":58,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":2,\\\"yardsToEndzone\\\":42},\\\"text\\\":\\\"(6:35) K.Cousins pass short middle to T.Conklin to JAX 32 for 10 yards (J.Jones).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"6:35\\\"},\\\"type\\\":{\\\"id\\\":\\\"24\\\",\\\"text\\\":\\\"Pass Reception\\\",\\\"abbreviation\\\":\\\"REC\\\"}},\\\"homeWinPercentage\\\":0.844,\\\"playId\\\":\\\"4012203034908\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"overtimePlayCount\\\":14,\\\"period\\\":{\\\"number\\\":5},\\\"homeScore\\\":24,\\\"awayScore\\\":24,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 10\\\",\\\"possessionText\\\":\\\"JAX 32\\\",\\\"downDistanceText\\\":\\\"1st & 10 at JAX 32\\\",\\\"distance\\\":10,\\\"yardLine\\\":68,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":32},\\\"text\\\":\\\"(5:57) D.Cook right guard to JAX 27 for 5 yards (J.Giles-Harris; J.Jones).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"5:57\\\"},\\\"type\\\":{\\\"id\\\":\\\"5\\\",\\\"text\\\":\\\"Rush\\\",\\\"abbreviation\\\":\\\"RUSH\\\"}},\\\"homeWinPercentage\\\":0.883,\\\"playId\\\":\\\"4012203034932\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"overtimePlayCount\\\":15,\\\"period\\\":{\\\"number\\\":5},\\\"homeScore\\\":24,\\\"awayScore\\\":24,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"2nd & 5\\\",\\\"possessionText\\\":\\\"JAX 27\\\",\\\"downDistanceText\\\":\\\"2nd & 5 at JAX 27\\\",\\\"distance\\\":5,\\\"yardLine\\\":73,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":2,\\\"yardsToEndzone\\\":27},\\\"text\\\":\\\"(5:21) D.Cook left end to JAX 28 for -1 yards (J.Schobert; M.Jack).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"5:21\\\"},\\\"type\\\":{\\\"id\\\":\\\"5\\\",\\\"text\\\":\\\"Rush\\\",\\\"abbreviation\\\":\\\"RUSH\\\"}},\\\"homeWinPercentage\\\":0.871,\\\"playId\\\":\\\"4012203034953\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"overtimePlayCount\\\":16,\\\"period\\\":{\\\"number\\\":5},\\\"homeScore\\\":24,\\\"awayScore\\\":24,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"3rd & 6\\\",\\\"possessionText\\\":\\\"JAX 28\\\",\\\"downDistanceText\\\":\\\"3rd & 6 at JAX 28\\\",\\\"distance\\\":6,\\\"yardLine\\\":72,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":3,\\\"yardsToEndzone\\\":28},\\\"text\\\":\\\"(4:38) D.Cook up the middle to JAX 18 for 10 yards (J.Jones).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"4:38\\\"},\\\"type\\\":{\\\"id\\\":\\\"5\\\",\\\"text\\\":\\\"Rush\\\",\\\"abbreviation\\\":\\\"RUSH\\\"}},\\\"homeWinPercentage\\\":0.925,\\\"playId\\\":\\\"4012203034974\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"overtimePlayCount\\\":17,\\\"period\\\":{\\\"number\\\":5},\\\"homeScore\\\":24,\\\"awayScore\\\":24,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & 10\\\",\\\"possessionText\\\":\\\"JAX 18\\\",\\\"downDistanceText\\\":\\\"1st & 10 at JAX 18\\\",\\\"distance\\\":10,\\\"yardLine\\\":82,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":18},\\\"text\\\":\\\"(4:03) D.Cook up the middle to JAX 14 for 4 yards (J.Schobert; T.Herndon).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"4:03\\\"},\\\"type\\\":{\\\"id\\\":\\\"5\\\",\\\"text\\\":\\\"Rush\\\",\\\"abbreviation\\\":\\\"RUSH\\\"}},\\\"homeWinPercentage\\\":0.949,\\\"playId\\\":\\\"4012203034995\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"overtimePlayCount\\\":18,\\\"period\\\":{\\\"number\\\":5},\\\"homeScore\\\":24,\\\"awayScore\\\":24,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"2nd & 6\\\",\\\"possessionText\\\":\\\"JAX 14\\\",\\\"downDistanceText\\\":\\\"2nd & 6 at JAX 14\\\",\\\"distance\\\":6,\\\"yardLine\\\":86,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":2,\\\"yardsToEndzone\\\":14},\\\"text\\\":\\\"(3:28) D.Cook right end to JAX 11 for 3 yards (D.Costin).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"3:28\\\"},\\\"type\\\":{\\\"id\\\":\\\"5\\\",\\\"text\\\":\\\"Rush\\\",\\\"abbreviation\\\":\\\"RUSH\\\"}},\\\"homeWinPercentage\\\":0.966,\\\"playId\\\":\\\"4012203035016\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"overtimePlayCount\\\":20,\\\"period\\\":{\\\"number\\\":5},\\\"homeScore\\\":24,\\\"awayScore\\\":24,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"3rd & 3\\\",\\\"possessionText\\\":\\\"JAX 11\\\",\\\"downDistanceText\\\":\\\"3rd & 3 at JAX 11\\\",\\\"distance\\\":3,\\\"yardLine\\\":89,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":3,\\\"yardsToEndzone\\\":11},\\\"text\\\":\\\"(3:03) D.Cook left guard to JAX 5 for 6 yards (J.Wilson; J.Jones).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"3:03\\\"},\\\"type\\\":{\\\"id\\\":\\\"5\\\",\\\"text\\\":\\\"Rush\\\",\\\"abbreviation\\\":\\\"RUSH\\\"}},\\\"homeWinPercentage\\\":0.981,\\\"playId\\\":\\\"4012203035054\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"overtimePlayCount\\\":19,\\\"period\\\":{\\\"number\\\":5},\\\"homeScore\\\":24,\\\"awayScore\\\":24,\\\"start\\\":{\\\"distance\\\":5,\\\"yardLine\\\":95,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":5},\\\"text\\\":\\\"Timeout #2 by MIN at 03:03.\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"3:01\\\"},\\\"type\\\":{\\\"id\\\":\\\"21\\\",\\\"text\\\":\\\"Timeout\\\",\\\"abbreviation\\\":\\\"TO\\\"}},\\\"homeWinPercentage\\\":0.966,\\\"playId\\\":\\\"4012203035037\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"overtimePlayCount\\\":21,\\\"period\\\":{\\\"number\\\":5},\\\"homeScore\\\":24,\\\"awayScore\\\":24,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"1st & Goal\\\",\\\"possessionText\\\":\\\"JAX 5\\\",\\\"downDistanceText\\\":\\\"1st & Goal at JAX 5\\\",\\\"distance\\\":5,\\\"yardLine\\\":95,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":1,\\\"yardsToEndzone\\\":5},\\\"text\\\":\\\"(2:27) D.Cook left guard to JAX 2 for 3 yards (J.Schobert).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"2:27\\\"},\\\"type\\\":{\\\"id\\\":\\\"5\\\",\\\"text\\\":\\\"Rush\\\",\\\"abbreviation\\\":\\\"RUSH\\\"}},\\\"homeWinPercentage\\\":0.992,\\\"playId\\\":\\\"4012203035075\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"overtimePlayCount\\\":22,\\\"period\\\":{\\\"number\\\":5},\\\"homeScore\\\":24,\\\"awayScore\\\":24,\\\"start\\\":{\\\"distance\\\":2,\\\"yardLine\\\":98,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":2,\\\"yardsToEndzone\\\":2},\\\"text\\\":\\\"Two-Minute Warning\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"2:00\\\"},\\\"type\\\":{\\\"id\\\":\\\"75\\\",\\\"text\\\":\\\"Two-minute warning\\\",\\\"abbreviation\\\":\\\"2Min Warn\\\"}},\\\"homeWinPercentage\\\":0.992,\\\"playId\\\":\\\"4012203035096\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"overtimePlayCount\\\":23,\\\"period\\\":{\\\"number\\\":5},\\\"homeScore\\\":24,\\\"awayScore\\\":24,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"2nd & Goal\\\",\\\"possessionText\\\":\\\"JAX 2\\\",\\\"downDistanceText\\\":\\\"2nd & Goal at JAX 2\\\",\\\"distance\\\":2,\\\"yardLine\\\":98,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":2,\\\"yardsToEndzone\\\":2},\\\"text\\\":\\\"(2:00) D.Cook up the middle to JAX 1 for 1 yard (D.Smoot; A.Gotsis).\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"2:00\\\"},\\\"type\\\":{\\\"id\\\":\\\"5\\\",\\\"text\\\":\\\"Rush\\\",\\\"abbreviation\\\":\\\"RUSH\\\"}},\\\"homeWinPercentage\\\":0.996,\\\"playId\\\":\\\"4012203035113\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"overtimePlayCount\\\":24,\\\"period\\\":{\\\"number\\\":5},\\\"homeScore\\\":24,\\\"awayScore\\\":24,\\\"start\\\":{\\\"distance\\\":1,\\\"yardLine\\\":99,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":3,\\\"yardsToEndzone\\\":1},\\\"text\\\":\\\"Timeout #1 by JAX at 01:53.\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"1:53\\\"},\\\"type\\\":{\\\"id\\\":\\\"21\\\",\\\"text\\\":\\\"Timeout\\\",\\\"abbreviation\\\":\\\"TO\\\"}},\\\"homeWinPercentage\\\":0.996,\\\"playId\\\":\\\"4012203035134\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"overtimePlayCount\\\":25,\\\"period\\\":{\\\"number\\\":5},\\\"homeScore\\\":24,\\\"awayScore\\\":24,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"3rd & Goal\\\",\\\"possessionText\\\":\\\"JAX 1\\\",\\\"downDistanceText\\\":\\\"3rd & Goal at JAX 1\\\",\\\"distance\\\":1,\\\"yardLine\\\":99,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":3,\\\"yardsToEndzone\\\":1},\\\"text\\\":\\\"(1:53) PENALTY on MIN-D.Dozier, False Start, 4 yards, enforced at JAX 1 - No Play.\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"1:53\\\"},\\\"type\\\":{\\\"id\\\":\\\"8\\\",\\\"text\\\":\\\"Penalty\\\",\\\"abbreviation\\\":\\\"PEN\\\"}},\\\"homeWinPercentage\\\":0.987,\\\"playId\\\":\\\"4012203035151\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"overtimePlayCount\\\":26,\\\"period\\\":{\\\"number\\\":5},\\\"homeScore\\\":27,\\\"awayScore\\\":24,\\\"start\\\":{\\\"shortDownDistanceText\\\":\\\"3rd & Goal\\\",\\\"possessionText\\\":\\\"JAX 5\\\",\\\"downDistanceText\\\":\\\"3rd & Goal at JAX 5\\\",\\\"distance\\\":5,\\\"yardLine\\\":95,\\\"team\\\":{\\\"id\\\":\\\"16\\\"},\\\"down\\\":3,\\\"yardsToEndzone\\\":5},\\\"text\\\":\\\"Dan Bailey 23 Yd Field Goal\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"1:49\\\"},\\\"type\\\":{\\\"id\\\":\\\"59\\\",\\\"text\\\":\\\"Field Goal Good\\\",\\\"abbreviation\\\":\\\"FG\\\"}},\\\"homeWinPercentage\\\":1,\\\"playId\\\":\\\"4012203035174\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0},{\\\"play\\\":{\\\"overtimePlayCount\\\":27,\\\"period\\\":{\\\"number\\\":5},\\\"homeScore\\\":27,\\\"awayScore\\\":24,\\\"start\\\":{\\\"distance\\\":0,\\\"yardLine\\\":0,\\\"down\\\":1,\\\"yardsToEndzone\\\":65},\\\"text\\\":\\\"END GAME\\\",\\\"clock\\\":{\\\"displayValue\\\":\\\"0:00\\\"},\\\"type\\\":{\\\"id\\\":\\\"66\\\",\\\"text\\\":\\\"End of Game\\\",\\\"abbreviation\\\":\\\"EG\\\"}},\\\"homeWinPercentage\\\":1,\\\"playId\\\":\\\"4012203035193\\\",\\\"tiePercentage\\\":0,\\\"secondsLeft\\\":0}];\\n\\t\\t\\t\\t\\t\\n\\n\\t\\t\\t\\t\\t\\n\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\n\\t\\t\\t\\t\\t\\t\\n\\n\\t\\t\\t\\t\\t\\tfunction loadScripts() {\\n\\t\\t\\t\\t\\t\\t\\tvar src = \\\"https://a.espncdn.com/redesign/0.591.3/js/dist/gamepackage-static.min.js\\\",\\n\\t\\t\\t\\t\\t\\t\\t\\tscript;\\n\\t\\t\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\tif (espn.gamepackage.status === \\\"in\\\") {\\n\\t\\t\\t\\t\\t\\t\\t\\tif (!espn.gamepackage.core) {\\n\\t\\t\\t\\t\\t\\t\\t\\t\\tsrc = src.replace(\\\"gamepackage.\\\", \\\"gamepackage.core.\\\");\\n\\t\\t\\t\\t\\t\\t\\t\\t} else if (espn.gamepackage.bundles && typeof espn.gamepackage.bundles[espn.gamepackage.sport] === \\\"function\\\") {\\n\\t\\t\\t\\t\\t\\t\\t\\t\\tespn.gamepackage.init();\\n\\t\\t\\t\\t\\t\\t\\t\\t\\tespn.gamepackage.bundles[espn.gamepackage.sport]();\\n\\t\\t\\t\\t\\t\\t\\t\\t\\treturn;\\n\\t\\t\\t\\t\\t\\t\\t\\t}\\n\\t\\t\\t\\t\\t\\t\\t} else if (espn.gamepackage.init) {\\n\\t\\t\\t\\t\\t\\t\\t\\tespn.gamepackage.init();\\n\\t\\t\\t\\t\\t\\t\\t\\treturn;\\n\\t\\t\\t\\t\\t\\t\\t}\\n\\n\\t\\t\\t\\t\\t\\t\\tscript = document.createElement(\\\"script\\\");\\n\\t\\t\\t\\t\\t\\t\\tscript.type = \\\"text/javascript\\\";\\n\\t\\t\\t\\t\\t\\t\\tscript.src = src;\\n\\t\\t\\t\\t\\t\\t\\tdocument.getElementsByTagName(\\\"head\\\")[0].appendChild(script);\\n\\t\\t\\t\\t\\t\\t}\\n\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\tif (window.espn_ui.deferReady === true) {\\n\\t\\t\\t\\t\\t\\t\\t\\t$(document).one(\\\"page.render\\\", loadScripts);\\n\\t\\t\\t\\t\\t\\t\\t} else {\\n\\t\\t\\t\\t\\t\\t\\t\\t$.subscribe(\\\"espn.defer.end\\\", loadScripts);\\n\\t\\t\\t\\t\\t\\t\\t}\\n\\t\\t\\t\\t\\t\\t\\n\\n\\t\\t\\t\\t\\t\\tif( typeof(newrelic) !== \\\"undefined\\\" ){\\n\\t\\t\\t\\t\\t\\t\\tnewrelic.setCustomAttribute( \\\"game-state\\\", espn.gamepackage.status );\\n\\t\\t\\t\\t\\t\\t}\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t})(jQuery);\\n\\t\\t\\t\"\n\n\nNow the short of this is that we have the full script text, so there’s a lot of random JavaScript and logic along with HTML around the actual JSON we want. We want to find the “starting edge” and the end of the JSON file, which should be [{ and }] respectively.\nI’ll start by removing all the new lines (\\n) and tabs (\\t), then finding anything that matches [{ and replace anything before it with [{, followed by the same idea for }].\nThis should return a raw string of the JSON content, which we can then parse with jsonlite! Regex is #magic, but in short the pattern of \".*(\\\\[\\\\{)\" finds any text .* ahead of [{ which needs to be escaped as (\\\\[\\\\{) and replaces it with the matched component (\\\\1) which should be [{. We do that for both the start and end of the JSON file, to remove all the extra text and just get the JSON file itself.\n\nraw_json_embed <- example_embed_json %>%\n  str_remove_all(\"\\\\n|\\\\t\") %>% \n  str_replace(\".*(\\\\[\\\\{)\", \"\\\\1\") %>% \n  str_replace(\"(\\\\}\\\\]).*\", \"\\\\1\")\n\nex_parsed_json <- jsonlite::parse_json(raw_json_embed)\n\nex_parsed_json %>% enframe()\n\n# A tibble: 216 × 2\n    name value           \n   <int> <list>          \n 1     1 <named list [5]>\n 2     2 <named list [5]>\n 3     3 <named list [5]>\n 4     4 <named list [5]>\n 5     5 <named list [5]>\n 6     6 <named list [5]>\n 7     7 <named list [5]>\n 8     8 <named list [5]>\n 9     9 <named list [5]>\n10    10 <named list [5]>\n# … with 206 more rows"
  },
  {
    "objectID": "posts/2020-12-13-extracting-json-from-websites-and-public-apis-with-r/index.html#tidyrhoist",
    "href": "posts/2020-12-13-extracting-json-from-websites-and-public-apis-with-r/index.html#tidyrhoist",
    "title": "Extracting JSON data from websites and public APIs with R",
    "section": "tidyr::hoist()",
    "text": "tidyr::hoist()\nWe’re going to introduce a new tidyr function in this section called hoist(). You can think of tidyr::hoist() as a way of extracting or hoisting specific list column elements into a new named column. This is especially helpful where the JSON has duplicate names, like id which really means game_id and id which really means play_id. With repeated names, unnest_ functions will error or append names as you’re essentially recreating existing columns.\n\nespn_url <- \"http://site.api.espn.com/apis/site/v2/sports/football/nfl/summary?event=401220303\"\n\nraw_espn_json <- httr::GET(espn_url) %>% \n  httr::content()\n\nraw_espn_json %>% str(max.level = 1)\n\nList of 17\n $ boxscore        :List of 2\n $ format          :List of 2\n $ gameInfo        :List of 3\n $ drives          :List of 1\n $ leaders         :List of 2\n $ broadcasts      : list()\n $ predictor       :List of 3\n $ pickcenter      :List of 4\n $ againstTheSpread:List of 2\n $ odds            : list()\n $ winprobability  :List of 217\n $ header          :List of 8\n $ scoringPlays    :List of 10\n $ news            :List of 3\n $ article         :List of 22\n $ videos          : list()\n $ standings       :List of 2\n\n\nNow I’m most interested in the winprobability data, although you could get all sorts of metadata about simple play-by-play, news, etc. This is a VERY long output, so I’m just going to grab the first few.\n\nraw_espn_json[[\"winprobability\"]] %>% length()\n\n[1] 217\n\nraw_espn_json[[\"winprobability\"]] %>% \n  .[1:3] %>% \n  str(max.level = 2)\n\nList of 3\n $ :List of 4\n  ..$ tiePercentage    : num 0\n  ..$ homeWinPercentage: num 0.832\n  ..$ secondsLeft      : int 0\n  ..$ playId           : chr \"4012203031\"\n $ :List of 4\n  ..$ tiePercentage    : num 0\n  ..$ homeWinPercentage: num 0.828\n  ..$ secondsLeft      : int 0\n  ..$ playId           : chr \"40122030340\"\n $ :List of 4\n  ..$ tiePercentage    : num 0\n  ..$ homeWinPercentage: num 0.807\n  ..$ secondsLeft      : int 0\n  ..$ playId           : chr \"40122030355\"\n\n\nSinec we have a long list of repeated lists of length 4, we can assume that unnest_wider() is the right choice here (4 distinct columns, that are already “long”). We could always rely on unnest_auto() to guess for us and then replace it with the correct function afterwards.\nI’m going to stick with my preferred workflow of tibble::enframe() and then unnest_wider.\n\nwin_pct_df <- raw_espn_json[[\"winprobability\"]] %>%\n  enframe() %>%\n  rename(row_id = name) %>%\n  unnest_wider(value) %>%\n  janitor::clean_names()\n\nwin_pct_df\n\n# A tibble: 217 × 5\n   row_id tie_percentage home_win_percentage seconds_left play_id     \n    <int>          <dbl>               <dbl>        <int> <chr>       \n 1      1              0               0.832            0 4012203031  \n 2      2              0               0.828            0 40122030340 \n 3      3              0               0.807            0 40122030355 \n 4      4              0               0.796            0 40122030379 \n 5      5              0               0.785            0 401220303108\n 6      6              0               0.777            0 401220303129\n 7      7              0               0.742            0 401220303150\n 8      8              0               0.741            0 401220303191\n 9      9              0               0.747            0 401220303213\n10     10              0               0.719            0 401220303257\n# … with 207 more rows"
  },
  {
    "objectID": "posts/2020-12-13-extracting-json-from-websites-and-public-apis-with-r/index.html#play-by-play",
    "href": "posts/2020-12-13-extracting-json-from-websites-and-public-apis-with-r/index.html#play-by-play",
    "title": "Extracting JSON data from websites and public APIs with R",
    "section": "Play-by-play",
    "text": "Play-by-play\nNow the other datasets we’re interested in are the drive info (for play-by-play), along with the game info like teams playing, play type, period, and time remaining.\nLet’s start with the core JSON data, and then extract the drives data.\n\nraw_espn_json %>% str(max.level = 1)\n\nList of 17\n $ boxscore        :List of 2\n $ format          :List of 2\n $ gameInfo        :List of 3\n $ drives          :List of 1\n $ leaders         :List of 2\n $ broadcasts      : list()\n $ predictor       :List of 3\n $ pickcenter      :List of 4\n $ againstTheSpread:List of 2\n $ odds            : list()\n $ winprobability  :List of 217\n $ header          :List of 8\n $ scoringPlays    :List of 10\n $ news            :List of 3\n $ article         :List of 22\n $ videos          : list()\n $ standings       :List of 2\n\nraw_espn_json[[\"drives\"]][[1]] %>% enframe()\n\n# A tibble: 30 × 2\n    name value            \n   <int> <list>           \n 1     1 <named list [13]>\n 2     2 <named list [13]>\n 3     3 <named list [13]>\n 4     4 <named list [13]>\n 5     5 <named list [13]>\n 6     6 <named list [13]>\n 7     7 <named list [13]>\n 8     8 <named list [13]>\n 9     9 <named list [13]>\n10    10 <named list [13]>\n# … with 20 more rows\n\n\nAgain we notice that this is already “long” so we can assume we need to unnest_wider(). I’ll also rename a few columns since they’re not very descriptive (and duplicates of other columns).\n\npbp_raw_espn <- raw_espn_json[[\"drives\"]][[1]] %>% \n  enframe() %>% \n  unnest_wider(value) %>% \n  rename(\n    drive_id = id,\n    drive_start = start,\n    drive_end = end\n  ) \n\npbp_raw_espn %>% str(max.level = 2)\n\ntibble [30 × 14] (S3: tbl_df/tbl/data.frame)\n $ name              : int [1:30] 1 2 3 4 5 6 7 8 9 10 ...\n $ drive_id          : chr [1:30] \"4012203031\" \"4012203032\" \"4012203033\" \"4012203034\" ...\n $ description       : chr [1:30] \"5 plays, 75 yards, 2:27\" \"3 plays, 12 yards, 1:22\" \"10 plays, 66 yards, 5:07\" \"5 plays, 5 yards, 3:08\" ...\n $ team              :List of 30\n $ drive_start       :List of 30\n $ drive_end         :List of 30\n $ timeElapsed       :List of 30\n $ yards             : int [1:30] 75 12 66 5 16 8 49 78 9 6 ...\n $ isScore           : logi [1:30] TRUE FALSE TRUE FALSE FALSE FALSE ...\n $ offensivePlays    : int [1:30] 5 3 10 5 4 3 11 10 3 5 ...\n $ result            : chr [1:30] \"TD\" \"PUNT\" \"FG\" \"PUNT\" ...\n $ shortDisplayResult: chr [1:30] \"TD\" \"PUNT\" \"FG\" \"PUNT\" ...\n $ displayResult     : chr [1:30] \"Touchdown\" \"Punt\" \"Field Goal\" \"Punt\" ...\n $ plays             :List of 30"
  },
  {
    "objectID": "posts/2020-12-13-extracting-json-from-websites-and-public-apis-with-r/index.html#lets-go-longer",
    "href": "posts/2020-12-13-extracting-json-from-websites-and-public-apis-with-r/index.html#lets-go-longer",
    "title": "Extracting JSON data from websites and public APIs with R",
    "section": "Let’s go longer",
    "text": "Let’s go longer\nAt this point we can see the data is at the drive level, and the description is the metadata about how long the drive lasted. We want actual plays, and there is a list column named plays. We’ll need to increase the length of the data, so let’s try unnest_longer().\n\npbp_raw_espn %>%  \n  unnest_longer(plays) %>% \n  str(max.level = 2)\n\ntibble [217 × 14] (S3: tbl_df/tbl/data.frame)\n $ name              : int [1:217] 1 1 1 1 1 1 2 2 2 2 ...\n $ drive_id          : chr [1:217] \"4012203031\" \"4012203031\" \"4012203031\" \"4012203031\" ...\n $ description       : chr [1:217] \"5 plays, 75 yards, 2:27\" \"5 plays, 75 yards, 2:27\" \"5 plays, 75 yards, 2:27\" \"5 plays, 75 yards, 2:27\" ...\n $ team              :List of 217\n $ drive_start       :List of 217\n $ drive_end         :List of 217\n $ timeElapsed       :List of 217\n $ yards             : int [1:217] 75 75 75 75 75 75 12 12 12 12 ...\n $ isScore           : logi [1:217] TRUE TRUE TRUE TRUE TRUE TRUE ...\n $ offensivePlays    : int [1:217] 5 5 5 5 5 5 3 3 3 3 ...\n $ result            : chr [1:217] \"TD\" \"TD\" \"TD\" \"TD\" ...\n $ shortDisplayResult: chr [1:217] \"TD\" \"TD\" \"TD\" \"TD\" ...\n $ displayResult     : chr [1:217] \"Touchdown\" \"Touchdown\" \"Touchdown\" \"Touchdown\" ...\n $ plays             :List of 217\n\n\nThis gives us 188 plays, but plays is still a list column, so we need to “widen” it with unnest_wider(). Let’s go ahead and do that and then look at what the data looks like.\n\npbp_raw_espn_plays <- pbp_raw_espn %>% \n  unnest_longer(plays) %>% \n  unnest_wider(plays) %>% \n  rename(play_id = id)\n\npbp_raw_espn_plays %>% \n  glimpse()\n\nRows: 217\nColumns: 29\n$ name               <int> 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, …\n$ drive_id           <chr> \"4012203031\", \"4012203031\", \"4012203031\", \"40122030…\n$ description        <chr> \"5 plays, 75 yards, 2:27\", \"5 plays, 75 yards, 2:27…\n$ team               <list> [\"Jaguars\", \"JAX\", \"Jacksonville Jaguars\", \"Jaguar…\n$ drive_start        <list> [[\"quarter\", 1], [\"15:00\"], 75, \"JAX 25\"], [[\"quar…\n$ drive_end          <list> [[\"quarter\", 1], [\"12:33\"], 0, \"MIN 0\"], [[\"quarte…\n$ timeElapsed        <list> [\"2:27\"], [\"2:27\"], [\"2:27\"], [\"2:27\"], [\"2:27\"], …\n$ yards              <int> 75, 75, 75, 75, 75, 75, 12, 12, 12, 12, 12, 12, 66,…\n$ isScore            <lgl> TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, FALSE, FALSE, F…\n$ offensivePlays     <int> 5, 5, 5, 5, 5, 5, 3, 3, 3, 3, 3, 3, 10, 10, 10, 10,…\n$ result             <chr> \"TD\", \"TD\", \"TD\", \"TD\", \"TD\", \"TD\", \"PUNT\", \"PUNT\",…\n$ shortDisplayResult <chr> \"TD\", \"TD\", \"TD\", \"TD\", \"TD\", \"TD\", \"PUNT\", \"PUNT\",…\n$ displayResult      <chr> \"Touchdown\", \"Touchdown\", \"Touchdown\", \"Touchdown\",…\n$ play_id            <chr> \"40122030340\", \"40122030355\", \"40122030379\", \"40122…\n$ sequenceNumber     <chr> \"4000\", \"5500\", \"7900\", \"10800\", \"12900\", \"15000\", …\n$ type               <list> [\"53\", \"Kickoff\", \"K\"], [\"24\", \"Pass Reception\", \"…\n$ text               <chr> \"D.Bailey kicks 65 yards from MIN 35 to end zone, T…\n$ awayScore          <int> 0, 0, 0, 0, 0, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, …\n$ homeScore          <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ period             <list> [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], …\n$ clock              <list> [\"15:00\"], [\"15:00\"], [\"14:25\"], [\"13:54\"], [\"13:2…\n$ scoringPlay        <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, FAL…\n$ priority           <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FA…\n$ modified           <chr> \"2020-12-06T22:12Z\", \"2020-12-06T22:12Z\", \"2020-12-…\n$ wallclock          <chr> \"2020-12-06T18:02:32Z\", \"2020-12-06T18:03:13Z\", \"20…\n$ start              <list> [0, 0, 35, 65, [\"16\"]], [1, 10, 75, 75, \"1st & 10 …\n$ end                <list> [1, 10, 75, 75, \"1st & 10 at JAX 25\", \"1st & 10\", …\n$ statYardage        <int> 0, 24, 8, 9, 6, 28, 25, 5, 0, 7, 0, 13, 4, 4, 6, 9,…\n$ scoringType        <list> <NULL>, <NULL>, <NULL>, <NULL>, <NULL>, [\"touchdow…"
  },
  {
    "objectID": "posts/2020-12-13-extracting-json-from-websites-and-public-apis-with-r/index.html#hoist-away",
    "href": "posts/2020-12-13-extracting-json-from-websites-and-public-apis-with-r/index.html#hoist-away",
    "title": "Extracting JSON data from websites and public APIs with R",
    "section": "Hoist away!",
    "text": "Hoist away!\nLooking good! We still have some list-columns to work on though (team, period, clock, start). Let’s pull some selected items from those columns via hoist(). I’m going to start with a small example, and limit the columns shown so that we don’t get overwhelmed.\n\npbp_raw_espn_plays %>%\n  select(drive_id, play_id, yards, team) %>% \n  slice(1) %>% \n  str(max.level = 4)\n\ntibble [1 × 4] (S3: tbl_df/tbl/data.frame)\n $ drive_id: chr \"4012203031\"\n $ play_id : chr \"40122030340\"\n $ yards   : int 75\n $ team    :List of 1\n  ..$ :List of 5\n  .. ..$ name            : chr \"Jaguars\"\n  .. ..$ abbreviation    : chr \"JAX\"\n  .. ..$ displayName     : chr \"Jacksonville Jaguars\"\n  .. ..$ shortDisplayName: chr \"Jaguars\"\n  .. ..$ logos           :List of 4\n\n\nThis shows us that the team list column has 5 named list items within it (name, abbreviation, displayName, shortDisplayName, and another list of lists for logos).\nhoist() takes several arguments, first a column to work on (.col), and then some new columns to create. Note that we’re using raw strings (\"name\") to pull named list elements from the list column or we could use a number to grab by position.\n\npbp_raw_espn_plays %>%\n  select(drive_id, play_id, yards, team) %>% \n  hoist(\n    .col = team,\n    pos_team = \"name\",\n    pos_abb = \"abbreviation\",\n    pos_full = \"displayName\",\n    pos_short = 4 # could also use \"shortDisplayName\"\n  )\n\n# A tibble: 217 × 8\n   drive_id   play_id     yards pos_team pos_abb pos_full pos_short team        \n   <chr>      <chr>       <int> <chr>    <chr>   <chr>    <chr>     <list>      \n 1 4012203031 40122030340    75 Jaguars  JAX     Jackson… Jaguars   <named list>\n 2 4012203031 40122030355    75 Jaguars  JAX     Jackson… Jaguars   <named list>\n 3 4012203031 40122030379    75 Jaguars  JAX     Jackson… Jaguars   <named list>\n 4 4012203031 4012203031…    75 Jaguars  JAX     Jackson… Jaguars   <named list>\n 5 4012203031 4012203031…    75 Jaguars  JAX     Jackson… Jaguars   <named list>\n 6 4012203031 4012203031…    75 Jaguars  JAX     Jackson… Jaguars   <named list>\n 7 4012203032 4012203031…    12 Vikings  MIN     Minneso… Vikings   <named list>\n 8 4012203032 4012203032…    12 Vikings  MIN     Minneso… Vikings   <named list>\n 9 4012203032 4012203032…    12 Vikings  MIN     Minneso… Vikings   <named list>\n10 4012203032 4012203032…    12 Vikings  MIN     Minneso… Vikings   <named list>\n# … with 207 more rows\n\n\nOk, so hopefully that shows you how we can first find the list column elements, and then hoist() a select few of them by name/position. For the next section I’m just going to hoist() the ones I want and then save the dataframe. While there are some other list columns, I’m just going to drop them as I’m not interested in them right now.\n\nespn_pbp_clean <- pbp_raw_espn_plays %>% \n  hoist(\n    .col = team,\n    pos_team = \"name\",\n    pos_abb = \"abbreviation\",\n    pos_full = \"displayName\",\n    pos_short = 4 # could also use \"shortDisplayName\"\n  ) %>% \n  hoist(\n    type,\n    play_type_id = \"id\",\n    play_type = \"text\",\n    play_type_abb = \"abbreviation\"\n  ) %>% \n  hoist(\n    period,\n    quarter = \"number\"\n  ) %>% \n  hoist(\n    clock,\n    clock = \"displayValue\"\n  ) %>% \n    janitor::clean_names() %>% \n  # drop remaining list columns\n  select(-where(is.list))"
  },
  {
    "objectID": "posts/2020-12-13-extracting-json-from-websites-and-public-apis-with-r/index.html#join-the-data",
    "href": "posts/2020-12-13-extracting-json-from-websites-and-public-apis-with-r/index.html#join-the-data",
    "title": "Extracting JSON data from websites and public APIs with R",
    "section": "Join the data",
    "text": "Join the data\nThe next thing we have to do is join the Win Probability data with the play-by-play info! This is easy as we have a common key column with play_id.\n\nespn_joined <- left_join(espn_pbp_clean, win_pct_df, by = \"play_id\") \n\nespn_joined %>% \n  glimpse()\n\nRows: 217\nColumns: 31\n$ name                 <int> 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3…\n$ drive_id             <chr> \"4012203031\", \"4012203031\", \"4012203031\", \"401220…\n$ description          <chr> \"5 plays, 75 yards, 2:27\", \"5 plays, 75 yards, 2:…\n$ pos_team             <chr> \"Jaguars\", \"Jaguars\", \"Jaguars\", \"Jaguars\", \"Jagu…\n$ pos_abb              <chr> \"JAX\", \"JAX\", \"JAX\", \"JAX\", \"JAX\", \"JAX\", \"MIN\", …\n$ pos_full             <chr> \"Jacksonville Jaguars\", \"Jacksonville Jaguars\", \"…\n$ pos_short            <chr> \"Jaguars\", \"Jaguars\", \"Jaguars\", \"Jaguars\", \"Jagu…\n$ yards                <int> 75, 75, 75, 75, 75, 75, 12, 12, 12, 12, 12, 12, 6…\n$ is_score             <lgl> TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, FALSE, FALSE,…\n$ offensive_plays      <int> 5, 5, 5, 5, 5, 5, 3, 3, 3, 3, 3, 3, 10, 10, 10, 1…\n$ result               <chr> \"TD\", \"TD\", \"TD\", \"TD\", \"TD\", \"TD\", \"PUNT\", \"PUNT…\n$ short_display_result <chr> \"TD\", \"TD\", \"TD\", \"TD\", \"TD\", \"TD\", \"PUNT\", \"PUNT…\n$ display_result       <chr> \"Touchdown\", \"Touchdown\", \"Touchdown\", \"Touchdown…\n$ play_id              <chr> \"40122030340\", \"40122030355\", \"40122030379\", \"401…\n$ sequence_number      <chr> \"4000\", \"5500\", \"7900\", \"10800\", \"12900\", \"15000\"…\n$ play_type_id         <chr> \"53\", \"24\", \"24\", \"5\", \"5\", \"67\", \"12\", \"24\", \"3\"…\n$ play_type            <chr> \"Kickoff\", \"Pass Reception\", \"Pass Reception\", \"R…\n$ play_type_abb        <chr> \"K\", \"REC\", \"REC\", \"RUSH\", \"RUSH\", \"TD\", NA, \"REC…\n$ text                 <chr> \"D.Bailey kicks 65 yards from MIN 35 to end zone,…\n$ away_score           <int> 0, 0, 0, 0, 0, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6…\n$ home_score           <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ quarter              <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ scoring_play         <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, F…\n$ priority             <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, …\n$ modified             <chr> \"2020-12-06T22:12Z\", \"2020-12-06T22:12Z\", \"2020-1…\n$ wallclock            <chr> \"2020-12-06T18:02:32Z\", \"2020-12-06T18:03:13Z\", \"…\n$ stat_yardage         <int> 0, 24, 8, 9, 6, 28, 25, 5, 0, 7, 0, 13, 4, 4, 6, …\n$ row_id               <int> 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 1…\n$ tie_percentage       <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ home_win_percentage  <dbl> 0.828, 0.807, 0.796, 0.785, 0.777, 0.742, 0.741, …\n$ seconds_left         <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n\n\nNow there’s one more tricky point, which is that there isn’t a column that says “home” vs “away”.\nESPN’s JSON reports this simply by position, we can access this data, and will need to create a logical statement in order to assign home vs away.\n\nraw_espn_json[[\"boxscore\"]][[\"teams\"]] %>% str(max.level = 2)\n\nList of 2\n $ :List of 2\n  ..$ team      :List of 11\n  ..$ statistics:List of 25\n $ :List of 2\n  ..$ team      :List of 11\n  ..$ statistics:List of 25\n\n\nFrom comparing the box scores and the JSON, the team listed first is always the away team. So for this game that means the Jaguars.\n\n# 1st team == AWAY\nraw_espn_json[[\"boxscore\"]][[\"teams\"]][[1]][[\"team\"]][[\"abbreviation\"]]\n\n[1] \"JAX\"\n\n# 2nd team == HOME\nraw_espn_json[[\"boxscore\"]][[\"teams\"]][[2]][[\"team\"]][[\"abbreviation\"]]\n\n[1] \"MIN\"\n\n\n\nfinal_espn <- espn_joined %>% \n  mutate(\n    home_team = raw_espn_json[[\"boxscore\"]][[\"teams\"]][[1]][[\"team\"]][[\"abbreviation\"]],\n    away_team = raw_espn_json[[\"boxscore\"]][[\"teams\"]][[2]][[\"team\"]][[\"abbreviation\"]]\n    )\n\nJust for fun, let’s create a very quick graph to compare against the ESPN Win Percentage plot! Note that we still need to calculate the game seconds (from the clock data), so I’ll just use the row number as the x-axis for now. We can see that this aligns well with the “actual” plot from ESPN’s box score!\n\nfinal_espn %>% \n  ggplot(aes(x = row_id, y = 1 - home_win_percentage)) +\n  geom_line(size = 1) +\n  scale_y_continuous(breaks = c(0, 0.25, .5, .75, 1), labels = c(100, \"\", 50, \"\", 100), limits = c(0, 1)) +\n  theme_minimal() +\n  theme(\n    panel.grid.minor = element_blank(),\n    panel.grid.major.x = element_blank(),\n    axis.text.y.right = element_text(size = 24),\n    axis.text.x = element_blank()\n  ) + \n  labs(x = \"\", y = \"\")\n\nWarning: Removed 1 row(s) containing missing values (geom_path)."
  },
  {
    "objectID": "posts/2020-12-13-extracting-json-from-websites-and-public-apis-with-r/index.html#roll-it-into-a-function",
    "href": "posts/2020-12-13-extracting-json-from-websites-and-public-apis-with-r/index.html#roll-it-into-a-function",
    "title": "Extracting JSON data from websites and public APIs with R",
    "section": "Roll it into a Function",
    "text": "Roll it into a Function\nWe can quickly convert that into a function. Eventually this will be rolled into espnscrapeR proper. For now, I just have espnscrapeR::get_espn_win_prob().\n\nget_espn_pbp <- function(game_id) {\n  espn_url <- glue::glue(\"http://site.api.espn.com/apis/site/v2/sports/football/nfl/summary?event={game_id}\")\n\n  raw_espn_json <- fromJSON(espn_url, simplifyVector = FALSE)\n\n  win_pct_df <- raw_espn_json[[\"winprobability\"]] %>%\n    enframe() %>%\n    rename(row_id = name) %>%\n    unnest_wider(value) %>%\n    janitor::clean_names()\n\n  espn_df <- raw_espn_json[[\"drives\"]][[1]] %>%\n    enframe() %>%\n    unnest_wider(value) %>%\n    rename(\n      drive_id = id,\n      drive_start = start,\n      drive_end = end\n    ) %>%\n    unnest_longer(plays) %>%\n    unnest_wider(plays)\n\n  pbp_raw_espn_plays <- pbp_raw_espn %>%\n    unnest_longer(plays) %>%\n    unnest_wider(plays) %>%\n    rename(play_id = id)\n\n  espn_pbp_clean <- pbp_raw_espn_plays %>%\n    hoist(\n      .col = team,\n      pos_team = \"name\",\n      pos_abb = \"abbreviation\",\n      pos_full = \"displayName\",\n      pos_short = 4 # could also use \"shortDisplayName\"\n    ) %>%\n    hoist(\n      type,\n      play_type_id = \"id\",\n      play_type = \"text\",\n      play_type_abb = \"abbreviation\"\n    ) %>%\n    hoist(\n      period,\n      quarter = \"number\"\n    ) %>%\n    hoist(\n      clock,\n      clock = \"displayValue\"\n    ) %>%\n    janitor::clean_names() %>%\n    # drop remaining list columns\n    select(-where(is.list))\n\n  espn_joined <- left_join(espn_pbp_clean, win_pct_df, by = \"play_id\")\n\n  final_espn <- espn_joined %>%\n    mutate(\n      home_team = raw_espn_json[[\"boxscore\"]][[\"teams\"]][[1]][[\"team\"]][[\"abbreviation\"]],\n      away_team = raw_espn_json[[\"boxscore\"]][[\"teams\"]][[2]][[\"team\"]][[\"abbreviation\"]]\n    )\n\n  final_espn\n}\n\nget_espn_pbp(\"401220303\") %>% glimpse()\n\nRows: 217\nColumns: 33\n$ name                 <int> 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3…\n$ drive_id             <chr> \"4012203031\", \"4012203031\", \"4012203031\", \"401220…\n$ description          <chr> \"5 plays, 75 yards, 2:27\", \"5 plays, 75 yards, 2:…\n$ pos_team             <chr> \"Jaguars\", \"Jaguars\", \"Jaguars\", \"Jaguars\", \"Jagu…\n$ pos_abb              <chr> \"JAX\", \"JAX\", \"JAX\", \"JAX\", \"JAX\", \"JAX\", \"MIN\", …\n$ pos_full             <chr> \"Jacksonville Jaguars\", \"Jacksonville Jaguars\", \"…\n$ pos_short            <chr> \"Jaguars\", \"Jaguars\", \"Jaguars\", \"Jaguars\", \"Jagu…\n$ yards                <int> 75, 75, 75, 75, 75, 75, 12, 12, 12, 12, 12, 12, 6…\n$ is_score             <lgl> TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, FALSE, FALSE,…\n$ offensive_plays      <int> 5, 5, 5, 5, 5, 5, 3, 3, 3, 3, 3, 3, 10, 10, 10, 1…\n$ result               <chr> \"TD\", \"TD\", \"TD\", \"TD\", \"TD\", \"TD\", \"PUNT\", \"PUNT…\n$ short_display_result <chr> \"TD\", \"TD\", \"TD\", \"TD\", \"TD\", \"TD\", \"PUNT\", \"PUNT…\n$ display_result       <chr> \"Touchdown\", \"Touchdown\", \"Touchdown\", \"Touchdown…\n$ play_id              <chr> \"40122030340\", \"40122030355\", \"40122030379\", \"401…\n$ sequence_number      <chr> \"4000\", \"5500\", \"7900\", \"10800\", \"12900\", \"15000\"…\n$ play_type_id         <chr> \"53\", \"24\", \"24\", \"5\", \"5\", \"67\", \"12\", \"24\", \"3\"…\n$ play_type            <chr> \"Kickoff\", \"Pass Reception\", \"Pass Reception\", \"R…\n$ play_type_abb        <chr> \"K\", \"REC\", \"REC\", \"RUSH\", \"RUSH\", \"TD\", NA, \"REC…\n$ text                 <chr> \"D.Bailey kicks 65 yards from MIN 35 to end zone,…\n$ away_score           <int> 0, 0, 0, 0, 0, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6…\n$ home_score           <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ quarter              <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ scoring_play         <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, F…\n$ priority             <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, …\n$ modified             <chr> \"2020-12-06T22:12Z\", \"2020-12-06T22:12Z\", \"2020-1…\n$ wallclock            <chr> \"2020-12-06T18:02:32Z\", \"2020-12-06T18:03:13Z\", \"…\n$ stat_yardage         <int> 0, 24, 8, 9, 6, 28, 25, 5, 0, 7, 0, 13, 4, 4, 6, …\n$ row_id               <int> 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 1…\n$ tie_percentage       <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ home_win_percentage  <dbl> 0.828, 0.807, 0.796, 0.785, 0.777, 0.742, 0.741, …\n$ seconds_left         <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ home_team            <chr> \"JAX\", \"JAX\", \"JAX\", \"JAX\", \"JAX\", \"JAX\", \"JAX\", …\n$ away_team            <chr> \"MIN\", \"MIN\", \"MIN\", \"MIN\", \"MIN\", \"MIN\", \"MIN\", …"
  },
  {
    "objectID": "posts/2020-12-13-extracting-json-from-websites-and-public-apis-with-r/index.html#hoist-again",
    "href": "posts/2020-12-13-extracting-json-from-websites-and-public-apis-with-r/index.html#hoist-again",
    "title": "Extracting JSON data from websites and public APIs with R",
    "section": "\nhoist again",
    "text": "hoist again\nSo we’re going to use hoist() to again grab specific items from our list columns. Here I’m passing increasing “depth” to hoist() via a list(). While it can be a bit hard to initially wrap your head around, hoist() is similar to native subsetting with R.\nSo the following code is roughly equivalent in base R and hoist(). Note that the subsetting base R version with [[ is getting the first element (of 333), so I’m going to grab the first element of our new home_team_id column from our vectorized hoist() call.\n\nex_id_subset <- espn_season_2018[[\"competitions\"]][[1]][[\"competitors\"]][[1]][[\"id\"]]\n\nex_id_hoist <- espn_season_2018 %>%\n  hoist(competitions, home_team_id = list(\"competitors\", 1, \"id\"))\n\nall.equal(ex_id_subset, ex_id_hoist[[\"home_team_id\"]][1])\n\n[1] TRUE\n\n\nSo we can now use that same idea to grab a few desired columns. We can sanity check our work by seeing how many games we have of each “type” with a quick count(). There should be 256 regular season games in each season.\n\nespn_season_2018_final <- espn_season_2018 %>%\n  hoist(\n    competitions,\n    home_team_id = list(\"competitors\", 1, \"id\"),\n    home_team_abb = list(\"competitors\", 1, \"team\", \"abbreviation\"),\n    away_team_id = list(\"competitors\", 2, \"id\"),\n    away_team_abb = list(\"competitors\", 2, \"team\", \"abbreviation\"),\n    home_score = list(\"competitors\", 1, \"score\"),\n    away_score = list(\"competitors\", 2, \"score\")\n  ) %>%\n  select(-where(is.list), -row_id) %>%\n  janitor::clean_names() %>%\n  rename(season_type = type) %>%\n  mutate(\n    season_type = case_when(\n      season_type == 1L ~ \"Preseason\",\n      season_type == 2L ~ \"Regular Season\",\n      season_type == 3L ~ \"Playoffs\",\n      TRUE ~ as.character(season_type),\n    )\n  )\n\nespn_season_2018_final %>% \n  count(season_type)\n\n# A tibble: 3 × 2\n  season_type        n\n  <chr>          <int>\n1 Playoffs          12\n2 Preseason         65\n3 Regular Season   256\n\n\nWe could then find a specific game or purrr::map() across all the games as needed.\nInside the below detail tag, we have the full method of getting the data as JSON, cleaning/rectangling, and returning as a relatively tidy dataframe.\n\nESPN Schedule Function\n\nget_espn_schedule <- function(season) {\n  espn_scores_url <- glue::glue(\"http://site.api.espn.com/apis/site/v2/sports/football/nfl/scoreboard?dates={season}&limit=500\")\n\n  raw_json_scores <- fromJSON(espn_scores_url, simplifyVector = FALSE)\n\n  espn_games <- raw_json_scores[[\"events\"]] %>%\n    enframe() %>%\n    rename(row_id = name) %>%\n    unnest_wider(value) %>%\n    rename(game_id = id)\n  \n  espn_season <- espn_games %>% \n    unnest_wider(season) %>% \n    unchop(competitions)\n\n  espn_season_final <- espn_season %>%\n    hoist(\n      competitions,\n      home_team_id = list(\"competitors\", 1, \"id\"),\n      home_team_abb = list(\"competitors\", 1, \"team\", \"abbreviation\"),\n      away_team_id = list(\"competitors\", 2, \"id\"),\n      away_team_abb = list(\"competitors\", 2, \"team\", \"abbreviation\"),\n      home_score = list(\"competitors\", 1, \"score\"),\n      away_score = list(\"competitors\", 2, \"score\")\n    ) %>%\n    select(-where(is.list), -row_id) %>%\n    janitor::clean_names() %>%\n    rename(season_type = type) %>%\n    mutate(\n      season_type = case_when(\n        season_type == 1L ~ \"Preseason\",\n        season_type == 2L ~ \"Regular Season\",\n        season_type == 3L ~ \"Playoffs\",\n        TRUE ~ as.character(season_type),\n      )\n    )\n  \n  espn_season_final\n}\n\n\n\n\n\n\n\nExpand for Session Info\n\n\n\n\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.0 (2022-04-22)\n os       macOS Monterey 12.2.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       America/Chicago\n date     2022-04-28\n pandoc   2.18 @ /Applications/RStudio.app/Contents/MacOS/quarto/bin/tools/ (via rmarkdown)\n quarto   0.9.294 @ /usr/local/bin/quarto\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version date (UTC) lib source\n dplyr       * 1.0.8   2022-02-08 [1] CRAN (R 4.2.0)\n forcats     * 0.5.1   2021-01-27 [1] CRAN (R 4.2.0)\n ggplot2     * 3.3.5   2021-06-25 [1] CRAN (R 4.2.0)\n jsonlite    * 1.8.0   2022-02-22 [1] CRAN (R 4.2.0)\n purrr       * 0.3.4   2020-04-17 [1] CRAN (R 4.2.0)\n reactable   * 0.2.3   2020-10-04 [1] CRAN (R 4.2.0)\n readr       * 2.1.2   2022-01-30 [1] CRAN (R 4.2.0)\n rvest       * 1.0.2   2021-10-16 [1] CRAN (R 4.2.0)\n sessioninfo * 1.2.2   2021-12-06 [1] CRAN (R 4.2.0)\n stringr     * 1.4.0   2019-02-10 [1] CRAN (R 4.2.0)\n tibble      * 3.1.6   2021-11-07 [1] CRAN (R 4.2.0)\n tidyr       * 1.2.0   2022-02-01 [1] CRAN (R 4.2.0)\n tidyverse   * 1.3.1   2021-04-15 [1] CRAN (R 4.2.0)\n xml2        * 1.3.3   2021-11-30 [1] CRAN (R 4.2.0)\n\n [1] /Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/library\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "posts/2021-03-21-meta-tagging-distill/index.html",
    "href": "posts/2021-03-21-meta-tagging-distill/index.html",
    "title": "Including and meta tagging extra content in a distill blog",
    "section": "",
    "text": "Including “extra” content in your blog is very useful for collecting all of your content beyond just blogposts. For example, I have a Resources page that sublinks to other things I’ve created or wanted to share at a specific URL.\nThese extra pieces of content include xaringan slides, books, or one-off RMarkdown “sites” that don’t really fit into a blogpost.\nMy approach is to store these extra pages into a new folder called /static/ in my blog project directory. I do this to generally keep my top-level directory a bit cleaner, and to separate them out from the core blog. Note that lastly, you do not need to put everything in /static if you don’t want to, and you can keep everything at the top-level directory which would serve up content at site-name.com/content-name.html."
  },
  {
    "objectID": "posts/2021-03-21-meta-tagging-distill/index.html#including-alternate-content",
    "href": "posts/2021-03-21-meta-tagging-distill/index.html#including-alternate-content",
    "title": "Including and meta tagging extra content in a distill blog",
    "section": "Including alternate content",
    "text": "Including alternate content\nAs long as you are using distill v 1.2 or later and rmarkdown v 2.7 or later, you can include alternate RMarkdown-generated content within your distill blog!\nAlternate format in this case really just means any other RMarkdown format besides distill.\nNow while you can knit files locally and see the output, it will not be moved to your _site directory and served up on your website until you rebuild the site.\nThese alternate-format pages are rebuilt and included in the _site directory whenever you run rmarkdown::render_site() OR build one of the top-level site pages (ie index.Rmd, about.Rmd, etc).\nSo for my example, my static pages get written to:_site/static/FILE-NAME.HTML\nand will show up on my blog at:themockup.blog/static/FILE-NAME.HTML\nFor example my gt cookbook is linked at:\nhttps://themockup.blog/static/gt-cookbook.html\nThat’s easy enough, and now you can include basically any piece of arbitrary content you create via RMarkdown, all collected underneath the main URL of your blog/site!\nResources pane\nSince I’m on distill, to provide links for everything I want to add another “tab” to my site that shows all the various extra content. I add the below code to my navbar in my _site.yaml file to add a new tab.\nnavbar:\n  right:\n    - text: \"Home\"\n      href: index.html\n    - text: \"Resources\"\n      href: resources.html\n    - text: \"About\"\nThe resources page itself can be super lightweight and just link out to the files, but I decided to use a reactable table that references all of the content so it is searchable and sortable. This page is generated by my resources.Rmd file.\nAgain, you could just provide the raw URL links as hyperlinks to the various pieces of content, it’s “just another page” so feel free to do whatever you want!"
  },
  {
    "objectID": "posts/2021-03-21-meta-tagging-distill/index.html#tagging",
    "href": "posts/2021-03-21-meta-tagging-distill/index.html#tagging",
    "title": "Including and meta tagging extra content in a distill blog",
    "section": "Tagging",
    "text": "Tagging\nHaving various pieces of content sublinked on your blog generally makes them available to folks trying to access the content on the web. However, it’s also a good idea to add “tags” to them so that they are organically discoverable via search engines. The other benefit is that tags can make your links display summary cards or other rich content on social media sites.\nAdding social cards/previews to one-off pieces of content and sub-pages of your blog can help a lot with engagement1. It also has the benefit of helping describe the linked content without having to embed ALL of the description into the body of the Tweet/LinkedIn post. Ultimately it’s also more rewarding as rather than a bare link or a preview card without an image, you can explicitly decide what you want the preview to show!1  In some cases, 2-3x more views/clicks per https://www.socialsongbird.com/2020/01/how-to-create-clickable-posts-on-social.html\nBlogposts\nNow for most blogposts in distill you are able to get social preview cards “for free” in that they can just be added via some extra lines in the YAML header. The preview argument turns into the preview image on the index page of your blog and in the meta tags. The title and description also get written into meta tags to be reused by social.\n---\ntitle: \"JavaScript & D3\"\ndescription: Enhance communication with interactive visualizations \nbase_url: https://rstudio.github.io/distill\npreview: images/javascript-d3-preview.png\ntwitter:\n  site: \"@rstudio\"\n  creator: \"@fly_upside_down\"\n---\n\n{distill} home page\nHowever, notably the preview image option is missing from the MAIN page of your distill blog.\nYou can use the strategies outlined below with metathis or <meta> tags to create a nice tag/meta details for your distill homepage as well.\nWhile I’ll be covering more details about metathis below, here is what my index.Rmd looks like that attaches <meta> tags via metathis\n---\ntitle: \"Posts\"\nsite: distill::distill_website\nlisting: posts\n---\n\n{r, include=FALSE, results='asis'}\nlibrary(metathis)\n\nmeta() %>%\n  meta_social(\n    title = \"The MockUp Blog\",\n    description = \"Tom's musings on all things R\",\n    url = \"https://themockup.blog/\",\n    image = \"https://raw.githubusercontent.com/jthomasmock/radix_themockup/master/static/logo-plot.png\",\n    image_alt = \"Chaos into tidy code\",\n    og_type = \"website\",\n    og_author = \"Tom Mock\",\n    twitter_card_type = \"summary\",\n    twitter_creator = \"@thomas_mock\"\n  )\n\n\nOthers have written about social card/meta tags for {blogdown}, with examples from Alison Hill, Xavier A, Sharleen W., and Len Kiefer.\n\nExtra content\nThose built-in options work great for blogposts, but again I also have quite a few extra pieces of content, like my {gt} cookbooks, {xaringan} slide decks, or example interactive tables.\nFor these non-blog pages, they are essentially just bare RMarkdown sites. As such, often I need to manually add the <meta> tags that tell the various social pages “what to do” with the page as far as previews.\n\n<meta> Tags\n<meta> tags are useful for search engine optimization (aka discoverability) of your content, for sharing on social media like LinkedIn or Twitter, or even messaging platforms like Slack, and generally helpful for accessibility. Garrick Aden-Buie recommended the Guide to <meta> and <head> details from Josh Buchea. That sublinks to LOTS of great detail for specific social pages.\nPer w3chools.com:\n\nThe <meta> tag defines metadata about an HTML document. Metadata is data (information) about data.\n\n\nMetadata is used by browsers (how to display content or reload page), search engines (keywords), and other web services.\n\nFurthermore, per the Mozilla blog:\n\nAs you travel around the web, you’ll find other types of metadata, too. A lot of the features you’ll see on websites are proprietary creations, designed to provide certain sites (such as social networking sites) with specific pieces of information they can use.\nFor example, Open Graph Data is a metadata protocol that Facebook invented to provide richer metadata for websites. Twitter also has its own similar proprietary metadata called Twitter Cards, which has a similar effect when the site’s URL is displayed on Twitter.com\n\nWriting <meta> tags\nYou can always write <meta> tags by hand, and they aren’t overly complicated, as seen in the Twitter Documentation:\n<meta name=\"twitter:card\" content=\"summary_large_image\">\n<meta name=\"twitter:site\" content=\"@nytimes\">\n<meta name=\"twitter:creator\" content=\"@SarahMaslinNir\">\n<meta name=\"twitter:title\" content=\"Parade of Fans for Houston\">\n<meta name=\"twitter:description\" content=\"NEWARK - The guest list and parade of limousines with celebrities emerging from them seemed more suited to a red carpet event in Hollywood or New York than than a gritty stretch of Sussex Avenue near the former site of the James M. Baxter Terrace public housing project here.\">\n<meta name=\"twitter:image\" content=\"http://graphics8.nytimes.com/images/2012/02/19/us/19whitney-span/19whitney-span-articleLarge.jpg\">\nHowever, thanks to Garrick Aden-Buie, you can save yourself a lot of effort and just use the {metathis} package, which provides R functions to generate <meta> tags.\nFrom the documentation, here’s an example of what a meta-tag generation looks like for the R4DS textbook.\n\nlibrary(metathis)\n\nmeta() %>%\n  meta_description(\n    \"This book will teach you how to do data science with R...\"\n  ) %>% \n  meta_name(\"github-repo\" = \"hadley/r4ds\") %>% \n  meta_viewport() %>% \n  meta_social(\n    title = \"R for Data Science\",\n    url = \"https://r4ds.had.co.nz\",\n    image = \"https://r4ds.had.co.nz/cover.png\",\n    image_alt = \"The cover of the R4DS book\",\n    og_type = \"book\",\n    og_author = c(\"Garrett Grolemund\", \"Hadley Wickham\"),\n    twitter_card_type = \"summary\",\n    twitter_creator = \"@hadley\"\n  )\n\nAnd the HTML output\n#> <meta name=\"viewport\" content=\"width=device-width, initial-scale=1, orientation=auto\"/>\n#> <meta name=\"description\" content=\"This book will teach you how to do data science with R...\"/>\n#> <meta name=\"github-repo\" content=\"hadley/r4ds\"/>\n#> <meta name=\"twitter:title\" content=\"R for Data Science\"/>\n#> <meta name=\"twitter:description\" content=\"This book will teach you how to do data science with R...\"/>\n#> <meta name=\"twitter:url\" content=\"https://r4ds.had.co.nz\"/>\n#> <meta name=\"twitter:image:src\" content=\"https://r4ds.had.co.nz/cover.png\"/>\n#> <meta name=\"twitter:image:alt\" content=\"The cover of the R4DS book\"/>\n#> <meta name=\"twitter:card\" content=\"summary\"/>\n#> <meta name=\"twitter:creator\" content=\"@hadley\"/>\n#> <meta name=\"twitter:site\" content=\"@hadley\"/>\n#> <meta property=\"og:title\" content=\"R for Data Science\"/>\n#> <meta property=\"og:description\" content=\"This book will teach you how to do data science with R...\"/>\n#> <meta property=\"og:url\" content=\"https://r4ds.had.co.nz\"/>\n#> <meta property=\"og:image\" content=\"https://r4ds.had.co.nz/cover.png\"/>\n#> <meta property=\"og:image:alt\" content=\"The cover of the R4DS book\"/>\n#> <meta property=\"og:type\" content=\"book\"/>\n#> <meta property=\"og:locale\" content=\"en_US\"/>\n#> <meta property=\"article:author\" content=\"Garrett Grolemund\"/>\n#> <meta property=\"article:author\" content=\"Hadley Wickham\"/>\nI prefer this to writing it all by hand, as it’s less error prone than me typing it out manually!\n\n{metathis} options\nAn aside that tripped me up is that the preview image needs to be linked as a URL, so you won’t be able to just link to a local file, but rather the site or GitHub URL for that specific image.\nGenerally you can just write a RMarkdown chunk with echo=FALSE as you’d expect and put the metathis code in it.\nmeta() %>% \n  meta_description(\"My awesome presentation\")\nHowever, for some pieces of content you in RMarkdown there are already <meta> tags that are generated, or they need to explicitly need to be added into the header of the HTML file.\nIn that cases where the basic approach is not working, I recommend following Garrick’s {metathis} advice from the readme.\nOption 1:\n\nUsing metathis::include_meta() to explicitly declare the <meta> tags as an HTML dependency\n\nOption 2 (if all else fails):\n\nIn other packages or situations, you can use include_meta() to explicitly declare the meta tags as an html dependency or use write_meta() to save the <meta> tags to an .html file that can be included via includes: in_header in the YAML of the RMarkdown doc. (In blogdown, consult your blogdown/hugo theme for the correct inclusion method.)\n\nmeta() %>% \n  meta_description(\"A fantastic blog post\") %>% \n  write_meta(\"meta.html\")\nThat will generally solve most problems for including social tags in RMarkdown."
  },
  {
    "objectID": "posts/2021-03-21-meta-tagging-distill/index.html#optimal-image-sizes",
    "href": "posts/2021-03-21-meta-tagging-distill/index.html#optimal-image-sizes",
    "title": "Including and meta tagging extra content in a distill blog",
    "section": "Optimal image sizes",
    "text": "Optimal image sizes\nEach of the social sites have “optimal” sizes/ratios of the images, and Hootsuite has a meta-guide of social media image sizing.\nThe short summary is, keep your image file size relatively small, as it’ll cost less in bandwidth and is presented relatively small anyway on social. Twitter specifically will crop your images to a square for basic preview cards."
  },
  {
    "objectID": "posts/2021-03-21-meta-tagging-distill/index.html#confirm-tags",
    "href": "posts/2021-03-21-meta-tagging-distill/index.html#confirm-tags",
    "title": "Including and meta tagging extra content in a distill blog",
    "section": "Confirm tags",
    "text": "Confirm tags\nYou can “check” to make sure your tags worked by using tools like:\n\n\nTwitter’s Card Validator\n\n\nLinkedIn’s Post Inspector\n\nMore generally, just doing a test post to your social feed\n\nNote that if your website is too large, you can’t always get the social “crawlers” to parse the page and return a preview. It’s a good idea to keep your image sizes relatively low, and generally not include TOO much content in a single page.\nNow rather than getting a blank preview card, you can get nice previews!\n\n\nTwitter Preview\n\n\n\n\nLinkedIn Preview\n\n\nSo go on and create your content, share it widely, and enjoy better previews/urls!\n\n\n\n\n\n\nExpand for Session Info\n\n\n\n\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.0 (2022-04-22)\n os       macOS Monterey 12.2.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       America/Chicago\n date     2022-04-28\n pandoc   2.18 @ /Applications/RStudio.app/Contents/MacOS/quarto/bin/tools/ (via rmarkdown)\n quarto   0.9.294 @ /usr/local/bin/quarto\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version date (UTC) lib source\n sessioninfo * 1.2.2   2021-12-06 [1] CRAN (R 4.2.0)\n\n [1] /Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/library\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "posts/2020-04-03-beer-and-pdftools-a-vignette/index.html#load-libraries",
    "href": "posts/2020-04-03-beer-and-pdftools-a-vignette/index.html#load-libraries",
    "title": "Beer and pdftools - a vignette",
    "section": "Load Libraries",
    "text": "Load Libraries\nWe’ll use ROpenSci’s pdftools package along with several tidyverse packages: - stringr - text manipulation - dplyr - general data manipulation - tidyr - data cleaning - purrr - repeated application of a function\n\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──\n\n\n✔ ggplot2 3.3.5     ✔ purrr   0.3.4\n✔ tibble  3.1.6     ✔ dplyr   1.0.8\n✔ tidyr   1.2.0     ✔ stringr 1.4.0\n✔ readr   2.1.2     ✔ forcats 0.5.1\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(pdftools)\n\nUsing poppler version 22.04.0"
  },
  {
    "objectID": "posts/2020-04-03-beer-and-pdftools-a-vignette/index.html#list-file-names",
    "href": "posts/2020-04-03-beer-and-pdftools-a-vignette/index.html#list-file-names",
    "title": "Beer and pdftools - a vignette",
    "section": "List File Names",
    "text": "List File Names\n\n# list all the files we have downloaded so far\nall_files <- list.files(\"pdfs\")\nlength(all_files)\n\n[1] 48\n\n\nWe have 48 PDFs, as expected - 12 months x 4 years = 48!\nNow let’s take a peek inside one of the PDFs."
  },
  {
    "objectID": "posts/2020-04-03-beer-and-pdftools-a-vignette/index.html#split-by-row",
    "href": "posts/2020-04-03-beer-and-pdftools-a-vignette/index.html#split-by-row",
    "title": "Beer and pdftools - a vignette",
    "section": "Split by row",
    "text": "Split by row\nWe can use stringr::str_split() to separate the text at each of the \\n newlines. This generates a list of character strings, we call unlist() to extract to a vector. We now have a nicely separated vector of character strings, where each row is a new string.\n\nraw_text <- pdftools::pdf_text(\"pdfs/ttb_monthly_stats_2011-01.pdf\") %>% \n  str_split(\"\\n\") %>% \n  unlist()\nraw_text\n\n [1] \"                                                                                                                          Report Date:\"         \n [2] \"                                           DEPARTMENT OF THE TREASURY                                                     30-MAR-2011\"          \n [3] \"                                 ALCOHOL AND TOBACCO TAX AND TRADE BUREAU\"                                                                      \n [4] \"                                                                                                                          Report Symbol:\"       \n [5] \"                                                  STATISTICAL REPORT - BEER                                               TTB S 5130-01-2011\"   \n [6] \"\"                                                                                                                                               \n [7] \"                                                      Reporting Period: January 2011                                      Page: 1 of 1\"         \n [8] \"\"                                                                                                                                               \n [9] \"\"                                                                                                                                               \n[10] \"                                                                                                       Current Year             Prior Year\"     \n[11] \"                                                                                   Prior Year           Cumulative             Cumulative\"      \n[12] \"MANUFACTURE OF BEER                                     Current Month            Current Month         Year to Date            Year to Date\"    \n[13] \"\"                                                                                                                                               \n[14] \"Production                                                    14,981,472              15,012,331          14,981,472               15,012,331\"  \n[15] \"Removals\"                                                                                                                                       \n[16] \"Taxable ($7.00/$18.00 per barrel)\"                                                                                                              \n[17] \"  In bottles and cans                                         11,571,819              11,908,922          11,571,819               11,908,922\"  \n[18] \"  In barrels and kegs                                          1,245,125                   1,245,143       1,245,125                1,245,143\"  \n[19] \"  Tax Determined, Premises Use                                      5,989                     5,267            5,989                     5,267\" \n[20] \"    Sub Total Taxable                                         12,822,933              13,159,332          12,822,933               13,159,332\"  \n[21] \"Tax-free\"                                                                                                                                       \n[22] \"  For export                                                     264,669                    224,066          264,669                  224,066\"  \n[23] \"  For vessels and aircraft                                               0                        0                   0                       0\"\n[24] \"  Consumed on brewery premises                                        886                       913              886                       913\" \n[25] \"     Sub Total Tax-Free                                          265,555                    224,979          265,555                  224,979\"  \n[26] \"  Total Removals                                              13,088,488              13,384,311          13,088,488               13,384,311\"  \n[27] \"Stocks On Hand end-of-month:                                   9,896,961                   9,993,268       9,896,961                9,993,268\"  \n[28] \"\"                                                                                                                                               \n[29] \"\"                                                                                                                                               \n[30] \"MATERIALS USED AT BREWERIES\"                                                                                                                    \n[31] \"\"                                                                                                                                               \n[32] \"  Malt and malt products                                    322,480,722              330,304,432         322,480,722              330,304,432\"  \n[33] \"  Corn and corn products                                      58,632,672              56,705,162          58,632,672               56,705,162\"  \n[34] \"  Rice and rice products                                    108,112,318               59,701,345         108,112,318               59,701,345\"  \n[35] \"  Barley and barley products                                   4,705,175                   3,668,374       4,705,175                3,668,374\"  \n[36] \"  Wheat and wheat products                                     1,210,137                   1,409,685       1,210,137                1,409,685\"  \n[37] \"    Total Grain products                                    495,141,024              451,788,998         495,141,024              451,788,998\"  \n[38] \"\"                                                                                                                                               \n[39] \"  Sugar and syrups                                            73,793,509              47,308,358          73,793,509               47,308,358\"  \n[40] \"  Hops (dry)                                                   6,059,066                   4,765,924       6,059,066                4,765,924\"  \n[41] \"  Hops (used as extracts)                                        296,605                    271,405          296,605                  271,405\"  \n[42] \"  Other                                                        7,972,930              10,537,742           7,972,930               10,537,742\"  \n[43] \"     Total Non-Grain products                                 88,122,110              62,883,429          88,122,110               62,883,429\"  \n[44] \"Total Used                                                  583,263,134              514,672,427         583,263,134              514,672,427\"  \n[45] \"\"                                                                                                                                               \n[46] \"\"                                                                                                                                               \n[47] \"        296,605 Pounds of hops is equivalent to          212,541     pounds of extract JAN 2011\"                                                \n[48] \"        271,405 Pounds of hops is equivalent to          101,087     pounds of extract JAN 2010\"                                                \n[49] \"\"                                                                                                                                               \n[50] \"\"                                                                                                                                               \n[51] \"\"                                                                                                                                               \n[52] \"\"                                                                                                                                               \n[53] \"NOTE: Changes in figures from prior reports could be due to amended reports being filed.\"                                                       \n[54] \"     This data is not final and may need to be amended.\"                                                                                        \n[55] \"\"                                                                                                                                               \n[56] \"\"                                                                                                                                               \n[57] \"\"                                                                                                                                               \n[58] \"http://www.ttb.gov\"                                                                                                                             \n[59] \"\""
  },
  {
    "objectID": "posts/2020-04-03-beer-and-pdftools-a-vignette/index.html#build-table",
    "href": "posts/2020-04-03-beer-and-pdftools-a-vignette/index.html#build-table",
    "title": "Beer and pdftools - a vignette",
    "section": "Build Table",
    "text": "Build Table\nNow that we have the data split into a vector we can start finding “rows” to drop. We can see that the 9th string is actually the column titles, and the table ends at the 36th string. However, this could change according to which PDF we are looking at, so rather than going by position we can use stringr::str_which() to match a logical with matched text.\n\n# Start of table - column names\nraw_text[9]\n\n[1] \"\"\n\n# End of table - last value\nraw_text[36]\n\n[1] \"  Wheat and wheat products                                     1,210,137                   1,409,685       1,210,137                1,409,685\"\n\n\nWe get the same “rows” with our matching str_which().\n\n# find start of table\nstringr::str_which(raw_text, \"MANUFACTURE OF BEER\")\n\n[1] 12\n\n# find end of table\nstringr::str_which(raw_text, \"Total Used\")\n\n[1] 44\n\n\nLet’s actually assign this now, rather than just printing. We can also remove leading/trailing whitespace with stringr::str_trim(). When we look at table_trimmed we can “see” a group of text strings that much closer resemble a table!\n\ntable_start <- stringr::str_which(raw_text, \"MANUFACTURE OF BEER\")\n  \n# End of table (drop all the asterisks and the other descriptors)\ntable_end <- stringr::str_which(raw_text, \"Total Used\")\n  \n# Trim the table to the start/end and drop whitespace at each line\ntable_trimmed <- raw_text[table_start:table_end] %>% \n  str_trim()\ntable_trimmed\n\n [1] \"MANUFACTURE OF BEER                                     Current Month            Current Month         Year to Date            Year to Date\"  \n [2] \"\"                                                                                                                                             \n [3] \"Production                                                    14,981,472              15,012,331          14,981,472               15,012,331\"\n [4] \"Removals\"                                                                                                                                     \n [5] \"Taxable ($7.00/$18.00 per barrel)\"                                                                                                            \n [6] \"In bottles and cans                                         11,571,819              11,908,922          11,571,819               11,908,922\"  \n [7] \"In barrels and kegs                                          1,245,125                   1,245,143       1,245,125                1,245,143\"  \n [8] \"Tax Determined, Premises Use                                      5,989                     5,267            5,989                     5,267\" \n [9] \"Sub Total Taxable                                         12,822,933              13,159,332          12,822,933               13,159,332\"    \n[10] \"Tax-free\"                                                                                                                                     \n[11] \"For export                                                     264,669                    224,066          264,669                  224,066\"  \n[12] \"For vessels and aircraft                                               0                        0                   0                       0\"\n[13] \"Consumed on brewery premises                                        886                       913              886                       913\" \n[14] \"Sub Total Tax-Free                                          265,555                    224,979          265,555                  224,979\"     \n[15] \"Total Removals                                              13,088,488              13,384,311          13,088,488               13,384,311\"  \n[16] \"Stocks On Hand end-of-month:                                   9,896,961                   9,993,268       9,896,961                9,993,268\"\n[17] \"\"                                                                                                                                             \n[18] \"\"                                                                                                                                             \n[19] \"MATERIALS USED AT BREWERIES\"                                                                                                                  \n[20] \"\"                                                                                                                                             \n[21] \"Malt and malt products                                    322,480,722              330,304,432         322,480,722              330,304,432\"  \n[22] \"Corn and corn products                                      58,632,672              56,705,162          58,632,672               56,705,162\"  \n[23] \"Rice and rice products                                    108,112,318               59,701,345         108,112,318               59,701,345\"  \n[24] \"Barley and barley products                                   4,705,175                   3,668,374       4,705,175                3,668,374\"  \n[25] \"Wheat and wheat products                                     1,210,137                   1,409,685       1,210,137                1,409,685\"  \n[26] \"Total Grain products                                    495,141,024              451,788,998         495,141,024              451,788,998\"    \n[27] \"\"                                                                                                                                             \n[28] \"Sugar and syrups                                            73,793,509              47,308,358          73,793,509               47,308,358\"  \n[29] \"Hops (dry)                                                   6,059,066                   4,765,924       6,059,066                4,765,924\"  \n[30] \"Hops (used as extracts)                                        296,605                    271,405          296,605                  271,405\"  \n[31] \"Other                                                        7,972,930              10,537,742           7,972,930               10,537,742\"  \n[32] \"Total Non-Grain products                                 88,122,110              62,883,429          88,122,110               62,883,429\"     \n[33] \"Total Used                                                  583,263,134              514,672,427         583,263,134              514,672,427\"\n\n\nRemove all the extra whitespace\nNext we need to remove all the huge whitespaces from between columns. The regular expression (regex) of \"\\\\s{2,}\" matches whitespaces of 2 or more. If we use stringr::str_replace_all() to take all the whitespaces > 2 and replace with a new delimiter such as \"|\" we can move to our next step. While we’re at it, let’s remove all the commas so that we can go straight to doubles rather than characters for all the beer production variables.\n\n# Replace long spaces with a col break symbol\nsquished_table <- str_replace_all(table_trimmed, \"\\\\s{2,}\", \"|\") %>% \n  str_remove_all(\",\")\nsquished_table\n\n [1] \"MANUFACTURE OF BEER|Current Month|Current Month|Year to Date|Year to Date\"\n [2] \"\"                                                                         \n [3] \"Production|14981472|15012331|14981472|15012331\"                           \n [4] \"Removals\"                                                                 \n [5] \"Taxable ($7.00/$18.00 per barrel)\"                                        \n [6] \"In bottles and cans|11571819|11908922|11571819|11908922\"                  \n [7] \"In barrels and kegs|1245125|1245143|1245125|1245143\"                      \n [8] \"Tax Determined Premises Use|5989|5267|5989|5267\"                          \n [9] \"Sub Total Taxable|12822933|13159332|12822933|13159332\"                    \n[10] \"Tax-free\"                                                                 \n[11] \"For export|264669|224066|264669|224066\"                                   \n[12] \"For vessels and aircraft|0|0|0|0\"                                         \n[13] \"Consumed on brewery premises|886|913|886|913\"                             \n[14] \"Sub Total Tax-Free|265555|224979|265555|224979\"                           \n[15] \"Total Removals|13088488|13384311|13088488|13384311\"                       \n[16] \"Stocks On Hand end-of-month:|9896961|9993268|9896961|9993268\"             \n[17] \"\"                                                                         \n[18] \"\"                                                                         \n[19] \"MATERIALS USED AT BREWERIES\"                                              \n[20] \"\"                                                                         \n[21] \"Malt and malt products|322480722|330304432|322480722|330304432\"           \n[22] \"Corn and corn products|58632672|56705162|58632672|56705162\"               \n[23] \"Rice and rice products|108112318|59701345|108112318|59701345\"             \n[24] \"Barley and barley products|4705175|3668374|4705175|3668374\"               \n[25] \"Wheat and wheat products|1210137|1409685|1210137|1409685\"                 \n[26] \"Total Grain products|495141024|451788998|495141024|451788998\"             \n[27] \"\"                                                                         \n[28] \"Sugar and syrups|73793509|47308358|73793509|47308358\"                     \n[29] \"Hops (dry)|6059066|4765924|6059066|4765924\"                               \n[30] \"Hops (used as extracts)|296605|271405|296605|271405\"                      \n[31] \"Other|7972930|10537742|7972930|10537742\"                                  \n[32] \"Total Non-Grain products|88122110|62883429|88122110|62883429\"             \n[33] \"Total Used|583263134|514672427|583263134|514672427\"                       \n\n\nConvert to tibble\nNow we have a nicely formatted vector of strings! We can use tibble::enframe() to create a dataframe/tibble out of the vector.\n\n# Convert to tibble\nraw_df <- enframe(squished_table)\nraw_df\n\n# A tibble: 33 × 2\n    name value                                                                  \n   <int> <chr>                                                                  \n 1     1 \"MANUFACTURE OF BEER|Current Month|Current Month|Year to Date|Year to …\n 2     2 \"\"                                                                     \n 3     3 \"Production|14981472|15012331|14981472|15012331\"                       \n 4     4 \"Removals\"                                                             \n 5     5 \"Taxable ($7.00/$18.00 per barrel)\"                                    \n 6     6 \"In bottles and cans|11571819|11908922|11571819|11908922\"              \n 7     7 \"In barrels and kegs|1245125|1245143|1245125|1245143\"                  \n 8     8 \"Tax Determined Premises Use|5989|5267|5989|5267\"                      \n 9     9 \"Sub Total Taxable|12822933|13159332|12822933|13159332\"                \n10    10 \"Tax-free\"                                                             \n# … with 23 more rows\n\n\nNext we can separate value into the 5 columns. Notice that there are a few “rows” where the data is NA as there were rows that acted only as indicators of the type of beer production. We’ll use them later.\n\nyear <- 2011\nmonth <- \"02\"\n# Convert to tibble\nbeer_df <- raw_df %>% \n    separate(value, \n             into = c(\"type\", \"month_current\", \"month_prior_year\", \"ytd_current\", \"ytd_prior_year\"), \n             sep = \"\\\\|\") %>% \n  slice(-1) %>% \n  mutate_at(vars(month_current:ytd_prior_year), as.double) %>% \n  mutate(year = as.integer(year), month = as.integer(month)) %>% \n  select(year, month, type, everything())\n\nWarning: Expected 5 pieces. Missing pieces filled with `NA` in 9 rows [2, 4, 5,\n10, 17, 18, 19, 20, 27].\n\nbeer_df\n\n# A tibble: 32 × 8\n    year month type              name month_current month_prior_year ytd_current\n   <int> <int> <chr>            <int>         <dbl>            <dbl>       <dbl>\n 1  2011     2 \"\"                   2            NA               NA          NA\n 2  2011     2 \"Production\"         3      14981472         15012331    14981472\n 3  2011     2 \"Removals\"           4            NA               NA          NA\n 4  2011     2 \"Taxable ($7.00…     5            NA               NA          NA\n 5  2011     2 \"In bottles and…     6      11571819         11908922    11571819\n 6  2011     2 \"In barrels and…     7       1245125          1245143     1245125\n 7  2011     2 \"Tax Determined…     8          5989             5267        5989\n 8  2011     2 \"Sub Total Taxa…     9      12822933         13159332    12822933\n 9  2011     2 \"Tax-free\"          10            NA               NA          NA\n10  2011     2 \"For export\"        11        264669           224066      264669\n# … with 22 more rows, and 1 more variable: ytd_prior_year <dbl>\n\n\nTechnically at this point, we have successfully converted from raw text to a dataframe/table/tibble! HOWEVER, for many many examples in the wild you will need to do additional data cleaning, data manipulation, factor assignment, etc. As such, I’ll continue working on this to get to a final output. I’ll also work on repeating this many times as opposed to one time."
  },
  {
    "objectID": "posts/2020-04-03-beer-and-pdftools-a-vignette/index.html#split-dataframe",
    "href": "posts/2020-04-03-beer-and-pdftools-a-vignette/index.html#split-dataframe",
    "title": "Beer and pdftools - a vignette",
    "section": "Split dataframe",
    "text": "Split dataframe\nNext we will add a column based on logic for the slice_num, and assign a grouping variable for either Barrels Produced (dataset 1) or Pounds of Materials Used (dataset 2). We can then drop the unneeded rows with a filter(), group_by() the newly produced grouping variable, and use dplyr::group_split() to separate the combined dataset into a list of both datasets.\n\n# split data into materials vs barrels produced\nsplit_df <- beer_df %>% \n  mutate(data_type = ifelse(name >= slice_num, \"Pounds of Materials Used\", \"Barrels Produced\"),\n         type = str_remove(type, \":\")) %>% \n  select(data_type, everything(), -name) %>% \n  filter(!str_detect(type, \"IN POUNDS|MATERIALS USED|MANUFACTURE OF BEER|BARRELS\")) %>% \n  group_by(data_type) %>% \n  group_split()\nglimpse(split_df)\n\nlist<tibble[,8]> [1:2] \n$ : tibble [17 × 8] (S3: tbl_df/tbl/data.frame)\n$ : tibble [14 × 8] (S3: tbl_df/tbl/data.frame)\n@ ptype: tibble [0 × 8] (S3: tbl_df/tbl/data.frame)"
  },
  {
    "objectID": "posts/2020-04-03-beer-and-pdftools-a-vignette/index.html#factor-cleaning-and-final-dataframes",
    "href": "posts/2020-04-03-beer-and-pdftools-a-vignette/index.html#factor-cleaning-and-final-dataframes",
    "title": "Beer and pdftools - a vignette",
    "section": "Factor cleaning and final dataframes",
    "text": "Factor cleaning and final dataframes\nWe can see that the split_df object is a list of 2 tibbles/dataframes. We can now operate on the individual dataframes and finalize the factor cleaning and assignment to make the data a bit tidier and analysis ready.\n\nmanufacture_df <- split_df[[1]] %>% \n  mutate(\n    tax_status = case_when(\n      type %in% c(\"In bottles and cans\", \"In kegs\", \"In barrels and kegs\",\n                  \"Tax Determined, Premises Use\") ~ \"Taxable\",\n      type == \"Sub Total Taxable\" ~ \"Sub Total Taxable\",\n      type %in% c(\"For export\", \"For vessels and aircraft\", \n                  \"Consumed on brewery premises\") ~ \"Tax Free\",\n      type == \"Sub Total Tax-Free\" ~ \"Sub Total Tax-Free\",\n      type %in% c(\"Production\", \"Total Removals\", \n                  \"Stocks On Hand end-of-month:\") ~ \"Totals\"\n      ),\n    tax_rate = dplyr::if_else(year <= 2017, \"$7/$18 per barrel\", \"$3.50/$16 per barrel\")\n    ) %>% \n  filter(!is.na(tax_status)) %>% \n  select(data_type, tax_status, everything())\n\n\n# clean up the material dataset\nmaterial_df <- split_df[[2]] %>% \n  mutate(\n    material_type = case_when(\n      str_detect(type, \"Malt|Corn|Rice|Barley|Wheat\") ~ \"Grain Products\",\n      str_detect(type, \"Sugar|Hops|Other\") ~ \"Non-Grain Products\",\n      str_detect(type, \"Total\") ~ type\n    )\n  ) %>% \n  select(data_type, material_type, everything())\n\nPrint the dataframes\nThe manufacture dataframe now has the labels, factors, etc separated into nice columns, with the 4x columns for specific barrels produced.\n\nmanufacture_df\n\n# A tibble: 9 × 10\n  data_type        tax_status    year month type  month_current month_prior_year\n  <chr>            <chr>        <int> <int> <chr>         <dbl>            <dbl>\n1 Barrels Produced Totals        2011     2 Prod…      14981472         15012331\n2 Barrels Produced Taxable       2011     2 In b…      11571819         11908922\n3 Barrels Produced Taxable       2011     2 In b…       1245125          1245143\n4 Barrels Produced Sub Total T…  2011     2 Sub …      12822933         13159332\n5 Barrels Produced Tax Free      2011     2 For …        264669           224066\n6 Barrels Produced Tax Free      2011     2 For …             0                0\n7 Barrels Produced Tax Free      2011     2 Cons…           886              913\n8 Barrels Produced Sub Total T…  2011     2 Sub …        265555           224979\n9 Barrels Produced Totals        2011     2 Tota…      13088488         13384311\n# … with 3 more variables: ytd_current <dbl>, ytd_prior_year <dbl>,\n#   tax_rate <chr>\n\n\nThe material dataframe now has the labels, factors, etc separated into nice columns, with the 4x columns for specific pounds of product used.\n\nmaterial_df\n\n# A tibble: 14 × 9\n   data_type      material_type  year month type  month_current month_prior_year\n   <chr>          <chr>         <int> <int> <chr>         <dbl>            <dbl>\n 1 Pounds of Mat… <NA>           2011     2 \"\"               NA               NA\n 2 Pounds of Mat… Grain Produc…  2011     2 \"Mal…     322480722        330304432\n 3 Pounds of Mat… Grain Produc…  2011     2 \"Cor…      58632672         56705162\n 4 Pounds of Mat… Grain Produc…  2011     2 \"Ric…     108112318         59701345\n 5 Pounds of Mat… Grain Produc…  2011     2 \"Bar…       4705175          3668374\n 6 Pounds of Mat… Grain Produc…  2011     2 \"Whe…       1210137          1409685\n 7 Pounds of Mat… Total Grain …  2011     2 \"Tot…     495141024        451788998\n 8 Pounds of Mat… <NA>           2011     2 \"\"               NA               NA\n 9 Pounds of Mat… Non-Grain Pr…  2011     2 \"Sug…      73793509         47308358\n10 Pounds of Mat… Non-Grain Pr…  2011     2 \"Hop…       6059066          4765924\n11 Pounds of Mat… Non-Grain Pr…  2011     2 \"Hop…        296605           271405\n12 Pounds of Mat… Non-Grain Pr…  2011     2 \"Oth…       7972930         10537742\n13 Pounds of Mat… Total Non-Gr…  2011     2 \"Tot…      88122110         62883429\n14 Pounds of Mat… Total Used     2011     2 \"Tot…     583263134        514672427\n# … with 2 more variables: ytd_current <dbl>, ytd_prior_year <dbl>\n\n\nFinished Cleaning\nWe have now finished cleaning the manufacting and material dataframes! However, we did this all line-by-line without functions and would need to repeat this for the other 47 PDFs! Let’s convert ALL that code into a function that outputs the final dataframes."
  },
  {
    "objectID": "posts/2020-04-03-beer-and-pdftools-a-vignette/index.html#all-possible-combos",
    "href": "posts/2020-04-03-beer-and-pdftools-a-vignette/index.html#all-possible-combos",
    "title": "Beer and pdftools - a vignette",
    "section": "All possible combos",
    "text": "All possible combos\nWe can use tidyr::crossing() again to generate the possible inputs and create the output dataframes as list column of two dataframes. Running this takes only about 2 seconds across the 48 PDFs! The output is not very exciting as the data is simply the year & month columns, plus a list-column called data. Let’s get the final outputs!\n\n# add the month_num as vector\nmonth_num <- c(\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\")\n# use crossing to generate all combos for the data \ndf_2011_2014 <- crossing(year = c(2011:2014), \n                         month = month_num) %>% \n  mutate(data = pmap(., get_beer_tables))\ndf_2011_2014\n\n# A tibble: 48 × 3\n    year month data      \n   <int> <chr> <list>    \n 1  2011 01    <list [2]>\n 2  2011 02    <list [2]>\n 3  2011 03    <list [2]>\n 4  2011 04    <list [2]>\n 5  2011 05    <list [2]>\n 6  2011 06    <list [2]>\n 7  2011 07    <list [2]>\n 8  2011 08    <list [2]>\n 9  2011 09    <list [2]>\n10  2011 10    <list [2]>\n# … with 38 more rows"
  },
  {
    "objectID": "posts/2020-04-03-beer-and-pdftools-a-vignette/index.html#final-output",
    "href": "posts/2020-04-03-beer-and-pdftools-a-vignette/index.html#final-output",
    "title": "Beer and pdftools - a vignette",
    "section": "Final output",
    "text": "Final output\nWe can now get just the output data, drop the other columns. We’re still working with list-columns, so let’s get to the manufacture_df and material_df.\n\nfinal_output <- df_2011_2014 %>%\n  # grab the data into respective columns\n  mutate(manufacture_data = map(data, 1),\n         material_data = map(data, 2)) %>% \n  select(manufacture_data, material_data)\nfinal_output\n\n# A tibble: 48 × 2\n   manufacture_data  material_data    \n   <list>            <list>           \n 1 <tibble [9 × 10]> <tibble [14 × 9]>\n 2 <tibble [9 × 10]> <tibble [14 × 9]>\n 3 <tibble [9 × 10]> <tibble [14 × 9]>\n 4 <tibble [9 × 10]> <tibble [14 × 9]>\n 5 <tibble [9 × 10]> <tibble [14 × 9]>\n 6 <tibble [9 × 10]> <tibble [14 × 9]>\n 7 <tibble [9 × 10]> <tibble [14 × 9]>\n 8 <tibble [9 × 10]> <tibble [14 × 9]>\n 9 <tibble [9 × 10]> <tibble [14 × 9]>\n10 <tibble [9 × 10]> <tibble [14 × 9]>\n# … with 38 more rows\n\n\nThe manufacture dataframe can be combined as below.\n\n# Grab just the manufacture data\nmanufacture_df <- final_output %>% \n  select(manufacture_data) %>% \n  unnest(manufacture_data)\n# Grab just the manufacture data\nmaterial_df <- final_output %>% \n  select(material_data) %>% \n  unnest(material_data)\n\nAnd now we can look at the outputs!\nManufacture dataset\n\nglimpse(manufacture_df)\n\nRows: 432\nColumns: 10\n$ data_type        <chr> \"Barrels Produced\", \"Barrels Produced\", \"Barrels Prod…\n$ tax_status       <chr> \"Totals\", \"Taxable\", \"Taxable\", \"Sub Total Taxable\", …\n$ year             <int> 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011,…\n$ month            <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,…\n$ type             <chr> \"Production\", \"In bottles and cans\", \"In barrels and …\n$ month_current    <dbl> 14981472, 11571819, 1245125, 12822933, 264669, 0, 886…\n$ month_prior_year <dbl> 15012331, 11908922, 1245143, 13159332, 224066, 0, 913…\n$ ytd_current      <dbl> 14981472, 11571819, 1245125, 12822933, 264669, 0, 886…\n$ ytd_prior_year   <dbl> 15012331, 11908922, 1245143, 13159332, 224066, 0, 913…\n$ tax_rate         <chr> \"$7/$18 per barrel\", \"$7/$18 per barrel\", \"$7/$18 per…\n\n\nMaterial dataset\n\nglimpse(material_df)\n\nRows: 637\nColumns: 9\n$ data_type        <chr> \"Pounds of Materials Used\", \"Pounds of Materials Used…\n$ material_type    <chr> NA, \"Grain Products\", \"Grain Products\", \"Grain Produc…\n$ year             <int> 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011,…\n$ month            <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,…\n$ type             <chr> \"\", \"Malt and malt products\", \"Corn and corn products…\n$ month_current    <dbl> NA, 322480722, 58632672, 108112318, 4705175, 1210137,…\n$ month_prior_year <dbl> NA, 330304432, 56705162, 59701345, 3668374, 1409685, …\n$ ytd_current      <dbl> NA, 322480722, 58632672, 108112318, 4705175, 1210137,…\n$ ytd_prior_year   <dbl> NA, 330304432, 56705162, 59701345, 3668374, 1409685, …"
  },
  {
    "objectID": "posts/2018-12-11-tidytuesday-a-weekly-social-data-project-in-r/index.html",
    "href": "posts/2018-12-11-tidytuesday-a-weekly-social-data-project-in-r/index.html",
    "title": "TidyTuesday",
    "section": "",
    "text": "Over the past month or so, the r4ds online learning community founded by Jesse Maegan has been developing projects intended to help connect mentors and learners. One of the first projects born out of this collaboration is #TidyTuesday, a weekly social data project focused on using tidyverse packages to clean, wrangle, tidy, and plot a new dataset every Tuesday.\nIf you are interested in joining the r4ds online learning community check out Jesse Maegan’s post here!\nEvery Monday we will release a new dataset on our GitHub that has been tamed, but does not always adhere to “tidy” data principles. This dataset will come from an article with an interesting plot. Our goal is to have you take a look at the raw data, and generate either a copy of the original plot or a novel take on the data! You can obviously use whatever techniques you feel are appropriate, but the data will be organized in a way that tidyverse tools will work well!"
  },
  {
    "objectID": "posts/2018-12-11-tidytuesday-a-weekly-social-data-project-in-r/index.html#why-such-an-emphasis-on-the-tidyverse",
    "href": "posts/2018-12-11-tidytuesday-a-weekly-social-data-project-in-r/index.html#why-such-an-emphasis-on-the-tidyverse",
    "title": "TidyTuesday",
    "section": "Why such an emphasis on the tidyverse?",
    "text": "Why such an emphasis on the tidyverse?\n\n\nThe typical Tidyverse workflow\n\n\nThe tidyverse is an “opinionated collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures.” The tidyverse is at the core of the the R for Data Science text written by Garrett Grolemund and Hadley Wickham. This book is aimed to be beginner-friendly but also deep enough to empower R experts as well. The framework of both the book and the tidyverse package is seen above.\nWe focus on the tidyverse package as the r4ds online learning community was founded “with the goal of creating a supportive and responsive online space for learners and mentors to gather and work through the R for Data Science text”. Beyond that, the tidyverse is consistent, powerful, and typically more beginner friendly. It is a good framework to get started with, and is complementary to base R (or the 1000s of other R packages)."
  },
  {
    "objectID": "posts/2018-12-11-tidytuesday-a-weekly-social-data-project-in-r/index.html#guidelines-for-tidytuesday",
    "href": "posts/2018-12-11-tidytuesday-a-weekly-social-data-project-in-r/index.html#guidelines-for-tidytuesday",
    "title": "TidyTuesday",
    "section": "Guidelines for TidyTuesday",
    "text": "Guidelines for TidyTuesday\nTo participate in TidyTuesday, you need to do a few things:\n\nCreate and save an image of a plot from R\nSave the code used to recreate your plot (include data tidy steps!)\nSubmit the plot and code on Twitter\nUse the #TidyTuesday hashtag (you can also tag me @thomas_mock)\nBrowse other submissions and like/comment on their work!\n\nHowever, that might seem like a lot! So at minimum please submit your plot with the hashtag #TidyTuesday.\nAll data will be posted on the data sets page on Monday. It will include the link to the original article (for context) and to the data set.\nIf you want to work on GitHub (a useful data science skill) feel free to post your code on GitHub! This will allow others to see and use your code, whereas an image of the code means they would have to re-type everything! Additionally, hosting on GitHub gives you a Data Science Portfolio to talk about/show in interviews, and allows you to access your code across different computers easily!\nGitHub link!\nGitHub Guide!\nYou can also upload your code into Carbon, a website the generates a high-quality image of your code.\nLastly, if you create your plot with the tidyverse you can save high quality ggplot2 images!"
  },
  {
    "objectID": "posts/2018-12-11-tidytuesday-a-weekly-social-data-project-in-r/index.html#rules-for-tidytuesday",
    "href": "posts/2018-12-11-tidytuesday-a-weekly-social-data-project-in-r/index.html#rules-for-tidytuesday",
    "title": "TidyTuesday",
    "section": "Rules for TidyTuesday",
    "text": "Rules for TidyTuesday\nWe welcome all newcomers, enthusiasts, and experts to participate, but be mindful of a few things:\n\nThis is NOT about criticizing the original authors. They are people like you and me and they have feelings. Focus on the data, the charts and improving your own techniques.\nThis is NOT about criticizing or tearing down your fellow #RStats practitioners! Be supportive and kind to each other! Like other’s posts and help promote the #RStats community!\nThe data set comes from the source article or the source that the article credits. Be mindful that the data is what it is and Tidy Tuesday is designed to help you practice data visualization and basic data wrangling.\nUse the hashtag #TidyTuesday on Twitter if you create your own version and would like to share it.\nInclude a picture of the visualisation when you post to Twitter.\nInclude a copy of the code used to create your visualization when you post to Twitter. Comment your code wherever possible to help yourself and others understand your process!\nFocus on improving your craft, even if you end up with someting simple! Make something quick, but purposeful!\nGive credit to the original data source whenever possible."
  },
  {
    "objectID": "posts/2018-12-11-tidytuesday-a-weekly-social-data-project-in-r/index.html#this-weeks-submissions",
    "href": "posts/2018-12-11-tidytuesday-a-weekly-social-data-project-in-r/index.html#this-weeks-submissions",
    "title": "TidyTuesday",
    "section": "This week’s submissions!",
    "text": "This week’s submissions!\nEveryone did such a great job! I’m posting all the ones that I can find through the hashtag, you can always tag me in your post to make sure you get noticed in the future.\n\n\nIf you have an apple and I have an apple and we exchange these apples then you and I will still each have one apple. But if you have an idea and I have an idea and we exchange these ideas, then each of us will have two ideas.— George Bernard Shaw#TidyTuesday - spreading ideas!\n\n— Thomas Mock (@thomas_mock) April 11, 2018"
  },
  {
    "objectID": "posts/2018-12-11-tidytuesday-a-weekly-social-data-project-in-r/index.html#other-useful-links",
    "href": "posts/2018-12-11-tidytuesday-a-weekly-social-data-project-in-r/index.html#other-useful-links",
    "title": "TidyTuesday",
    "section": "Other Useful Links",
    "text": "Other Useful Links\nThe R4DS Online Learning Community\nThe R for Data Science textbook\nCarbon lets you post beautiful code directly to Twitter!\nWe will use the fivethirtyeight package frequently for “tame data\nGitHub lets you host raw code for free!\nA guide to getting started with GitHub\nHow to save high quality ggplot2 images\n\n\n\n\n\n\nExpand for Session Info\n\n\n\n\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.0 (2022-04-22)\n os       macOS Monterey 12.2.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       America/Chicago\n date     2022-04-28\n pandoc   2.18 @ /Applications/RStudio.app/Contents/MacOS/quarto/bin/tools/ (via rmarkdown)\n quarto   0.9.294 @ /usr/local/bin/quarto\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version date (UTC) lib source\n sessioninfo * 1.2.2   2021-12-06 [1] CRAN (R 4.2.0)\n\n [1] /Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/library\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "posts/2021-01-28-removing-image-backgrounds-with-magick/index.html",
    "href": "posts/2021-01-28-removing-image-backgrounds-with-magick/index.html",
    "title": "Removing image backgrounds with magick",
    "section": "",
    "text": "Colin Welsh reached out on Twitter asking about removing the background from player headshots for use in dark-themed table. He had a bunch of player headshots for the NHL, but they had a white background which he wanted to remove and then embed the headshots in gt.\nHe thought that magick could be used to remove the background, and let’s see what we can do!\nIf you missed my last blogpost, it has some more details on the {magick} package. In short, magick is an R wrapper around the ImageMagick library that is used for image processing.\nFor another fantastic longer form blogpost, make sure to check out Deemah’s blogpost on Miracles with magick! I adapted some of his examples for the logos at the end. He pointed out rightfully so, that simply replacing ALL white with transparent can have some negative effects (this REALLy is a problem with logos). I’ve gone ahead and rebuilt the examples with that in mind."
  },
  {
    "objectID": "posts/2021-01-28-removing-image-backgrounds-with-magick/index.html#load-the-data",
    "href": "posts/2021-01-28-removing-image-backgrounds-with-magick/index.html#load-the-data",
    "title": "Removing image backgrounds with magick",
    "section": "Load the Data",
    "text": "Load the Data\nWe’ll load our libraries and pull in the data of interest, there are a lot of columns but I’ll limit it to a subset later on.\n\nlibrary(tidyverse)\nlibrary(gt)\nlibrary(magick)\n\nskater_game_score <- read_csv(\"hockey_data.csv\")\n\nRows: 50 Columns: 26\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (15): player, team.x, num_last_first, player_team_num, position, positio...\ndbl (11): games, g, a1, a2, pts, gs_tot, gs_avg, season, jersey_number, year...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nglimpse(skater_game_score)\n\nRows: 50\nColumns: 26\n$ player          <chr> \"CONNOR.MCDAVID\", \"NATHAN.MACKINNON\", \"MIKKO.RANTANEN\"…\n$ games           <dbl> 7, 6, 6, 6, 6, 7, 6, 6, 7, 7, 6, 6, 6, 6, 6, 5, 7, 5, …\n$ g               <dbl> 4, 2, 5, 1, 5, 4, 3, 3, 4, 3, 0, 1, 3, 2, 4, 3, 2, 3, …\n$ a1              <dbl> 4, 5, 1, 6, 1, 6, 1, 1, 2, 4, 2, 4, 2, 4, 1, 2, 3, 3, …\n$ a2              <dbl> 2, 1, 1, 3, 2, 0, 2, 3, 1, 2, 5, 1, 4, 2, 2, 1, 2, 1, …\n$ pts             <dbl> 10, 8, 7, 10, 8, 10, 6, 7, 7, 9, 7, 6, 9, 8, 7, 6, 7, …\n$ gs_tot          <dbl> 11.855, 10.630, 10.020, 9.785, 9.690, 9.135, 8.785, 8.…\n$ team.x          <chr> \"EDM\", \"COL\", \"COL\", \"L.A\", \"MTL\", \"TOR\", \"TOR\", \"PIT\"…\n$ gs_avg          <dbl> 1.5067857, 1.7733333, 1.8225000, 1.7329167, 1.3850000,…\n$ num_last_first  <chr> \"97 MCDAVID, CONNOR\", \"29 MACKINNON, NATHAN\", \"96 RANT…\n$ player_team_num <chr> \"EDM97\", \"COL29\", \"COL96\", \"L.A11\", \"MTL73\", \"TOR16\", …\n$ position        <chr> \"C\", \"C\", \"R\", \"C\", \"C\", \"C\", \"C\", \"C\", \"C\", \"C\", \"C\",…\n$ position_type   <chr> \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\",…\n$ season          <dbl> 20202021, 20202021, 20202021, 20202021, 20202021, 2020…\n$ session         <chr> \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"R\",…\n$ team.y          <chr> \"EDM\", \"COL\", \"COL\", \"L.A\", \"MTL\", \"TOR\", \"TOR\", \"PIT\"…\n$ jersey_number   <dbl> 97, 29, 96, 11, 73, 16, 34, 87, 91, 29, 9, 4, 55, 61, …\n$ first_name      <chr> \"CONNOR\", \"NATHAN\", \"MIKKO\", \"ANZE\", \"TYLER\", \"MITCHEL…\n$ last_name       <chr> \"MCDAVID\", \"MACKINNON\", \"RANTANEN\", \"KOPITAR\", \"TOFFOL…\n$ year            <dbl> 20202021, 20202021, 20202021, 20202021, 20202021, 2020…\n$ full_name       <chr> \"CONNOR MCDAVID\", \"NATHAN MACKINNON\", \"MIKKO RANTANEN\"…\n$ team_name       <chr> \"Oilers\", \"Avalanche\", \"Avalanche\", \"Kings\", \"Canadien…\n$ player_id       <dbl> 8478402, 8477492, 8478420, 8471685, 8475726, 8478483, …\n$ logo            <chr> \"http://content.sportslogos.net/logos/1/12/thumbs/1227…\n$ headshot_url    <chr> \"https://cms.nhl.bamgrid.com/images/headshots/current/…\n$ action_shot_url <chr> \"https://cms.nhl.bamgrid.com/images/actionshots/847840…"
  },
  {
    "objectID": "posts/2021-01-28-removing-image-backgrounds-with-magick/index.html#initial-table",
    "href": "posts/2021-01-28-removing-image-backgrounds-with-magick/index.html#initial-table",
    "title": "Removing image backgrounds with magick",
    "section": "Initial Table",
    "text": "Initial Table\nWe can quickly convert this into gt table like so. Look pretty good, and the player headshots look fine as well.\n\nskater_game_score %>% \n  slice(1:10) %>%\n  select(player, headshot_url, games:pts)%>% \n  gt() %>% \n  text_transform(\n    locations = cells_body(vars(headshot_url)),\n    fn = function(x){\n      web_image(url = x)\n    }\n  )\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\nplayer\n      headshot_url\n      games\n      g\n      a1\n      a2\n      pts\n    \n\n\nCONNOR.MCDAVID\n\n7\n4\n4\n2\n10\n\n\nNATHAN.MACKINNON\n\n6\n2\n5\n1\n8\n\n\nMIKKO.RANTANEN\n\n6\n5\n1\n1\n7\n\n\nANZE.KOPITAR\n\n6\n1\n6\n3\n10\n\n\nTYLER.TOFFOLI\n\n6\n5\n1\n2\n8\n\n\nMITCH.MARNER\n\n7\n4\n6\n0\n10\n\n\nAUSTON.MATTHEWS\n\n6\n3\n1\n2\n6\n\n\nSIDNEY.CROSBY\n\n6\n3\n1\n3\n7\n\n\nJOHN.TAVARES\n\n7\n4\n2\n1\n7\n\n\nLEON.DRAISAITL\n\n7\n3\n4\n2\n9\n\n\n\n\n\n\nThe real problem here is that Colin was interested in using a black background for his table. Let’s see what that looks like. Here we can see that the player background adds a lot of unnecessary white to our otherwise nice looking black table.\n\nskater_game_score %>% \n  slice(1:10) %>%\n  select(player, headshot_url, games:pts)%>% \n  gt() %>% \n  text_transform(\n    locations = cells_body(vars(headshot_url)),\n    fn = function(x){\n      web_image(url = x)\n    }\n  ) %>% \n  tab_options(\n    table.background.color = \"black\"\n  )\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\nplayer\n      headshot_url\n      games\n      g\n      a1\n      a2\n      pts\n    \n\n\nCONNOR.MCDAVID\n\n7\n4\n4\n2\n10\n\n\nNATHAN.MACKINNON\n\n6\n2\n5\n1\n8\n\n\nMIKKO.RANTANEN\n\n6\n5\n1\n1\n7\n\n\nANZE.KOPITAR\n\n6\n1\n6\n3\n10\n\n\nTYLER.TOFFOLI\n\n6\n5\n1\n2\n8\n\n\nMITCH.MARNER\n\n7\n4\n6\n0\n10\n\n\nAUSTON.MATTHEWS\n\n6\n3\n1\n2\n6\n\n\nSIDNEY.CROSBY\n\n6\n3\n1\n3\n7\n\n\nJOHN.TAVARES\n\n7\n4\n2\n1\n7\n\n\nLEON.DRAISAITL\n\n7\n3\n4\n2\n9"
  },
  {
    "objectID": "posts/2021-01-28-removing-image-backgrounds-with-magick/index.html#clean-the-images",
    "href": "posts/2021-01-28-removing-image-backgrounds-with-magick/index.html#clean-the-images",
    "title": "Removing image backgrounds with magick",
    "section": "Clean the images",
    "text": "Clean the images\nSo our goal is to remove the white background and turn it transparent. There are 3 steps here:\n\nExtract the image name\n\nOptionally trim extra whitespace from the images\n\nTurn the background white into transparent and save to disk\n\nExtract the image name\nWe have a url that points at a player headshot. An example is:\nhttps://cms.nhl.bamgrid.com/images/headshots/current/168x168/8478402.jpg\nWhich returns:\n\nNow, we only need the image name, not the URL. We can remove the extra “fluff” around the image name with regex + stringr::str_replace() or base::gsub().\nNow… if you’re anything like me, the below regex kind of looks like gibberish.\n\nex_url <- \"https://cms.nhl.bamgrid.com/images/headshots/current/168x168/8478402.jpg\"\n\nstr_replace(ex_url, \".*[/]([^.]+)[.].*\", \"\\\\1\")\n\n[1] \"8478402\"\n\n\nIf you want to see some explanations for the regex, see the details tag below.\n\nFun aside on regex\nThis regex code: .*[/]([^.]+)[.].* gives us the following explanation at regex101.com\n\n\n.* matches any character (except for line terminators)\n\n\n* Quantifier — Matches between zero and unlimited times, as many times as possible, giving back as needed (greedy)\nThis basically finds everything up to the next portion\n\n\n\nMatch a single character present in the list below [/]\n\n\n/ matches the character / literally (case sensitive)\nThis finds a literal / and with the previous code (.*) all the stuff before it\n\n\n\n1st Capturing Group ([^.]+)\n\nMatch a single character not present in the list below [^.]+\n\n\n+ Quantifier — Matches between one and unlimited times, as many times as possible, giving back as needed (greedy)\n\n. matches the character . literally (case sensitive)\n\n\nA capture group allows us to reference this portion later (with \\\\1)\n\n\n\nMatch a single character present in the list below [.]\n\n\n. matches the character . literally (case sensitive)\nFind the . and then anything after the .\n\n\n\n\n.* matches any character (except for line terminators)\n\n\n* Quantifier — Matches between zero and unlimited times, as many times as possible, giving back as needed (greedy)\n\n\n\nWe can see the capture group via str_match(), this will separate out the full match from the capture group.\n\nstr_match(ex_url, \".*[/]([^.]+)[.].*\")\n\n     [,1]                                                                      \n[1,] \"https://cms.nhl.bamgrid.com/images/headshots/current/168x168/8478402.jpg\"\n     [,2]     \n[1,] \"8478402\"\n\n\nNote that this could actually be much simpler to fix…just remove the static portions!\n\nex_url %>% \n  str_remove(\"https://cms.nhl.bamgrid.com/images/headshots/current/168x168/\") %>% \n  str_remove(\".jpg\")\n\n[1] \"8478402\"\n\n\nTrim the image and remove background\nWe can now trim the image if necessary and turn the background “white” into transparent. Note we’re using image_fill() here instead of simply image_background() which would replace ALL the white in the image with transparency.\n\n\nfuzz: relative color distance (value between 0 and 100) to be considered similar in the filling algorithm\n\n\nrefcolor = \"white\": the reference color that we’re replacing\n\n\ncolor = \"transparent\": the replacement of white with transparent\n\n\npoint = \"+1+1\": The location where we start “filling” or flooding the image with replacement, where '1+1' indicates 1 pixel in from the top left\n\n\n# clean image and write to disk\nclean_img_transparent <- function(img_url, trim = FALSE){\n  \n  # find the name of the img and extract it\n  img_name <- str_replace(img_url, \".*[/]([^.]+)[.].*\", \"\\\\1\")\n  \n  # some images need to be trimmed\n  trim_area <- if(isTRUE(trim)){\n    geometry_area(0, 0, 0, 10)\n  } else {\n    geometry_area(0, 0, 0, 0)\n  }\n  \n  img_url %>% \n    image_read() %>% \n    image_crop(geometry = trim_area) %>% \n    image_fill(\n      color = \"transparent\", \n      refcolor = \"white\", \n      fuzz = 4,\n      point = \"+1+1\" # start at top left 1 pixel in\n      ) \n}\n\nWe can test the function with and without trimming, then stack them next to each other. I will use image_ggplot() to “show” the image in this RMarkdown blog, but interactively you could remove that as it prints to the R Console.\n\nimg_ex <- clean_img_transparent(ex_url)\nimg_ex_trim <- clean_img_transparent(ex_url, trim = TRUE) \n\nc(img_ex, img_ex_trim) %>% \n  image_append() %>% \n  image_ggplot()\n\n\n\n\nThis looks great, but the for the last portion we’ll need to write to disk. It doesn’t really “look” any different, but the whitepspace around the player image is now “transparent”.\nWe could see this more clearly by replacing with a different color. Note that again if you just used image_transparent() as I did in a previous version of this post you’d “lose” some white details in the player’s jersey/sweater.\n\nex_url %>% \n    image_read() %>% \n    image_crop(geometry = geometry_area(0, 0, 0, 10)) %>% \n    image_fill(\n      color = \"green\", \n      refcolor = \"white\", \n      fuzz = 4,\n      point = \"+1+1\" # start at top left 1 pixel in\n      ) %>% \n  image_ggplot()\n\n\n\n\nWrite to disk\nWe can now use image_write() to write the image to disk so it can be used with gt::local_image(). We’ll add that to our function.\n\n# clean image and write to disk\nclean_img_transparent <- function(img_url, trim = FALSE){\n  \n  # find the name of the img and extract it\n  img_name <- str_replace(img_url, \".*[/]([^.]+)[.].*\", \"\\\\1\")\n  \n  # some images need to be trimmed\n  trim_area <- if(isTRUE(trim)){\n    geometry_area(0, 0, 0, 10)\n  } else {\n    geometry_area(0, 0, 0, 0)\n  }\n  \n  img_url %>% \n    image_read() %>% \n    image_crop(geometry = trim_area) %>% \n    image_fill(\n      color = \"transparent\", \n      refcolor = \"white\", \n      fuzz = 4,\n      point = \"+1+1\"\n      ) %>% \n    image_write(path = paste0(img_name, \".png\"), format = \"png\")\n}"
  },
  {
    "objectID": "posts/2021-01-28-removing-image-backgrounds-with-magick/index.html#logo-fill",
    "href": "posts/2021-01-28-removing-image-backgrounds-with-magick/index.html#logo-fill",
    "title": "Removing image backgrounds with magick",
    "section": "Logo Fill",
    "text": "Logo Fill\nWe can use a logo with a lot of whitespace, to play around with.\n\nlogo_url  <- \"http://content.sportslogos.net/logos/1/16/thumbs/124.gif\"                     \n\nraw_logo <- logo_url %>%\n  image_read() \n\nraw_logo %>%\n  image_ggplot()\n\n\n\n\nFor our steps we’re going to fill (basically flood) in the white space around the logo with green. Now because some logos (like the Avalanche) have areas that can’t get flooded with color in one path, I’m going to flood at each corner (top left, top right, bottom left, bottom right). For our real usage, we’re going to convert this “green” space to transparent instead.\n\nimg_filled <- raw_logo %>% \n    image_fill(\"green\", \"+1+1\", fuzz = 50, refcolor = \"white\") %>% \n    image_fill(\"green\", \"+140+1\", fuzz = 50, refcolor = \"white\") %>% \n    image_fill(\"green\", \"+1+99\", fuzz = 50, refcolor = \"white\") %>% \n    image_fill(\"green\", \"+140+99\", fuzz = 50, refcolor = \"white\")\n\nimg_filled %>% \n  image_ggplot()\n\n\n\nimg_filled <- raw_logo %>% \n    image_fill(\"transparent\", \"+1+1\", fuzz = 50, refcolor = \"white\") %>% \n    image_fill(\"transparent\", \"+140+1\", fuzz = 50, refcolor = \"white\") %>% \n    image_fill(\"transparent\", \"+1+99\", fuzz = 50, refcolor = \"white\") %>% \n    image_fill(\"transparent\", \"+140+99\", fuzz = 50, refcolor = \"white\")"
  },
  {
    "objectID": "posts/2021-01-28-removing-image-backgrounds-with-magick/index.html#logo-edges-and-mask",
    "href": "posts/2021-01-28-removing-image-backgrounds-with-magick/index.html#logo-edges-and-mask",
    "title": "Removing image backgrounds with magick",
    "section": "Logo edges and mask",
    "text": "Logo edges and mask\nNow that we have a transparency around the logo, we can take that ‘opacity’ channel and extract everything but that.\n\nimg_filled %>% \n    image_channel(\"Opacity\") %>% \n    image_convert(matte=FALSE) %>% \n  image_ggplot()\n\n\n\n\nNow to create a proper “mask” that we can apply to the image, we can negate this and apply a gentle blur to make the edges not as “sharp” against the background.\n\nlogo_mask <- img_filled %>% \n    image_channel(\"Opacity\") %>% \n    image_convert(matte=FALSE) %>% \n    image_negate() %>% \n    image_blur()\n\nlogo_mask %>% \n  image_ggplot()\n\n\n\n\nThis looks great as a mask! Note, that you can’t really “see” the mask here since it’s really just affecting the whitespace around the logo.\n\nimage_composite(raw_logo, logo_mask, operator = \"CopyOpacity\") %>% \n  image_ggplot()"
  },
  {
    "objectID": "posts/2021-01-28-removing-image-backgrounds-with-magick/index.html#function-applied",
    "href": "posts/2021-01-28-removing-image-backgrounds-with-magick/index.html#function-applied",
    "title": "Removing image backgrounds with magick",
    "section": "Function applied",
    "text": "Function applied\nWe can convert this to a function just like we did above. We’re getting the name, then reading in the image from a url, applying our fills, converting to transparent, flipping the image as a mask, and then applying our blur. Once we apply the mask we’ll write it back to disk.\n\nclean_logo_transparent <- function(img_url) {\n  \n  # find the name of the img and extract it\n  img_name <- str_replace(img_url, \".*[/]([^.]+)[.].*\", \"\\\\1\")\n\n  raw_img <- img_url %>%\n    image_read() %>% \n    image_convert(\"PNG\")\n  \n  img_mask <- raw_img  %>% \n    image_fill(\"transparent\", \"+1+1\", fuzz = 2, refcolor = \"white\") %>% \n    image_fill(\"transparent\", \"+1+99\", fuzz = 2, refcolor = \"white\") %>% \n    image_fill(\"transparent\", \"+140+1\", fuzz = 2, refcolor = \"white\") %>% \n    image_fill(\"transparent\", \"+140+99\", fuzz = 2, refcolor = \"white\") %>% \n    image_channel(\"Opacity\") %>%\n    image_convert(matte=FALSE) %>%\n    image_negate() %>%\n    image_blur()\n  \n  \n  image_composite(raw_img, img_mask, operator = \"CopyOpacity\") %>%\n    image_write(paste0(img_name, \".png\"))\n}\n\nOnce again, we can use purrr::pwalk() to write out the images to disk in bulk.\n\nskater_game_score %>% \n  slice(1:10) %>%\n  select(img_url = logo) %>% \n  filter(str_detect(img_url, pattern = \"NA.jpg\", negate = TRUE)) %>% \n  pwalk(clean_logo_transparent)"
  },
  {
    "objectID": "posts/2021-01-28-removing-image-backgrounds-with-magick/index.html#put-in-a-table",
    "href": "posts/2021-01-28-removing-image-backgrounds-with-magick/index.html#put-in-a-table",
    "title": "Removing image backgrounds with magick",
    "section": "Put in a table",
    "text": "Put in a table\nOur code here is again just a repeat of what we did above. This turns out remarkably nice!\n\nskater_game_score %>% \n  slice(1:10) %>%\n  mutate(\n    img_name = str_replace(logo, \".*[/]([^.]+)[.].*\", \"\\\\1\"),\n    img_name = paste0(img_name, \".png\"),\n    img_name = map(img_name, local_image),\n    img_name = map(img_name, ~html(as.character(.x)))\n  ) %>% \n  select(player, img_name, games:pts) %>% \n  gt() %>% \n  tab_options(\n    table.background.color = \"black\"\n  ) \n\n\n\n\n\n\nplayer\n      img_name\n      games\n      g\n      a1\n      a2\n      pts\n    \n\n\nCONNOR.MCDAVID\n\n7\n4\n4\n2\n10\n\n\nNATHAN.MACKINNON\n\n6\n2\n5\n1\n8\n\n\nMIKKO.RANTANEN\n\n6\n5\n1\n1\n7\n\n\nANZE.KOPITAR\n\n6\n1\n6\n3\n10\n\n\nTYLER.TOFFOLI\n\n6\n5\n1\n2\n8\n\n\nMITCH.MARNER\n\n7\n4\n6\n0\n10\n\n\nAUSTON.MATTHEWS\n\n6\n3\n1\n2\n6\n\n\nSIDNEY.CROSBY\n\n6\n3\n1\n3\n7\n\n\nJOHN.TAVARES\n\n7\n4\n2\n1\n7\n\n\nLEON.DRAISAITL\n\n7\n3\n4\n2\n9"
  },
  {
    "objectID": "posts/2021-01-28-removing-image-backgrounds-with-magick/index.html#put-in-a-table-1",
    "href": "posts/2021-01-28-removing-image-backgrounds-with-magick/index.html#put-in-a-table-1",
    "title": "Removing image backgrounds with magick",
    "section": "Put in a table",
    "text": "Put in a table\nOur code here is again just a repeat of what we did above. This turns out remarkably nice!\n\nskater_game_score %>% \n  slice(1:10) %>%\n  mutate(\n    img_name = str_replace(logo, \".*[/]([^.]+)[.].*\", \"\\\\1\"),\n    img_name = paste0(img_name, \".png\"),\n    img_name = map(img_name, local_image),\n    img_name = map(img_name, ~html(as.character(.x)))\n  ) %>% \n  select(player, img_name, games:pts) %>% \n  gt() %>% \n  tab_options(\n    table.background.color = \"black\"\n  ) \n\n\n\n\n\n\nplayer\n      img_name\n      games\n      g\n      a1\n      a2\n      pts\n    \n\n\nCONNOR.MCDAVID\n\n7\n4\n4\n2\n10\n\n\nNATHAN.MACKINNON\n\n6\n2\n5\n1\n8\n\n\nMIKKO.RANTANEN\n\n6\n5\n1\n1\n7\n\n\nANZE.KOPITAR\n\n6\n1\n6\n3\n10\n\n\nTYLER.TOFFOLI\n\n6\n5\n1\n2\n8\n\n\nMITCH.MARNER\n\n7\n4\n6\n0\n10\n\n\nAUSTON.MATTHEWS\n\n6\n3\n1\n2\n6\n\n\nSIDNEY.CROSBY\n\n6\n3\n1\n3\n7\n\n\nJOHN.TAVARES\n\n7\n4\n2\n1\n7\n\n\nLEON.DRAISAITL\n\n7\n3\n4\n2\n9\n\n\n\n\n\n\nThanks to Colin for sharing this problem, and for Deemah pointing me to his blogpost!\n\n\n\n\n\n\nExpand for Session Info\n\n\n\n\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.0 (2022-04-22)\n os       macOS Monterey 12.2.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       America/Chicago\n date     2022-04-28\n pandoc   2.18 @ /Applications/RStudio.app/Contents/MacOS/quarto/bin/tools/ (via rmarkdown)\n quarto   0.9.294 @ /usr/local/bin/quarto\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version    date (UTC) lib source\n dplyr       * 1.0.8      2022-02-08 [1] CRAN (R 4.2.0)\n forcats     * 0.5.1      2021-01-27 [1] CRAN (R 4.2.0)\n ggplot2     * 3.3.5      2021-06-25 [1] CRAN (R 4.2.0)\n gt          * 0.5.0.9000 2022-04-27 [1] Github (rstudio/gt@0d4c83d)\n magick      * 2.7.3      2021-08-18 [1] CRAN (R 4.2.0)\n purrr       * 0.3.4      2020-04-17 [1] CRAN (R 4.2.0)\n readr       * 2.1.2      2022-01-30 [1] CRAN (R 4.2.0)\n sessioninfo * 1.2.2      2021-12-06 [1] CRAN (R 4.2.0)\n stringr     * 1.4.0      2019-02-10 [1] CRAN (R 4.2.0)\n tibble      * 3.1.6      2021-11-07 [1] CRAN (R 4.2.0)\n tidyr       * 1.2.0      2022-02-01 [1] CRAN (R 4.2.0)\n tidyverse   * 1.3.1      2021-04-15 [1] CRAN (R 4.2.0)\n\n [1] /Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/library\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "The MockUp",
    "section": "",
    "text": "Want to support my blog? \n\n\n\n\n\n\n\n\n\n\n   \n     \n     Order By\nDefault\n\n          Title\n        \n\n          Date - Oldest\n        \n\n          Date - Newest\n        \n\n\n\n\n\n \n\n\n\n\nRolling summaries with {slider} in R\n\n\n\n\n\nSlip and slide with the tidyverse\n\n\n\n\n\n\n2022-11-16\n\n\n6 min\n\n\n\n\n\n\n \n\n\n\n\nUse R to generate a Quarto blogpost\n\n\n\n\n\nThe {cli} and {fs} packages make life easy!\n\n\n\n\n\n\n2022-11-08\n\n\n10 min\n\n\n\n\n\n\n \n\n\n\n\nAdd a semi-transparent overlay to an image with {magick}\n\n\n\n\n\nBecause who has time for CSS and gradients?\n\n\n\n\n\n\n2022-06-22\n\n\n3 min\n\n\n\n\n\n\n \n\n\n\n\nBeautiful tables in R with gtExtras\n\n\n\n\n\nMerging static tables with graphics is a powerful combo\n\n\n\n\n\n\n2022-06-13\n\n\n13 min\n\n\n\n\n\n\n \n\n\n\n\nAdding session info to blog posts\n\n\n\n\n\nA snapshot of your code state\n\n\n\n\n\n\n2022-04-18\n\n\n4 min\n\n\n\n\n\n\n \n\n\n\n\nDisplaying verbatim code chunks in RMarkdown and Xaringan presentations\n\n\n\n\n\nBecause the best way to teach RMarkdown is with RMarkdown.\n\n\n\n\n\n\n2021-08-27\n\n\n6 min\n\n\n\n\n\n\n \n\n\n\n\nReminder to test with a reprex\n\n\n\n\n\n“It’s basically the rubber duck in disguise” - Jenny Bryan.\n\n\n\n\n\n\n2021-07-28\n\n\n10 min\n\n\n\n\n\n\n \n\n\n\n\nThree years of TidyTuesday\n\n\n\n\n\nThe future holds a deeper focus on inclusivity.\n\n\n\n\n\n\n2021-04-01\n\n\n17 min\n\n\n\n\n\n\n \n\n\n\n\nIncluding and meta tagging extra content in a distill blog\n\n\n\n\n\nCollect and organize all your content, and then customize how it appears on social media.\n\n\n\n\n\n\n2021-03-21\n\n\n9 min\n\n\n\n\n\n\n \n\n\n\n\nCreating a custom gt function for aligning first-row text and testing it with testthat\n\n\n\n\n\nCreating and testing your own functions is fun!\n\n\n\n\n\n\n2021-03-07\n\n\n15 min\n\n\n\n\n\n\n \n\n\n\n\nJoins vs case whens - speed and memory tradeoffs\n\n\n\n\n\nSpoiler - joins are fastest, and can be easy to prep!\n\n\n\n\n\n\n2021-02-13\n\n\n27 min\n\n\n\n\n\n\n \n\n\n\n\nRemoving image backgrounds with magick\n\n\n\n\n\nTables with dark backgrounds deserve transparent logos!\n\n\n\n\n\n\n2021-01-28\n\n\n13 min\n\n\n\n\n\n\n \n\n\n\n\nReading tables from images with magick\n\n\n\n\n\nmagick is an R package for manipulating images in R\n\n\n\n\n\n\n2021-01-18\n\n\n18 min\n\n\n\n\n\n\n \n\n\n\n\n2020 in Review\n\n\n\n\n\nSurviving a pandemic at home.\n\n\n\n\n\n\n2020-12-31\n\n\n9 min\n\n\n\n\n\n\n \n\n\n\n\nCreating and using custom ggplot2 themes\n\n\n\n\n\nThe best way to make each plot your own.\n\n\n\n\n\n\n2020-12-26\n\n\n39 min\n\n\n\n\n\n\n \n\n\n\n\nExtracting JSON data from websites and public APIs with R\n\n\n\n\n\ntidyr + jsonlite are magical.\n\n\n\n\n\n\n2020-12-13\n\n\n26 min\n\n\n\n\n\n\n \n\n\n\n\nBullet Chart Variants in R\n\n\n\n\n\nEfficient display of several measures at once.\n\n\n\n\n\n\n2020-11-29\n\n\n19 min\n\n\n\n\n\n\n \n\n\n\n\nEmbedding custom HTML in gt tables\n\n\n\n\n\nHTML is basically a superpower.\n\n\n\n\n\n\n2020-10-31\n\n\n29 min\n\n\n\n\n\n\n \n\n\n\n\nPlotting Points as Images in ggplot\n\n\n\n\n\nTrials and tribulations of the various strategies.\n\n\n\n\n\n\n2020-10-11\n\n\n18 min\n\n\n\n\n\n\n \n\n\n\n\nFunctions and Themes for gt tables\n\n\n\n\n\nSave time and effort in making beautiful tables\n\n\n\n\n\n\n2020-09-28\n\n\n21 min\n\n\n\n\n\n\n \n\n\n\n\n10+ Guidelines for Better Tables in R\n\n\n\n\n\nMake tables people ACTUALLY want to read.\n\n\n\n\n\n\n2020-09-04\n\n\n60 min\n\n\n\n\n\n\n \n\n\n\n\nHeatmaps in ggplot2\n\n\n\n\n\nIt’s more than just a passing fad.\n\n\n\n\n\n\n2020-08-28\n\n\n22 min\n\n\n\n\n\n\n \n\n\n\n\nBuilding a blog with distill\n\n\n\n\n\nI love simplicity.\n\n\n\n\n\n\n2020-08-01\n\n\n12 min\n\n\n\n\n\n\n \n\n\n\n\nA bar chart 5 ways in ggplot2\n\n\n\n\n\nAndy, Tom, and ggplot2 walk into a bar…\n\n\n\n\n\n\n2020-08-01\n\n\n8 min\n\n\n\n\n\n\n \n\n\n\n\nMeta RMarkdown - Taxonomy and Use cases\n\n\n\n\n\nA meta collection of all things R Markdown.\n\n\n\n\n\n\n2020-07-25\n\n\n12 min\n\n\n\n\n\n\n \n\n\n\n\nClient-side interactivity - do more with Crosstalk\n\n\n\n\n\nBecause sharing data is caring\n\n\n\n\n\n\n2020-05-29\n\n\n16 min\n\n\n\n\n\n\n \n\n\n\n\nEasily parsing JSON in R with jsonlite and purrr\n\n\n\n\n\nIt’s turtles all the way down…\n\n\n\n\n\n\n2020-05-22\n\n\n15 min\n\n\n\n\n\n\n \n\n\n\n\ngt - a (G)rammar of (T)ables\n\n\n\n\n\nNot to be confused with a Game of Thrones\n\n\n\n\n\n\n2020-05-18\n\n\n18 min\n\n\n\n\n\n\n \n\n\n\n\nreactable - An Interactive Tables Guide\n\n\n\n\n\nPart 2: How to draw the rest of the owl.\n\n\n\n\n\n\n2020-05-15\n\n\n18 min\n\n\n\n\n\n\n \n\n\n\n\nQB Salaries vs Playoff Appearances\n\n\n\n\n\nInteractive tables make bad takes more fun.\n\n\n\n\n\n\n2020-05-13\n\n\n8 min\n\n\n\n\n\n\n \n\n\n\n\nFlipping tibbles for many models\n\n\n\n\n\nPivoting data from wide to long to run many models at once\n\n\n\n\n\n\n2020-05-01\n\n\n7 min\n\n\n\n\n\n\n \n\n\n\n\nBigger, nflfastR, dbplyr\n\n\n\n\n\nDoing more with dplyr and SQL\n\n\n\n\n\n\n2020-04-28\n\n\n14 min\n\n\n\n\n\n\n \n\n\n\n\nBeer and pdftools - a vignette\n\n\n\n\n\nA guide to extracting tables from many PDFs using the pdftools package\n\n\n\n\n\n\n2020-04-04\n\n\n17 min\n\n\n\n\n\n\n \n\n\n\n\nCrossing 10,000 - Tidy simulation\n\n\n\n\n\nTidy simulation with dice rolls\n\n\n\n\n\n\n2020-04-03\n\n\n10 min\n\n\n\n\n\n\n \n\n\n\n\nAdd a logo to your plot\n\n\n\n\n\nPut a bird on it - Portlandia.\n\n\n\n\n\n\n2019-01-09\n\n\n7 min\n\n\n\n\n\n\n \n\n\n\n\nTidyTuesday enhancements\n\n\n\n\n\nMaking #TidyTuesday better.\n\n\n\n\n\n\n2019-01-02\n\n\n9 min\n\n\n\n\n\n\n \n\n\n\n\nTidyTuesday\n\n\n\n\n\nA weekly social data project in R\n\n\n\n\n\n\n2018-04-05\n\n\n9 min\n\n\n\n\n\n\n \n\n\n\n\nFunctional Progamming in R with purrr\n\n\n\n\n\nMinimizing repetition with further replication\n\n\n\n\n\n\n2018-03-18\n\n\n7 min\n\n\n\n\n\n\n \n\n\n\n\nA Gentle Guide to Tidy Statistics in R\n\n\n\n\n\nWorking your way through a basic analysis\n\n\n\n\n\n\n2018-03-16\n\n\n23 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "readme.html",
    "href": "readme.html",
    "title": "The MockUp",
    "section": "",
    "text": "This is my personal blog, you can find it at TheMockup.blog."
  },
  {
    "objectID": "about.html#current-state",
    "href": "about.html#current-state",
    "title": "Tom Mock",
    "section": "Current State",
    "text": "Current State\nI fell in love with R and data science through my graduate research, using R and RStudio to wrangle, analyze, model, and visualize my data. I became passionate about growing the R community, and founded #TidyTuesday to help newcomers and seasoned vets improve their Tidyverse skills.\nI am the Customer Enablement Lead at Posit, helping our customers be as successful as possible with RStudio software in their environment.\nIn my home town of San Antonio, my wife and I run on the local trails, play with our Boston Terrier “Howard”, spend lots of time with our local families, grill/smoke plenty of meat, and are always on the lookout for great new food, especially churros."
  },
  {
    "objectID": "about.html#contact",
    "href": "about.html#contact",
    "title": "Tom Mock",
    "section": "Contact",
    "text": "Contact\nYou should definitely just tweet @ me @thomas_mock."
  },
  {
    "objectID": "static/resources/gt-cookbook.html#introduction",
    "href": "static/resources/gt-cookbook.html#introduction",
    "title": "gt cookbook",
    "section": "Introduction",
    "text": "Introduction\nThis cookbook attempts to walk through many of the example usecases for gt, and provide useful commentary around the use of the various gt functions. The full gt documentation has other more succinct examples and full function arguments.\nFor advanced use cases, make sure to check out the Advanced Cookbook"
  },
  {
    "objectID": "static/resources/gt-cookbook.html#basic-usage",
    "href": "static/resources/gt-cookbook.html#basic-usage",
    "title": "gt cookbook",
    "section": "Basic Usage",
    "text": "Basic Usage\nTo create a gt table, use gt() on a data frame.\n\nlibrary(gt)\nlibrary(dplyr)\ngt(head(mtcars))\n\n\n\n\n\n\nmpg\n      cyl\n      disp\n      hp\n      drat\n      wt\n      qsec\n      vs\n      am\n      gear\n      carb\n    \n\n\n21.0\n6\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\n21.0\n6\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\n22.8\n4\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\n21.4\n6\n258\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\n18.7\n8\n360\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\n18.1\n6\n225\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\n\n\n\n# pipe also works just fine!\nhead(mtcars) %>% \n  gt()\n\n\n\n\n\n\nmpg\n      cyl\n      disp\n      hp\n      drat\n      wt\n      qsec\n      vs\n      am\n      gear\n      carb\n    \n\n\n21.0\n6\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\n21.0\n6\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\n22.8\n4\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\n21.4\n6\n258\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\n18.7\n8\n360\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\n18.1\n6\n225\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\n\n\n\n\nPreview long table\nSometimes you may want to see just a small portion of your input data. We can use gt_preview() in place of gt() to get the first x rows of data and the last y rows of data (which can be set by the top_n and bottom_n arguments).\n\ngtcars %>%\n  dplyr::select(mfr, model, year) %>%\n  gt_preview()\n\n\n\n\n\n\n\n      mfr\n      model\n      year\n    \n\n\n1\nFord\nGT\n2017\n\n\n2\nFerrari\n458 Speciale\n2015\n\n\n3\nFerrari\n458 Spider\n2015\n\n\n4\nFerrari\n458 Italia\n2014\n\n\n5\nFerrari\n488 GTB\n2016\n\n\n6..46\n\n\n\n\n\n47\nRolls-Royce\nWraith\n2016"
  },
  {
    "objectID": "static/resources/gt-cookbook.html#save-output",
    "href": "static/resources/gt-cookbook.html#save-output",
    "title": "gt cookbook",
    "section": "Save output",
    "text": "Save output\nWhile the vast majority of the time you will simply execute the code inside RMarkdown or Shiny and get your beautiful table back, you can explicitly save the output to various different formats.\ngtsave() is the function, and it takes a gt table object and a filename.\n\nThe gtsave() function makes it easy to save a gt table to a file. The function guesses the file type by the extension provided in the output filename, producing either an HTML, PDF, PNG, LaTeX, or RTF file.\n\nThe most traditional format is HTML, which can be embedded into an existing website (ie Wordpress or a CMS), but the other formats (PDF, LaTex, RTF, PNG) have other use cases.\nPDF can be combined with other PDF formats, LaTeX can be placed into an existing doc, RTF can be copied into Word, Excel, or Powerpoint, and PNG can be used to post images of tables to social media like Twitter.\nRaw output\nThere are also functions for as_raw_html() or as_rtf() which allow you to get the raw output in the active R session. These are useful but seldom actually used unless for specific reasons. Again, in most examples you will simply call the gt code in your RMarkdown or Shiny app."
  },
  {
    "objectID": "static/resources/gt-cookbook.html#grouping-and-summary-rows",
    "href": "static/resources/gt-cookbook.html#grouping-and-summary-rows",
    "title": "gt cookbook",
    "section": "Grouping and Summary Rows",
    "text": "Grouping and Summary Rows\nYou can group rows in a table by specifying one or more columns in groupname_col:\n\nhead(mtcars) %>% \n  mutate(cyl = paste(cyl, \"Cylinders\")) %>% \n  gt(groupname_col = \"cyl\")\n\n\n\n\n\n\nmpg\n      disp\n      hp\n      drat\n      wt\n      qsec\n      vs\n      am\n      gear\n      carb\n    \n\n\n6 Cylinders\n    \n\n21.0\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\n21.0\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\n21.4\n258\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\n18.1\n225\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\n4 Cylinders\n    \n\n22.8\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\n8 Cylinders\n    \n\n18.7\n360\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\n\n\n\n\nOr by simply using dplyr::group_by()\n\nhead(mtcars) %>% \n  mutate(cyl = paste(cyl, \"Cylinders\")) %>% \n  group_by(cyl) %>% \n  gt()\n\n\n\n\n\n\nmpg\n      disp\n      hp\n      drat\n      wt\n      qsec\n      vs\n      am\n      gear\n      carb\n    \n\n\n6 Cylinders\n    \n\n21.0\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\n21.0\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\n21.4\n258\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\n18.1\n225\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\n4 Cylinders\n    \n\n22.8\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\n8 Cylinders\n    \n\n18.7\n360\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\n\n\n\n\nCustom groups\nYou can also create custom groups with gt::tab_row_group(). This is typically useful for creating your own groups within gt itself, and it can include specific rows based on a logical statement (ie hp > 600).\n\ngtcars %>%\n  dplyr::select(model, year, hp, trq) %>%\n  head(8) %>% \n  gt() %>% \n  tab_row_group(\n    group = \"powerful\",\n    rows = hp <= 600\n  ) %>%\n  tab_row_group(\n    group = \"super powerful\",\n    rows = hp > 600\n  )\n\n\n\n\n\n\nmodel\n      year\n      hp\n      trq\n    \n\n\nsuper powerful\n    \n\nGT\n2017\n647\n550\n\n\n488 GTB\n2016\n661\n561\n\n\nGTC4Lusso\n2017\n680\n514\n\n\nFF\n2015\n652\n504\n\n\npowerful\n    \n\n458 Speciale\n2015\n597\n398\n\n\n458 Spider\n2015\n562\n398\n\n\n458 Italia\n2014\n562\n398\n\n\nCalifornia\n2015\n553\n557\n\n\n\n\n\n\nYou can also create meta-groups of a grouping category this way.\n\ngtcars %>% \n  dplyr::select(mfr:hp, mpg_c, mpg_h) %>% \n  dplyr::filter(mfr %in% c(\"Ford\", \"Dodge\", \"Chevrolet\", \"Nissan\", \"Acura\")) %>% \n  gt() %>% \n  tab_row_group(\n    group = \"Japanese\",\n    rows = mfr %in% c(\"Nissan\", \"Acura\")\n  ) %>% \n  tab_row_group(\n    group = \"American\",\n    rows = mfr %in% c(\"Ford\", \"Dodge\", \"Chevrolet\")\n  )\n\n\n\n\n\n\nmfr\n      model\n      year\n      trim\n      bdy_style\n      hp\n      mpg_c\n      mpg_h\n    \n\n\nAmerican\n    \n\nFord\nGT\n2017\nBase Coupe\ncoupe\n647\n11\n18\n\n\nChevrolet\nCorvette\n2016\nZ06 Coupe\ncoupe\n650\n15\n22\n\n\nDodge\nViper\n2017\nGT Coupe\ncoupe\n645\n12\n19\n\n\nJapanese\n    \n\nAcura\nNSX\n2017\nBase Coupe\ncoupe\n573\n21\n22\n\n\nNissan\nGT-R\n2016\nPremium Coupe\ncoupe\n545\n16\n22\n\n\n\n\n\n\nRow names\nYou can also convert a column into table rownames and specify it in the original gt() call.\n\nhead(mtcars) %>% \n  mutate(cyl = paste(cyl, \"Cylinders\")) %>% \n  gt(rowname_col = \"cyl\")\n\n\n\n\n\n\n\n      mpg\n      disp\n      hp\n      drat\n      wt\n      qsec\n      vs\n      am\n      gear\n      carb\n    \n\n\n6 Cylinders\n21.0\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\n6 Cylinders\n21.0\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\n4 Cylinders\n22.8\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\n6 Cylinders\n21.4\n258\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\n8 Cylinders\n18.7\n360\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\n6 Cylinders\n18.1\n225\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\n\n\n\n\nIf you have a data.frame with rownames attached, you can use the rownames_to_stub argument to parse these properly.\n\nhead(mtcars) %>% \n  gt(rownames_to_stub = TRUE)\n\n\n\n\n\n\n\n      mpg\n      cyl\n      disp\n      hp\n      drat\n      wt\n      qsec\n      vs\n      am\n      gear\n      carb\n    \n\n\nMazda RX4\n21.0\n6\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\nMazda RX4 Wag\n21.0\n6\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\nDatsun 710\n22.8\n4\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\nHornet 4 Drive\n21.4\n6\n258\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\nHornet Sportabout\n18.7\n8\n360\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\nValiant\n18.1\n6\n225\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\n\n\n\n\nHowever, a tibble will drop rownames, so you can convert a data.frame’s existing rownames to a column with tibble::rownames_to_column(). gt will automatically use columns named rowname as a rowname stub.\n\nhead(mtcars) %>% \n  tibble::rownames_to_column() %>% \n  gt()\n\n\n\n\n\n\n\n      mpg\n      cyl\n      disp\n      hp\n      drat\n      wt\n      qsec\n      vs\n      am\n      gear\n      carb\n    \n\n\nMazda RX4\n21.0\n6\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\nMazda RX4 Wag\n21.0\n6\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\nDatsun 710\n22.8\n4\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\nHornet 4 Drive\n21.4\n6\n258\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\nHornet Sportabout\n18.7\n8\n360\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\nValiant\n18.1\n6\n225\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\n\n\n\n\nRownames and groups\nCombining rownames with groups can sometimes make the table easier to parse. Compare the two tables below:\n\n\n\nmtcars %>% \n  head() %>% \n  select(cyl, mpg:drat) %>% \n  mutate(cyl = paste(cyl, \"Cylinders\")) %>% \n  gt(groupname_col = \"cyl\")\n\n\n\n\n\n\nmpg\n      disp\n      hp\n      drat\n    \n\n\n6 Cylinders\n    \n\n21.0\n160\n110\n3.90\n\n\n21.0\n160\n110\n3.90\n\n\n21.4\n258\n110\n3.08\n\n\n18.1\n225\n105\n2.76\n\n\n4 Cylinders\n    \n\n22.8\n108\n93\n3.85\n\n\n8 Cylinders\n    \n\n18.7\n360\n175\n3.15\n\n\n\n\n\n\n\n\n\nhead(mtcars) %>% \n  select(cyl, mpg:drat) %>% \n  tibble::rownames_to_column() %>% \n  mutate(cyl = paste(cyl, \"Cylinders\")) %>% \n  gt(groupname_col = \"cyl\", rowname_col = \"rowname\")\n\n\n\n\n\n\n\n      mpg\n      disp\n      hp\n      drat\n    \n\n\n6 Cylinders\n    \n\nMazda RX4\n21.0\n160\n110\n3.90\n\n\nMazda RX4 Wag\n21.0\n160\n110\n3.90\n\n\nHornet 4 Drive\n21.4\n258\n110\n3.08\n\n\nValiant\n18.1\n225\n105\n2.76\n\n\n4 Cylinders\n    \n\nDatsun 710\n22.8\n108\n93\n3.85\n\n\n8 Cylinders\n    \n\nHornet Sportabout\n18.7\n360\n175\n3.15\n\n\n\n\n\n\n\n\nCreate blank rownames\nI typically will use a rowname column whenever I group data, but sometimes there may not be a “good” column to use here. You can pass in blank spaces to artificially move the group label to be presented closer to a “stub”.\n\nhead(mtcars) %>% \n  mutate(cyl = paste(cyl, \"Cylinders\")) %>% \n  mutate(blank_rowname = purrr::map(list(rep(\"&nbsp\", 8)), gt::html)) %>% \n  gt(rowname_col = \"blank_rowname\", groupname_col = \"cyl\")\n\n\n\n\n\n\n\n      mpg\n      disp\n      hp\n      drat\n      wt\n      qsec\n      vs\n      am\n      gear\n      carb\n    \n\n\n6 Cylinders\n    \n\n&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp\n21.0\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\n&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp\n21.0\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\n&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp\n21.4\n258\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\n&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp\n18.1\n225\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\n4 Cylinders\n    \n\n&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp\n22.8\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\n8 Cylinders\n    \n\n&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp\n18.7\n360\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\n\n\n\n\nSummary Rows\nWhen rows are grouped, you can create summary rows in a column using the summary_rows function:\n\nmtcars %>% \n  head(8) %>% \n  tibble::rownames_to_column(var = \"name\") %>%\n  mutate(cyl = paste(cyl, \"Cylinders\")) %>% \n  gt(groupname_col = \"cyl\", rowname_col = \"name\") %>% \n  summary_rows(\n    groups = TRUE,\n    fns = list(Average = ~mean(.))\n    )\n\n\n\n\n\n\n\n      mpg\n      disp\n      hp\n      drat\n      wt\n      qsec\n      vs\n      am\n      gear\n      carb\n    \n\n\n6 Cylinders\n    \n\nMazda RX4\n21.0\n160.0\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\nMazda RX4 Wag\n21.0\n160.0\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\nHornet 4 Drive\n21.4\n258.0\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\nValiant\n18.1\n225.0\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\nAverage\n20.38\n200.75\n108.75\n3.41\n3.04\n18.29\n0.50\n0.50\n3.50\n2.50\n\n\n4 Cylinders\n    \n\nDatsun 710\n22.8\n108.0\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\nMerc 240D\n24.4\n146.7\n62\n3.69\n3.190\n20.00\n1\n0\n4\n2\n\n\nAverage\n23.60\n127.35\n77.50\n3.77\n2.75\n19.30\n1.00\n0.50\n4.00\n1.50\n\n\n8 Cylinders\n    \n\nHornet Sportabout\n18.7\n360.0\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\nDuster 360\n14.3\n360.0\n245\n3.21\n3.570\n15.84\n0\n0\n3\n4\n\n\nAverage\n16.50\n360.00\n210.00\n3.18\n3.50\n16.43\n0.00\n0.00\n3.00\n3.00\n\n\n\n\n\n\nFurther customization of Summary Rows\nYou can pass additional summarization functions to the fns argument, optionally specify columns to apply the summary to, and apply a formatter to format the output.\n\nmtcars %>% \n  head(8) %>% \n  tibble::rownames_to_column(var = \"name\") %>%\n  mutate(cyl = paste(cyl, \"Cylinders\")) %>% \n  gt(groupname_col = \"cyl\", rowname_col = \"name\") %>% \n  summary_rows(\n    groups = TRUE,\n    columns = c(mpg, disp, hp),\n    fns = list(\n      min = ~min(.),\n      max = ~max(.),\n      avg = ~mean(.)\n      ),\n    formatter = fmt_number\n    )\n\n\n\n\n\n\n\n      mpg\n      disp\n      hp\n      drat\n      wt\n      qsec\n      vs\n      am\n      gear\n      carb\n    \n\n\n6 Cylinders\n    \n\nMazda RX4\n21.0\n160.0\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\nMazda RX4 Wag\n21.0\n160.0\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\nHornet 4 Drive\n21.4\n258.0\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\nValiant\n18.1\n225.0\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\nmin\n18.10\n160.00\n105.00\n—\n—\n—\n—\n—\n—\n—\n\n\nmax\n21.40\n258.00\n110.00\n—\n—\n—\n—\n—\n—\n—\n\n\navg\n20.38\n200.75\n108.75\n—\n—\n—\n—\n—\n—\n—\n\n\n4 Cylinders\n    \n\nDatsun 710\n22.8\n108.0\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\nMerc 240D\n24.4\n146.7\n62\n3.69\n3.190\n20.00\n1\n0\n4\n2\n\n\nmin\n22.80\n108.00\n62.00\n—\n—\n—\n—\n—\n—\n—\n\n\nmax\n24.40\n146.70\n93.00\n—\n—\n—\n—\n—\n—\n—\n\n\navg\n23.60\n127.35\n77.50\n—\n—\n—\n—\n—\n—\n—\n\n\n8 Cylinders\n    \n\nHornet Sportabout\n18.7\n360.0\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\nDuster 360\n14.3\n360.0\n245\n3.21\n3.570\n15.84\n0\n0\n3\n4\n\n\nmin\n14.30\n360.00\n175.00\n—\n—\n—\n—\n—\n—\n—\n\n\nmax\n18.70\n360.00\n245.00\n—\n—\n—\n—\n—\n—\n—\n\n\navg\n16.50\n360.00\n210.00\n—\n—\n—\n—\n—\n—\n—\n\n\n\n\n\n\nYou can use any of R’s built-in aggregate functions, or a custom function.\n# some examples\nsum()     # Sum of numbers\nmean()    # Mean of numbers\nmax()     # Maximum of numbers\nmin()     # Minimum of numbers\nmedian()  # Median of numbers\nsd()      # Standard Deviation of numbers\nOr a custom aggregate function: ::: {.cell}\nmode <- function(x) {\n  unique_var <- unique(x)\n  unique_var[which.max(tabulate(match(x, unique_var)))]\n}\n:::\nMultiple groups\nYou can supply multiple groups via dplyr::group_by(), which are then appended with a - separator.\n\nhead(mtcars, 8) %>% \n  tibble::rownames_to_column(var = \"name\") %>%\n  mutate(cyl = paste(cyl, \"Cylinders\")) %>% \n  group_by(cyl, gear) %>% \n  arrange(cyl) %>%\n  gt(rowname_col = \"name\") %>% \n  summary_rows(\n    groups = TRUE,\n    fns = list(Average = ~mean(.))\n    )\n\n\n\n\n\n\n\n      mpg\n      disp\n      hp\n      drat\n      wt\n      qsec\n      vs\n      am\n      carb\n    \n\n\n4 Cylinders - 4\n    \n\nDatsun 710\n22.8\n108.0\n93\n3.85\n2.320\n18.61\n1\n1\n1\n\n\nMerc 240D\n24.4\n146.7\n62\n3.69\n3.190\n20.00\n1\n0\n2\n\n\nAverage\n23.60\n127.35\n77.50\n3.77\n2.75\n19.30\n1.00\n0.50\n1.50\n\n\n6 Cylinders - 4\n    \n\nMazda RX4\n21.0\n160.0\n110\n3.90\n2.620\n16.46\n0\n1\n4\n\n\nMazda RX4 Wag\n21.0\n160.0\n110\n3.90\n2.875\n17.02\n0\n1\n4\n\n\nAverage\n21.00\n160.00\n110.00\n3.90\n2.75\n16.74\n0.00\n1.00\n4.00\n\n\n6 Cylinders - 3\n    \n\nHornet 4 Drive\n21.4\n258.0\n110\n3.08\n3.215\n19.44\n1\n0\n1\n\n\nValiant\n18.1\n225.0\n105\n2.76\n3.460\n20.22\n1\n0\n1\n\n\nAverage\n19.75\n241.50\n107.50\n2.92\n3.34\n19.83\n1.00\n0.00\n1.00\n\n\n8 Cylinders - 3\n    \n\nHornet Sportabout\n18.7\n360.0\n175\n3.15\n3.440\n17.02\n0\n0\n2\n\n\nDuster 360\n14.3\n360.0\n245\n3.21\n3.570\n15.84\n0\n0\n4\n\n\nAverage\n16.50\n360.00\n210.00\n3.18\n3.50\n16.43\n0.00\n0.00\n3.00\n\n\n\n\n\n\nGrand summary\nGrand summary rows incorporate all of the available data, regardless of whether some of the data are part of row groups.\n\nhead(mtcars, 8) %>% \n  tibble::rownames_to_column(var = \"name\") %>%\n  mutate(cyl = paste(cyl, \"Cylinders\")) %>% \n  gt(rowname_col = \"name\", groupname_col = \"cyl\") %>% \n  grand_summary_rows(fns = list(Average = ~mean(.)))\n\n\n\n\n\n\n\n      mpg\n      disp\n      hp\n      drat\n      wt\n      qsec\n      vs\n      am\n      gear\n      carb\n    \n\n\n6 Cylinders\n    \n\nMazda RX4\n21.0\n160.0\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\nMazda RX4 Wag\n21.0\n160.0\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\nHornet 4 Drive\n21.4\n258.0\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\nValiant\n18.1\n225.0\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\n4 Cylinders\n    \n\nDatsun 710\n22.8\n108.0\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\nMerc 240D\n24.4\n146.7\n62\n3.69\n3.190\n20.00\n1\n0\n4\n2\n\n\n8 Cylinders\n    \n\nHornet Sportabout\n18.7\n360.0\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\nDuster 360\n14.3\n360.0\n245\n3.21\n3.570\n15.84\n0\n0\n3\n4\n\n\nAverage\n20.21\n222.21\n126.25\n3.44\n3.09\n18.08\n0.50\n0.38\n3.50\n2.38"
  },
  {
    "objectID": "static/resources/gt-cookbook.html#column-formatting",
    "href": "static/resources/gt-cookbook.html#column-formatting",
    "title": "gt cookbook",
    "section": "Column Formatting",
    "text": "Column Formatting\nYou can format data in a column by using the various fmt_??? functions:\ninfo_date_style() # View a table with info on date styles\n\ninfo_time_style() # View a table with info on time styles\n\ninfo_currencies() # View a table with info on supported currencies\n\ninfo_locales()    # View a table with info on supported locales\nexibble\nThe exibble dataset is built into gt and has a lot of different formats to demo the specific fmt_??? functions.\n\ndplyr::glimpse(exibble)\n\nRows: 8\nColumns: 9\n$ num      <dbl> 1.111e-01, 2.222e+00, 3.333e+01, 4.444e+02, 5.550e+03, NA, 7.…\n$ char     <chr> \"apricot\", \"banana\", \"coconut\", \"durian\", NA, \"fig\", \"grapefr…\n$ fctr     <fct> one, two, three, four, five, six, seven, eight\n$ date     <chr> \"2015-01-15\", \"2015-02-15\", \"2015-03-15\", \"2015-04-15\", \"2015…\n$ time     <chr> \"13:35\", \"14:40\", \"15:45\", \"16:50\", \"17:55\", NA, \"19:10\", \"20…\n$ datetime <chr> \"2018-01-01 02:22\", \"2018-02-02 14:33\", \"2018-03-03 03:44\", \"…\n$ currency <dbl> 49.950, 17.950, 1.390, 65100.000, 1325.810, 13.255, NA, 0.440\n$ row      <chr> \"row_1\", \"row_2\", \"row_3\", \"row_4\", \"row_5\", \"row_6\", \"row_7\"…\n$ group    <chr> \"grp_a\", \"grp_a\", \"grp_a\", \"grp_a\", \"grp_b\", \"grp_b\", \"grp_b\"…\n\n\n\nexibble %>% \n  gt(rowname_col = \"row\", groupname_col = \"group\") %>% \n  fmt_number(columns = vars(num)) %>% \n  fmt_date(columns = vars(date)) %>% \n  fmt_time(columns = vars(time)) %>% \n  fmt_datetime(columns = vars(datetime)) %>% \n  fmt_currency(columns = vars(currency))\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\n\n      num\n      char\n      fctr\n      date\n      time\n      datetime\n      currency\n    \n\n\ngrp_a\n    \n\nrow_1\n0.11\napricot\none\nThursday, January 15, 2015\n13:35\nMonday, January 1, 2018 02:22\n$49.95\n\n\nrow_2\n2.22\nbanana\ntwo\nSunday, February 15, 2015\n14:40\nFriday, February 2, 2018 14:33\n$17.95\n\n\nrow_3\n33.33\ncoconut\nthree\nSunday, March 15, 2015\n15:45\nSaturday, March 3, 2018 03:44\n$1.39\n\n\nrow_4\n444.40\ndurian\nfour\nWednesday, April 15, 2015\n16:50\nWednesday, April 4, 2018 15:55\n$65,100.00\n\n\ngrp_b\n    \n\nrow_5\n5,550.00\nNA\nfive\nFriday, May 15, 2015\n17:55\nSaturday, May 5, 2018 04:00\n$1,325.81\n\n\nrow_6\nNA\nfig\nsix\nMonday, June 15, 2015\nNA\nWednesday, June 6, 2018 16:11\n$13.26\n\n\nrow_7\n777,000.00\ngrapefruit\nseven\nNA\n19:10\nSaturday, July 7, 2018 05:22\nNA\n\n\nrow_8\n8,880,000.00\nhoneydew\neight\nSaturday, August 15, 2015\n20:20\nNA\n$0.44\n\n\n\n\n\n\nTo use a specific locale for data formatting, provide specific arguments to the respective functions.\nDate formatting\n\nexibble %>% \n  select(date, time, datetime) %>% \n  gt(rowname_col = \"row\", groupname_col = \"group\") %>% \n  fmt_date(columns = vars(date), date_style = 3) %>% \n  fmt_time(columns = vars(time), time_style = 5) %>% \n  fmt_datetime(columns = vars(datetime), date_style = 6, time_style = 4)\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\ndate\n      time\n      datetime\n    \n\n\nThu, Jan 15, 2015\n1 PM\nJan 1, 2018 2:22 AM\n\n\nSun, Feb 15, 2015\n2 PM\nFeb 2, 2018 2:33 PM\n\n\nSun, Mar 15, 2015\n3 PM\nMar 3, 2018 3:44 AM\n\n\nWed, Apr 15, 2015\n4 PM\nApr 4, 2018 3:55 PM\n\n\nFri, May 15, 2015\n5 PM\nMay 5, 2018 4:00 AM\n\n\nMon, Jun 15, 2015\nNA\nJun 6, 2018 4:11 PM\n\n\nNA\n7 PM\nJul 7, 2018 5:22 AM\n\n\nSat, Aug 15, 2015\n8 PM\nNA\n\n\n\n\n\n\nCurrency formatting\n\nmoney <- data.frame(\n  USD = c(12.12, 2141.213, 0.42, 1.55, 34414),\n  EUR = c(10.68, 1884.27, 0.37, 1.36, 30284.32),\n  INR = c(861.07, 152122.48, 29.84, 110, 2444942.63),\n  JPY = c(1280, 226144, 44.36, 164, 3634634.61),\n  MAD = c(115.78, 20453.94, 4.01, 15, 328739.73)\n)\n\nmoney %>%\n  gt() %>%\n  fmt_currency(columns = vars(USD), currency = \"USD\") %>%\n  fmt_currency(columns = vars(EUR), currency = \"EUR\") %>%\n  fmt_currency(columns = vars(INR), currency = \"INR\") %>%\n  fmt_currency(columns = vars(JPY), currency = \"JPY\") %>%\n  fmt_currency(columns = vars(MAD), currency = \"MAD\")\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\nUSD\n      EUR\n      INR\n      JPY\n      MAD\n    \n\n\n$12.12\n€10.68\n₹861.07\n¥1,280\nDh115.78\n\n\n$2,141.21\n€1,884.27\n₹152,122.48\n¥226,144\nDh20,453.94\n\n\n$0.42\n€0.37\n₹29.84\n¥44\nDh4.01\n\n\n$1.55\n€1.36\n₹110.00\n¥164\nDh15.00\n\n\n$34,414.00\n€30,284.32\n₹2,444,942.63\n¥3,634,635\nDh328,739.73\n\n\n\n\n\n\nPercent formatting\n\ndata.frame(\n  x = 1:5,\n  y = 6:10,\n  percent = seq(from = 0.1, to =  0.2, by = 0.025)\n) %>% \n  gt() %>% \n  fmt_percent(columns = vars(percent), decimals = 1)\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\nx\n      y\n      percent\n    \n\n\n1\n6\n10.0%\n\n\n2\n7\n12.5%\n\n\n3\n8\n15.0%\n\n\n4\n9\n17.5%\n\n\n5\n10\n20.0%\n\n\n\n\n\n\nNumber formatting\nNumeric formatting can include changes to the number of decimals, separators (ie “,”), or even suffixing (ie K, Mb, etc).\n\nexibble %>% \n  select(group, num, currency) %>% \n  gt() %>% \n  fmt_number(columns = vars(num), decimals = 4, sep_mark = \"\") %>% \n  # Suffixing scale and apply suffixes to larger numbers \n  fmt_number(columns = vars(currency), decimals = 1, suffixing = TRUE)\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\ngroup\n      num\n      currency\n    \n\n\ngrp_a\n0.1111\n50.0\n\n\ngrp_a\n2.2220\n17.9\n\n\ngrp_a\n33.3300\n1.4\n\n\ngrp_a\n444.4000\n65.1K\n\n\ngrp_b\n5550.0000\n1.3K\n\n\ngrp_b\nNA\n13.3\n\n\ngrp_b\n777000.0000\nNA\n\n\ngrp_b\n8880000.0000\n0.4\n\n\n\n\n\n\nDisplaying missing values\nMissing values are ignored by formatters and shown as NA by default. You can specify missing values with other indicators with fmt_missing\n\nexibble %>% \n  select(group, currency, num) %>% \n  gt() %>% \n  fmt_missing(columns = vars(currency), rows = is.na(currency)) %>% \n  fmt_missing(columns = vars(num), rows = is.na(num), missing_text = \"none\")\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\ngroup\n      currency\n      num\n    \n\n\ngrp_a\n49.950\n1.111e-01\n\n\ngrp_a\n17.950\n2.222e+00\n\n\ngrp_a\n1.390\n3.333e+01\n\n\ngrp_a\n65100.000\n4.444e+02\n\n\ngrp_b\n1325.810\n5.550e+03\n\n\ngrp_b\n13.255\nnone\n\n\ngrp_b\n—\n7.770e+05\n\n\ngrp_b\n0.440\n8.880e+06\n\n\n\n\n\n\nFormat markdown\nYou can also parse cell content that contains arbitrary markdown.\n\n# Create a few Markdown-based\n# text snippets\ntext_1a <- \"\n### This is Markdown.\n\nMarkdown’s syntax is comprised entirely of\npunctuation characters, which punctuation\ncharacters have been carefully chosen so as\nto look like what they mean... assuming\nyou’ve ever used email.\n\"\n\ntext_1b <- \"\nInfo on Markdown syntax can be found\n[here](https://daringfireball.net/projects/markdown/).\n\"\n\ntext_2a <- \"\nThe **gt** package has these datasets:\n\n - `countrypops`\n - `sza`\n - `gtcars`\n - `sp500`\n - `pizzaplace`\n - `exibble`\n\"\n\ntext_2b <- \"\nThere's a quick reference [here](https://commonmark.org/help/).\n\"\n\n# Arrange the text snippets as a tibble\n# using the `dplyr::tribble()` function;\n# then, create a gt table and format\n# all columns with `fmt_markdown()`\ndplyr::tribble(\n  ~Markdown, ~md,\n  text_1a,   text_2a,\n  text_1b,   text_2b,\n  ) %>%\n  gt() %>%\n  fmt_markdown(columns = TRUE) %>%\n  tab_options(table.width = px(400))\n\nWarning: `columns = TRUE` has been deprecated in gt 0.3.0:\n* please use `columns = everything()` instead\n\n\n\n\n\n\n\nMarkdown\n      md\n    \n\n\n\nThis is Markdown.\nMarkdown’s syntax is comprised entirely of\npunctuation characters, which punctuation\ncharacters have been carefully chosen so as\nto look like what they mean... assuming\nyou’ve ever used email.\n\n\nThe gt package has these datasets:\n\ncountrypops\nsza\ngtcars\nsp500\npizzaplace\nexibble\n\n\n\n\n\nInfo on Markdown syntax can be found\nhere.\n\n\nThere's a quick reference here.\n\n\n\n\n\n\n\nCustom data formatting\nIf none of the built-in formatters apply to your data, you can use fmt() instead.\n\ndata.frame(\n  count = c(1L, 2L, 3L, 4L, 5L),\n  weight_g = c(150.65, 149.65, 171.28, 142.58, 139.04),\n  color = c(\"green\", \"yellow\", \"yellow\", \"green\", \"yellow\")\n) %>% \n  gt() %>% \n  fmt(\n    columns = vars(count),\n    fns = function(x){ paste(x, \"bananas\")}\n  ) \n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\ncount\n      weight_g\n      color\n    \n\n\n1 bananas\n150.65\ngreen\n\n\n2 bananas\n149.65\nyellow\n\n\n3 bananas\n171.28\nyellow\n\n\n4 bananas\n142.58\ngreen\n\n\n5 bananas\n139.04\nyellow"
  },
  {
    "objectID": "static/resources/gt-cookbook.html#create-or-modify-parts",
    "href": "static/resources/gt-cookbook.html#create-or-modify-parts",
    "title": "gt cookbook",
    "section": "Create or Modify Parts",
    "text": "Create or Modify Parts\nAdd a header\n\ndata.frame(\n  count = c(1L, 2L, 3L, 4L, 5L),\n  weight_g = c(150.65, 149.65, 171.28, 142.58, 139.04),\n  color = c(\"green\", \"yellow\", \"yellow\", \"green\", \"yellow\")\n) %>% \n  gt() %>% \n  tab_header(\n    title = \"Number of bananas, weight, and ripeness\",\n    subtitle = \"Bananas sourced in Mar 2021\"\n    )\n\n\n\n\n\n\n\nNumber of bananas, weight, and ripeness\n    \n\nBananas sourced in Mar 2021\n    \n\n\ncount\n      weight_g\n      color\n    \n\n\n1\n150.65\ngreen\n\n\n2\n149.65\nyellow\n\n\n3\n171.28\nyellow\n\n\n4\n142.58\ngreen\n\n\n5\n139.04\nyellow\n\n\n\n\n\n\nFormat header\nYou can parse markdown with md() or HTML with html().\n\ndata.frame(\n  count = c(1L, 2L, 3L, 4L, 5L),\n  weight_g = c(150.65, 149.65, 171.28, 142.58, 139.04),\n  color = c(\"green\", \"yellow\", \"yellow\", \"green\", \"yellow\")\n) %>% \n  gt() %>% \n  tab_header(\n    title = md(\"**Number of bananas, weight, and ripeness**\"),\n    subtitle = html(\"Bananas sourced in <em><b>Mar 2021<b></em>\")\n    )\n\n\n\n\n\n\n\nNumber of bananas, weight, and ripeness\n    \n\nBananas sourced in Mar 2021\n\n    \n\n\ncount\n      weight_g\n      color\n    \n\n\n1\n150.65\ngreen\n\n\n2\n149.65\nyellow\n\n\n3\n171.28\nyellow\n\n\n4\n142.58\ngreen\n\n\n5\n139.04\nyellow\n\n\n\n\n\n\nAdd spanner column labels\nYou can create column label “groups” with the tab_spanner() function.\n\nhead(gtcars, 8) %>%\n  dplyr::select(model:mpg_h, msrp) %>%  \n  gt(rowname_col = \"model\") %>%\n  tab_spanner(\n    label = \"Performance\",\n    columns = vars(hp, hp_rpm, trq, trq_rpm, mpg_c, mpg_h)\n  ) %>% \n  tab_spanner(\n    label = \"Car Info\",\n    columns = vars(year, bdy_style, trim)\n  )\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\n\n\n      \n        Car Info\n      \n      \n        Performance\n      \n      msrp\n    \n\nyear\n      bdy_style\n      trim\n      hp\n      hp_rpm\n      trq\n      trq_rpm\n      mpg_c\n      mpg_h\n    \n\n\n\nGT\n2017\ncoupe\nBase Coupe\n647\n6250\n550\n5900\n11\n18\n447000\n\n\n458 Speciale\n2015\ncoupe\nBase Coupe\n597\n9000\n398\n6000\n13\n17\n291744\n\n\n458 Spider\n2015\nconvertible\nBase\n562\n9000\n398\n6000\n13\n17\n263553\n\n\n458 Italia\n2014\ncoupe\nBase Coupe\n562\n9000\n398\n6000\n13\n17\n233509\n\n\n488 GTB\n2016\ncoupe\nBase Coupe\n661\n8000\n561\n3000\n15\n22\n245400\n\n\nCalifornia\n2015\nconvertible\nBase Convertible\n553\n7500\n557\n4750\n16\n23\n198973\n\n\nGTC4Lusso\n2017\ncoupe\nBase Coupe\n680\n8250\n514\n5750\n12\n17\n298000\n\n\nFF\n2015\ncoupe\nBase Coupe\n652\n8000\n504\n6000\n11\n16\n295000\n\n\n\n\n\n\nAdd spanner delim\nFor columns that are well formatted, gt can parse the delimiter and “split” the label into its component parts.\n\nhead(gtcars, 8) %>%\n  dplyr::select(model:trim, mpg_city = mpg_c, mpg_hwy = mpg_h) %>%  \n  gt(rowname_col = \"model\") %>%\n  tab_spanner_delim(delim = \"_\")\n\n\n\n\n\n\n\n\n      year\n      trim\n      \n        mpg\n      \n    \n\ncity\n      hwy\n    \n\n\n\nGT\n2017\nBase Coupe\n11\n18\n\n\n458 Speciale\n2015\nBase Coupe\n13\n17\n\n\n458 Spider\n2015\nBase\n13\n17\n\n\n458 Italia\n2014\nBase Coupe\n13\n17\n\n\n488 GTB\n2016\nBase Coupe\n15\n22\n\n\nCalifornia\n2015\nBase Convertible\n16\n23\n\n\nGTC4Lusso\n2017\nBase Coupe\n12\n17\n\n\nFF\n2015\nBase Coupe\n11\n16"
  },
  {
    "objectID": "static/resources/gt-cookbook.html#locations",
    "href": "static/resources/gt-cookbook.html#locations",
    "title": "gt cookbook",
    "section": "Locations",
    "text": "Locations\ngt usesthe locations argument across many functions to let you tightly customize specific components. These are considered “Helper Functions”, and are further expended in the gt documentation.\nLocations is used with the various cells_??? functions like: cells_title, cells_stubhead, cells_column_spanners().\nCell body\nFor the cells_body(), it includes arguments for columns and rows, allowing you to specify specific columns or even columns + subsets of specific rows based on logicals.\n\nhead(gtcars, 8) %>%\n  dplyr::select(model:trim, mpg_city = mpg_c, mpg_hwy = mpg_h) %>%  \n  gt(rowname_col = \"model\") %>% \n  tab_style(\n    style = cell_text(color = \"red\"),\n    locations = cells_body(\n      columns = vars(trim),\n      rows = trim == \"Base Convertible\"\n      )\n  )\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\n\n      year\n      trim\n      mpg_city\n      mpg_hwy\n    \n\n\nGT\n2017\nBase Coupe\n11\n18\n\n\n458 Speciale\n2015\nBase Coupe\n13\n17\n\n\n458 Spider\n2015\nBase\n13\n17\n\n\n458 Italia\n2014\nBase Coupe\n13\n17\n\n\n488 GTB\n2016\nBase Coupe\n15\n22\n\n\nCalifornia\n2015\nBase Convertible\n16\n23\n\n\nGTC4Lusso\n2017\nBase Coupe\n12\n17\n\n\nFF\n2015\nBase Coupe\n11\n16\n\n\n\n\n\n\nTable title\nTable header/title can be affected by cells_title, and it can affect either the title, subtitle or both (default).\n\nhead(gtcars, 8) %>%\n  dplyr::select(model:trim, mpg_city = mpg_c, mpg_hwy = mpg_h) %>%  \n  gt() %>% \n  tab_header(\n    title = \"These are not efficient cars\",\n    subtitle = \"But they are fast\"\n    ) %>% \n  tab_style(\n    style = cell_text(color = \"black\", weight = \"bold\", align = \"left\"),\n    locations = cells_title(\"title\")\n  )\n\n\n\n\n\n\n\nThese are not efficient cars\n    \n\nBut they are fast\n    \n\n\nmodel\n      year\n      trim\n      mpg_city\n      mpg_hwy\n    \n\n\nGT\n2017\nBase Coupe\n11\n18\n\n\n458 Speciale\n2015\nBase Coupe\n13\n17\n\n\n458 Spider\n2015\nBase\n13\n17\n\n\n458 Italia\n2014\nBase Coupe\n13\n17\n\n\n488 GTB\n2016\nBase Coupe\n15\n22\n\n\nCalifornia\n2015\nBase Convertible\n16\n23\n\n\nGTC4Lusso\n2017\nBase Coupe\n12\n17\n\n\nFF\n2015\nBase Coupe\n11\n16\n\n\n\n\n\n\nTable stub\nYou can affect both the stubhead and the stub rows themselves as well.\n\nhead(gtcars, 8) %>%\n  dplyr::select(model:trim, mpg_city = mpg_c, mpg_hwy = mpg_h) %>%  \n  gt(rowname_col = \"model\") %>% \n  tab_stubhead(\"Car Models\") %>% \n  tab_style(\n    style = list(\n      cell_fill(\"black\"),\n      cell_text(color = \"white\", weight = \"bold\")\n      ),\n    locations = cells_stubhead()\n  ) %>% \n  tab_style(\n    style = cell_text(color = \"darkgrey\", weight = \"bold\"),\n    locations = cells_stub()\n  )\n\n\n\n\n\n\nCar Models\n      year\n      trim\n      mpg_city\n      mpg_hwy\n    \n\n\nGT\n2017\nBase Coupe\n11\n18\n\n\n458 Speciale\n2015\nBase Coupe\n13\n17\n\n\n458 Spider\n2015\nBase\n13\n17\n\n\n458 Italia\n2014\nBase Coupe\n13\n17\n\n\n488 GTB\n2016\nBase Coupe\n15\n22\n\n\nCalifornia\n2015\nBase Convertible\n16\n23\n\n\nGTC4Lusso\n2017\nBase Coupe\n12\n17\n\n\nFF\n2015\nBase Coupe\n11\n16\n\n\n\n\n\n\nRow group\nRow groups can be further emphasized by changing the background or other styling.\n\ngtcars %>% \n  filter(mfr %in% c(\"Ferrari\", \"Porsche\")) %>% \n  dplyr::select(mfr, model:trim, mpg_city = mpg_c, mpg_hwy = mpg_h) %>%  \n  gt(rowname_col = \"model\", groupname_col = \"mfr\") %>% \n  tab_style(\n    style = list(\n      cell_fill(\"black\"),\n      cell_text(color = \"white\", weight = \"bold\")\n      ),\n    locations = cells_row_groups()\n  ) %>% \n  tab_style(\n    style = cell_text(color = \"darkgrey\", weight = \"bold\"),\n    locations = cells_stub()\n  )\n\n\n\n\n\n\n\n      year\n      trim\n      mpg_city\n      mpg_hwy\n    \n\n\nFerrari\n    \n\n458 Speciale\n2015\nBase Coupe\n13\n17\n\n\n458 Spider\n2015\nBase\n13\n17\n\n\n458 Italia\n2014\nBase Coupe\n13\n17\n\n\n488 GTB\n2016\nBase Coupe\n15\n22\n\n\nCalifornia\n2015\nBase Convertible\n16\n23\n\n\nGTC4Lusso\n2017\nBase Coupe\n12\n17\n\n\nFF\n2015\nBase Coupe\n11\n16\n\n\nF12Berlinetta\n2015\nBase Coupe\n11\n16\n\n\nLaFerrari\n2015\nBase Coupe\n12\n16\n\n\nPorsche\n    \n\n718 Boxster\n2017\nBase Convertible\n21\n28\n\n\n718 Cayman\n2017\nBase Coupe\n20\n29\n\n\n911\n2016\nCarrera Coupe\n20\n28\n\n\nPanamera\n2016\nBase Sedan\n18\n28\n\n\n\n\n\n\nGroup summary\nTo affect the grouped summary rows (or grand summary rows) you can use cells_summary() or cells_grand_summary().\n\ngtcars %>% \n  dplyr::filter(mfr %in% c(\"Ferrari\", \"Porsche\", \"Lamborghini\")) %>% \n  dplyr::group_by(mfr) %>% \n  dplyr::slice_head(n = 3) %>% \n  dplyr::ungroup() %>% \n  dplyr::select(mfr, model:trim, mpg_city = mpg_c, mpg_hwy = mpg_h) %>%  \n  gt(rowname_col = \"model\", groupname_col = \"mfr\") %>% \n  gt::summary_rows(\n    groups = TRUE, columns = vars(mpg_city, mpg_hwy),\n    fns = list(Average = ~mean(.)),\n    formatter = fmt_number, decimals = 1\n  ) %>% \n  tab_style(\n    style = list(\n      cell_text(color = \"white\", font = google_font(\"Fira Mono\")),\n      cell_fill(\"black\")\n    ),\n    locations = cells_summary()\n  )\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\n\n      year\n      trim\n      mpg_city\n      mpg_hwy\n    \n\n\nFerrari\n    \n\n458 Speciale\n2015\nBase Coupe\n13\n17\n\n\n458 Spider\n2015\nBase\n13\n17\n\n\n458 Italia\n2014\nBase Coupe\n13\n17\n\n\nAverage\n—\n—\n13.0\n17.0\n\n\nLamborghini\n    \n\nAventador\n2015\nLP 700-4 Coupe\n11\n18\n\n\nHuracan\n2015\nLP 610-4 Coupe\n16\n20\n\n\nGallardo\n2014\nLP 550-2 Coupe\n12\n20\n\n\nAverage\n—\n—\n13.0\n19.3\n\n\nPorsche\n    \n\n718 Boxster\n2017\nBase Convertible\n21\n28\n\n\n718 Cayman\n2017\nBase Coupe\n20\n29\n\n\n911\n2016\nCarrera Coupe\n20\n28\n\n\nAverage\n—\n—\n20.3\n28.3\n\n\n\n\n\n\nSpanners and labels\nYou can also affect the column labels or spanners above the labels. Note the use of a spanner id to make it easy to identify the specific spanner to apply the changes to.\n\nexibble %>%\n  dplyr::select(-fctr, -currency, -group) %>%\n  gt(rowname_col = \"row\") %>%\n  tab_spanner(\n    label = \"dates and times\",\n    id = \"dt\",\n    columns = vars(date, time, datetime)\n  ) %>%\n  tab_style(\n    style = cell_text(color = \"darkgrey\", transform = \"uppercase\"),\n    locations = cells_column_spanners(spanners = \"dt\")\n  ) %>% \n  tab_style(\n    style = cell_text(weight = \"bold\"),\n    locations = cells_column_labels(columns = vars(date, time, datetime))\n  )\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\n\n\n      num\n      char\n      \n        dates and times\n      \n    \n\ndate\n      time\n      datetime\n    \n\n\n\nrow_1\n1.111e-01\napricot\n2015-01-15\n13:35\n2018-01-01 02:22\n\n\nrow_2\n2.222e+00\nbanana\n2015-02-15\n14:40\n2018-02-02 14:33\n\n\nrow_3\n3.333e+01\ncoconut\n2015-03-15\n15:45\n2018-03-03 03:44\n\n\nrow_4\n4.444e+02\ndurian\n2015-04-15\n16:50\n2018-04-04 15:55\n\n\nrow_5\n5.550e+03\nNA\n2015-05-15\n17:55\n2018-05-05 04:00\n\n\nrow_6\nNA\nfig\n2015-06-15\nNA\n2018-06-06 16:11\n\n\nrow_7\n7.770e+05\ngrapefruit\nNA\n19:10\n2018-07-07 05:22\n\n\nrow_8\n8.880e+06\nhoneydew\n2015-08-15\n20:20\nNA"
  },
  {
    "objectID": "static/resources/gt-cookbook.html#add-notes",
    "href": "static/resources/gt-cookbook.html#add-notes",
    "title": "gt cookbook",
    "section": "Add notes",
    "text": "Add notes\nYou can also add footnotes or sourcenotes to arbitrary locations within the table. Both will “output” to the bottom of the table, but can place their respective indicators elsewhere.\nAdd footnote\nFootnotes can be added to arbitrary locations with tab_footnote(). Here we add a footnote specifically to the mpg_h column label.\n\ngtcars %>%\n  dplyr::select(model, year, trq, mpg_h) %>%\n  head(6) %>% \n  gt(rowname_col = \"model\") %>%\n  tab_footnote(\n    locations = cells_column_labels(vars(mpg_h)),\n    footnote = \"Miles per Gallon on Highway\"\n  )\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\n\n      year\n      trq\n      mpg_h1\n\n    \n\n\nGT\n2017\n550\n18\n\n\n458 Speciale\n2015\n398\n17\n\n\n458 Spider\n2015\n398\n17\n\n\n458 Italia\n2014\n398\n17\n\n\n488 GTB\n2016\n561\n22\n\n\nCalifornia\n2015\n557\n23\n\n\n\n\n1 Miles per Gallon on Highway\n    \n\n\n\n\nThe location argument allows for other areas to be specified, and the footnote argument can also parse markdown/HTML with the md() and html() helpers.\n\ngtcars %>%\n  dplyr::select(model, year, trq, mpg_h) %>%\n  head(6) %>% \n  gt(rowname_col = \"model\") %>%\n  tab_footnote(\n    locations = cells_stub(rows = c(2,3,6)),\n    footnote = md(\"Manufacturing was interruped for these cars in **2015**\")\n  )\n\n\n\n\n\n\n\n      year\n      trq\n      mpg_h\n    \n\n\nGT\n2017\n550\n18\n\n\n458 Speciale1\n\n2015\n398\n17\n\n\n458 Spider1\n\n2015\n398\n17\n\n\n458 Italia\n2014\n398\n17\n\n\n488 GTB\n2016\n561\n22\n\n\nCalifornia1\n\n2015\n557\n23\n\n\n\n\n1 Manufacturing was interruped for these cars in 2015\n\n    \n\n\n\n\nAdd a source note\nSource notes, like “data sourced from…” can be added with tab_source_note(), and again it can parse arbitrary HTML or md.\n\nsource_tag <- \"Data from <a href='https://www.edmunds.com'>Edmunds.com</a>\"\n\ngtcars %>%\n  dplyr::select(model, year, trq, mpg_h) %>%\n  head(6) %>% \n  gt(rowname_col = \"model\") %>% \n  tab_source_note(html(source_tag))\n\n\n\n\n\n\n\n      year\n      trq\n      mpg_h\n    \n\n\nGT\n2017\n550\n18\n\n\n458 Speciale\n2015\n398\n17\n\n\n458 Spider\n2015\n398\n17\n\n\n458 Italia\n2014\n398\n17\n\n\n488 GTB\n2016\n561\n22\n\n\nCalifornia\n2015\n557\n23\n\n\n\nData from Edmunds.com"
  },
  {
    "objectID": "static/resources/gt-cookbook.html#conditional-styling",
    "href": "static/resources/gt-cookbook.html#conditional-styling",
    "title": "gt cookbook",
    "section": "Conditional styling",
    "text": "Conditional styling\nYou can transform specific portions of the table based on conditional logic.\nExample conditionals include:\nbase:ifelse()\ndplyr::if_else()\ndplyr::case_when()\nText transform\nYou can change specific text based on a function with text_transform(). This is extremely powerful, but specific to only the column being transformed.\n\ndata.frame(\n  count = c(1L, 2L, 3L, 4L, 5L),\n  weight_g = c(150.65, 149.65, 171.28, 142.58, 139.04),\n  color = c(\"green\", \"yellow\", \"yellow\", \"green\", \"yellow\")\n) %>% \n  gt() %>% \n  text_transform(\n    locations = cells_body(\n      columns = vars(weight_g)),\n    fn = function(x) {\n      paste0(\n        x, \" (\",\n        dplyr::case_when(\n          x > 150   ~ \"large\",\n          x <= 150  ~ \"small\"),\n        \")\")\n    }\n  ) \n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\ncount\n      weight_g\n      color\n    \n\n\n1\n150.65 (large)\ngreen\n\n\n2\n149.65 (small)\nyellow\n\n\n3\n171.28 (large)\nyellow\n\n\n4\n142.58 (small)\ngreen\n\n\n5\n139.04 (small)\nyellow\n\n\n\n\n\n\nFormatting changes\nYou can logically match to rows and apply specific styling to them such as color.\n\nstocks <- data.frame(\n  Symbol = c(\"GOOG\", \"FB\", \"AMZN\", \"NFLX\", \"TSLA\"),\n  Price = c(1265.13, 187.89, 1761.33, 276.82, 328.13),\n  Change = c(4.14, 1.51, -19.45, 5.32, -12.45)\n)\nstocks %>% \n  gt() %>% \n  tab_style(\n    style = cell_text(color = \"red\", weight = \"bold\"),\n    locations = cells_body(\n      columns = vars(Change),\n      rows = Change < 0\n    )\n  ) %>% \n  tab_style(\n    style = cell_text(color = \"blue\", weight = \"bold\"),\n    locations = cells_body(\n      columns = vars(Change),\n      rows = Change >= 0\n    )\n  )\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\nSymbol\n      Price\n      Change\n    \n\n\nGOOG\n1265.13\n4.14\n\n\nFB\n187.89\n1.51\n\n\nAMZN\n1761.33\n-19.45\n\n\nNFLX\n276.82\n5.32\n\n\nTSLA\n328.13\n-12.45\n\n\n\n\n\n\nStyle the table\nWith the tab_style() function we can target specific cells and apply styles to them. This is best done in conjunction with the helper functions cell_text(), cell_fill(), and cell_borders().\nAt present this function is focused on the application of styles for HTML output only (as such, other output formats will ignore all tab_style() calls). Using the aforementioned helper functions, here are some of the styles we can apply:\n\nthe background color of the cell (cell_fill(): color)\nthe cell’s text color, font, and size (cell_text(): color, font, size)\nthe text style (cell_text(): style), enabling the use of italics or oblique text.\nthe text weight (cell_text(): weight), allowing the use of thin to bold text (the degree of choice is greater with variable fonts)\nthe alignment and indentation of text (cell_text(): align and indent)\nthe cell borders (cell_borders())\n\n\ndata.frame(\n  count = c(1L, 2L, 3L, 4L, 5L),\n  weight_g = c(150.65, 149.65, 171.28, 142.58, 139.04),\n  color = c(\"green\", \"yellow\", \"yellow\", \"green\", \"yellow\")\n) %>% \n  gt() %>% \n  tab_style(\n    style = list(\n      cell_fill(color = \"lightgrey\"),\n      \"font-variant: small-caps;\"\n    ),\n    locations = cells_body(columns = vars(color))\n  ) %>% \n  tab_style(\n    style = list(\n      cell_text(color = \"green\")\n    ),\n    locations = cells_body(\n      columns = vars(color),\n      # conditional logic\n      rows = color == \"green\"\n    )\n  ) %>% \n  tab_style(\n    style = list(\n      cell_text(color = \"goldenrod\")\n    ),\n    locations = cells_body(\n      columns = vars(color),\n      # conditional logic\n      rows = color == \"yellow\"\n    )\n  ) %>% \n  tab_style(\n    style = list(\n      cell_borders(sides = \"right\", color = \"black\", weight = px(3))\n    ),\n    locations = cells_body(\n      # entire column\n      columns = vars(weight_g)\n    )\n  ) %>% \n  tab_style(\n    style = list(\n      cell_text(transform = \"uppercase\", weight = \"bold\")\n    ),\n    # different location\n    locations = cells_column_labels(everything())\n  )\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\ncount\n      weight_g\n      color\n    \n\n\n1\n150.65\ngreen\n\n\n2\n149.65\nyellow\n\n\n3\n171.28\nyellow\n\n\n4\n142.58\ngreen\n\n\n5\n139.04\nyellow"
  },
  {
    "objectID": "static/resources/gt-cookbook.html#modify-columns",
    "href": "static/resources/gt-cookbook.html#modify-columns",
    "title": "gt cookbook",
    "section": "Modify Columns",
    "text": "Modify Columns\nColumn labels\nThe cols_label() function provides the flexibility to relabel one or more columns and we even have the option to use the md() or html() helper functions for rendering column labels from Markdown or using HTML.\n\nhead(mtcars) %>% \n  gt() %>% \n  cols_label(\n    mpg = \"Miles/Gal\",\n    cyl = \"Cylinders\"\n  )\n\n\n\n\n\n\nMiles/Gal\n      Cylinders\n      disp\n      hp\n      drat\n      wt\n      qsec\n      vs\n      am\n      gear\n      carb\n    \n\n\n21.0\n6\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\n21.0\n6\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\n22.8\n4\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\n21.4\n6\n258\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\n18.7\n8\n360\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\n18.1\n6\n225\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\n\n\n\n\nRelabel with markdown or HTML\nYou can also parse markdown with md() or HTML with html() within the label string.\n\nhead(mtcars) %>% \n  gt() %>% \n  cols_label(\n    mpg = md(\"**Miles/Gal**\"),       # recognizes markdown syntax\n    cyl = html(\"<em>Cylinders</em>\") # recognizes HTML syntax\n  )\n\n\n\n\n\n\nMiles/Gal\n      Cylinders\n      disp\n      hp\n      drat\n      wt\n      qsec\n      vs\n      am\n      gear\n      carb\n    \n\n\n21.0\n6\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\n21.0\n6\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\n22.8\n4\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\n21.4\n6\n258\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\n18.7\n8\n360\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\n18.1\n6\n225\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\n\n\n\n\nColumn Alignment\n\nThe individual alignments of columns (which includes the column labels and all of their data cells) can be modified. We have the option to align text to the left, the center, and the right.\n\nFor this example we’ve also included all the table lines to “show” the alignment a bit better.\n\ncountrypops %>%\n  dplyr::select(-contains(\"code\")) %>%\n  dplyr::filter(country_name == \"Mongolia\") %>%\n  tail(5) %>%\n  gt() %>%\n  cols_align(\n    align = \"left\",\n    columns = vars(country_name)\n  ) %>% \n  cols_align(\n    align = \"center\",\n    columns = vars(year)\n  ) %>% \n  cols_align(\n    align = \"right\",\n    columns = vars(population)\n  ) %>% \n  tab_options(table.width = px(300)) %>% \n  opt_table_lines()\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\ncountry_name\n      year\n      population\n    \n\n\nMongolia\n2013\n2869107\n\n\nMongolia\n2014\n2923896\n\n\nMongolia\n2015\n2976877\n\n\nMongolia\n2016\n3027398\n\n\nMongolia\n2017\n3075647\n\n\n\n\n\n\nOptimal alignment\nTypically, the best practice is to use left-align for text of variable length and right-align for numeric values. The reasoning can be highlighted in the table below. We want to align numeric values on the same scale so that they can be compared on the same scale, whereas text is more easily readable left-aligned. Center-align can be used with strings or values of equal-length.\nNote that fmt_number and other fmt_??? applied to numeric will automatically right-align, but text will default to left-align.\n\ngt::exibble %>% \n  select(group, char, num, currency) %>% \n  gt() %>% \n  cols_align(align = \"center\", columns = vars(group)) %>% \n  fmt_number(columns = vars(num)) %>% \n  fmt_currency(columns = vars(currency))\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\ngroup\n      char\n      num\n      currency\n    \n\n\ngrp_a\napricot\n0.11\n$49.95\n\n\ngrp_a\nbanana\n2.22\n$17.95\n\n\ngrp_a\ncoconut\n33.33\n$1.39\n\n\ngrp_a\ndurian\n444.40\n$65,100.00\n\n\ngrp_b\nNA\n5,550.00\n$1,325.81\n\n\ngrp_b\nfig\nNA\n$13.26\n\n\ngrp_b\ngrapefruit\n777,000.00\nNA\n\n\ngrp_b\nhoneydew\n8,880,000.00\n$0.44\n\n\n\n\n\n\nColumn Width\n\nWe choose which columns get specific widths. This can be in units of pixels (easily set by use of the px() helper function), or, as percentages (where the pct() helper function is useful).\n\n\ncountrypops %>%\n  dplyr::select(-contains(\"code\")) %>%\n  dplyr::filter(country_name == \"Mongolia\") %>%\n  tail(5) %>%\n  gt() %>% \n  cols_width(\n    vars(country_name) ~ px(200),\n    vars(year) ~ px(50),\n    vars(population) ~ px(100)\n  )\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\n\n\n\n\n\ncountry_name\n      year\n      population\n    \n\n\nMongolia\n2013\n2869107\n\n\nMongolia\n2014\n2923896\n\n\nMongolia\n2015\n2976877\n\n\nMongolia\n2016\n3027398\n\n\nMongolia\n2017\n3075647\n\n\n\n\n\n\nChange all columns\nYou can use the everything() function to affect all columns (or remaining columns).\n\nmtcars %>% \n  tibble::rownames_to_column(\"names\") %>% \n  head(8) %>%\n  gt() %>% \n  cols_width(\n    vars(names) ~ px(150),\n    everything() ~ px(60)\n  ) %>% \n  opt_table_lines()\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nnames\n      mpg\n      cyl\n      disp\n      hp\n      drat\n      wt\n      qsec\n      vs\n      am\n      gear\n      carb\n    \n\n\nMazda RX4\n21.0\n6\n160.0\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\nMazda RX4 Wag\n21.0\n6\n160.0\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\nDatsun 710\n22.8\n4\n108.0\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\nHornet 4 Drive\n21.4\n6\n258.0\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\nHornet Sportabout\n18.7\n8\n360.0\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\nValiant\n18.1\n6\n225.0\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\nDuster 360\n14.3\n8\n360.0\n245\n3.21\n3.570\n15.84\n0\n0\n3\n4\n\n\nMerc 240D\n24.4\n4\n146.7\n62\n3.69\n3.190\n20.00\n1\n0\n4\n2\n\n\n\n\n\n\nMove columns\nYou can move columns to the beginning, end, or arbitrary locations.\nTo start\n\ncountrypops %>% \n  dplyr::select(country_name, year:population) %>% \n  tail(8) %>% \n  gt() %>% \n  cols_move_to_start(vars(year))\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\nyear\n      country_name\n      population\n    \n\n\n2010\nZimbabwe\n14086317\n\n\n2011\nZimbabwe\n14386649\n\n\n2012\nZimbabwe\n14710826\n\n\n2013\nZimbabwe\n15054506\n\n\n2014\nZimbabwe\n15411675\n\n\n2015\nZimbabwe\n15777451\n\n\n2016\nZimbabwe\n16150362\n\n\n2017\nZimbabwe\n16529904\n\n\n\n\n\n\nTo end\n\ncountrypops %>% \n  dplyr::select(country_name, year:population) %>% \n  tail(8) %>% \n  gt() %>% \n  cols_move_to_end(vars(year))\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\ncountry_name\n      population\n      year\n    \n\n\nZimbabwe\n14086317\n2010\n\n\nZimbabwe\n14386649\n2011\n\n\nZimbabwe\n14710826\n2012\n\n\nZimbabwe\n15054506\n2013\n\n\nZimbabwe\n15411675\n2014\n\n\nZimbabwe\n15777451\n2015\n\n\nZimbabwe\n16150362\n2016\n\n\nZimbabwe\n16529904\n2017\n\n\n\n\n\n\nWherever you want\n\ncountrypops %>% \n  dplyr::select(country_name, year:population) %>% \n  tail(8) %>% \n  gt() %>% \n  cols_move(\n    columns = vars(country_name),\n    after = vars(year)\n    )\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\nyear\n      country_name\n      population\n    \n\n\n2010\nZimbabwe\n14086317\n\n\n2011\nZimbabwe\n14386649\n\n\n2012\nZimbabwe\n14710826\n\n\n2013\nZimbabwe\n15054506\n\n\n2014\nZimbabwe\n15411675\n\n\n2015\nZimbabwe\n15777451\n\n\n2016\nZimbabwe\n16150362\n\n\n2017\nZimbabwe\n16529904\n\n\n\n\n\n\nHide columns\nYou can also hide arbitrary columns, but still reference them inside gt.\n\nzim_code <- unique(countrypops$country_code_2) %>% .[length(.)]\ncountrypops %>% \n  tail(8) %>% \n  gt() %>% \n  cols_hide(columns = dplyr::contains(\"code\")) %>% \n  tab_footnote(\n    footnote = paste(\"The country code is\", zim_code),\n    locations = cells_body(\n      columns = vars(country_name),\n      rows = country_code_2 == zim_code\n    )\n  )\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\ncountry_name\n      year\n      population\n    \n\n\nZimbabwe1\n\n2010\n14086317\n\n\nZimbabwe1\n\n2011\n14386649\n\n\nZimbabwe1\n\n2012\n14710826\n\n\nZimbabwe1\n\n2013\n15054506\n\n\nZimbabwe1\n\n2014\n15411675\n\n\nZimbabwe1\n\n2015\n15777451\n\n\nZimbabwe1\n\n2016\n16150362\n\n\nZimbabwe1\n\n2017\n16529904\n\n\n\n\n1 The country code is ZW\n    \n\n\n\n\nMerge columns\nColumns can be merged with glue-like syntax.\n\nsp500 %>%\n  dplyr::slice(50:55) %>%\n  dplyr::select(-volume, -adj_close) %>%\n  gt() %>%\n  cols_merge(\n    columns = vars(open, close),\n    hide_columns = vars(close),\n    pattern = \"{1}&mdash;{2}\"\n  ) %>%\n  cols_merge(\n    columns = vars(low, high),\n    hide_columns = vars(high),\n    pattern = \"{1}&mdash;{2}\"\n  ) %>%\n  cols_label(\n    open = \"open/close\",\n    low = \"low/high\"\n  )\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\ndate\n      open/close\n      low/high\n    \n\n\n2015-10-21\n2033.47—2018.94\n2017.22—2037.97\n\n\n2015-10-20\n2033.13—2030.77\n2026.61—2039.12\n\n\n2015-10-19\n2031.73—2033.66\n2022.31—2034.45\n\n\n2015-10-16\n2024.37—2033.11\n2020.46—2033.54\n\n\n2015-10-15\n1996.47—2023.86\n1996.47—2024.15\n\n\n2015-10-14\n2003.66—1994.24\n1990.73—2009.56"
  },
  {
    "objectID": "static/resources/gt-cookbook.html#table-customization",
    "href": "static/resources/gt-cookbook.html#table-customization",
    "title": "gt cookbook",
    "section": "Table Customization",
    "text": "Table Customization\nYou can customize table “theme” using several options, which can all be combined:\nBordered\n\nhead(mtcars) %>% \n  gt() %>% \n  opt_table_lines(\"all\")\n\n\n\n\n\n\nmpg\n      cyl\n      disp\n      hp\n      drat\n      wt\n      qsec\n      vs\n      am\n      gear\n      carb\n    \n\n\n21.0\n6\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\n21.0\n6\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\n22.8\n4\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\n21.4\n6\n258\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\n18.7\n8\n360\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\n18.1\n6\n225\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\n\n\n\n\nBorderless\n\nhead(mtcars) %>% \n  gt() %>% \n  opt_table_lines(\"none\")\n\n\n\n\n\n\nmpg\n      cyl\n      disp\n      hp\n      drat\n      wt\n      qsec\n      vs\n      am\n      gear\n      carb\n    \n\n\n21.0\n6\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\n21.0\n6\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\n22.8\n4\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\n21.4\n6\n258\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\n18.7\n8\n360\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\n18.1\n6\n225\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\n\n\n\n\nOutlined\n\nhead(mtcars) %>% \n  gt() %>% \n  opt_table_outline()\n\n\n\n\n\n\nmpg\n      cyl\n      disp\n      hp\n      drat\n      wt\n      qsec\n      vs\n      am\n      gear\n      carb\n    \n\n\n21.0\n6\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\n21.0\n6\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\n22.8\n4\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\n21.4\n6\n258\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\n18.7\n8\n360\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\n18.1\n6\n225\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\n\n\n\n\nStriped\n\nhead(mtcars) %>% \n  gt() %>% \n  opt_row_striping()\n\n\n\n\n\n\nmpg\n      cyl\n      disp\n      hp\n      drat\n      wt\n      qsec\n      vs\n      am\n      gear\n      carb\n    \n\n\n21.0\n6\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\n21.0\n6\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\n22.8\n4\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\n21.4\n6\n258\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\n18.7\n8\n360\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\n18.1\n6\n225\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\n\n\n\n\nAdd dividers\nYou can specify locations to add borders/dividers and control the weight/color/side of the border.\n\nhead(mtcars) %>% \n  gt() %>% \n  tab_style(\n    style = cell_borders(sides = \"right\", color = \"black\", \n                         style = \"dashed\", weight = px(3)),\n    locations = cells_body(\n      columns = vars(cyl)\n    )\n  ) %>% \n  tab_style(\n    style = cell_borders(sides = \"bottom\", color = \"black\", weight = px(3)),\n    locations = cells_column_labels(everything())\n  )\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\nmpg\n      cyl\n      disp\n      hp\n      drat\n      wt\n      qsec\n      vs\n      am\n      gear\n      carb\n    \n\n\n21.0\n6\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\n21.0\n6\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\n22.8\n4\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\n21.4\n6\n258\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\n18.7\n8\n360\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\n18.1\n6\n225\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\n\n\n\n\nYou can also include locations outside of the cell body, ie the column labels or other locations.\n\nhead(mtcars) %>% \n  dplyr::select(cyl, everything()) %>% \n  gt() %>% \n  opt_table_lines(\"none\") %>% \n  opt_row_striping() %>% \n  tab_style(\n    style = cell_borders(sides = \"right\", color = \"black\", weight = px(3)),\n    locations = cells_body(\n      columns = vars(cyl)\n    )\n  ) %>% \n  tab_style(\n    style = cell_borders(sides = c(\"top\", \"bottom\"), \n                         color = \"black\", weight = px(3)),\n    locations = cells_column_labels(everything())\n  ) %>% \n  tab_style(\n    style = cell_borders(sides = \"bottom\", color = \"black\", weight = px(3)),\n    locations = cells_body(rows = 6)\n  )\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\ncyl\n      mpg\n      disp\n      hp\n      drat\n      wt\n      qsec\n      vs\n      am\n      gear\n      carb\n    \n\n\n6\n21.0\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\n6\n21.0\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\n4\n22.8\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\n6\n21.4\n258\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\n8\n18.7\n360\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\n6\n18.1\n225\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\n\n\n\n\nAdjust fonts\nYou can use system fonts or bring in Google fonts with google_font().\n\n# change font for entire table\nhead(mtcars) %>% \n  dplyr::select(cyl, everything()) %>% \n  gt() %>% \n  opt_table_font(font = google_font(\"Fira Mono\"))\n\n\n\n\n\ncyl\n      mpg\n      disp\n      hp\n      drat\n      wt\n      qsec\n      vs\n      am\n      gear\n      carb\n    \n\n\n6\n21.0\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\n6\n21.0\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\n4\n22.8\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\n6\n21.4\n258\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\n8\n18.7\n360\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\n6\n18.1\n225\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\n\n\nFonts by location\nAdjusting font by location can be done via tab_style().\n\nhead(mtcars) %>% \n  dplyr::select(cyl, everything()) %>% \n  gt() %>% \n  # change cell body font\n  tab_style(\n    style = cell_text(\n      font = google_font(\"Fira Mono\"), size = px(14)),\n    locations = cells_body(columns = everything())\n  ) %>% \n  # change column labels\n  tab_style(\n    style = cell_text(\n      font = google_font(\"Indie Flower\"), \n      weight = \"bold\",\n      size = px(30)\n      ),\n    locations = cells_column_labels(everything())\n  )\n\n\n\n\n\n\ncyl\n      mpg\n      disp\n      hp\n      drat\n      wt\n      qsec\n      vs\n      am\n      gear\n      carb\n    \n\n\n6\n21.0\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\n6\n21.0\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\n4\n22.8\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\n6\n21.4\n258\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\n8\n18.7\n360\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\n6\n18.1\n225\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\n\n\n\n\nAnd the changes can be made outside of just the body of the table, for example the title/header.\n\ncountrypops %>%\n  dplyr::select(-contains(\"code\")) %>%\n  tail(5) %>%\n  gt() %>% \n  tab_style(\n    style = cell_text(font = google_font(\"Fira Mono\")),\n    locations = cells_body(columns = vars(year, population))\n  ) %>% \n  tab_style(\n    style = cell_text(font = google_font(\"Raleway\"), weight = \"bold\"),\n    locations = cells_body(columns = vars(country_name))\n  ) %>% \n  tab_style(\n    style = cell_text(\n      font = google_font(\"Indie Flower\"), \n      weight = \"bold\", \n      align = \"left\",\n      size = px(40)\n      ),\n    locations = cells_title(\"title\")\n  ) %>% \n  tab_header(\"Population changes\")\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\nPopulation changes\n    \n\ncountry_name\n      year\n      population\n    \n\n\nZimbabwe\n2013\n15054506\n\n\nZimbabwe\n2014\n15411675\n\n\nZimbabwe\n2015\n15777451\n\n\nZimbabwe\n2016\n16150362\n\n\nZimbabwe\n2017\n16529904\n\n\n\n\n\n\nTable options\n\nModify the options available in a table. These options are named by the components, the subcomponents, and the element that can adjusted.\n\nThis is where the bulk of theme-changes can be done. tab_options has dozens of different table components that can be adjusted. The full details can be found in the {gt} documentation. You can customize all sorts of arbitrary components based globally.\n\nhead(mtcars) %>% \n  gt() %>% \n  tab_options(\n    table.background.color = \"black\",\n    column_labels.background.color = \"grey\",\n    column_labels.font.size = px(16),\n    table.font.size = px(12),\n    data_row.padding = px(4),\n    table.width = px(250)\n  )\n\n\n\n\n\n\nmpg\n      cyl\n      disp\n      hp\n      drat\n      wt\n      qsec\n      vs\n      am\n      gear\n      carb\n    \n\n\n21.0\n6\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\n21.0\n6\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\n22.8\n4\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\n21.4\n6\n258\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\n18.7\n8\n360\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\n18.1\n6\n225\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1"
  },
  {
    "objectID": "static/resources/gt-cookbook.html#conditional-formatting",
    "href": "static/resources/gt-cookbook.html#conditional-formatting",
    "title": "gt cookbook",
    "section": "Conditional formatting",
    "text": "Conditional formatting\nColor scales\nTo add color scales, you can use R’s built-in color utilities (or other color manipulation packages like {paletteer}):\nConditional coloring\n\nIt’s possible to add color to data cells according to their values. The data_color() function colors all rows of any columns supplied. There are two ways to define how cells are colored: (1) through the use of a supplied color palette, and (2) through use of a color mapping function available from the {scales} package. The first method colorizes cell data according to whether values are character or numeric. The second method provides more control over how cells are colored since we provide an explicit color function and thus other requirements such as bin counts, cut points, or a numeric domain.\n\n\ncountrypops %>%\n  dplyr::filter(country_name == \"Mongolia\") %>%\n  dplyr::select(-contains(\"code\")) %>%\n  tail(10) %>%\n  gt() %>%\n  data_color(\n    columns = vars(population),\n    colors = scales::col_numeric(\n      palette = c(\n        \"white\", \"orange\", \"red\"),\n      domain = NULL)\n  )\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\ncountry_name\n      year\n      population\n    \n\n\nMongolia\n2008\n2628131\n\n\nMongolia\n2009\n2668289\n\n\nMongolia\n2010\n2712650\n\n\nMongolia\n2011\n2761516\n\n\nMongolia\n2012\n2814226\n\n\nMongolia\n2013\n2869107\n\n\nMongolia\n2014\n2923896\n\n\nMongolia\n2015\n2976877\n\n\nMongolia\n2016\n3027398\n\n\nMongolia\n2017\n3075647\n\n\n\n\n\n\n\nFactors\nFactors are typically more appropriate with qualitative palettes, and we can use scales::col_factor() to apply colors to the specific column of interest. Note that the color palette needs to be equal to the unique number of factors. In the example below we pass n = 3 since we have 3 different trim types.\n\ngtcars %>% \n  dplyr::filter(mfr == \"Ferrari\", hp < 900) %>% \n  dplyr::select(model, hp, trim, mpg_h, msrp) %>% \n  gt() %>% \n  data_color(\n    columns = vars(trim),\n    colors = scales::col_factor(\n      palette = paletteer::paletteer_d(\n        n = 3, palette = \"colorblindr::OkabeIto\"\n        ) %>% as.character(),\n      domain = NULL\n      )\n  )\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\nmodel\n      hp\n      trim\n      mpg_h\n      msrp\n    \n\n\n458 Speciale\n597\nBase Coupe\n17\n291744\n\n\n458 Spider\n562\nBase\n17\n263553\n\n\n458 Italia\n562\nBase Coupe\n17\n233509\n\n\n488 GTB\n661\nBase Coupe\n22\n245400\n\n\nCalifornia\n553\nBase Convertible\n23\n198973\n\n\nGTC4Lusso\n680\nBase Coupe\n17\n298000\n\n\nFF\n652\nBase Coupe\n16\n295000\n\n\nF12Berlinetta\n731\nBase Coupe\n16\n319995\n\n\n\n\n\n\n\nMultiple columns\nThis can also be applied across multiple columns at once. Here’s an example using the built in nottem dataset. While red-green color scales are very commonly used, they are not color-blind friendly.\nWe can alternatively use something like red-white-blue, or purple-white-green.\n\ndimnames <- list(start(nottem)[1]:end(nottem)[1], month.abb)\ntemps <- matrix(nottem, ncol = 12, byrow = TRUE, dimnames = dimnames) %>% \n  data.frame() %>% \n  tibble::rownames_to_column() %>% \n  head(10)\n\ntemps %>% \n  gt() %>% \n  data_color(\n    columns = vars(month.abb),\n    colors = scales::col_numeric(\n      c(\"#63be7b\", \"#ffeb84\", \"#f87274\"), \n      domain = range(nottem))\n  )\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\nNote: Using an external vector in selections is ambiguous.\nℹ Use `all_of(month.abb)` instead of `month.abb` to silence this message.\nℹ See <https://tidyselect.r-lib.org/reference/faq-external-vector.html>.\nThis message is displayed once per session.\n\n\n\n\n\n\n\n\n      Jan\n      Feb\n      Mar\n      Apr\n      May\n      Jun\n      Jul\n      Aug\n      Sep\n      Oct\n      Nov\n      Dec\n    \n\n\n1920\n40.6\n40.8\n44.4\n46.7\n54.1\n58.5\n57.7\n56.4\n54.3\n50.5\n42.9\n39.8\n\n\n1921\n44.2\n39.8\n45.1\n47.0\n54.1\n58.7\n66.3\n59.9\n57.0\n54.2\n39.7\n42.8\n\n\n1922\n37.5\n38.7\n39.5\n42.1\n55.7\n57.8\n56.8\n54.3\n54.3\n47.1\n41.8\n41.7\n\n\n1923\n41.8\n40.1\n42.9\n45.8\n49.2\n52.7\n64.2\n59.6\n54.4\n49.2\n36.3\n37.6\n\n\n1924\n39.3\n37.5\n38.3\n45.5\n53.2\n57.7\n60.8\n58.2\n56.4\n49.8\n44.4\n43.6\n\n\n1925\n40.0\n40.5\n40.8\n45.1\n53.8\n59.4\n63.5\n61.0\n53.0\n50.0\n38.1\n36.3\n\n\n1926\n39.2\n43.4\n43.4\n48.9\n50.6\n56.8\n62.5\n62.0\n57.5\n46.7\n41.6\n39.8\n\n\n1927\n39.4\n38.5\n45.3\n47.1\n51.7\n55.0\n60.4\n60.5\n54.7\n50.3\n42.3\n35.2\n\n\n1928\n40.8\n41.1\n42.8\n47.3\n50.9\n56.4\n62.2\n60.5\n55.4\n50.2\n43.0\n37.3\n\n\n1929\n34.8\n31.3\n41.0\n43.9\n53.1\n56.9\n62.5\n60.3\n59.8\n49.2\n42.9\n41.9\n\n\n\n\n\n\n“Hulk” Colors\n\ntemps %>% \n  gt() %>% \n  data_color(\n    columns = vars(month.abb),\n    colors = scales::col_numeric(\n      colorspace::diverge_hcl(n = 9, palette = \"Purple-Green\") %>% rev(), \n      domain = range(nottem))\n  )\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\n\n      Jan\n      Feb\n      Mar\n      Apr\n      May\n      Jun\n      Jul\n      Aug\n      Sep\n      Oct\n      Nov\n      Dec\n    \n\n\n1920\n40.6\n40.8\n44.4\n46.7\n54.1\n58.5\n57.7\n56.4\n54.3\n50.5\n42.9\n39.8\n\n\n1921\n44.2\n39.8\n45.1\n47.0\n54.1\n58.7\n66.3\n59.9\n57.0\n54.2\n39.7\n42.8\n\n\n1922\n37.5\n38.7\n39.5\n42.1\n55.7\n57.8\n56.8\n54.3\n54.3\n47.1\n41.8\n41.7\n\n\n1923\n41.8\n40.1\n42.9\n45.8\n49.2\n52.7\n64.2\n59.6\n54.4\n49.2\n36.3\n37.6\n\n\n1924\n39.3\n37.5\n38.3\n45.5\n53.2\n57.7\n60.8\n58.2\n56.4\n49.8\n44.4\n43.6\n\n\n1925\n40.0\n40.5\n40.8\n45.1\n53.8\n59.4\n63.5\n61.0\n53.0\n50.0\n38.1\n36.3\n\n\n1926\n39.2\n43.4\n43.4\n48.9\n50.6\n56.8\n62.5\n62.0\n57.5\n46.7\n41.6\n39.8\n\n\n1927\n39.4\n38.5\n45.3\n47.1\n51.7\n55.0\n60.4\n60.5\n54.7\n50.3\n42.3\n35.2\n\n\n1928\n40.8\n41.1\n42.8\n47.3\n50.9\n56.4\n62.2\n60.5\n55.4\n50.2\n43.0\n37.3\n\n\n1929\n34.8\n31.3\n41.0\n43.9\n53.1\n56.9\n62.5\n60.3\n59.8\n49.2\n42.9\n41.9\n\n\n\n\n\n\nRed blue palette\n\ntemps %>% \n  gt() %>% \n  data_color(\n    columns = vars(month.abb),\n    colors = scales::col_numeric(\n      colorspace::diverge_hcl(n = 9, palette = \"Blue-Red 3\"), \n      domain = range(nottem))\n  )\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\n\n      Jan\n      Feb\n      Mar\n      Apr\n      May\n      Jun\n      Jul\n      Aug\n      Sep\n      Oct\n      Nov\n      Dec\n    \n\n\n1920\n40.6\n40.8\n44.4\n46.7\n54.1\n58.5\n57.7\n56.4\n54.3\n50.5\n42.9\n39.8\n\n\n1921\n44.2\n39.8\n45.1\n47.0\n54.1\n58.7\n66.3\n59.9\n57.0\n54.2\n39.7\n42.8\n\n\n1922\n37.5\n38.7\n39.5\n42.1\n55.7\n57.8\n56.8\n54.3\n54.3\n47.1\n41.8\n41.7\n\n\n1923\n41.8\n40.1\n42.9\n45.8\n49.2\n52.7\n64.2\n59.6\n54.4\n49.2\n36.3\n37.6\n\n\n1924\n39.3\n37.5\n38.3\n45.5\n53.2\n57.7\n60.8\n58.2\n56.4\n49.8\n44.4\n43.6\n\n\n1925\n40.0\n40.5\n40.8\n45.1\n53.8\n59.4\n63.5\n61.0\n53.0\n50.0\n38.1\n36.3\n\n\n1926\n39.2\n43.4\n43.4\n48.9\n50.6\n56.8\n62.5\n62.0\n57.5\n46.7\n41.6\n39.8\n\n\n1927\n39.4\n38.5\n45.3\n47.1\n51.7\n55.0\n60.4\n60.5\n54.7\n50.3\n42.3\n35.2\n\n\n1928\n40.8\n41.1\n42.8\n47.3\n50.9\n56.4\n62.2\n60.5\n55.4\n50.2\n43.0\n37.3\n\n\n1929\n34.8\n31.3\n41.0\n43.9\n53.1\n56.9\n62.5\n60.3\n59.8\n49.2\n42.9\n41.9\n\n\n\n\n\n\nMultiple colors\nMultiple calls to data_color() can provide different color palettes or ranges.\n\ngtcars %>% \n  dplyr::filter(mfr == \"Ferrari\", hp < 900) %>% \n  dplyr::select(model, hp, mpg_c, mpg_h, msrp) %>% \n  gt() %>% \n  data_color(\n    columns = vars(hp),\n    colors = scales::col_numeric(\n      palette = c(\n        \"white\", \"orange\", \"red\"),\n      domain = c(500, 750))\n  ) %>% \n  data_color(\n    columns = vars(mpg_c, mpg_h),\n    colors = scales::col_numeric(\n      palette = c(\n        \"white\", \"green\"),\n      domain = c(10, 25))\n  ) %>% \n  data_color(\n    columns = vars(msrp),\n    colors = scales::col_numeric(\n      palette = c(\n        \"white\", \"pink\", \"red\"),\n      domain = NULL)\n  )\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\nmodel\n      hp\n      mpg_c\n      mpg_h\n      msrp\n    \n\n\n458 Speciale\n597\n13\n17\n291744\n\n\n458 Spider\n562\n13\n17\n263553\n\n\n458 Italia\n562\n13\n17\n233509\n\n\n488 GTB\n661\n15\n22\n245400\n\n\nCalifornia\n553\n16\n23\n198973\n\n\nGTC4Lusso\n680\n12\n17\n298000\n\n\nFF\n652\n11\n16\n295000\n\n\nF12Berlinetta\n731\n11\n16\n319995\n\n\n\n\n\n\n\n{paleteer} palettes\nTo make this process easier we can elect to use the {paletteer} package, which makes a wide range of palettes from various R packages readily available.\n\npizzaplace %>%\n  dplyr::filter(\n    type %in% c(\"chicken\", \"supreme\")) %>%\n  dplyr::group_by(type, size) %>%\n  dplyr::summarize(\n    sold = dplyr::n(),\n    income = sum(price)\n  ) %>%\n  gt(rowname_col = \"size\") %>%\n  data_color(\n    columns = vars(sold, income),\n    colors = scales::col_numeric(\n      palette = paletteer::paletteer_d(\n        palette = \"ggsci::red_material\"\n        ) %>% as.character(),\n      domain = NULL\n      )\n  )\n\n`summarise()` has grouped output by 'type'. You can override using the\n`.groups` argument.\n\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\n\n      sold\n      income\n    \n\n\nchicken\n    \n\nL\n4932\n102339.0\n\n\nM\n3894\n65224.5\n\n\nS\n2224\n28356.0\n\n\nsupreme\n    \n\nL\n4564\n94258.5\n\n\nM\n4046\n66475.0\n\n\nS\n3377\n47463.5\n\n\n\n\n\n\nColor Palette functions\nWhile you can manually call outputs to scales::col_numeric(), you can also build a palette function. Note that the palette can be manually created or pulled from a metapackage like colorspace or paletteer.\n\nmy_color_pal <- function(x) {\n  scales::col_numeric(\n    palette = paletteer::paletteer_d(\n      palette = \"ggsci::red_material\"\n    ) %>% as.character(),\n    domain = NULL\n  )(x)\n}\n\npizzaplace %>%\n  dplyr::filter(\n    type %in% c(\"chicken\", \"supreme\")) %>%\n  dplyr::group_by(type, size) %>%\n  dplyr::summarize(\n    sold = dplyr::n(),\n    income = sum(price), .groups = \"drop\"\n  ) %>%\n  gt(rowname_col = \"size\") %>%\n  data_color(\n    columns = vars(sold, income),\n    colors = my_color_pal\n  )\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\n\n      type\n      sold\n      income\n    \n\n\nL\nchicken\n4932\n102339.0\n\n\nM\nchicken\n3894\n65224.5\n\n\nS\nchicken\n2224\n28356.0\n\n\nL\nsupreme\n4564\n94258.5\n\n\nM\nsupreme\n4046\n66475.0\n\n\nS\nsupreme\n3377\n47463.5"
  },
  {
    "objectID": "static/resources/gt-cookbook-advanced.html#introduction",
    "href": "static/resources/gt-cookbook-advanced.html#introduction",
    "title": "gt cookbook - advanced",
    "section": "Introduction",
    "text": "Introduction\nThis cookbook attempts to walk through many of the advanced applications for gt, and provide useful commentary around the use of the various gt functions. The full gt documentation has other more succinct examples and full function arguments.\nFor more introductory use cases, make sure to check out the {gt} Cookbook\nMany of these examples rely on some working knowledge of:\n\nHTML\n\nCSS\n\nFunctional Programming\n\n\npurrr and or apply\n\n\nI am a big fan the Mozilla MDN Web Docs for learning more about how to code up the web with front-end developement. They have sections on general reference material, Tutorials, and Developer Guides.\nAs far as functional programming and purrr, I suggest checking out R4DS Functions Chapter, R4DS Iteration chapter, and Advanced R’s Function chapter, and lastly the Learn to purrr guide by Rebecca Barter."
  },
  {
    "objectID": "static/resources/gt-cookbook-advanced.html#custom-css",
    "href": "static/resources/gt-cookbook-advanced.html#custom-css",
    "title": "gt cookbook - advanced",
    "section": "Custom CSS",
    "text": "Custom CSS\nFor more control over styling, you can add custom class names to the table and apply your own CSS. Note that this can require more effort than the built in gt functions, but also allows some things that aren’t possible by the functions align (like hover highlighting!).\n\n exibble %>%\n  dplyr::select(num, currency) %>%\n  gt(id = \"one\") %>% # need to name the table so that you can apply CSS\n  fmt_currency(\n    columns = vars(currency),\n    currency = \"HKD\"\n  ) %>%\n  fmt_scientific(\n    columns = vars(num)\n  ) %>%\n  opt_css(\n    css = \"\n    #one .gt_table {\n      background-color: lightgrey;\n    }\n    #one .gt_row {\n      padding: 20px 30px;\n    }\n    #one tr:hover {\n    background-color: #f5f8ff;\n    }\n    #one .gt_col_heading {\n      text-align: center !important;\n    }\n    \"\n  )\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\nnum\n      currency\n    \n\n\n1.11 × 10−1\n\nHK$49.95\n\n\n2.22\nHK$17.95\n\n\n3.33 × 101\n\nHK$1.39\n\n\n4.44 × 102\n\nHK$65,100.00\n\n\n5.55 × 103\n\nHK$1,325.81\n\n\nNA\nHK$13.26\n\n\n7.77 × 105\n\nNA\n\n\n8.88 × 106\n\nHK$0.44\n\n\n\n\n\n\nThe examples here embed CSS for demonstration, but it’s often better to put CSS in an external style sheet. You can learn more about adding custom CSS to R Markdown documents here, or to Shiny apps here."
  },
  {
    "objectID": "static/resources/gt-cookbook-advanced.html#parse-arbitrary-html",
    "href": "static/resources/gt-cookbook-advanced.html#parse-arbitrary-html",
    "title": "gt cookbook - advanced",
    "section": "Parse arbitrary HTML",
    "text": "Parse arbitrary HTML\nBecause gt supports HTML, you can also optionally “create” HTML strings prior to passing them into gt proper.\n\ncolor_span <- function(x){paste0(\"<span style='color: \", x, \";'>\", x, \"</span>\")}\n\ndata.frame(\n  count = c(1L, 2L, 3L, 4L, 5L),\n  weight_g = c(150.65, 149.65, 171.28, 142.58, 139.04),\n  color = c(\"green\", \"yellow\", \"yellow\", \"green\", \"yellow\")\n) %>% \n  mutate(color = color_span(color)) %>% \n  mutate(color = purrr::map(color, gt::html)) %>% \n  gt() \n\n\n\n\n\n\ncount\n      weight_g\n      color\n    \n\n\n1\n150.65\ngreen\n\n\n2\n149.65\nyellow\n\n\n3\n171.28\nyellow\n\n\n4\n142.58\ngreen\n\n\n5\n139.04\nyellow\n\n\n\n\n\n\nEmbed URLs\nYou can also use things like htmltools or glue to arbitrarily build HTML content like hyperlinks.\n\nlibrary(htmltools)\nex_sites <- data.frame(\n  Address = c(\"https://google.com\", \"https://yahoo.com\", \"https://duckduckgo.com\"),\n  Site = c(\"Google\", \"Yahoo\", \"DuckDuckGo\")\n)\ngt(ex_sites) %>% \n  text_transform(\n    locations = cells_body(columns = vars(Address)),\n    fn = function(x) {\n    purrr::map(x,  ~htmltools::tags$a(href = .x, target = \"_blank\", .x))\n      }\n  ) %>% \n  text_transform(\n    locations = cells_body(columns = vars(Site)),\n    fn = function(x) {\n    purrr::map2(\n      .x = x, .y = ex_sites$Address, \n      .f = ~glue::glue('<a href=\"{.y}\" target=\"_blank\">{.x}</a>'))\n      }\n  )\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\nAddress\n      Site\n    \n\n\nhttps://google.com\nGoogle\n\n\nhttps://yahoo.com\nYahoo\n\n\nhttps://duckduckgo.com\nDuckDuckGo\n\n\n\n\n\n\nEmbed data\nWhile gt tables can be beautiful, it’s often best to also include the raw data for download. You can see how to do this with Markdown or HTML thanks to Bob Rudis’ example.\n\nwrite.csv2(mtcars, \"./file.csv\")\n\nencoded <- readLines(\"./file.csv\") %>% \n  paste0(collapse=\"\\n\") %>% \n  openssl::base64_encode() -> encoded\n\nThe raw markdown could be embedded in a Shiny app or RMarkdown document as seen below.\n[Download CSV](data:text/csv;base64,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)\nOr you can embed it as HTML using the html_csv object as seen above/below.\n\nhtml_encode <- sprintf('data:text/csv;base64,%s', encoded)\nhtml_csv <- glue::glue(\n  \"<a download='mtcars.csv' href='{html_encode}'>CSV Download</a>\"\n  )\n\nhead(mtcars) %>% \n  gt() %>% \n  tab_source_note(html(html_csv))\n\n\n\n\n\n\nmpg\n      cyl\n      disp\n      hp\n      drat\n      wt\n      qsec\n      vs\n      am\n      gear\n      carb\n    \n\n\n21.0\n6\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\n21.0\n6\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\n22.8\n4\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\n21.4\n6\n258\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\n18.7\n8\n360\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\n18.1\n6\n225\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\n\nCSV Download\n    \n\n\n\n\n\nYou can make this process a bit easier with the downloadthis R package. It supports csv, Excel and even .rds files! It also takes care of the “download button”, and supports Bootstrap button styles. H/t to Kyle Cuilla for the suggestion and Jonathan Regenstein for the ask of how to do this.\n\nlibrary(downloadthis)\n\nhead(mtcars) %>%\n  gt() %>%\n  tab_source_note(\n    mtcars %>%\n      download_this(\n        output_name = \"mtcars\",\n        output_extension = \".csv\", # CSV output\n        button_label = \"Download csv\",\n        button_type = \"default\",\n      )\n  )\n\n\n\n\n\n\nmpg\n      cyl\n      disp\n      hp\n      drat\n      wt\n      qsec\n      vs\n      am\n      gear\n      carb\n    \n\n\n21.0\n6\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\n21.0\n6\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\n22.8\n4\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\n21.4\n6\n258\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\n18.7\n8\n360\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\n18.1\n6\n225\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\n\n\n   Download csv\n\n    \n\n\n\n\n\nYou can specify the file/output extension, and the button type to alter the appearance. Note that the code works inline as seen above, or defined in an external object as seen below.\n\nattach_excel <- mtcars %>%\n  download_this(\n    output_name = \"mtcars\",\n    output_extension = \".xlsx\", # Excel file type\n    button_label = \"Download Excel\",\n    button_type = \"primary\", # change button type\n  )\n\nhead(mtcars) %>%\n  gt() %>%\n  tab_source_note(attach_excel)\n\n\n\n\n\n\nmpg\n      cyl\n      disp\n      hp\n      drat\n      wt\n      qsec\n      vs\n      am\n      gear\n      carb\n    \n\n\n21.0\n6\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\n21.0\n6\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\n22.8\n4\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\n21.4\n6\n258\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\n18.7\n8\n360\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\n18.1\n6\n225\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\n\n\n   Download Excel\n\n    \n\n\n\n\n\nYou can continue and go one step farther by adding custom styling CSS to the table to affect the button style.\n\nattach_excel <- mtcars %>%\n  download_this(\n    output_name = \"mtcars\",\n    output_extension = \".xlsx\", # Excel file type\n    button_label = \"Download Excel\",\n    class = \"buttonExcel\"\n  )\n\nhead(mtcars) %>%\n  gt() %>%\n  opt_css(\n    css = \"\n    .buttonExcel{\n    font-size: 12px;\n    color: #fff;\n    background-color: black;\n    border-color: black;\n    font-weight: bold;\n    border-radius: 10px;\n    padding: 4px;\n    }\n    \n    .buttonExcel:hover,\n    .buttonExcel:active,\n    .buttonExcel:focus,\n    .buttonExcel.active {\n    background: grey;\n    color: #ffffff;\n    border-color: grey;\n    }\n    \"\n  ) %>% \n  tab_source_note(attach_excel)\n\n\n\n\n\n\nmpg\n      cyl\n      disp\n      hp\n      drat\n      wt\n      qsec\n      vs\n      am\n      gear\n      carb\n    \n\n\n21.0\n6\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\n21.0\n6\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\n22.8\n4\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\n21.4\n6\n258\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\n18.7\n8\n360\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\n18.1\n6\n225\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\n\n\n   Download Excel\n\n    \n\n\n\n\nCombine and stack\nCombine text into div containers and then “stack” the text on top of each other with alternating color.\n\nstack_function <- function(x){\n  \n  name <- sub(x = x, pattern = \" .*$\", replacement = \"\")\n  model <- sub(x = x, pattern = \".*? \", replacement = \"\")\n\n  \n  glue::glue(\n    \"<div style='line-height:10px'>\n    <span style='font-weight:bold;font-variant:small-caps;font-size:14px'>\n    {name}</div>\n    <div style='line-height:12px'>\n    <span style ='font-weight:bold;color:grey;font-size:10px'>\n    {model}</span></div>\"\n  )\n    }\n\nhead(gtcars) %>% \n  dplyr::select(mfr, model, year, trim, hp) %>%\n  gt() %>% \n  cols_merge(\n    columns = vars(mfr, model)\n  ) %>% \n  text_transform(\n    locations = cells_body(\n      columns = vars(mfr)\n    ),\n    fn = stack_function\n  ) %>% \n  tab_options(\n    data_row.padding = px(5),\n  )\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\nmfr\n      year\n      trim\n      hp\n    \n\n\n\n\n\nFord\n\n\n\nGT\n\n\n2017\nBase Coupe\n647\n\n\n\n\n\nFerrari\n\n\n\n458 Speciale\n\n\n2015\nBase Coupe\n597\n\n\n\n\n\nFerrari\n\n\n\n458 Spider\n\n\n2015\nBase\n562\n\n\n\n\n\nFerrari\n\n\n\n458 Italia\n\n\n2014\nBase Coupe\n562\n\n\n\n\n\nFerrari\n\n\n\n488 GTB\n\n\n2016\nBase Coupe\n661\n\n\n\n\n\nFerrari\n\n\n\nCalifornia\n\n\n2015\nBase Convertible\n553\n\n\n\n\n\n\nAlign symbol on first row only\nWe can align text on the first row only even with a suffix (ie symbol at the end). This can be done with just gt, but it’s a bit verbose.\nThis example applies a percent label to the hp_pct column and properly maintains the decimal place alignment.\n\nhead(gtcars) %>%\n  mutate(hp_pct = (hp/max(hp) * 100)) %>% \n  dplyr::select(mfr, model, year, trim, hp, hp_pct) %>%\n  gt() %>%\n  # use a mono-spaced font\n  tab_style(\n    style = cell_text(font = google_font(\"Fira Mono\")),\n    locations = cells_body(columns = vars(hp_pct))\n    ) %>% \n  # align the column of interst to right\n  cols_align(align = \"right\", columns = vars(hp_pct)) %>% \n  # round and transform the first row to percent\n  text_transform(\n    locations = cells_body(vars(hp_pct), rows = 1),\n    fn = function(x){ \n      fmt_val <- format(as.double(x), nsmall = 1, digits = 1)\n      paste0(fmt_val, \"%\") %>% gt::html()}\n  ) %>% \n  text_transform(\n    locations = cells_body(vars(hp_pct), rows = 2:6),\n    fn = function(x){ \n      # round remaining rows, add a non-breaking space\n     fmt_val <- format(as.double(x), nsmall = 1, digits = 1)\n     lapply(fmt_val, function(x) paste0(x, '&nbsp') %>% gt::html())\n  })\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\nmfr\n      model\n      year\n      trim\n      hp\n      hp_pct\n    \n\n\nFord\nGT\n2017\nBase Coupe\n647\n97.9%\n\n\nFerrari\n458 Speciale\n2015\nBase Coupe\n597\n 90.3&nbsp\n\n\nFerrari\n458 Spider\n2015\nBase\n562\n 85.0&nbsp\n\n\nFerrari\n458 Italia\n2014\nBase Coupe\n562\n 85.0&nbsp\n\n\nFerrari\n488 GTB\n2016\nBase Coupe\n661\n100.0&nbsp\n\n\nFerrari\nCalifornia\n2015\nBase Convertible\n553\n 83.7&nbsp\n\n\n\n\n\n\nWe can do the same thing with a custom gt function that we’ll call fmt_symbol_first().\n\nfmt_symbol_first <- function(\n  gt_data,\n  column = NULL,        # column of interest to apply to\n  symbol = NULL,        # symbol to add, optionally\n  suffix = \"\",          # suffix to add, optionally\n  decimals = NULL,      # number of decimal places to round to\n  last_row_n,           # what's the last row in data?\n  symbol_first = FALSE  # symbol before or after suffix?\n) {\n  \n  # Test and error out if mandatory columns are missing\n  stopifnot(\"`symbol_first` argument must be a logical\" = is.logical(symbol_first))\n  stopifnot(\"`last_row_n` argument must be specified and numeric\" = is.numeric(last_row_n))\n  stopifnot(\"Input must be a gt table\" = class(gt_data)[[1]] == \"gt_tbl\")\n\n  # needs to type convert to double to play nicely with decimals and rounding\n  # as it's converted to character by gt::text_transform\n  add_to_first <- function(x, suff = suffix, symb = symbol) {\n    if (!is.null(decimals)) {\n      x <- suppressWarnings(as.double(x))\n      fmt_val <- format(x = x, nsmall = decimals, digits = decimals)\n    } else {\n      fmt_val <- x\n    }\n\n    # combine the value, passed suffix, symbol -> html\n    if (isTRUE(symbol_first)) {\n      paste0(fmt_val, symb, suff) %>% gt::html()\n    } else {\n      paste0(fmt_val, suff, symb) %>% gt::html()\n    }\n  }\n\n  # repeat non-breaking space for combined length of suffix + symbol\n  # logic is based on is a NULL passed or not\n  if (!is.null(symbol) | !identical(as.character(symbol), character(0))) {\n    suffix <- ifelse(identical(as.character(suffix), character(0)), \"\", suffix)\n    length_nbsp <- c(\"&nbsp\", rep(\"&nbsp\", nchar(suffix))) %>%\n      paste0(collapse = \"\")\n  } else {\n    suffix <- ifelse(identical(as.character(suffix), character(0)), \"\", suffix)\n    length_nbsp <- rep(\"&nbsp\", nchar(suffix)) %>%\n      paste0(collapse = \"\")\n  }\n\n  # affect rows OTHER than the first row\n  add_to_remainder <- function(x, length = length_nbsp) {\n    if (!is.null(decimals)) {\n      # if decimal not null, convert to double\n      x <- suppressWarnings(as.double(x))\n      # then round and format ALL to force specific decimals\n      fmt_val <- format(x = x, nsmall = decimals, digits = decimals)\n    } else {\n      fmt_val <- x\n    }\n    paste0(fmt_val, length) %>% lapply(FUN = gt::html)\n  }\n\n  # pass gt object\n  # align right to make sure the spacing is meaningful\n  gt_data %>%\n    cols_align(align = \"right\", columns = vars({{ column }})) %>%\n    # convert to mono-font for column of interest\n    tab_style(\n      style = cell_text(font = google_font(\"Fira Mono\")),\n      locations = cells_body(columns = vars({{ column }}))\n    ) %>%\n    # transform first rows\n    text_transform(\n      locations = cells_body(vars({{ column }}), rows = 1),\n      fn = add_to_first\n    ) %>%\n    # transform remaining rows\n    text_transform(\n      locations = cells_body(vars({{ column }}), rows = 2:last_row_n),\n      fn = add_to_remainder\n    )\n}\n\nApply the custom function.\nWe can then use the function as a one-liner, and format just that column of interest.\n\nhead(gtcars) %>%\n  mutate(hp_pct = (hp/max(hp) * 100)) %>% \n  dplyr::select(mfr, model, year, trim, hp, hp_pct) %>%\n  gt() %>% \n  opt_table_lines() %>% \n  fmt_symbol_first(column = hp_pct, decimals = 1, suffix = \"%\", last_row_n = 6)\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\nmfr\n      model\n      year\n      trim\n      hp\n      hp_pct\n    \n\n\nFord\nGT\n2017\nBase Coupe\n647\n97.9%\n\n\nFerrari\n458 Speciale\n2015\nBase Coupe\n597\n 90.3&nbsp\n\n\nFerrari\n458 Spider\n2015\nBase\n562\n 85.0&nbsp\n\n\nFerrari\n458 Italia\n2014\nBase Coupe\n562\n 85.0&nbsp\n\n\nFerrari\n488 GTB\n2016\nBase Coupe\n661\n100.0&nbsp\n\n\nFerrari\nCalifornia\n2015\nBase Convertible\n553\n 83.7&nbsp\n\n\n\n\n\n\nSparkline plots\nWe can embed sparkline plots with some help from the kableExtra package.\n\nmtcars %>%\n  group_by(cyl) %>%\n  summarize(mpg_data = list(mpg), .groups = \"drop\") %>%\n  gt() %>%\n  text_transform(\n    locations = cells_body(columns = vars(mpg_data)),\n    fn = function(x) {\n      data_in <- purrr::pluck(., \"_data\", \"mpg_data\")\n      plot <- purrr::map(\n        data_in, ~ kableExtra::spec_plot(\n          .x, ylim = range(mtcars$mpg), \n          same_lim = TRUE, width = 300, height = 70\n          )\n        )\n      \n      plot <- purrr::map_chr(plot, \"svg_text\")\n    }\n  )\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\ncyl\n      mpg_data\n    \n\n\n4\n\n\n\n\n\n6\n\n\n\n\n\n8\n\n\n\n\n\n\n\n\n\nCreate a function\nWe can alternatively write a function to do something similar.\n\ngt_plot <- function(table_data, plot_col, data_col, plot_fun, ...){\n  # save the data extract ahead of time \n  # to be used in our anonymous function below\n  data_in = purrr::pluck(table_data, \"_data\", data_col)\n\n  text_transform(\n    table_data,\n    # note the use of {{}} here - this is tidy eval\n    # that allows you to indicate specific columns\n    locations = cells_body(columns = vars({{plot_col}})),\n    fn = function(x){\n      plot <- purrr::map(data_in, plot_fun, width = 300, height = 70, same_lim = FALSE, ...)\n      plot_svg <- purrr::map(plot, \"svg_text\")\n      purrr::map(plot_svg, gt::html)\n    }\n  )\n}\n\nAnd then we can use that function!\n\nmtcars %>% \n  group_by(cyl) %>% \n  summarize(mpg_data = list(mpg), .groups = \"drop\") %>% \n  gt() %>% \n  # note you can leave mpg_data unquoted for the tidyeval\n  # but have to quote mpg_data for the pluck\n  gt_plot(mpg_data, \"mpg_data\", plot_fun = kableExtra::spec_plot)\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\ncyl\n      mpg_data\n    \n\n\n4\n\n\n\n\n\n6\n\n\n\n\n\n8\n\n\n\n\n\n\n\n\n\nInteractive sparklines\nWe can use the sparkline package to embed interactive sparklines.\n\ngt_spark <- function(table_data, plot_col, data_col){\n  # save the data extract ahead of time \n  # to be used in our anonymous function below\n  data_in = purrr::pluck(table_data, \"_data\", data_col)\n  \n  text_transform(\n    table_data,\n    # note the use of {{}} here - this is tidy eval\n    # that allows you to indicate specific columns\n    locations = cells_body(columns = vars({{plot_col}})),\n    fn = function(x){\n      sparkline_plot <- purrr::map(\n        data_in, \n        ~sparkline::spk_chr(values = .x, chartRangeMin = 0)\n        )\n      \n      purrr::map(sparkline_plot, gt::html)\n    }\n  )\n}\n\nWe can then apply the function to work very succinctly, referencing only the internal list-column data.\n\nmtcars %>% \n  group_by(cyl) %>% \n  summarize(mpg_data = list(mpg), .groups = \"drop\") %>% \n  gt() %>% \n  # note you can leave mpg_data unquoted for the tidyeval\n  # but have to quote mpg_data for the pluck\n  gt_spark(mpg_data, \"mpg_data\")\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\ncyl\n      mpg_data\n    \n\n\n4\n\n\n\n\n\n\n6\n\n\n\n\n\n\n8\n\n\n\n\n\n\n\n\n\n\nTooltips\nTooltips can be added with HTML tags.\n\nlibrary(htmltools)\n\n#    \n# Add tooltip to column labels\nwith_tooltip <- function(value, tooltip) {\n  tags$abbr(\n    style = \"text-decoration: underline;\n    text-decoration-style: solid; color: blue\",\n    title = tooltip,\n    value\n  ) %>% \n    as.character()\n}\n\nmtcars %>% \n  head() %>% \n  tibble::rownames_to_column() %>% \n  select(rowname, mpg:hp) %>% \n  gt() %>% \n   cols_label(\n    mpg = gt::html(with_tooltip(\"MPG\", \"Miles per Gallon\")),\n    cyl = gt::html(with_tooltip(\"CYL\", \"Number of Cylinders\")),\n    disp = gt::html(with_tooltip(\"DISP\", \"Displacement\")),\n    hp = gt::html(with_tooltip(\"HP\", \"Horsepower\")),\n  )\n\n\n\n\n\n\n\n      MPG\n      CYL\n      DISP\n      HP\n    \n\n\nMazda RX4\n21.0\n6\n160\n110\n\n\nMazda RX4 Wag\n21.0\n6\n160\n110\n\n\nDatsun 710\n22.8\n4\n108\n93\n\n\nHornet 4 Drive\n21.4\n6\n258\n110\n\n\nHornet Sportabout\n18.7\n8\n360\n175\n\n\nValiant\n18.1\n6\n225\n105\n\n\n\n\n\n\nAdd icons\nYou can add arbitrary icons with the fontawesome R package.\n\nmtcars %>% \n  head() %>% \n  gt() %>% \n  text_transform(\n    locations = cells_body(columns = vars(cyl), rows = cyl == 4),\n    fn = function(x){gt::html(fontawesome::fa(\"truck-pickup\", fill = \"blue\"))}\n  ) %>% \n  text_transform(\n    locations = cells_body(columns = vars(cyl), rows = cyl == 6),\n    fn = function(x){gt::html(fontawesome::fa(\"truck\", fill = \"grey\"))}\n  ) %>% \n  text_transform(\n    locations = cells_body(columns = vars(cyl), rows = cyl == 8),\n    fn = function(x){gt::html(fontawesome::fa(\"truck-monster\", fill = \"red\"))}\n  )\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\nmpg\n      cyl\n      disp\n      hp\n      drat\n      wt\n      qsec\n      vs\n      am\n      gear\n      carb\n    \n\n\n21.0\n\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\n21.0\n\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\n22.8\n\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\n21.4\n\n258\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\n18.7\n\n360\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\n18.1\n\n225\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\n\n\n\n\nAdd rating stars\nYou can take the icons example a step further, and assign rating stars. For this example, we’re creating HTML content in the data itself, before passing it into gt. This example adapted from reactable.\n\n# note you could use ANY font-awesome logo\n# https://fontawesome.com/cheatsheet\nrating_stars <- function(rating, max_rating = 5) {\n  rounded_rating <- floor(rating + 0.5)  # always round up\n  stars <- lapply(seq_len(max_rating), function(i) {\n    if (i <= rounded_rating) fontawesome::fa(\"star\", fill= \"orange\") else fontawesome::fa(\"star\", fill= \"grey\")\n  })\n  label <- sprintf(\"%s out of %s\", rating, max_rating)\n  div_out <- htmltools::div(title = label, \"aria-label\" = label, role = \"img\", stars)\n  \n  as.character(div_out) %>% \n    gt::html()\n}\n\nmtcars %>% \n  slice(1:5) %>% \n  mutate(rating = purrr::map(sample(1:5, size = 5, TRUE), rating_stars)) %>% \n  gt()\n\n\n\n\n\n\nmpg\n      cyl\n      disp\n      hp\n      drat\n      wt\n      qsec\n      vs\n      am\n      gear\n      carb\n      rating\n    \n\n\n21.0\n6\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n  \n\n\n\n21.0\n6\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n  \n\n\n\n22.8\n4\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n  \n\n\n\n21.4\n6\n258\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n  \n\n\n\n18.7\n8\n360\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n  \n\n\n\n\n\n\n\nTags and badges\nAgain we can create a custom function and use purrr::map() to generate the HTML code before passing it into gt. Example adapted from reactable documentation.\n\nadd_cyl_color <- function(cyl){\n      add_color <- if (cyl == 4) {\n        \"background: hsl(116, 60%, 90%); color: hsl(116, 30%, 25%);\"\n      } else if (cyl == 6) {\n        \"background: hsl(230, 70%, 90%); color: hsl(230, 45%, 30%);\"\n      } else if (cyl == 8) {\n        \"background: hsl(350, 70%, 90%); color: hsl(350, 45%, 30%);\"\n      }\n      div_out <- htmltools::div(\n        style = paste(\n          \"display: inline-block; padding: 2px 12px; border-radius: 15px; font-weight: 600; font-size: 12px;\",\n          add_color\n          ),\n        paste(cyl, \"Cylinders\")\n      )\n      \n      as.character(div_out) %>% \n        gt::html()\n}\n\nmtcars %>% \n  head() %>% \n  mutate(cylinder = purrr::map(cyl, add_cyl_color)) %>% \n  gt()\n\n\n\n\n\n\nmpg\n      cyl\n      disp\n      hp\n      drat\n      wt\n      qsec\n      vs\n      am\n      gear\n      carb\n      cylinder\n    \n\n\n21.0\n6\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n6 Cylinders\n\n\n21.0\n6\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n6 Cylinders\n\n\n22.8\n4\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n4 Cylinders\n\n\n21.4\n6\n258\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n6 Cylinders\n\n\n18.7\n8\n360\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n8 Cylinders\n\n\n18.1\n6\n225\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n6 Cylinders\n\n\n\n\n\n\nBadges\nWe can also use badges in a similar way.\n\n\n\n\nadd_badge <- function(x){\n      add_color <- if (x == \"Paid\") {\n        \"background: hsl(116, 60%, 90%); color: hsl(116, 30%, 25%);\"\n      } else if (x == \"Pending\") {\n        \"background: hsl(230, 70%, 90%); color: hsl(230, 45%, 30%);\"\n      } else if (x == \"Canceled\") {\n        \"background: hsl(350, 70%, 90%); color: hsl(350, 45%, 30%);\"\n      }\n      div_out <- htmltools::div(\n        style = paste(\n          \"display: inline-block; padding: 2px 12px; border-radius: 15px; font-weight: 600; font-size: 12px;\",\n          add_color\n          ),\n        x\n      )\n      \n      as.character(div_out) %>% \n        gt::html()\n}\n\n\norders <- data.frame(\n  Order = 2300:2304,\n  Created = seq(as.Date(\"2019-04-01\"), by = \"day\", length.out = 5),\n  Customer = sample(rownames(MASS::painters), 5),\n  Status = sample(c(\"Pending\", \"Paid\", \"Canceled\"), 5, replace = TRUE)\n) %>% \n  mutate(Status = purrr::map(Status, add_badge))\n\norders %>% \n  gt()\n\n\n\n\n\n\nOrder\n      Created\n      Customer\n      Status\n    \n\n\n2300\n2019-04-01\nLanfranco\nPaid\n\n\n2301\n2019-04-02\nVan Leyden\nPaid\n\n\n2302\n2019-04-03\nDa Vinci\nPending\n\n\n2303\n2019-04-04\nCaravaggio\nCanceled\n\n\n2304\n2019-04-05\nPordenone\nCanceled\n\n\n\n\n\n\nExpandable sections\nYou can embed expandable sections with <details> HTML, and we can build up some contents of the details tag with the use of htmltools.\n\nlibrary(htmltools)\n\nsource_details <- paste0(\n  \"<details>\", \"<summary><strong>Table Key, click to expand</strong></summary>\",\n  div(\"cyl: Cylinders\"), div(\"disp: Displacement\"), div(\"hp: Horsepower\"),\n  \"</details\"\n)\n\nhead(mtcars) %>% \n  gt() %>% \n  tab_source_note(source_note = html(source_details))\n\n\n\n\n\n\nmpg\n      cyl\n      disp\n      hp\n      drat\n      wt\n      qsec\n      vs\n      am\n      gear\n      carb\n    \n\n\n21.0\n6\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\n21.0\n6\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\n22.8\n4\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\n21.4\n6\n258\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\n18.7\n8\n360\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\n18.1\n6\n225\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\nTable Key, click to expandcyl: Cylinders\ndisp: Displacement\nhp: Horsepower\n\n\n\n\nBar charts\nThere are different ways to create bar charts, but the example below is adapted from the reactable documentation. The original source on CSS bars using HTML and CSS.\n\nbar_chart <- function(label, height = \"16px\", fill = \"#00bfc4\", background = \"white\") {\n  bar <- glue::glue(\n    \"<div style='background:{fill};width:{label}%;height:{height};'></div>\"\n    )\n  chart <- glue::glue(\n    \"<div style='flex-grow:1;margin-left:8px;background:{background};'>{bar}</div>\"\n  )\n  glue::glue(\n    \"<div style='display:flex;align-items:left';>{chart}</div>\"\n    ) %>%\n  gt::html()\n  \n}\n\nmtcars %>% \n  head() %>% \n  mutate(\n    mpg_val = mpg/max(mpg) * 100,\n    mpg_plot = purrr::map(mpg_val, ~bar_chart(label = .x)),\n    mpg_plot2 = purrr::map(\n      mpg_val, \n      ~bar_chart(label = .x, fill = \"#fc5185\", background = \"#e1e1e1\")\n      ),\n    ) %>% \n  select(cyl, hp, disp, mpg, mpg_plot, mpg_plot2) %>% \n  gt() %>% \n  cols_align(align = \"left\", columns = vars(mpg_plot)) \n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\ncyl\n      hp\n      disp\n      mpg\n      mpg_plot\n      mpg_plot2\n    \n\n\n6\n110\n160\n21.0\n\n\n\n\n6\n110\n160\n21.0\n\n\n\n\n4\n93\n108\n22.8\n\n\n\n\n6\n110\n258\n21.4\n\n\n\n\n8\n175\n360\n18.7\n\n\n\n\n6\n105\n225\n18.1\n\n\n\n\n\n\n\n\nEmbed images\nThe function provides a convenient way to generate an HTML fragment with an image URL. Because this function is currently HTML-based, it is only useful for HTML table output. To use this function inside of data cells, it is recommended that the text_transform() function is used.\n\nr_png_url <- \"https://www.r-project.org/logo/Rlogo.png\"\n\ndplyr::tibble(\n    pixels = px(seq(10, 20, 5)),\n    image = seq(10, 20, 5)\n  ) %>%\n  gt() %>%\n  text_transform(\n    locations = cells_body(vars(image)),\n    fn = function(x) {\n      web_image(\n        url = r_png_url,\n        height = as.numeric(x)\n      )\n    }\n  )\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\npixels\n      image\n    \n\n\n10px\n\n\n\n15px\n\n\n\n20px\n\n\n\n\n\n\n\nMore images\nYou can include multiple images by parsing the url along with purrr::map() or lapply()\n\ntibble::tribble(\n  ~team_abb, ~headshot_href,      ~short_name, ~qbr_total, ~qb_plays,\n       \"GB\",    \"8439.png\",     \"A. Rodgers\",       84.4,       608,\n       \"KC\", \"3139477.png\",     \"P. Mahomes\",       82.9,       710,\n      \"BUF\", \"3918298.png\",       \"J. Allen\",       81.7,       729,\n      \"TEN\",   \"14876.png\",   \"R. Tannehill\",       78.3,       594\n  ) %>% \n  mutate(\n    headshot_href = paste0(\n      \"https://a.espncdn.com/i/headshots/nfl/players/full/\", headshot_href\n      )\n    ) %>% \n  gt() %>%\n  text_transform(\n    locations = cells_body(vars(headshot_href)),\n    fn = function(x) {purrr::map(x,~ web_image(url = .x, height = 30))}\n  )\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\nteam_abb\n      headshot_href\n      short_name\n      qbr_total\n      qb_plays\n    \n\n\nGB\n\nA. Rodgers\n84.4\n608\n\n\nKC\n\nP. Mahomes\n82.9\n710\n\n\nBUF\n\nJ. Allen\n81.7\n729\n\n\nTEN\n\nR. Tannehill\n78.3\n594"
  },
  {
    "objectID": "static/resources/gt-cookbook-advanced.html#gt-functions",
    "href": "static/resources/gt-cookbook-advanced.html#gt-functions",
    "title": "gt cookbook - advanced",
    "section": "\ngt functions",
    "text": "gt functions\nThis section assumes that you become familiar with the {{ var }} syntax, known as “embrace” or “curly curly”. This allows the tidy-evaluation of bare names. A brief example below with a custom function.\n\nex_function <- function(column){\n  mtcars %>% \n    # provide the embrace around the variable name\n    # and it can be parsed by tidy-eval\n    group_by({{ column }}) %>% \n    summarize(mean = mean(mpg)) %>% \n    ungroup()\n}\n\nex_function(cyl)\n\n# A tibble: 3 × 2\n    cyl  mean\n  <dbl> <dbl>\n1     4  26.7\n2     6  19.7\n3     8  15.1\n\n\nWhile that example shows the usage of {{ var }}, you can also read a bit more in the rlang docs.\nBasic functions\nYou can create repeatable functions with a specific purpose relatively easily with gt.\n\ncar_table <- function(grouping){\n  mtcars %>% \n    head() %>% \n    gt(groupname_col = grouping) %>% \n    opt_row_striping() %>% \n    tab_options(\n      data_row.padding = px(4)\n    ) %>% \n    tab_style(\n      style = list(\n        cell_fill(color = \"black\"),\n        cell_text(color = \"white\", weight = \"bold\")\n      ),\n      locations = cells_row_groups()\n    )\n}\n\ncar_table(\"am\")\n\n\n\n\n\n\nmpg\n      cyl\n      disp\n      hp\n      drat\n      wt\n      qsec\n      vs\n      gear\n      carb\n    \n\n\n1\n    \n\n21.0\n6\n160\n110\n3.90\n2.620\n16.46\n0\n4\n4\n\n\n21.0\n6\n160\n110\n3.90\n2.875\n17.02\n0\n4\n4\n\n\n22.8\n4\n108\n93\n3.85\n2.320\n18.61\n1\n4\n1\n\n\n0\n    \n\n21.4\n6\n258\n110\n3.08\n3.215\n19.44\n1\n3\n1\n\n\n18.7\n8\n360\n175\n3.15\n3.440\n17.02\n0\n3\n2\n\n\n18.1\n6\n225\n105\n2.76\n3.460\n20.22\n1\n3\n1\n\n\n\n\n\n\n\nThese can be even useful with datasets that are similar in structure (ie same columns), but change week to week, for example reports.\n\ncar_table <- function(data_in){\n  # provide data_in as an argument, so that the table is similar\n  # but the data itself can change\n  data_in %>% \n    gt(groupname_col = \"cyl\") %>% \n    opt_row_striping() %>% \n    tab_options(\n      data_row.padding = px(4)\n    ) %>% \n    tab_style(\n      style = list(\n        cell_fill(color = \"black\"),\n        cell_text(color = \"white\", weight = \"bold\")\n      ),\n      locations = cells_row_groups()\n    )\n}\n\nmtcars %>% \n  slice_sample(n = 12) %>% \n  car_table()\n\n\n\n\n\n\nmpg\n      disp\n      hp\n      drat\n      wt\n      qsec\n      vs\n      am\n      gear\n      carb\n    \n\n\n6\n    \n\n21.0\n160.0\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\n19.7\n145.0\n175\n3.62\n2.770\n15.50\n0\n1\n5\n6\n\n\n8\n    \n\n15.0\n301.0\n335\n3.54\n3.570\n14.60\n0\n1\n5\n8\n\n\n10.4\n472.0\n205\n2.93\n5.250\n17.98\n0\n0\n3\n4\n\n\n15.8\n351.0\n264\n4.22\n3.170\n14.50\n0\n1\n5\n4\n\n\n19.2\n400.0\n175\n3.08\n3.845\n17.05\n0\n0\n3\n2\n\n\n14.7\n440.0\n230\n3.23\n5.345\n17.42\n0\n0\n3\n4\n\n\n4\n    \n\n30.4\n95.1\n113\n3.77\n1.513\n16.90\n1\n1\n5\n2\n\n\n22.8\n108.0\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\n21.4\n121.0\n109\n4.11\n2.780\n18.60\n1\n1\n4\n2\n\n\n26.0\n120.3\n91\n4.43\n2.140\n16.70\n0\n1\n5\n2\n\n\n30.4\n75.7\n52\n4.93\n1.615\n18.52\n1\n1\n4\n2"
  },
  {
    "objectID": "static/resources/gt-cookbook-advanced.html#create-a-theme",
    "href": "static/resources/gt-cookbook-advanced.html#create-a-theme",
    "title": "gt cookbook - advanced",
    "section": "Create a theme",
    "text": "Create a theme\nCreating a theme is similar to a normal function and can be done by passing in a gt object, and setting some parameters in various gt functions. Here we define a basic theme.\n\nmy_gt_theme <- function(data, ...) {\n  data %>%\n    tab_options(\n      table.background.color = \"black\",\n      column_labels.background.color = \"grey\",\n      column_labels.font.size = px(16),\n      table.font.size = px(12),\n      data_row.padding = px(4),\n      ...\n    )\n}\n\nAnd we can then apply that theme. Note that the theme is intentionally relative garish but we can see that we turned some of the arguments into a one-liner.\n\nhead(gtcars) %>% \n  gt() %>% \n  my_gt_theme(table.font.color.light = \"lightgreen\")\n\n\n\n\n\n\nmfr\n      model\n      year\n      trim\n      bdy_style\n      hp\n      hp_rpm\n      trq\n      trq_rpm\n      mpg_c\n      mpg_h\n      drivetrain\n      trsmn\n      ctry_origin\n      msrp\n    \n\n\nFord\nGT\n2017\nBase Coupe\ncoupe\n647\n6250\n550\n5900\n11\n18\nrwd\n7a\nUnited States\n447000\n\n\nFerrari\n458 Speciale\n2015\nBase Coupe\ncoupe\n597\n9000\n398\n6000\n13\n17\nrwd\n7a\nItaly\n291744\n\n\nFerrari\n458 Spider\n2015\nBase\nconvertible\n562\n9000\n398\n6000\n13\n17\nrwd\n7a\nItaly\n263553\n\n\nFerrari\n458 Italia\n2014\nBase Coupe\ncoupe\n562\n9000\n398\n6000\n13\n17\nrwd\n7a\nItaly\n233509\n\n\nFerrari\n488 GTB\n2016\nBase Coupe\ncoupe\n661\n8000\n561\n3000\n15\n22\nrwd\n7a\nItaly\n245400\n\n\nFerrari\nCalifornia\n2015\nBase Convertible\nconvertible\n553\n7500\n557\n4750\n16\n23\nrwd\n7a\nItaly\n198973\n\n\n\n\n\n\nExample Theme\nA “prettier” theme based off an ESPN table style.\n\ngt_theme_espn <- function(data, ...){\n  data %>% \n    opt_all_caps()  %>%\n    opt_table_font(\n      font = list(\n        google_font(\"Lato\"),\n        default_fonts()\n      )\n    )  %>% \n    opt_row_striping() %>% \n    tab_options(\n      row.striping.background_color = \"#fafafa\",\n      table_body.hlines.color = \"#f6f7f7\",\n      source_notes.font.size = 12,\n      table.font.size = 16,\n      table.width = px(700),\n      heading.align = \"left\",\n      heading.title.font.size = 24,\n      table.border.top.color = \"transparent\",\n      table.border.top.width = px(3),\n      data_row.padding = px(7),\n      ...\n    ) \n}\n\n\nhead(gtcars) %>% \n  dplyr::select(mfr:mpg_c) %>% \n  gt() %>% \n  gt_theme_espn()\n\n\n\n\n\nmfr\n      model\n      year\n      trim\n      bdy_style\n      hp\n      hp_rpm\n      trq\n      trq_rpm\n      mpg_c\n    \n\n\nFord\nGT\n2017\nBase Coupe\ncoupe\n647\n6250\n550\n5900\n11\n\n\nFerrari\n458 Speciale\n2015\nBase Coupe\ncoupe\n597\n9000\n398\n6000\n13\n\n\nFerrari\n458 Spider\n2015\nBase\nconvertible\n562\n9000\n398\n6000\n13\n\n\nFerrari\n458 Italia\n2014\nBase Coupe\ncoupe\n562\n9000\n398\n6000\n13\n\n\nFerrari\n488 GTB\n2016\nBase Coupe\ncoupe\n661\n8000\n561\n3000\n15\n\n\nFerrari\nCalifornia\n2015\nBase Convertible\nconvertible\n553\n7500\n557\n4750\n16\n\n\n\n\nFiveThirtyEight Theme\nMy favorite tables come from FiveThirtyEight, so here is an example theme that closely follows their style.\n\ngt_theme_538 <- function(data,...) {\n  data %>%\n  opt_all_caps()  %>%\n  opt_table_font(\n    font = list(\n      google_font(\"Chivo\"),\n      default_fonts()\n    )\n  ) %>%\n    tab_style(\n      style = cell_borders(\n        sides = \"bottom\", color = \"transparent\", weight = px(2)\n      ),\n      locations = cells_body(\n        columns = TRUE,\n        # This is a relatively sneaky way of changing the bottom border\n        # Regardless of data size\n        rows = nrow(data$`_data`)\n      )\n    )  %>% \n  tab_options(\n    column_labels.background.color = \"white\",\n    table.border.top.width = px(3),\n    table.border.top.color = \"transparent\",\n    table.border.bottom.color = \"transparent\",\n    table.border.bottom.width = px(3),\n    column_labels.border.top.width = px(3),\n    column_labels.border.top.color = \"transparent\",\n    column_labels.border.bottom.width = px(3),\n    column_labels.border.bottom.color = \"black\",\n    data_row.padding = px(3),\n    source_notes.font.size = 12,\n    table.font.size = 16,\n    heading.align = \"left\",\n    ...\n  ) \n}\n\n\nhead(gtcars) %>% \n  dplyr::select(mfr:mpg_c) %>% \n  gt() %>% \n  gt_theme_538() \n\nWarning: `columns = TRUE` has been deprecated in gt 0.3.0:\n* please use `columns = everything()` instead\n\n\n\n\nmfr\n      model\n      year\n      trim\n      bdy_style\n      hp\n      hp_rpm\n      trq\n      trq_rpm\n      mpg_c\n    \n\n\nFord\nGT\n2017\nBase Coupe\ncoupe\n647\n6250\n550\n5900\n11\n\n\nFerrari\n458 Speciale\n2015\nBase Coupe\ncoupe\n597\n9000\n398\n6000\n13\n\n\nFerrari\n458 Spider\n2015\nBase\nconvertible\n562\n9000\n398\n6000\n13\n\n\nFerrari\n458 Italia\n2014\nBase Coupe\ncoupe\n562\n9000\n398\n6000\n13\n\n\nFerrari\n488 GTB\n2016\nBase Coupe\ncoupe\n661\n8000\n561\n3000\n15\n\n\nFerrari\nCalifornia\n2015\nBase Convertible\nconvertible\n553\n7500\n557\n4750\n16"
  },
  {
    "objectID": "static/resources/gt-cookbook-advanced.html#tidy-eval",
    "href": "static/resources/gt-cookbook-advanced.html#tidy-eval",
    "title": "gt cookbook - advanced",
    "section": "Tidy eval",
    "text": "Tidy eval\nNow, I want to preface this by saying that the entire tidyeval framework used in gt is currently under active development to be more closely aligned with the tidyverse. You’ll note the relatively legacy use of vars() inside gt.\nMost of this is only required for creating your own functions, although there are some sharp edges around specifying columns in vars().\nFor some nice reading about tidyeval beyond the scope of just gt, see:\n\n\nAdvanced R - book\n\nTidyeval - book\n\nTo start off, let’s revisit an example from the cookbook. First we’ll prep the data.\n\ndimnames <- list(start(nottem)[1]:end(nottem)[1], month.abb)\ntemps <- matrix(nottem, ncol = 12, byrow = TRUE, dimnames = dimnames) %>% \n  data.frame() %>% \n  tibble::rownames_to_column() %>% \n  head(10)\n\ntemps %>% \n  tibble()\n\n# A tibble: 10 × 13\n   rowname   Jan   Feb   Mar   Apr   May   Jun   Jul   Aug   Sep   Oct   Nov\n   <chr>   <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n 1 1920     40.6  40.8  44.4  46.7  54.1  58.5  57.7  56.4  54.3  50.5  42.9\n 2 1921     44.2  39.8  45.1  47    54.1  58.7  66.3  59.9  57    54.2  39.7\n 3 1922     37.5  38.7  39.5  42.1  55.7  57.8  56.8  54.3  54.3  47.1  41.8\n 4 1923     41.8  40.1  42.9  45.8  49.2  52.7  64.2  59.6  54.4  49.2  36.3\n 5 1924     39.3  37.5  38.3  45.5  53.2  57.7  60.8  58.2  56.4  49.8  44.4\n 6 1925     40    40.5  40.8  45.1  53.8  59.4  63.5  61    53    50    38.1\n 7 1926     39.2  43.4  43.4  48.9  50.6  56.8  62.5  62    57.5  46.7  41.6\n 8 1927     39.4  38.5  45.3  47.1  51.7  55    60.4  60.5  54.7  50.3  42.3\n 9 1928     40.8  41.1  42.8  47.3  50.9  56.4  62.2  60.5  55.4  50.2  43  \n10 1929     34.8  31.3  41    43.9  53.1  56.9  62.5  60.3  59.8  49.2  42.9\n# … with 1 more variable: Dec <dbl>\n\n\n\nWe’ll also define our “Hulk palette” as a function.\n\nhulk_pal <- function(x){\n  scales::col_numeric(\n      colorspace::diverge_hcl(n = 9, palette = \"Purple-Green\") %>% rev(), \n      domain = range(nottem)\n      )(x)\n}\n\nThis function supplies a number or a vector of numbers to generate colors.\n\n# January is cold\ntemps$Jan %>% hulk_pal() %>%  scales::show_col()\n\n\n\n\n\n# June is warm\ntemps$Jun %>% hulk_pal() %>%  scales::show_col()\n\n\n\n\nSequence of columns\nYou may typically use something like Jan:Dec to indicate the columns from Jan TO Dec, but this won’t work in vars(). This throws an error Error: Can't convert a call to a string. However we can accomplish similar things through other techniques.\n\ntemps %>% \n  gt() %>% \n  data_color(\n    # note use of sequence\n    columns = vars(Jan:Dec),\n    colors = hulk_pal\n  )\n\n#> Error: Can't convert a call to a string\n\nRaw strings\nYou can pass raw strings into vars(). Since our names of the columns are month abbreviation, we can take advantage of the built in month.abb string.\n\nmonth.abb\n\n [1] \"Jan\" \"Feb\" \"Mar\" \"Apr\" \"May\" \"Jun\" \"Jul\" \"Aug\" \"Sep\" \"Oct\" \"Nov\" \"Dec\"\n\n\nWe can compare the code for the below, note the use of month.abb first or manually naming ALL the column names second.\n\ntemps %>% \n  gt() %>% \n  data_color(\n    # note use of month.abb\n    columns = vars(month.abb),\n    colors = hulk_pal\n  )\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\nNote: Using an external vector in selections is ambiguous.\nℹ Use `all_of(month.abb)` instead of `month.abb` to silence this message.\nℹ See <https://tidyselect.r-lib.org/reference/faq-external-vector.html>.\nThis message is displayed once per session.\n\n\n\n\n\n\n\n\n      Jan\n      Feb\n      Mar\n      Apr\n      May\n      Jun\n      Jul\n      Aug\n      Sep\n      Oct\n      Nov\n      Dec\n    \n\n\n1920\n40.6\n40.8\n44.4\n46.7\n54.1\n58.5\n57.7\n56.4\n54.3\n50.5\n42.9\n39.8\n\n\n1921\n44.2\n39.8\n45.1\n47.0\n54.1\n58.7\n66.3\n59.9\n57.0\n54.2\n39.7\n42.8\n\n\n1922\n37.5\n38.7\n39.5\n42.1\n55.7\n57.8\n56.8\n54.3\n54.3\n47.1\n41.8\n41.7\n\n\n1923\n41.8\n40.1\n42.9\n45.8\n49.2\n52.7\n64.2\n59.6\n54.4\n49.2\n36.3\n37.6\n\n\n1924\n39.3\n37.5\n38.3\n45.5\n53.2\n57.7\n60.8\n58.2\n56.4\n49.8\n44.4\n43.6\n\n\n1925\n40.0\n40.5\n40.8\n45.1\n53.8\n59.4\n63.5\n61.0\n53.0\n50.0\n38.1\n36.3\n\n\n1926\n39.2\n43.4\n43.4\n48.9\n50.6\n56.8\n62.5\n62.0\n57.5\n46.7\n41.6\n39.8\n\n\n1927\n39.4\n38.5\n45.3\n47.1\n51.7\n55.0\n60.4\n60.5\n54.7\n50.3\n42.3\n35.2\n\n\n1928\n40.8\n41.1\n42.8\n47.3\n50.9\n56.4\n62.2\n60.5\n55.4\n50.2\n43.0\n37.3\n\n\n1929\n34.8\n31.3\n41.0\n43.9\n53.1\n56.9\n62.5\n60.3\n59.8\n49.2\n42.9\n41.9\n\n\n\n\n\n\n\n\ntemps %>% \n  gt() %>% \n  data_color(\n    columns = vars(\n      Jan, Feb, Mar, Apr, May, Jun, \n      Jul, Aug, Sep, Oct, Nov, Dec\n      ),\n    colors = hulk_pal\n  )\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\n\n      Jan\n      Feb\n      Mar\n      Apr\n      May\n      Jun\n      Jul\n      Aug\n      Sep\n      Oct\n      Nov\n      Dec\n    \n\n\n1920\n40.6\n40.8\n44.4\n46.7\n54.1\n58.5\n57.7\n56.4\n54.3\n50.5\n42.9\n39.8\n\n\n1921\n44.2\n39.8\n45.1\n47.0\n54.1\n58.7\n66.3\n59.9\n57.0\n54.2\n39.7\n42.8\n\n\n1922\n37.5\n38.7\n39.5\n42.1\n55.7\n57.8\n56.8\n54.3\n54.3\n47.1\n41.8\n41.7\n\n\n1923\n41.8\n40.1\n42.9\n45.8\n49.2\n52.7\n64.2\n59.6\n54.4\n49.2\n36.3\n37.6\n\n\n1924\n39.3\n37.5\n38.3\n45.5\n53.2\n57.7\n60.8\n58.2\n56.4\n49.8\n44.4\n43.6\n\n\n1925\n40.0\n40.5\n40.8\n45.1\n53.8\n59.4\n63.5\n61.0\n53.0\n50.0\n38.1\n36.3\n\n\n1926\n39.2\n43.4\n43.4\n48.9\n50.6\n56.8\n62.5\n62.0\n57.5\n46.7\n41.6\n39.8\n\n\n1927\n39.4\n38.5\n45.3\n47.1\n51.7\n55.0\n60.4\n60.5\n54.7\n50.3\n42.3\n35.2\n\n\n1928\n40.8\n41.1\n42.8\n47.3\n50.9\n56.4\n62.2\n60.5\n55.4\n50.2\n43.0\n37.3\n\n\n1929\n34.8\n31.3\n41.0\n43.9\n53.1\n56.9\n62.5\n60.3\n59.8\n49.2\n42.9\n41.9\n\n\n\n\n\n\nNumbered\nNow you can skip using vars() and the named column and just supply the column number. This is a great usecase if you have a lot of columns that need to be used and want a low-effort way of indicating.\n\ntemps %>% \n  gt() %>% \n  data_color(\n    columns = 2:13,\n    colors = hulk_pal\n  )\n\n\n\n\n\n\n\n      Jan\n      Feb\n      Mar\n      Apr\n      May\n      Jun\n      Jul\n      Aug\n      Sep\n      Oct\n      Nov\n      Dec\n    \n\n\n1920\n40.6\n40.8\n44.4\n46.7\n54.1\n58.5\n57.7\n56.4\n54.3\n50.5\n42.9\n39.8\n\n\n1921\n44.2\n39.8\n45.1\n47.0\n54.1\n58.7\n66.3\n59.9\n57.0\n54.2\n39.7\n42.8\n\n\n1922\n37.5\n38.7\n39.5\n42.1\n55.7\n57.8\n56.8\n54.3\n54.3\n47.1\n41.8\n41.7\n\n\n1923\n41.8\n40.1\n42.9\n45.8\n49.2\n52.7\n64.2\n59.6\n54.4\n49.2\n36.3\n37.6\n\n\n1924\n39.3\n37.5\n38.3\n45.5\n53.2\n57.7\n60.8\n58.2\n56.4\n49.8\n44.4\n43.6\n\n\n1925\n40.0\n40.5\n40.8\n45.1\n53.8\n59.4\n63.5\n61.0\n53.0\n50.0\n38.1\n36.3\n\n\n1926\n39.2\n43.4\n43.4\n48.9\n50.6\n56.8\n62.5\n62.0\n57.5\n46.7\n41.6\n39.8\n\n\n1927\n39.4\n38.5\n45.3\n47.1\n51.7\n55.0\n60.4\n60.5\n54.7\n50.3\n42.3\n35.2\n\n\n1928\n40.8\n41.1\n42.8\n47.3\n50.9\n56.4\n62.2\n60.5\n55.4\n50.2\n43.0\n37.3\n\n\n1929\n34.8\n31.3\n41.0\n43.9\n53.1\n56.9\n62.5\n60.3\n59.8\n49.2\n42.9\n41.9\n\n\n\n\n\n\nNames\nYou can subset the names of the column but without using tidyeval must assign it to an object to use it inside vars().\n\ncols_affect <- names(temps)[2:13]\n\ntemps %>% \n  gt() %>% \n  data_color(\n    columns = vars(cols_affect),\n    colors = hulk_pal\n  )\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\nNote: Using an external vector in selections is ambiguous.\nℹ Use `all_of(cols_affect)` instead of `cols_affect` to silence this message.\nℹ See <https://tidyselect.r-lib.org/reference/faq-external-vector.html>.\nThis message is displayed once per session.\n\n\n\n\n\n\n\n\n      Jan\n      Feb\n      Mar\n      Apr\n      May\n      Jun\n      Jul\n      Aug\n      Sep\n      Oct\n      Nov\n      Dec\n    \n\n\n1920\n40.6\n40.8\n44.4\n46.7\n54.1\n58.5\n57.7\n56.4\n54.3\n50.5\n42.9\n39.8\n\n\n1921\n44.2\n39.8\n45.1\n47.0\n54.1\n58.7\n66.3\n59.9\n57.0\n54.2\n39.7\n42.8\n\n\n1922\n37.5\n38.7\n39.5\n42.1\n55.7\n57.8\n56.8\n54.3\n54.3\n47.1\n41.8\n41.7\n\n\n1923\n41.8\n40.1\n42.9\n45.8\n49.2\n52.7\n64.2\n59.6\n54.4\n49.2\n36.3\n37.6\n\n\n1924\n39.3\n37.5\n38.3\n45.5\n53.2\n57.7\n60.8\n58.2\n56.4\n49.8\n44.4\n43.6\n\n\n1925\n40.0\n40.5\n40.8\n45.1\n53.8\n59.4\n63.5\n61.0\n53.0\n50.0\n38.1\n36.3\n\n\n1926\n39.2\n43.4\n43.4\n48.9\n50.6\n56.8\n62.5\n62.0\n57.5\n46.7\n41.6\n39.8\n\n\n1927\n39.4\n38.5\n45.3\n47.1\n51.7\n55.0\n60.4\n60.5\n54.7\n50.3\n42.3\n35.2\n\n\n1928\n40.8\n41.1\n42.8\n47.3\n50.9\n56.4\n62.2\n60.5\n55.4\n50.2\n43.0\n37.3\n\n\n1929\n34.8\n31.3\n41.0\n43.9\n53.1\n56.9\n62.5\n60.3\n59.8\n49.2\n42.9\n41.9\n\n\n\n\n\n\nNames + !!!\n\nIf you use tidyeval’s bang-bang-bang operator (!!!), then you can parse the R code inside the vars() call.\n\ntemps %>% \n  gt() %>% \n  data_color(\n    columns = vars(!!!names(temps)[2:13]),\n    colors = hulk_pal\n  )\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\n\n      Jan\n      Feb\n      Mar\n      Apr\n      May\n      Jun\n      Jul\n      Aug\n      Sep\n      Oct\n      Nov\n      Dec\n    \n\n\n1920\n40.6\n40.8\n44.4\n46.7\n54.1\n58.5\n57.7\n56.4\n54.3\n50.5\n42.9\n39.8\n\n\n1921\n44.2\n39.8\n45.1\n47.0\n54.1\n58.7\n66.3\n59.9\n57.0\n54.2\n39.7\n42.8\n\n\n1922\n37.5\n38.7\n39.5\n42.1\n55.7\n57.8\n56.8\n54.3\n54.3\n47.1\n41.8\n41.7\n\n\n1923\n41.8\n40.1\n42.9\n45.8\n49.2\n52.7\n64.2\n59.6\n54.4\n49.2\n36.3\n37.6\n\n\n1924\n39.3\n37.5\n38.3\n45.5\n53.2\n57.7\n60.8\n58.2\n56.4\n49.8\n44.4\n43.6\n\n\n1925\n40.0\n40.5\n40.8\n45.1\n53.8\n59.4\n63.5\n61.0\n53.0\n50.0\n38.1\n36.3\n\n\n1926\n39.2\n43.4\n43.4\n48.9\n50.6\n56.8\n62.5\n62.0\n57.5\n46.7\n41.6\n39.8\n\n\n1927\n39.4\n38.5\n45.3\n47.1\n51.7\n55.0\n60.4\n60.5\n54.7\n50.3\n42.3\n35.2\n\n\n1928\n40.8\n41.1\n42.8\n47.3\n50.9\n56.4\n62.2\n60.5\n55.4\n50.2\n43.0\n37.3\n\n\n1929\n34.8\n31.3\n41.0\n43.9\n53.1\n56.9\n62.5\n60.3\n59.8\n49.2\n42.9\n41.9\n\n\n\n\n\n\nStrings\nYou can pass raw strings to vars() and separate them by commas.\n\ntemps %>% \n  gt() %>% \n  data_color(\n    columns = vars(\"Jan\", \"Feb\"),\n    colors = hulk_pal\n  )\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\n\n      Jan\n      Feb\n      Mar\n      Apr\n      May\n      Jun\n      Jul\n      Aug\n      Sep\n      Oct\n      Nov\n      Dec\n    \n\n\n1920\n40.6\n40.8\n44.4\n46.7\n54.1\n58.5\n57.7\n56.4\n54.3\n50.5\n42.9\n39.8\n\n\n1921\n44.2\n39.8\n45.1\n47.0\n54.1\n58.7\n66.3\n59.9\n57.0\n54.2\n39.7\n42.8\n\n\n1922\n37.5\n38.7\n39.5\n42.1\n55.7\n57.8\n56.8\n54.3\n54.3\n47.1\n41.8\n41.7\n\n\n1923\n41.8\n40.1\n42.9\n45.8\n49.2\n52.7\n64.2\n59.6\n54.4\n49.2\n36.3\n37.6\n\n\n1924\n39.3\n37.5\n38.3\n45.5\n53.2\n57.7\n60.8\n58.2\n56.4\n49.8\n44.4\n43.6\n\n\n1925\n40.0\n40.5\n40.8\n45.1\n53.8\n59.4\n63.5\n61.0\n53.0\n50.0\n38.1\n36.3\n\n\n1926\n39.2\n43.4\n43.4\n48.9\n50.6\n56.8\n62.5\n62.0\n57.5\n46.7\n41.6\n39.8\n\n\n1927\n39.4\n38.5\n45.3\n47.1\n51.7\n55.0\n60.4\n60.5\n54.7\n50.3\n42.3\n35.2\n\n\n1928\n40.8\n41.1\n42.8\n47.3\n50.9\n56.4\n62.2\n60.5\n55.4\n50.2\n43.0\n37.3\n\n\n1929\n34.8\n31.3\n41.0\n43.9\n53.1\n56.9\n62.5\n60.3\n59.8\n49.2\n42.9\n41.9\n\n\n\n\n\n\nStrings + c()\n\nIF you use a c() you need to use the !!! operator. More details at Advanced R.\n\ntemps %>% \n  gt() %>% \n  data_color(\n    columns = vars(!!!c(\"Jan\", \"Feb\")),\n    colors = hulk_pal\n  )\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\n\n      Jan\n      Feb\n      Mar\n      Apr\n      May\n      Jun\n      Jul\n      Aug\n      Sep\n      Oct\n      Nov\n      Dec\n    \n\n\n1920\n40.6\n40.8\n44.4\n46.7\n54.1\n58.5\n57.7\n56.4\n54.3\n50.5\n42.9\n39.8\n\n\n1921\n44.2\n39.8\n45.1\n47.0\n54.1\n58.7\n66.3\n59.9\n57.0\n54.2\n39.7\n42.8\n\n\n1922\n37.5\n38.7\n39.5\n42.1\n55.7\n57.8\n56.8\n54.3\n54.3\n47.1\n41.8\n41.7\n\n\n1923\n41.8\n40.1\n42.9\n45.8\n49.2\n52.7\n64.2\n59.6\n54.4\n49.2\n36.3\n37.6\n\n\n1924\n39.3\n37.5\n38.3\n45.5\n53.2\n57.7\n60.8\n58.2\n56.4\n49.8\n44.4\n43.6\n\n\n1925\n40.0\n40.5\n40.8\n45.1\n53.8\n59.4\n63.5\n61.0\n53.0\n50.0\n38.1\n36.3\n\n\n1926\n39.2\n43.4\n43.4\n48.9\n50.6\n56.8\n62.5\n62.0\n57.5\n46.7\n41.6\n39.8\n\n\n1927\n39.4\n38.5\n45.3\n47.1\n51.7\n55.0\n60.4\n60.5\n54.7\n50.3\n42.3\n35.2\n\n\n1928\n40.8\n41.1\n42.8\n47.3\n50.9\n56.4\n62.2\n60.5\n55.4\n50.2\n43.0\n37.3\n\n\n1929\n34.8\n31.3\n41.0\n43.9\n53.1\n56.9\n62.5\n60.3\n59.8\n49.2\n42.9\n41.9\n\n\n\n\n\n\nFunctions\nFunctions require some special subsets of tidyeval. There are multiple ways to approach this with the current implementation of tidyeval, although this will hopefully become even more robust over time as the gt team continues to develop the package.\nPass the dots\nFor representing multiple columns at once, you can just “pass the dots” into the function. More details about the dots.\n\ncolor_columns <- function(data_in, ..., palette = hulk_pal) {\n  data_in %>%\n    gt() %>%\n    data_color(\n      columns = vars(...),\n      colors = palette\n    )\n}\n\ncolor_columns(temps, Jan, Feb, Mar, Apr, May, Jun)\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\n\n      Jan\n      Feb\n      Mar\n      Apr\n      May\n      Jun\n      Jul\n      Aug\n      Sep\n      Oct\n      Nov\n      Dec\n    \n\n\n1920\n40.6\n40.8\n44.4\n46.7\n54.1\n58.5\n57.7\n56.4\n54.3\n50.5\n42.9\n39.8\n\n\n1921\n44.2\n39.8\n45.1\n47.0\n54.1\n58.7\n66.3\n59.9\n57.0\n54.2\n39.7\n42.8\n\n\n1922\n37.5\n38.7\n39.5\n42.1\n55.7\n57.8\n56.8\n54.3\n54.3\n47.1\n41.8\n41.7\n\n\n1923\n41.8\n40.1\n42.9\n45.8\n49.2\n52.7\n64.2\n59.6\n54.4\n49.2\n36.3\n37.6\n\n\n1924\n39.3\n37.5\n38.3\n45.5\n53.2\n57.7\n60.8\n58.2\n56.4\n49.8\n44.4\n43.6\n\n\n1925\n40.0\n40.5\n40.8\n45.1\n53.8\n59.4\n63.5\n61.0\n53.0\n50.0\n38.1\n36.3\n\n\n1926\n39.2\n43.4\n43.4\n48.9\n50.6\n56.8\n62.5\n62.0\n57.5\n46.7\n41.6\n39.8\n\n\n1927\n39.4\n38.5\n45.3\n47.1\n51.7\n55.0\n60.4\n60.5\n54.7\n50.3\n42.3\n35.2\n\n\n1928\n40.8\n41.1\n42.8\n47.3\n50.9\n56.4\n62.2\n60.5\n55.4\n50.2\n43.0\n37.3\n\n\n1929\n34.8\n31.3\n41.0\n43.9\n53.1\n56.9\n62.5\n60.3\n59.8\n49.2\n42.9\n41.9\n\n\n\n\n\n\nWrapper\nSimilarly, this could just be a wrapper around data_color alone, rather than the full gt pipeline.\n\ndata_color_cols <- function(gt_data, ..., palette = hulk_pal) {\n  gt_data %>%\n    data_color(\n      columns = vars(...),\n      colors = palette\n    )\n}\n\ntemps %>% \n  gt() %>% \n  data_color_cols(Jan, Feb, Mar, Apr, May, Jun)\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\n\n      Jan\n      Feb\n      Mar\n      Apr\n      May\n      Jun\n      Jul\n      Aug\n      Sep\n      Oct\n      Nov\n      Dec\n    \n\n\n1920\n40.6\n40.8\n44.4\n46.7\n54.1\n58.5\n57.7\n56.4\n54.3\n50.5\n42.9\n39.8\n\n\n1921\n44.2\n39.8\n45.1\n47.0\n54.1\n58.7\n66.3\n59.9\n57.0\n54.2\n39.7\n42.8\n\n\n1922\n37.5\n38.7\n39.5\n42.1\n55.7\n57.8\n56.8\n54.3\n54.3\n47.1\n41.8\n41.7\n\n\n1923\n41.8\n40.1\n42.9\n45.8\n49.2\n52.7\n64.2\n59.6\n54.4\n49.2\n36.3\n37.6\n\n\n1924\n39.3\n37.5\n38.3\n45.5\n53.2\n57.7\n60.8\n58.2\n56.4\n49.8\n44.4\n43.6\n\n\n1925\n40.0\n40.5\n40.8\n45.1\n53.8\n59.4\n63.5\n61.0\n53.0\n50.0\n38.1\n36.3\n\n\n1926\n39.2\n43.4\n43.4\n48.9\n50.6\n56.8\n62.5\n62.0\n57.5\n46.7\n41.6\n39.8\n\n\n1927\n39.4\n38.5\n45.3\n47.1\n51.7\n55.0\n60.4\n60.5\n54.7\n50.3\n42.3\n35.2\n\n\n1928\n40.8\n41.1\n42.8\n47.3\n50.9\n56.4\n62.2\n60.5\n55.4\n50.2\n43.0\n37.3\n\n\n1929\n34.8\n31.3\n41.0\n43.9\n53.1\n56.9\n62.5\n60.3\n59.8\n49.2\n42.9\n41.9\n\n\n\n\n\n\nFunction + Strings\nIf you’d like to avoid using ... or would prefer strings, you can pass raw strings vars() and use !!! to parse the vector of strings.\n\ndata_color_cols <- function(gt_data, columns, palette = hulk_pal) {\n\n  gt_data %>%\n    data_color(\n      columns = vars(!!!columns),\n      colors = palette\n    )\n}\n\ntemps %>% \n  gt() %>% \n  data_color_cols(columns = c(\"Jan\", \"Feb\", \"Mar\"))\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\n\n      Jan\n      Feb\n      Mar\n      Apr\n      May\n      Jun\n      Jul\n      Aug\n      Sep\n      Oct\n      Nov\n      Dec\n    \n\n\n1920\n40.6\n40.8\n44.4\n46.7\n54.1\n58.5\n57.7\n56.4\n54.3\n50.5\n42.9\n39.8\n\n\n1921\n44.2\n39.8\n45.1\n47.0\n54.1\n58.7\n66.3\n59.9\n57.0\n54.2\n39.7\n42.8\n\n\n1922\n37.5\n38.7\n39.5\n42.1\n55.7\n57.8\n56.8\n54.3\n54.3\n47.1\n41.8\n41.7\n\n\n1923\n41.8\n40.1\n42.9\n45.8\n49.2\n52.7\n64.2\n59.6\n54.4\n49.2\n36.3\n37.6\n\n\n1924\n39.3\n37.5\n38.3\n45.5\n53.2\n57.7\n60.8\n58.2\n56.4\n49.8\n44.4\n43.6\n\n\n1925\n40.0\n40.5\n40.8\n45.1\n53.8\n59.4\n63.5\n61.0\n53.0\n50.0\n38.1\n36.3\n\n\n1926\n39.2\n43.4\n43.4\n48.9\n50.6\n56.8\n62.5\n62.0\n57.5\n46.7\n41.6\n39.8\n\n\n1927\n39.4\n38.5\n45.3\n47.1\n51.7\n55.0\n60.4\n60.5\n54.7\n50.3\n42.3\n35.2\n\n\n1928\n40.8\n41.1\n42.8\n47.3\n50.9\n56.4\n62.2\n60.5\n55.4\n50.2\n43.0\n37.3\n\n\n1929\n34.8\n31.3\n41.0\n43.9\n53.1\n56.9\n62.5\n60.3\n59.8\n49.2\n42.9\n41.9\n\n\n\n\n\n\nEmbrace\nThe embracing operator {{ }} can be used for single columns.\n\ncolor_column <- function(data_in, column, palette = hulk_pal) {\n\n  data_in %>%\n    gt() %>%\n    data_color(\n      columns = vars({{column}}),\n      colors = palette\n    )\n}\n\ncolor_columns(temps, Jun)\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\n\n      Jan\n      Feb\n      Mar\n      Apr\n      May\n      Jun\n      Jul\n      Aug\n      Sep\n      Oct\n      Nov\n      Dec\n    \n\n\n1920\n40.6\n40.8\n44.4\n46.7\n54.1\n58.5\n57.7\n56.4\n54.3\n50.5\n42.9\n39.8\n\n\n1921\n44.2\n39.8\n45.1\n47.0\n54.1\n58.7\n66.3\n59.9\n57.0\n54.2\n39.7\n42.8\n\n\n1922\n37.5\n38.7\n39.5\n42.1\n55.7\n57.8\n56.8\n54.3\n54.3\n47.1\n41.8\n41.7\n\n\n1923\n41.8\n40.1\n42.9\n45.8\n49.2\n52.7\n64.2\n59.6\n54.4\n49.2\n36.3\n37.6\n\n\n1924\n39.3\n37.5\n38.3\n45.5\n53.2\n57.7\n60.8\n58.2\n56.4\n49.8\n44.4\n43.6\n\n\n1925\n40.0\n40.5\n40.8\n45.1\n53.8\n59.4\n63.5\n61.0\n53.0\n50.0\n38.1\n36.3\n\n\n1926\n39.2\n43.4\n43.4\n48.9\n50.6\n56.8\n62.5\n62.0\n57.5\n46.7\n41.6\n39.8\n\n\n1927\n39.4\n38.5\n45.3\n47.1\n51.7\n55.0\n60.4\n60.5\n54.7\n50.3\n42.3\n35.2\n\n\n1928\n40.8\n41.1\n42.8\n47.3\n50.9\n56.4\n62.2\n60.5\n55.4\n50.2\n43.0\n37.3\n\n\n1929\n34.8\n31.3\n41.0\n43.9\n53.1\n56.9\n62.5\n60.3\n59.8\n49.2\n42.9\n41.9\n\n\n\n\n\n\nWrapper\nSimilarly, this could just be a wrapper around data_color alone, rather than the full gt pipeline.\n\ndata_color_col <- function(gt_data, column, palette = hulk_pal) {\n\n  gt_data %>%\n    data_color(\n      columns = vars({{column}}),\n      colors = palette\n    )\n}\n\ntemps %>% \n  gt() %>% \n  data_color_col(column = Jun)\n\nWarning: `columns = vars(...)` has been deprecated in gt 0.3.0:\n* please use `columns = c(...)` instead\n\n\n\n\n\n\n\n\n      Jan\n      Feb\n      Mar\n      Apr\n      May\n      Jun\n      Jul\n      Aug\n      Sep\n      Oct\n      Nov\n      Dec\n    \n\n\n1920\n40.6\n40.8\n44.4\n46.7\n54.1\n58.5\n57.7\n56.4\n54.3\n50.5\n42.9\n39.8\n\n\n1921\n44.2\n39.8\n45.1\n47.0\n54.1\n58.7\n66.3\n59.9\n57.0\n54.2\n39.7\n42.8\n\n\n1922\n37.5\n38.7\n39.5\n42.1\n55.7\n57.8\n56.8\n54.3\n54.3\n47.1\n41.8\n41.7\n\n\n1923\n41.8\n40.1\n42.9\n45.8\n49.2\n52.7\n64.2\n59.6\n54.4\n49.2\n36.3\n37.6\n\n\n1924\n39.3\n37.5\n38.3\n45.5\n53.2\n57.7\n60.8\n58.2\n56.4\n49.8\n44.4\n43.6\n\n\n1925\n40.0\n40.5\n40.8\n45.1\n53.8\n59.4\n63.5\n61.0\n53.0\n50.0\n38.1\n36.3\n\n\n1926\n39.2\n43.4\n43.4\n48.9\n50.6\n56.8\n62.5\n62.0\n57.5\n46.7\n41.6\n39.8\n\n\n1927\n39.4\n38.5\n45.3\n47.1\n51.7\n55.0\n60.4\n60.5\n54.7\n50.3\n42.3\n35.2\n\n\n1928\n40.8\n41.1\n42.8\n47.3\n50.9\n56.4\n62.2\n60.5\n55.4\n50.2\n43.0\n37.3\n\n\n1929\n34.8\n31.3\n41.0\n43.9\n53.1\n56.9\n62.5\n60.3\n59.8\n49.2\n42.9\n41.9"
  },
  {
    "objectID": "static/resources/resources.html",
    "href": "static/resources/resources.html",
    "title": " ",
    "section": "",
    "text": "Title\n\n\nDescription\n\n\n\n\n\n100 Women - BBC\n\n\nAn interactive {reactable} table based off the 100 women of 2020\n\n\n\n\ngt cookbook\n\n\nA cookbook of core examples with extending {gt}\n\n\n\n\ngt cookbook - advanced\n\n\nA cookbook of advanced examples with extending {gt}\n\n\n\n\n{nflseedR} table\n\n\nAn interactive {reactable} table with {nflseedR} data, styled like FiveThirtyEight\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "static/resources/resources.html#presentations",
    "href": "static/resources/resources.html#presentations",
    "title": " ",
    "section": "Presentations",
    "text": "Presentations"
  },
  {
    "objectID": "static/resources/resources.html#random",
    "href": "static/resources/resources.html#random",
    "title": " ",
    "section": "Random",
    "text": "Random\nFavorite Cocktail Recipes"
  },
  {
    "objectID": "static/resources/100-women.html",
    "href": "static/resources/100-women.html",
    "title": "100 Women - BBC",
    "section": "",
    "text": "The BBC has revealed its list of 100 inspiring and influential women from around the world for 2020.\n\n\nThis year 100 Women is highlighting those who are leading change and making a difference during these turbulent times.\nThe list includes Sanna Marin, who leads Finland's all-female coalition government, Michelle Yeoh, star of the new Avatar and Marvel films and Sarah Gilbert, who heads the Oxford University research into a coronavirus vaccine, as well as Jane Fonda, a climate activist and actress.\nAnd in an extraordinary year, when countless women around the world have made a sacrifice to help others, the first place on the list is left open to acknowledge their work and to remember those who have lost their lives while making a difference.\n\n\n\n\n\n\n\n\nThe BBC's 100 Women of 2020\nThough BBC 100 Women cannot name every woman across the globe who has made a contribution, the 'First Spot' missing from the list of 100 is designed to allow you to think of the people who have had an impact on you, over the course of 2020.\n\n\n\n\n\nSource: \nBBC"
  },
  {
    "objectID": "static/resources/nflseedr.html",
    "href": "static/resources/nflseedr.html",
    "title": "{nflseedR} table",
    "section": "",
    "text": "2020 NFL Simulations\nTeam points simulated based off team QBR (QuarterBack Rating) via {nflseedR}\n\n\n\nSimulation by @thomas_mock via 1,000 {nflseedR} simulated games"
  },
  {
    "objectID": "posts/2022-06-22-magick-overlay/index.html",
    "href": "posts/2022-06-22-magick-overlay/index.html",
    "title": "Add a semi-transparent overlay to an image with {magick}",
    "section": "",
    "text": "I often find myself needing to apply a semi-transparent overlay in slides or reports to provide a better backdrop for text on top of a hero/splash image.\nYou can apply an overlay with CSS + background-image + gradients, but let’s do it natively in R with magick as that gives us more flexibility outside of a HTML environment."
  },
  {
    "objectID": "posts/2022-06-22-magick-overlay/index.html#get-an-image",
    "href": "posts/2022-06-22-magick-overlay/index.html#get-an-image",
    "title": "Add a semi-transparent overlay to an image with {magick}",
    "section": "Get an image",
    "text": "Get an image\nI’ll load magick and read in an example image of my coworker dog Howard.\n\nlibrary(magick)\n\nLinking to ImageMagick 6.9.12.3\nEnabled features: cairo, fontconfig, freetype, heic, lcms, pango, raw, rsvg, webp\nDisabled features: fftw, ghostscript, x11\n\nlibrary(scales)\n\nraw_img <- image_read(\"https://pbs.twimg.com/media/EabpU96WsAIJjG0?format=jpg&name=large\")\nraw_img"
  },
  {
    "objectID": "posts/2022-06-22-magick-overlay/index.html#define-overlay-function",
    "href": "posts/2022-06-22-magick-overlay/index.html#define-overlay-function",
    "title": "Add a semi-transparent overlay to an image with {magick}",
    "section": "Define overlay function",
    "text": "Define overlay function\nThe basic idea is to draw a rectangle the exact size of the image OVER the image with some transparency.\nThe create_overlay() function takes a raw image url/path or magick-image and then applies your chosen color to it.\n\ncreate_overlay <- function(img, overlay_color = \"#00000060\", out_file = NULL){\n  if(!(\"magick-image\" %in% class(img))){\n    raw_img <- image_read(img)\n  } else if (\"magick-image\" %in% class(img)){\n    raw_img <- img\n  }\n  \n  # get image dimensions\n  img_info <- image_info(raw_img)\n  \n  # draw the raw image\n  img_overlay <- image_draw(raw_img)\n  # draw a rectangle of equal proportion to the raw image\n  rect(0, 0, img_info$width, img_info$height, col = overlay_color, border = NA)\n  # save the results\n  dev.off()\n  \n  # return it or return + save out\n  if(!is.null(out_file)){\n    image_write(img_overlay, path = out_file)\n    message(paste(\"Image saved as\", out_file))\n    return(img_overlay)\n  } else {\n    return(img_overlay)\n  }\n}\n\nWe can then use the function to apply some colors. Hex codes are typically 6 digits, but you can add transparency by varying the values at the end of string. So #000000 is black but #00000050 is black with 50% transparency.\n\nscales::show_col(c(\"#000000\", paste0(\"#000000\", seq(90, 10, length.out = 5))))\n\n\n\n\nAlternatively, you could use scales::alpha() to convert named colors like \"red\" to their alpha ranges.\n\nscales::alpha(\"red\", seq(1, 0.1, length.out = 6)) |> \n  scales::show_col()"
  },
  {
    "objectID": "posts/2022-06-22-magick-overlay/index.html#compare-the-image",
    "href": "posts/2022-06-22-magick-overlay/index.html#compare-the-image",
    "title": "Add a semi-transparent overlay to an image with {magick}",
    "section": "Compare the image",
    "text": "Compare the image\nNow we can use our function to generate the overlay image but it’s rather large… and I’d like to see it side-by-side with the original for easier comparison. We can use magick::image_append() + magick::image_resize().\n\nfaded_img <- create_overlay(raw_img, overlay_color = scales::alpha(\"black\", 0.4))\nimage_info(faded_img)\n\n  format width height colorspace matte filesize density\n1   JPEG  1536   2048       sRGB  TRUE        0   72x72\n\nimage_append(\n  image_resize(c(raw_img, faded_img), 350)\n)\n\n\n\n\nNow, let’s roll that into another function.\n\ncompare_img <- function(faded_img, img, px = 350){\n  image_append(\n    image_resize(c(img, faded_img), px)\n  )\n}\n\nfaded_compare <- compare_img(faded_img, raw_img)\nfaded_compare\n\n\n\n\nWe can also play around with other colors!\n\ncompare_img(create_overlay(raw_img, scales::alpha(\"red\", 0.15)), raw_img)\n\n\n\ncompare_img(create_overlay(raw_img, scales::alpha(\"yellow\", 0.15)), raw_img)\n\n\n\ncompare_img(create_overlay(raw_img, scales::alpha(\"blue\", 0.15)), raw_img)\n\n\n\n\nLooks great, but we should see how our text looks as well.\n\nadd_text  <- function(img, text = \"Hello there!\", font_size = 50, color = \"white\",\n                      loc = c(\"+175+100\", \"+50+305\")){\n  img |> \n  image_annotate(text, size = font_size, color = color,\n                 location = loc[1], gravity = \"center\") |> \n  image_annotate(text, size = font_size, color = color,\n                 location = loc[2])\n}\n\nfaded_compare |> \n  add_text()\n\n\n\n\nIn my opinion, it’s quite a bit easier to read the text with the faded overlay!\n\n# save it out for use in another article\ncreate_overlay(raw_img, scales::alpha(\"black\", 0.4)) |> \n  image_resize(500) |> \n  image_annotate(\"Goodbye Howard!\", \"center\", size = 60, color = \"white\", \n                 location = \"+0+130\")\n\n\n\n\n\n\n\n\n\n\nExpand for Session Info\n\n\n\n\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.0 (2022-04-22)\n os       macOS Monterey 12.4\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       America/Chicago\n date     2022-08-01\n pandoc   2.18 @ /Applications/RStudio.app/Contents/MacOS/quarto/bin/tools/ (via rmarkdown)\n quarto   1.0.37 @ /usr/local/bin/quarto\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version date (UTC) lib source\n magick      * 2.7.3   2021-08-18 [1] CRAN (R 4.2.0)\n scales      * 1.2.0   2022-04-13 [1] CRAN (R 4.2.0)\n sessioninfo * 1.2.2   2021-12-06 [1] CRAN (R 4.2.0)\n\n [1] /Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/library\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "posts/2022-06-22-magick-overlay/index.html#quick-overlay",
    "href": "posts/2022-06-22-magick-overlay/index.html#quick-overlay",
    "title": "Add a semi-transparent overlay to an image with {magick}",
    "section": "Quick overlay",
    "text": "Quick overlay\nYou can apply a quick overlay of a single color with a simple “one liner” - but we’ll go a bit more custom in case as I’m sure I’ll want to know how someday!\n\nimage_colorize(raw_img, 37, \"black\") |> \n  image_resize(350)"
  },
  {
    "objectID": "posts/2022-07-29-posit/index.html",
    "href": "posts/2022-07-29-posit/index.html",
    "title": "RStudio::conf retrospective",
    "section": "",
    "text": "I wrote this up partially while traveling back home and a bit on Monday morning. It’s a loosely collected aggregation of my thoughts immediately post rstudio::conf.\nA short summary: - We finally got to meet back up in person! - RStudio PBC is now Posit PBC, same people, new name! - Quarto was officially released!\n\nThe name change of RStudio PBC to Posit PBC doesn’t change the humans behind the scenes, it’s simply a way for us to better tell the story of what we’ve been doing for many years.\n\nYou can read more about RStudio’s name change to Posit PBC at:\n\nRStudio blog: RStudio is becoming Posit\n\nOur eventual new homepage at posit.co\n\n\n\n\n\n\n\nNote\n\n\n\nImportantly, the RStudio IDE will stay as RStudio - the name change is to clarify that Posit the company produces many pieces of software, like Connect or Workbench in addition to the RStudio IDE itself."
  },
  {
    "objectID": "posts/2022-07-29-posit/index.html#years-of-waiting",
    "href": "posts/2022-07-29-posit/index.html#years-of-waiting",
    "title": "RStudio::conf retrospective",
    "section": "2 years of waiting",
    "text": "2 years of waiting\nWhile I absolutely think being part of a remote work as the default company is a blessing and a benefit, I still would love to see my coworkers in person a few times a year. The ongoing COVID-19 pandemic meant I saw exactly one coworker from Feb 2020 to July 2022. I was lucky enough to be able to make a trip up to Denver Colorado in Spring of 2021, and see my good friend and long-time coworker Nichole Monhait. My wife and I were able to enjoy an amazing weekend hiking and checking out breweries there in Denver, and we met up with Nichole at a fantastic spot called “Cerebral Brewing”, which I highly recommend if you’re ever in Denver. The memory also sticks out to me since Cerebral Brewing has an annual event called “Work from Home” - given that I have been full time remote worker for years, I felt connected to this moment in time, celebrating friends, family, and being lucky enough to work from home during a pandemic.\nOutside of that weekend trip, my in-person interaction with the R/Data Science community or fellow RStudio employees was essentially non-existent for over 2 years. While I absolutely want to be a remote worker, I also massively enjoy RStudio “Workweeks” where the entire company gets together for a week to collaborate and meet each other in a fun location. On top of that, I also look forward every year to rstudio::conf and meeting up with the community of data scientists that we serve. Not having either of those events was tough, to say the least. I missed the excitement, the energy, the hard-to-put-into-words “vibes” that the community and coworkers provide at places like rstudio::conf or Workweek. Two years is a long time to wait!\nrstudio::conf delivered above expectations, everyone that I directly observed followed mask rules and we were able to meet in human-space!! I also appreciated the weather being cool enough to eat outdoors, and the brave souls who also stayed outside during meals. It was absolutely fantastic meeting back up with old friends and colleagues, meeting data-Twitter friends for the first time in person, and meeting lots of new Posit coworkers for the first time! I can’t wait for posit::conf 2023!!!"
  },
  {
    "objectID": "posts/2022-07-29-posit/index.html#months-of-quarto",
    "href": "posts/2022-07-29-posit/index.html#months-of-quarto",
    "title": "RStudio::conf retrospective",
    "section": "6 months of Quarto",
    "text": "6 months of Quarto\nStarting in early 2022, I have had the absolute pleasure of also serving as the “deputized” Product Manager of Quarto integration into RStudio Team. Getting to spend so much time with the Quarto dev team, the RStudio Workbench team and the RStudio Connect team has been an absolute highlight and honor of my time at RStudio.\nThe Quarto dev team effort culminated in the first stable release of Quarto v1.0.36 at rstudio::conf, two workshops on Quarto, a keynote by Dr. Mine Çetinkaya-Rundel and Dr. Julia Stewart Lowndes, a presentations on Quarto for presentations and one for websites/blogs, and even one on using Quarto for Python package development with nbdev!\nI’m so excited for the future of Quarto and seeing what the R, Python, Julia, and JavaScript data science communities can do with it!\nFor me directly, I am ecstatic that Quarto is working in RStudio Workbench (RStudio IDE, VSCode, JupyterLab) and in RStudio Connect - we even have nice installation docs! As part of my effort, I also led a “Getting started with Quarto” workshop for a small group of brave learners, and an announcement overview of Quarto in “Quarto for the Curious” to almost 900 attendees.\n\n\n\n\n\n\nNote\n\n\n\nIf I have one piece of advice for new learners of Quarto, it is to embrace the pandoc divs and spans syntax.\n\n\n\n\nA pandoc div is made up of a starting and ending ::: + some .class\n::: {.Some-Class}\nSome Content\n:::\n\nA pandoc span is applied to individuals strings/text as opposed to an entire chunk or paragraph.\nStyled [text]{.Some-Class} and \nplain text."
  },
  {
    "objectID": "posts/2022-07-29-posit/index.html#the-now",
    "href": "posts/2022-07-29-posit/index.html#the-now",
    "title": "RStudio::conf retrospective",
    "section": "The now",
    "text": "The now\nWhile I have always been impressed with all of the amazing software that RStudio has put together, it has always been “about the people” in terms of how and what we are building. RStudio is a company made up of so many humans who follow the ethos of “Kind, Humble, Hungry”. This is so true, that I’ve literally baked that mantra into my R Console, and everytime I restart R, I am greeted with the following message in my RStudio R console:\n ---------------------------------\n [Today is 2022-08-01]\n Using R 4.2.0 \n Be humble, hungry and kind. \n Be so good they can't ignore you.\n ---------------------------------\n\n3 Rules of Robotics\nTo me, RStudio’s culture is literally the espousing of that mantra, almost like our own implementation of Isaac Asimov’s 3 Rules of Robotics11 Wikipedia\n\nA robot may not injure a human being or, through inaction, allow a human being to come to harm.\n\nA robot must obey orders given it by human beings except where such orders would conflict with the First Law.\n\nA robot must protect its own existence as long as such protection does not conflict with the First or Second Law.\n\n\n\nThe 3 Rules of Positrons\n\nBe Kind: The first rule, it’s also the most important. To quote several leaders at RStudio: “There is no room for jerks at RStudio”. The “brilliant jerk” or the “10x toxic programmer” doesn’t have a home here. We still have our share of > 1x programmers, but they’re approaching their work at RStudio with humility and kindness. Kindness also means building with empathy for our users and new learners with rich documentation and examples.\nBe Humble: Build a community and welcome others into it, regardless of where they are in their journey. As someone who is so cross-functional internally, I’m constantly amazed at how humble some of the smartest and most successful teams are at RStudio. Again, there’s not a desire to “show off” or bring others down to make yourself look better, but rather the default of how can we collaborate and help each other.\nBe Hungry: To be successful in any industry, much less one with so much in the way of startups or existing companies with deep investor backed warbanks, you have to be driven and hungry to accomplish complex tasks. This doesn’t come at the expense of our first two rules (be kind and be humble), but more specifically AFTER, just as Isaac Asimov’s rules of robotics have a specific order.\n\n\n\n\nXKCD - Three Laws of Robotoics\n\n\n\n\nHard work trumps passion\nThe other mantra that I remind myself of every time I open the R Console is “Be so good they can’t ignore you”. This is a quote from Cal Newport’s book of the same name. This is more of a personal mission but could also apply to a company. You can’t simply be excited about a topic and the work gets magically done. I believe you have to put the time in to apply and develop skills in the technical sense (scripting/coding, software engineering, data science, statistics) and in the human sense (empathy, user-friendly documentation, kindness, leading others, running meetings, etc) to be successful. You can and likely will develop a passion for that topic that you spend so much time on, but it wasn’t necessarily some romantic “love at first sight” moment.\nThe name change of RStudio to Posit doesn’t change the mindset of the humans behind the scenes, it’s simply a way for us to better tell the story of what we’ve been doing for many years. We are building a company that wants to meet data scientists where they are, develop amazing tools and frameworks, and both build community and welcome humans from all around to join it. For anyone in the R community with doubts or fear - the number of R developers/contributors at Posit is not decreasing, but rather additional contributors in both R and Python are being added as the company continues to grow. Enhancements to RMarkdown via Quarto apply to all languages, enhancements to"
  },
  {
    "objectID": "posts/2022-07-29-posit/index.html#years-is-a-long-time",
    "href": "posts/2022-07-29-posit/index.html#years-is-a-long-time",
    "title": "RStudio::conf retrospective",
    "section": "10 years is a long time",
    "text": "10 years is a long time\nJoe Cheng’s talk on the “Past and Future of Shiny” was my favorite talk of this year’s conference, and probably my second-favorite talk EVER. Number one will always be JJ’s announcement of RStudio becoming both a B-Corp and a Public Benefit Corp, and literally encoding our mission of “creating free and open-source software for data science, scientific research, and technical communication” into the company’s corporate charter and DNA. Whereas JJ’s talk was a celebration of who we are and what we are becoming, Joe’s talk was one of his own humanity, his own doubts, stresses, and his history, as well as our eventual amazing success all through the lens of Shiny and the community that has made the project so successful.\nJoe’s talk spanned his journey with Shiny over a decade. It celebrated moments of success and moments of almost failure. Ultimately, it ended with the announcement of Shiny for python, expanding the potential impact that both Posit PBC and Shiny itself can have. His talk also announced a lot of the new features like the Shiny UI Editor for R! Again, don’t think of this as less development with R but rather as Posit expands the number of employees, we’re also adding Shiny library developers for both R and Python!\nAugust always holds a special place in my heart, as a symbolic “new year” of my time at RStudio. August 1, 2022 begins the 5th year of my journey at RStudio/Posit PBC - or the halfway mark of my first decade. Sometimes I dream of one day being a keynote speaker at posit::conf - what will my 10 year story be?"
  },
  {
    "objectID": "posts/2022-07-29-posit/index.html#years-is-even-longer",
    "href": "posts/2022-07-29-posit/index.html#years-is-even-longer",
    "title": "RStudio::conf retrospective",
    "section": "100 years is even longer",
    "text": "100 years is even longer\nBuilding a company that will last 100 years is akin to growing trees that we will never feel the shade of. It’s planting seeds and curating for the long term, building the shade and comfort for the next generation rather than simply building for the now and screw the future.\nI was always proud to call RStudio PBC the place I worked, and will continue to be excited to call Posit PBC the place I am now working - because it’s still the same place! While the name may have changed, the humans that make up the company have not. We are expanding our focus by adding more employees rather than asking existing core developers to switch their focus."
  },
  {
    "objectID": "posts/2022-11-08-use-r-to-generate-a-quarto-blogpost/index.html",
    "href": "posts/2022-11-08-use-r-to-generate-a-quarto-blogpost/index.html",
    "title": "Use R to generate a Quarto blogpost",
    "section": "",
    "text": "I am a Quarto super fan for many reasons, and use Quarto for my personal blog. As such, I wanted to simplify the process of creating new blog posts for myself, so I wrote a quick function to do just that!\nI used it to write this meta blogpost:\nThis function generates the core skeleton of a Quarto post, including the directory, the index.qmd and writes out some boilerplate information.\nWe’ll use a few packages to get this done."
  },
  {
    "objectID": "posts/2022-11-08-use-r-to-generate-a-quarto-blogpost/index.html#title-of-post",
    "href": "posts/2022-11-08-use-r-to-generate-a-quarto-blogpost/index.html#title-of-post",
    "title": "Use R to generate a Quarto blogpost",
    "section": "Title of post",
    "text": "Title of post\nFor the title, we want to convert a proper title to a kebab case title (kebab-case-like-this), with the date attached as well for easy sorting of folders.\n\ntitle <- \"Use R to generate a Quarto blogpost\"\n# convert to kebab case and remove non space or alphanumeric characters\ntitle_kebab <- stringr::str_to_lower(title) |> \n  stringr::str_remove_all(\"[^[:alnum:][:space:]]\") |> \n  stringr::str_replace_all(\" \", \"-\")\ntitle_kebab\n\n[1] \"use-r-to-generate-a-quarto-blogpost\"\n\n\nWe can add a warning with cli if the title is too long. Too long is subjective, but we can arbitrary say 80 characters. My blog is at https://themockup.blog/posts/ and we want to add the date, so we have about 40 characters to work with.\n\n80 - nchar(\"https://themockup.blog/posts/2022-11-08-\")\n\n[1] 40\n\n\n\ntitle_limit <- 40\n# we can put that into an if() to add the warning if criterion met\nif(nchar(title_kebab) >= title_limit){\n    cli::cli_alert_warning(\"Warning: Title slug is longer than {.val {title_limit}} characters!\")\n}\n\n# we can force it to print like below\ncli::cli_alert_warning(\"Warning: Title slug is longer than {.val {title_limit}} characters!\")\n\n! Warning: Title slug is longer than 40 characters!\n\n\nAfter that, we can add the date and optionally the draft prefix, files with _ at the head are ignored by Quarto. This is largely redundant with the draft: true YAML option - but this safeguards against additional files that could be rendered in that folder.\n\ndraft <- FALSE\ndate <- \"2022-11-08\" #< Sys.Date() for ISO date\nif(draft){\n  slug <- glue::glue(\"posts/_{date}-{title_kebab}\")\n  cli::cli_alert_info(\"Appending a '_' to folder name to avoid render while a draft, remove '_' when finished.\")\n} else {\n  slug <- glue::glue(\"posts/{date}-{title_kebab}\")\n}\n\nslug\n\nposts/2022-11-08-use-r-to-generate-a-quarto-blogpost"
  },
  {
    "objectID": "posts/2022-11-08-use-r-to-generate-a-quarto-blogpost/index.html#create-folder",
    "href": "posts/2022-11-08-use-r-to-generate-a-quarto-blogpost/index.html#create-folder",
    "title": "Use R to generate a Quarto blogpost",
    "section": "Create folder",
    "text": "Create folder\nThe folder name is what will end up as the URL “slug”, so we will end up with a url like:\nhttps://themockup.blog/posts/2022-11-08-use-r-to-generate-a-quarto-blogpost\n\n# create and alert about directory\nfs::dir_create(\n  path = slug\n)\n\n\n# print alert\ncli::cli_alert_success(\"Folder created at {.file {slug}}\")\n\n✔ Folder created at posts/2022-11-08-use-r-to-generate-a-quarto-blogpost"
  },
  {
    "objectID": "posts/2022-11-08-use-r-to-generate-a-quarto-blogpost/index.html#create-blogpost-file-as-index.qmd",
    "href": "posts/2022-11-08-use-r-to-generate-a-quarto-blogpost/index.html#create-blogpost-file-as-index.qmd",
    "title": "Use R to generate a Quarto blogpost",
    "section": "Create blogpost file as index.qmd\n",
    "text": "Create blogpost file as index.qmd\n\nWe want to name our file index.qmd so that our slug is clean as:\nhttps://themockup.blog/posts/2022-11-08-use-r-to-generate-a-quarto-blogpost\ninstead of:\nhttps://themockup.blog/posts/2022-11-08-use-r-to-generate-a-quarto-blogpost/some-file.html\nAdd description and wrap\nWe can take the description and limit the width to <= 80 characters (includes the spacing that YAML needs). We will replace the line breaks \\n with leading spaces AND line breaks \"  \\n\" so that the alignment in the YAML is ok.\n\ndescription <- \"The {cli} and {fs} package make life easy!\"\n# wrap description at 77 characters\ndescription <- stringr::str_wrap(description, width = 77) |> \n  stringr::str_replace_all(\"[\\n]\", \"\\n  \")\ndescription\n\n[1] \"The {cli} and {fs} package make life easy!\"\n\n\nIf the description were long…\n\nlong_desc <- \"  Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum\" |> \n  stringr::str_wrap(width = 77) |> \n  stringr::str_replace_all(\"[\\n]\", \"\\n  \") \n\npaste0(\"description: |\\n  \", long_desc)|> \n  cat()\n\ndescription: |\n  Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod\n  tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam,\n  quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo\n  consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse\n  cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non\n  proident, sunt in culpa qui officia deserunt mollit anim id est laborum"
  },
  {
    "objectID": "posts/2022-11-08-use-r-to-generate-a-quarto-blogpost/index.html#start-file",
    "href": "posts/2022-11-08-use-r-to-generate-a-quarto-blogpost/index.html#start-file",
    "title": "Use R to generate a Quarto blogpost",
    "section": "Start file",
    "text": "Start file\nWe are using our default index.qmd to again avoid increasing the length of the slug.\n\nfile <- \"index.qmd\"\n# start generating file\nnew_post_file <- glue::glue(\"{slug}/{file}\")\nnew_post_file\n\nposts/2022-11-08-use-r-to-generate-a-quarto-blogpost/index.qmd\n\n\nBuild YAML core\nNow we can start building up the YAML, using the glue package to insert the inputs:\n\nauthor <- \"Tom Mock\"\nnew_post_core <- c(\n  \"---\",\n  glue::glue('title: \"{title}\"'),\n  \"description: |\",\n  glue::glue('  {description}'),\n  glue::glue(\"author: {author}\"),\n  glue::glue(\"date: {date}\")\n)\n\nnew_post_core\n\n[1] \"---\"                                           \n[2] \"title: \\\"Use R to generate a Quarto blogpost\\\"\"\n[3] \"description: |\"                                \n[4] \"  The {cli} and {fs} package make life easy!\"  \n[5] \"author: Tom Mock\"                              \n[6] \"date: 2022-11-08\"                              \n\n\nOptionally adding the draft: true YAML option if needed…\n\n# add draft if draft\nif(draft){\n  new_post_text <- c(\n    new_post_core,\n    \"draft: true\",\n    \"---\\n\"\n    )\n} else {\n  new_post_text <- c(\n    new_post_core,\n    \"---\\n\"\n  )\n}\n\nThen we throw it all together and collapse with new lines (\\n):\n\n# finalize new post text\nnew_post_text <- paste0(\n  new_post_text,\n  collapse = \"\\n\"\n  )\n\nnew_post_text |> cat()\n\n---\ntitle: \"Use R to generate a Quarto blogpost\"\ndescription: |\n  The {cli} and {fs} package make life easy!\nauthor: Tom Mock\ndate: 2022-11-08\n---"
  },
  {
    "objectID": "posts/2022-11-08-use-r-to-generate-a-quarto-blogpost/index.html#write-out-to-the-file",
    "href": "posts/2022-11-08-use-r-to-generate-a-quarto-blogpost/index.html#write-out-to-the-file",
    "title": "Use R to generate a Quarto blogpost",
    "section": "Write out to the file",
    "text": "Write out to the file\nWe can create a new file and then write out the YAML, I have this chunk as eval: false right now so that it doesn’t clobber our existing blog post…\n\nfs::file_create(new_post_file) # <- don't want to recreate it :)\nwriteLines(\n  text = new_post_text,\n  con = new_post_file\n  )\n\n\n# create file and alert\n# fs::file_create(new_post_file) <- don't want to recreate it :)\ncli::cli_alert_success(\"File created at {.file {new_post_file}}\")\n\n✔ Folder created at posts/2022-11-08-use-r-to-generate-a-quarto-blogpost\nJust for funsies we can also print out the raw text using cat() to accurately reflect what we’re adding with the new lines and spacing.\n\n# print new post information\ncat(new_post_text)\n\n---\ntitle: \"Use R to generate a Quarto blogpost\"\ndescription: |\n  The {cli} and {fs} package make life easy!\nauthor: Tom Mock\ndate: 2022-11-08\n---\n\n\nThen we can have RStudio open the file we just wrote out!\n\nrstudioapi::documentOpen(new_post_file, line = length(new_post_text))\n\nFor safety, we could use the {yesno} package to prompt the user that the cat() output looks correct:\n\nif(yesno::yesno2(\"\\nDoes that look correct and are you ready to write to disk?\")){\n    writeLines(\n    text = new_post_text,\n    con = new_post_file\n    )\n  \n  rstudioapi::documentOpen(new_post_file, line = length(new_post_text))\n  }\n\nyesno::yesno2(\"\\nDoes that look correct and are you ready to write to disk?\")\nAre you ready to write that to disk?\n1: Yes\n2: No\n\nSelection: 1\n[1] TRUE"
  },
  {
    "objectID": "posts/2022-11-08-use-r-to-generate-a-quarto-blogpost/index.html#all-together",
    "href": "posts/2022-11-08-use-r-to-generate-a-quarto-blogpost/index.html#all-together",
    "title": "Use R to generate a Quarto blogpost",
    "section": "All together",
    "text": "All together\nPutting it all together, we can create a new blogpost rapidly!\n\nnew_post(\n  \"Use R to generate a Quarto blogpost\", \n  description = \"The {cli} and {fs} package make life easy!\",\n  draft = FALSE\n  )\n\n✔ Folder created at posts/2022-11-08-use-r-to-generate-a-quarto-blogpost\n✔ File created at posts/2022-11-08-use-r-to-generate-a-quarto-blogpost/index.qmd\n---\ntitle: \"Use R to generate a Quarto blogpost\"\ndescription: |\n  The {cli} and {fs} package make life easy!\nauthor: Tom Mock\ndate: 2022-11-08\n---\nThe full function!\n\nnew_post <- function(\n    title, \n    file = \"index.qmd\",\n    description = \"\",\n    author = \"Tom Mock\", \n    date = Sys.Date(), \n    draft = FALSE, \n    title_limit = 40,\n    open_file = TRUE\n    ){\n\n  # convert to kebab case and remove non space or alphanumeric characters\n  title_kebab <- stringr::str_to_lower(title) |> \n    stringr::str_remove_all(\"[^[:alnum:][:space:]]\") |> \n    stringr::str_replace_all(\" \", \"-\")\n  \n  # warn if a very long slug\n  if(nchar(title_kebab) >= title_limit){\n    cli::cli_alert_warning(\"Warning: Title slug is longer than {.val {title_limit}} characters!\")\n  }\n  \n  # generate the slug as draft, prefix with _ which prevents\n  # quarto from rendering/recognizing the folder\n  if(draft){\n    slug <- glue::glue(\"posts/_{date}-{title_kebab}\")\n    cli::cli_alert_info(\"Appending a '_' to folder name to avoid render while a draft, remove '_' when finished.\")\n  } else {\n    slug <- glue::glue(\"posts/{date}-{title_kebab}\")\n  }\n  \n  # create and alert about directory\n  fs::dir_create(\n    path = slug\n  )\n  cli::cli_alert_success(\"Folder created at {.file {slug}}\")\n  \n  # wrap description at 77 characters\n  description <- stringr::str_wrap(description, width = 77) |> \n    stringr::str_replace_all(\"[\\n]\", \"\\n  \")\n  \n  # start generating file\n  new_post_file <- glue::glue(\"{slug}/{file}\")\n  \n  # build yaml core\n  new_post_core <- c(\n    \"---\",\n    glue::glue('title: \"{title}\"'),\n    \"description: |\",\n    glue::glue('  {description}'),\n    glue::glue(\"author: {author}\"),\n    glue::glue(\"date: {date}\")\n  )\n  \n  # add draft if draft\n  if(draft){\n    new_post_text <- c(\n      new_post_core,\n      \"draft: true\",\n      \"---\\n\"\n      )\n  } else {\n    new_post_text <- c(\n      new_post_core,\n      \"---\\n\"\n    )\n  }\n  \n  # finalize new post text\n  new_post_text <- paste0(\n    new_post_text,\n    collapse = \"\\n\"\n    )\n  \n  # create file and alert\n  fs::file_create(new_post_file)\n  cli::cli_alert_success(\"File created at {.file {new_post_file}}\")\n  \n  # print new post information\n  cat(new_post_text)\n  \n  if(yesno::yesno2(\"Are you ready to write that to disk?\")){\n    writeLines(\n    text = new_post_text,\n    con = new_post_file\n    )\n  \n  rstudioapi::documentOpen(new_post_file, line = length(new_post_text))\n  } \n  \n}\n\n\n\n\n\n\n\nExpand for Session Info\n\n\n\n\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.0 (2022-04-22)\n os       macOS Monterey 12.6\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       America/Chicago\n date     2022-11-08\n pandoc   2.19.2 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/ (via rmarkdown)\n quarto   1.2.242 @ /usr/local/bin/quarto\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version date (UTC) lib source\n cli         * 3.4.1   2022-09-23 [1] CRAN (R 4.2.0)\n fs          * 1.5.2   2021-12-08 [1] CRAN (R 4.2.0)\n glue        * 1.6.2   2022-02-24 [1] CRAN (R 4.2.0)\n sessioninfo * 1.2.2   2021-12-06 [1] CRAN (R 4.2.0)\n stringr     * 1.4.1   2022-08-20 [1] CRAN (R 4.2.0)\n yesno       * 0.1.2   2020-07-10 [1] CRAN (R 4.2.0)\n\n [1] /Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/library\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "posts/2022-11-16-rolling-summaries-with-slider-in-r/index.html",
    "href": "posts/2022-11-16-rolling-summaries-with-slider-in-r/index.html",
    "title": "Rolling summaries with {slider} in R",
    "section": "",
    "text": "I have been a big fan of the slider package for a long time! It recently had a CRAN release for v0.3 - check out the package documentation at https://slider.r-lib.org/news/index.html.\nWhile it is a useful tool for any time series or rolling summary analysis, I’ll demo an example with some sports data."
  },
  {
    "objectID": "posts/2022-11-16-rolling-summaries-with-slider-in-r/index.html#libraries-and-data",
    "href": "posts/2022-11-16-rolling-summaries-with-slider-in-r/index.html#libraries-and-data",
    "title": "Rolling summaries with {slider} in R",
    "section": "Libraries and data",
    "text": "Libraries and data\nWe’ll use nflreadr to load the nflfastR database, along with the tidyverse and slider itself.\n\nlibrary(tidyverse)\n\n── Attaching packages ────────────────────────────────── tidyverse 1.3.2.9000 ──\n✔ ggplot2   3.4.0      ✔ dplyr     1.0.10\n✔ tibble    3.1.8      ✔ stringr   1.4.1 \n✔ tidyr     1.2.1      ✔ forcats   0.5.1 \n✔ readr     2.1.3      ✔ lubridate 1.8.0 \n✔ purrr     0.3.5      \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(nflreadr)\nlibrary(slider)\nlibrary(ggridges)\nlibrary(ggtext)\n\n# load the years when Mahomes has been active\npbp_db <- nflreadr::load_pbp(2017:2022)"
  },
  {
    "objectID": "posts/2022-11-16-rolling-summaries-with-slider-in-r/index.html#filter-the-data",
    "href": "posts/2022-11-16-rolling-summaries-with-slider-in-r/index.html#filter-the-data",
    "title": "Rolling summaries with {slider} in R",
    "section": "Filter the data",
    "text": "Filter the data\nWe’ll limit ourselves to some of the top QBs in the NFL.\n\nqb_names <- c(\n  \"P.Mahomes\",\n  \"A.Rodgers\",\n  \"J.Allen\",\n  \"D.Prescott\",\n  \"R.Tannehill\",\n  \"D.Carr\",\n  \"R.Wilson\",\n  \"T.Brady\",\n  \"M.Stafford\",\n  \"L.Jackson\",\n  \"M.Ryan\",\n  \"K.Cousins\"\n)\n\nAnd then figure out the last date/week:\n\ncur_date <- pbp_db |> \n  filter(passer_player_name ==\"P.Mahomes\") |> \n  distinct(game_date, .keep_all = TRUE) |> \n  slice_max(game_date, n = 1) |> \n  select(game_date, week, season)\n\nAnd then get the values of interest for these specific QBs.\n\nqb_tops <- pbp_db |>\n  filter(\n    !is.na(epa),\n    play_type %in% c(\"pass\", \"run\")\n  ) |>\n  filter(\n    passer_player_name %in% qb_names |\n      rusher_player_name %in% qb_names,\n  ) |>\n  mutate(\n    name = if_else(\n      is.na(passer_player_name), \n      rusher_player_name, \n      passer_player_name\n      )\n    ) |>\n  select(name, posteam, defteam, season, game_id, epa)\n\nglimpse(qb_tops)\n\nRows: 39,188\nColumns: 6\n$ name    <chr> \"M.Stafford\", \"M.Stafford\", \"M.Stafford\", \"M.Stafford\", \"M.Sta…\n$ posteam <chr> \"DET\", \"DET\", \"DET\", \"DET\", \"DET\", \"DET\", \"DET\", \"DET\", \"DET\",…\n$ defteam <chr> \"ARI\", \"ARI\", \"ARI\", \"ARI\", \"ARI\", \"ARI\", \"ARI\", \"ARI\", \"ARI\",…\n$ season  <int> 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 20…\n$ game_id <chr> \"2017_01_ARI_DET\", \"2017_01_ARI_DET\", \"2017_01_ARI_DET\", \"2017…\n$ epa     <dbl> -11.6032015, -0.5463381, -1.5034251, -1.7764411, -0.1084029, -…\n\n\nThe data is now ready for some analysis! We hae the player’s name, season, game_id and their EPA (expected points added)."
  },
  {
    "objectID": "posts/2022-11-16-rolling-summaries-with-slider-in-r/index.html#slide-across-values",
    "href": "posts/2022-11-16-rolling-summaries-with-slider-in-r/index.html#slide-across-values",
    "title": "Rolling summaries with {slider} in R",
    "section": "Slide across values",
    "text": "Slide across values\nAt a basic level, the slide_ functions allow you to reference a specific row along with previous rows (lagging) and the next rows (leading).\nI find this most useful for rolling summarizing functions such as rolling means. From the slider docs:\n\nslider is a package for rolling analysis using window functions. “Window functions” is a term that I’ve borrowed from SQL that means that some function is repeatedly applied to different “windows” of your data as you step through it. Typical examples of applications of window functions include rolling averages, cumulative sums, and more complex things such as rolling regressions.\n\nMost typically, this will be used within an existing dataframe, but let’s show a quick example on a vector.\nWe can return a list of equal length to the input, that accumulates the current row plus 2 values before it. Note that it slides across the values and won’t return more than the 3 requested (current row + 2 rows before).\nslide() will return a list object.\n\nslide(1:4, ~.x, .before = 2)\n\n[[1]]\n[1] 1\n\n[[2]]\n[1] 1 2\n\n[[3]]\n[1] 1 2 3\n\n[[4]]\n[1] 2 3 4\n\n\nOr more realistically, we can generate the rolling mean of the current row and up to two rows before. Note that I’ve now used slide_dbl() - similar to purrr there is specific type safety, and you specify what you want to return (character, dbl, list as default, etc).\n\nslide_dbl(1:4, mean, .before = 2)\n\n[1] 1.0 1.5 2.0 3.0\n\n\nThis is basically equivalent to the below:\n\nc(\n  mean(1),\n  mean(1:2),\n  mean(1:3),\n  mean(2:4)\n)\n\n[1] 1.0 1.5 2.0 3.0\n\n\nI also want to callout the .complete argument:\n\nShould the function be evaluated on complete windows only? If FALSE, the default, then partial computations will be allowed.\n\n.complete = TRUE will only generate complete computations of the current row and the specific .before or .after amount. See below where we need at least 3 observations to generate the mean, and the first two calculations return NA (since they are length 1 and length 2, respectively.)\n\nslide_dbl(1:4, mean, .before = 2, .complete = TRUE)\n\n[1] NA NA  2  3\n\n\nKind of like the below (but again much more safety/power in slider):\n\nc(\n  ifelse(length(1)   == 3, mean(1),   NA),\n  ifelse(length(1:2) == 3, mean(1:2), NA),\n  ifelse(length(1:3) == 3, mean(1:3), NA),\n  ifelse(length(2:4) == 3, mean(2:4), NA)\n)\n\n[1] NA NA  2  3\n\n\nLastly, there are also specialized functions for typical summaries - great for the most common usecases!\n\nslider::slide_mean(1:4, before = 2)\n\n[1] 1.0 1.5 2.0 3.0\n\nslider::slide_sum(1:4, before = 2)\n\n[1] 1 3 6 9\n\nslider::slide_max(1:4, before = 2, step = 2)\n\n[1]  1 NA  3 NA"
  },
  {
    "objectID": "posts/2022-11-16-rolling-summaries-with-slider-in-r/index.html#slide-across-rows",
    "href": "posts/2022-11-16-rolling-summaries-with-slider-in-r/index.html#slide-across-rows",
    "title": "Rolling summaries with {slider} in R",
    "section": "Slide across rows",
    "text": "Slide across rows\nNow vectors are fine, but we want to use it in a dataframe, across “windows” in a specific column.\nWe can read the below code as: - For each quarterback - Calculate the rolling average of EPA - Of the current row, and the 99 previous rows - and only for .complete windows - so it will return NA for windows < 100\n\ntest_slide <- qb_tops |>\n  group_by(name) |>\n  summarize(\n    slide_mean = slide_dbl(\n      .x = epa, .f = mean, \n      .before = 99L, .complete = TRUE\n      ),\n  )\n\n`summarise()` has grouped output by 'name'. You can override using the\n`.groups` argument.\n\ntest_slide\n\n# A tibble: 39,188 × 2\n# Groups:   name [12]\n   name      slide_mean\n   <chr>          <dbl>\n 1 A.Rodgers         NA\n 2 A.Rodgers         NA\n 3 A.Rodgers         NA\n 4 A.Rodgers         NA\n 5 A.Rodgers         NA\n 6 A.Rodgers         NA\n 7 A.Rodgers         NA\n 8 A.Rodgers         NA\n 9 A.Rodgers         NA\n10 A.Rodgers         NA\n# … with 39,178 more rows\n\n\nNotice that the first few rows are all NA since we have specified .complete = TRUE. For our analysis, we’ll want to exclude NA values after.\nWe can calculate the rolling mean and a lot more!\n\nqb_sum <- qb_tops |>\n  group_by(name) |>\n  summarize(\n    slide_mean = slide_dbl(.x = epa, .f = mean, .before = 99L, .complete = TRUE),\n    slide_median = slide_dbl(.x = epa, .f = median, .before = 99L, .complete = TRUE),\n    slide_sum = slide_dbl(.x = epa, .f = sum, .before = 99L, .complete = TRUE),\n    absolute_median = median(epa),\n    absolute_mean = mean(epa),\n    absolute_sum = sum(epa),\n    posteam = tail(posteam, n = 1)\n  ) |>\n  ungroup() |>\n  filter(!is.na(slide_mean)) |>\n  # sort by the overall best median\n  arrange(desc(absolute_median))\n\n`summarise()` has grouped output by 'name'. You can override using the\n`.groups` argument.\n\nqb_sum |> glimpse()\n\nRows: 38,000\nColumns: 8\n$ name            <chr> \"P.Mahomes\", \"P.Mahomes\", \"P.Mahomes\", \"P.Mahomes\", \"P…\n$ slide_mean      <dbl> 0.4677885, 0.4682522, 0.5148074, 0.4598741, 0.4597226,…\n$ slide_median    <dbl> 0.2908019, 0.2908019, 0.3427478, 0.2908019, 0.2908019,…\n$ slide_sum       <dbl> 46.77885, 46.82522, 51.48074, 45.98741, 45.97226, 45.7…\n$ absolute_median <dbl> 0.1340611, 0.1340611, 0.1340611, 0.1340611, 0.1340611,…\n$ absolute_mean   <dbl> 0.2810101, 0.2810101, 0.2810101, 0.2810101, 0.2810101,…\n$ absolute_sum    <dbl> 993.6518, 993.6518, 993.6518, 993.6518, 993.6518, 993.…\n$ posteam         <chr> \"KC\", \"KC\", \"KC\", \"KC\", \"KC\", \"KC\", \"KC\", \"KC\", \"KC\", …"
  },
  {
    "objectID": "posts/2022-11-16-rolling-summaries-with-slider-in-r/index.html#plot-the-rolling-mean",
    "href": "posts/2022-11-16-rolling-summaries-with-slider-in-r/index.html#plot-the-rolling-mean",
    "title": "Rolling summaries with {slider} in R",
    "section": "Plot the rolling mean",
    "text": "Plot the rolling mean\nWe can then plot the distribution of the rolling mean. First we’ll generate a vector of colors to use for names and then join the team colors to the QB dataframe for plotting.\n\nname_colors <- if_else(\n  unique(qb_sum$name) == \"P.Mahomes\", \n  \"#e31837\", \n  \"black\"\n  ) |> rev()\n\ndens_df <- qb_sum |>\n  group_by(name) |>\n  mutate(\n    median_of_slides = median(slide_mean),\n    fill_color = if_else(name == \"P.Mahomes\", \"#e31837\", \"grey\"),\n    out_color = if_else(name == \"P.Mahomes\", \"#e31837\", \"white\")\n  ) |>\n  ungroup() |>\n  left_join(\n    nflfastR::teams_colors_logos |> select(posteam = team_abbr, team_color),\n    by = \"posteam\"\n  )\n\nThen we can arrange the data by the overall median, create density ridgelines, and add some context.\n\nmahomes_plot <- dens_df |>\n  ggplot(\n    aes(\n      x = slide_mean,\n      y = fct_reorder(name, median_of_slides, .desc = FALSE),\n      fill = team_color\n    )\n  ) +\n  geom_density_ridges(\n    quantile_lines = TRUE,\n    quantiles = 2,\n    color = \"#f0f0f0\",\n    size = 0.5\n  ) +\n  geom_vline(xintercept = 0, linewidth = 1, alpha = 0.5) +\n  coord_cartesian(xlim = c(-0.3, 0.65)) +\n  theme_minimal() +\n  scale_fill_identity(aesthetics = c(\"fill\", \"color\")) +\n  scale_x_continuous(breaks = scales::pretty_breaks(n = 8)) +\n  labs(\n    x = \"Rolling 100 play mean EPA\",\n    y = \"\",\n    caption = \"\\n**Plot**: @thomas_mock | **Data**: nflfastR\",\n    title = \"Mahomes doesn't have bad streaks\",\n    subtitle = glue::glue(\"Distribution of rolling 100 play average passing/running EPA,\\nthrough Week {cur_date$week} of {cur_date$season}\")\n  ) +\n  tomtom::theme_538() +\n  theme(\n    axis.text.y = element_text(\n      color = name_colors,\n      face = c(rep(\"plain\", 16), \"bold\"),\n      size = 14,\n      vjust = 0\n    ),\n    panel.grid.major.y = element_blank(),\n    panel.grid.minor = element_blank(),\n    plot.caption = element_markdown(size = 12),\n    plot.background = element_rect(fill = \"white\", color = \"white\")\n  )\n\nmahomes_plot\n\n\n\n\n\n\n\n\n\n\nExpand for Session Info\n\n\n\n\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.0 (2022-04-22)\n os       macOS Monterey 12.6\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       America/Chicago\n date     2022-11-17\n pandoc   2.19.2 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/ (via rmarkdown)\n quarto   1.2.242 @ /usr/local/bin/quarto\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version    date (UTC) lib source\n dplyr       * 1.0.10     2022-09-01 [1] CRAN (R 4.2.0)\n forcats     * 0.5.1      2021-01-27 [1] CRAN (R 4.2.0)\n ggplot2     * 3.4.0      2022-11-04 [1] CRAN (R 4.2.0)\n ggridges    * 0.5.3      2021-01-08 [1] CRAN (R 4.2.0)\n ggtext      * 0.1.1      2022-09-14 [1] Github (wilkelab/ggtext@50fdaba)\n lubridate   * 1.8.0      2021-10-07 [1] CRAN (R 4.2.0)\n nflreadr    * 1.3.0      2022-08-06 [1] CRAN (R 4.2.0)\n purrr       * 0.3.5      2022-10-06 [1] CRAN (R 4.2.0)\n readr       * 2.1.3      2022-10-01 [1] CRAN (R 4.2.0)\n sessioninfo * 1.2.2      2021-12-06 [1] CRAN (R 4.2.0)\n slider      * 0.2.2      2021-07-01 [1] CRAN (R 4.2.0)\n stringr     * 1.4.1      2022-08-20 [1] CRAN (R 4.2.0)\n tibble      * 3.1.8      2022-07-22 [1] CRAN (R 4.2.0)\n tidyr       * 1.2.1      2022-09-08 [1] CRAN (R 4.2.0)\n tidyverse   * 1.3.2.9000 2022-08-16 [1] Github (tidyverse/tidyverse@3be8283)\n\n [1] /Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/library\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "til.html",
    "href": "til.html",
    "title": "Things I’ve learned and want to remember",
    "section": "",
    "text": "Want to support my blog? \n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nDate\n\n\nTitle\n\n\n\n\n\n\n\n2022-11-27\n\n\ndata.table::rleid() is pretty cool!\n\n\n\n\n2022-11-27\n\n\nPitch sequence aggregation\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "til/rleid.html",
    "href": "til/rleid.html",
    "title": "data.table::rleid() is pretty cool!",
    "section": "",
    "text": "Longer example on QB Starts"
  },
  {
    "objectID": "til/pitches.html",
    "href": "til/pitches.html",
    "title": "Pitch sequence aggregation",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching packages ────────────────────────────────── tidyverse 1.3.2.9000 ──\n✔ ggplot2   3.4.0           ✔ dplyr     1.0.99.9000\n✔ tibble    3.1.8           ✔ stringr   1.4.1      \n✔ tidyr     1.2.1           ✔ forcats   0.5.1      \n✔ readr     2.1.3           ✔ lubridate 1.8.0      \n✔ purrr     0.3.5           \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\npitches <- c(\n  \"Two Seam FB\",\n  \"Cutter\",\n  \"Slider\",\n  \"Knuckleball\",\n  \"Change Up\"\n)\n\n\nset.seed(37)\nfake_pitch <- tibble(\n  at_bat = rep(1:5, each = 3)\n) %>%\n  mutate(pitch_type = sample(pitches, size = 15, replace = TRUE))\n\n# include 1st pitch output\nfake_pitch %>%\n  group_by(at_bat) %>% \n  mutate(pitch_n = row_number()) %>% \n  mutate(\n    pitch_seq = slider::slide2_chr(\n      pitch_type,\n      pitch_n,\n      ~paste(.x,collapse = \"-\"),\n      .before = 1L\n    )\n  ) %>%\n  ungroup()\n\n# A tibble: 15 × 4\n   at_bat pitch_type  pitch_n pitch_seq              \n    <int> <chr>         <int> <chr>                  \n 1      1 Cutter            1 Cutter                 \n 2      1 Slider            2 Cutter-Slider          \n 3      1 Change Up         3 Slider-Change Up       \n 4      2 Knuckleball       1 Knuckleball            \n 5      2 Two Seam FB       2 Knuckleball-Two Seam FB\n 6      2 Knuckleball       3 Two Seam FB-Knuckleball\n 7      3 Knuckleball       1 Knuckleball            \n 8      3 Change Up         2 Knuckleball-Change Up  \n 9      3 Cutter            3 Change Up-Cutter       \n10      4 Knuckleball       1 Knuckleball            \n11      4 Slider            2 Knuckleball-Slider     \n12      4 Two Seam FB       3 Slider-Two Seam FB     \n13      5 Knuckleball       1 Knuckleball            \n14      5 Slider            2 Knuckleball-Slider     \n15      5 Slider            3 Slider-Slider          \n\n\n\n# output NA for 1st pitch\nfake_pitch %>%\n  group_by(at_bat) %>% \n  mutate(pitch_n = row_number()) %>% \n  mutate(\n    pitch_seq = slider::slide2_chr(\n      pitch_type,\n      pitch_n,\n      ~paste(.x,collapse = \"-\"),\n      .before = 1L,\n      .complete = TRUE # force complete measures (at least 2x pitches)\n    )\n  ) %>% \n  ungroup()\n\n# A tibble: 15 × 4\n   at_bat pitch_type  pitch_n pitch_seq              \n    <int> <chr>         <int> <chr>                  \n 1      1 Cutter            1 <NA>                   \n 2      1 Slider            2 Cutter-Slider          \n 3      1 Change Up         3 Slider-Change Up       \n 4      2 Knuckleball       1 <NA>                   \n 5      2 Two Seam FB       2 Knuckleball-Two Seam FB\n 6      2 Knuckleball       3 Two Seam FB-Knuckleball\n 7      3 Knuckleball       1 <NA>                   \n 8      3 Change Up         2 Knuckleball-Change Up  \n 9      3 Cutter            3 Change Up-Cutter       \n10      4 Knuckleball       1 <NA>                   \n11      4 Slider            2 Knuckleball-Slider     \n12      4 Two Seam FB       3 Slider-Two Seam FB     \n13      5 Knuckleball       1 <NA>                   \n14      5 Slider            2 Knuckleball-Slider     \n15      5 Slider            3 Slider-Slider"
  },
  {
    "objectID": "til/pitches.html#plot-it",
    "href": "til/pitches.html#plot-it",
    "title": "Pitch sequence aggregation",
    "section": "Plot it",
    "text": "Plot it\n\nset.seed(37)\n\nfake_pitch <- tibble(\n  at_bat = rep(c(1:5), each = 9),\n  batter = rep(rep(c(\"A.Name\", \"B.Name\", \"C.Name\"), each = 3), 5)\n) %>%\n  mutate(pitch_type = sample(pitches, size = 45, replace = TRUE))\n\nfake_pitch %>%\n  group_by(at_bat) %>% \n  mutate(pitch_n = row_number()) %>% \n  mutate(\n    pitch_seq = slider::slide2_chr(\n      pitch_type,\n      pitch_n,\n      ~paste(.x,collapse = \"-\"),\n      .before = 1L,\n      .complete = TRUE\n    )\n  ) %>% \n  ungroup() %>% \n  count(at_bat, pitch_seq) %>% \n  filter(!is.na(pitch_seq)) %>% \n  group_by(pitch_seq) %>% \n  mutate(roll_n = cumsum(n)) %>% \n  ggplot(aes(x = at_bat, y = roll_n, group = 1)) +\n  geom_step(aes(group = 1), direction = \"hv\") +\n  geom_point() +\n  facet_wrap(~pitch_seq) +\n  scale_y_continuous(limits = c(0, 5))\n\n`geom_path()`: Each group consists of only one observation.\nℹ Do you need to adjust the group aesthetic?\n`geom_path()`: Each group consists of only one observation.\nℹ Do you need to adjust the group aesthetic?\n`geom_path()`: Each group consists of only one observation.\nℹ Do you need to adjust the group aesthetic?\n`geom_path()`: Each group consists of only one observation.\nℹ Do you need to adjust the group aesthetic?\n`geom_path()`: Each group consists of only one observation.\nℹ Do you need to adjust the group aesthetic?\n`geom_path()`: Each group consists of only one observation.\nℹ Do you need to adjust the group aesthetic?\n`geom_path()`: Each group consists of only one observation.\nℹ Do you need to adjust the group aesthetic?\n`geom_path()`: Each group consists of only one observation.\nℹ Do you need to adjust the group aesthetic?\n`geom_path()`: Each group consists of only one observation.\nℹ Do you need to adjust the group aesthetic?"
  },
  {
    "objectID": "til/rleid.html#create-a-dataframe",
    "href": "til/rleid.html#create-a-dataframe",
    "title": "data.table::rleid() is pretty cool!",
    "section": "Create a dataframe",
    "text": "Create a dataframe\n\nlibrary(tidyverse)\n\n── Attaching packages ────────────────────────────────── tidyverse 1.3.2.9000 ──\n✔ ggplot2   3.4.0           ✔ dplyr     1.0.99.9000\n✔ tibble    3.1.8           ✔ stringr   1.4.1      \n✔ tidyr     1.2.1           ✔ forcats   0.5.1      \n✔ readr     2.1.3           ✔ lubridate 1.8.0      \n✔ purrr     0.3.5           \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(magrittr)\n\n\nAttaching package: 'magrittr'\n\nThe following object is masked from 'package:purrr':\n\n    set_names\n\nThe following object is masked from 'package:tidyr':\n\n    extract\n\nlibrary(data.table)\n\n\nAttaching package: 'data.table'\n\nThe following objects are masked from 'package:lubridate':\n\n    hour, isoweek, mday, minute, month, quarter, second, wday, week,\n    yday, year\n\nThe following objects are masked from 'package:dplyr':\n\n    between, first, last\n\nThe following object is masked from 'package:purrr':\n\n    transpose\n\n# create a df of\"streaks\" or repeats\nex_df <- tibble(\n  x = c(\"a\", \"a\", rep(\"b\", 3), rep(\"a\", 5)),\n  num = 1:10\n) \n\n# print the data\nex_df\n\n# A tibble: 10 × 2\n   x       num\n   <chr> <int>\n 1 a         1\n 2 a         2\n 3 b         3\n 4 b         4\n 5 b         5\n 6 a         6\n 7 a         7\n 8 a         8\n 9 a         9\n10 a        10"
  },
  {
    "objectID": "til/rleid.html#example-of-rle-or-run-length-encoding",
    "href": "til/rleid.html#example-of-rle-or-run-length-encoding",
    "title": "data.table::rleid() is pretty cool!",
    "section": "Example of rle or run-length encoding",
    "text": "Example of rle or run-length encoding\n\n# rle or run-length encoding\n# summarizes a vector into the length of each repeat\n# and the value that is repeated\n# technically this is a form of recoverable data compression\n# IE you end up with fewer bytes but it tells you what a long vector\n# could be, and can be recreated\n\n# this can be read as the betters a, b, a\n# where the first a is repeated 2x\n# the b is repeated 3x\n# the next a is repeated 5x\nrle(ex_df$x)\n\nRun Length Encoding\n  lengths: int [1:3] 2 3 5\n  values : chr [1:3] \"a\" \"b\" \"a\""
  },
  {
    "objectID": "til/rleid.html#example-of-rleid",
    "href": "til/rleid.html#example-of-rleid",
    "title": "data.table::rleid() is pretty cool!",
    "section": "Example of rleid",
    "text": "Example of rleid\n\n# rleid() generates the ids or repeated group of equal length\n# to the original vector\n\nex_df$x\n\n [1] \"a\" \"a\" \"b\" \"b\" \"b\" \"a\" \"a\" \"a\" \"a\" \"a\"\n\ndata.table::rleid(ex_df$x)\n\n [1] 1 1 2 2 2 3 3 3 3 3\n\n\n\n# it can be used on a vector, in a dataframe, in a datatable or a tibble\n# note that it can be used within mutate() since it returns\n# a vector of equal length, ie the number of rows is not changed\nex_df %>% \n  mutate(rleid = data.table::rleid(x))\n\n# A tibble: 10 × 3\n   x       num rleid\n   <chr> <int> <int>\n 1 a         1     1\n 2 a         2     1\n 3 b         3     2\n 4 b         4     2\n 5 b         5     2\n 6 a         6     3\n 7 a         7     3\n 8 a         8     3\n 9 a         9     3\n10 a        10     3"
  },
  {
    "objectID": "til/rleid.html#rle-is-a-summary-function",
    "href": "til/rleid.html#rle-is-a-summary-function",
    "title": "data.table::rleid() is pretty cool!",
    "section": "rle is a summary function",
    "text": "rle is a summary function\n\n# note that rle() is a _summary_ function, and generates fewer rows\nex_df %>% \n  summarize(lengths = rle(x)$lengths,\n            values =rle(x)$values)\n\n# A tibble: 3 × 2\n  lengths values\n    <int> <chr> \n1       2 a     \n2       3 b     \n3       5 a"
  },
  {
    "objectID": "til/rleid.html#recover-the-original-data",
    "href": "til/rleid.html#recover-the-original-data",
    "title": "data.table::rleid() is pretty cool!",
    "section": "Recover the original data",
    "text": "Recover the original data\n\n# we can create a summary\n# and then recover the original data\nfinal_df <- ex_df %>% \n  summarize(\n    lengths = rle(x)$lengths,\n    values =rle(x)$values\n    ) %T>% print() %>% \n  summarize(\n    x = rep(values, times=lengths),\n    num = 1:sum(lengths)\n    )\n\n# A tibble: 3 × 2\n  lengths values\n    <int> <chr> \n1       2 a     \n2       3 b     \n3       5 a     \n\n\n\nfinal_df\n\n# A tibble: 10 × 2\n   x       num\n   <chr> <int>\n 1 a         1\n 2 a         2\n 3 b         3\n 4 b         4\n 5 b         5\n 6 a         6\n 7 a         7\n 8 a         8\n 9 a         9\n10 a        10\n\n# original and recreation are identical\nall.equal(final_df, ex_df)\n\n[1] TRUE\n\n\n\n\n\n\n\n\nExpand for Session Info\n\n\n\n\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.0 (2022-04-22)\n os       macOS Monterey 12.6\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       America/Chicago\n date     2022-11-27\n pandoc   2.19.2 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/ (via rmarkdown)\n quarto   1.2.269 @ /usr/local/bin/quarto\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version     date (UTC) lib source\n data.table  * 1.14.3      2022-05-09 [1] Github (Rdatatable/data.table@e9a323d)\n dplyr       * 1.0.99.9000 2022-11-18 [1] Github (tidyverse/dplyr@0a55cf5)\n forcats     * 0.5.1       2021-01-27 [1] CRAN (R 4.2.0)\n ggplot2     * 3.4.0       2022-11-04 [1] CRAN (R 4.2.0)\n lubridate   * 1.8.0       2021-10-07 [1] CRAN (R 4.2.0)\n magrittr    * 2.0.3       2022-03-30 [1] CRAN (R 4.2.0)\n purrr       * 0.3.5       2022-10-06 [1] CRAN (R 4.2.0)\n readr       * 2.1.3       2022-10-01 [1] CRAN (R 4.2.0)\n sessioninfo * 1.2.2       2021-12-06 [1] CRAN (R 4.2.0)\n stringr     * 1.4.1       2022-08-20 [1] CRAN (R 4.2.0)\n tibble      * 3.1.8       2022-07-22 [1] CRAN (R 4.2.0)\n tidyr       * 1.2.1       2022-09-08 [1] CRAN (R 4.2.0)\n tidyverse   * 1.3.2.9000  2022-08-16 [1] Github (tidyverse/tidyverse@3be8283)\n\n [1] /Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/library\n\n──────────────────────────────────────────────────────────────────────────────"
  }
]