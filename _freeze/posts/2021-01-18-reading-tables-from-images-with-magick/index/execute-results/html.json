{
  "hash": "e4f7b122e65c7d4eeb37af1d2c8b3036",
  "result": {
    "markdown": "---\ntitle: \"Reading tables from images with magick\"\ndescription: |\n  magick is an R package for manipulating images in R\nauthor: Thomas Mock\ndate: 01-18-2021\nimage: norm_normal_file_format.png\ncategories:\n  - magick\n  - web scraping\n---\n\n\n\n\n# ImageMagick\n\n[ImageMagick](https://imagemagick.org/index.php) is a robust and comprehensive open-source image processing library, and per the official [docs](https://imagemagick.org/index.php):\n\n> Use ImageMagick® to create, edit, compose, or convert bitmap images. It can read and write images in a variety of formats (over 200) including PNG, JPEG, GIF, HEIC, TIFF, DPX, EXR, WebP, Postscript, PDF, and SVG. ImageMagick can resize, flip, mirror, rotate, distort, shear and transform images, adjust image colors, apply various special effects, or draw text, lines, polygons, ellipses and Bézier curves.\n\nWhile you can use it from various APIs, tools or CLIs, one of the easiest ways for R users to get started is with the R wrapper by ROpenSci's Jeroen Ooms called [`magick`](https://docs.ropensci.org/magick/index.html). This package provides a large set of pipe-friendly functions allowing for interactive editing and testing.\n\nI've written briefly about `magick` before, specifically in using it to [add logos to final `ggplot2` images](https://themockup.blog/posts/2019-01-09-add-a-logo-to-your-plot/), but today will be a different use-case, namely using `magick` to read data embedded in images.\n\nAnother note is that while the docs for `ImageMagick` proper and the `magick` R wrapper are very good, `ImageMagick` is an entire piece of software. This means that there is an amazing breadth of applications, knowledge, and tricks to apply. I think of it a lot like `regex`, where it's very useful but for many applications we only scratch the surface. For a nice \"cookbook\" for using `ImageMagick`, check out this [resource](https://legacy.imagemagick.org/Usage/). It's a \"legacy\" guide, but many of the examples can be converted to `magick` in R or from the CLI itself.\n\n# The problem\n\nThere are many times where someone shares data as an image, whether intentionally due to software constraints (ie Twitter) or as a result of not understanding the implications (image inside a PDF or in a Word Doc). [xkcd.com](https://xkcd.com/2116/) jokingly refers to this as `.norm` or as the Normal File Format. While it's far from ideal or a _real_ file format, it's all too common to see data as images in the \"wild\". \nI'll be using some examples from Twitter images and extracting the raw data from these. There are multiple levels of difficulty, namely that screenshots on Twitter are not uniform, often of relatively low quality (ie DPI), and contain additional \"decoration\" like colors or grid-lines. We'll do our best to make it work!\n\n\n:::{.aside}\n::: {.cell}\n::: {.cell-output-display}\n![https://xkcd.com/2116/](norm_normal_file_format.png){width=152}\n:::\n:::\n\n:::\n\n\nExample one is from Seth Walder, who was kind enough to share the raw data for ESPN's \"Sacks created\" stat. \nGiven that it was a quality image, and there were 3 of them, I wanted to try OCR (optical character recognition)!\n\n<blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">OK here&#39;s the top 46 players -- everyone with at least 5.5 sacks created.<br><br>Sacks created is an ESPN stat using NFL Next Gen Stats data. <a href=\"https://t.co/cNL23Dna9h\">pic.twitter.com/cNL23Dna9h</a></p>&mdash; Seth Walder (@SethWalder) <a href=\"https://twitter.com/SethWalder/status/1349785021922631682?ref_src=twsrc%5Etfw\">January 14, 2021</a></blockquote> <script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n\n# Excel Screenshot\n\nSo let's get after it! We'll need two packages, but I'll also load `tidyverse` for the eventual analysis/plotting as well. Also, note that I adapted some of this from a [StackOverflow post](code adapted from: https://stackoverflow.com/questions/54000691/extracting-tables-from-jpeg-into-a-dataframe-in-r) talking about extracting tables from images.\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(magick)\nlibrary(tesseract)\n\nsack_url <- \"https://pbs.twimg.com/media/ErtmQ1PXYAEUQoY?format=jpg&name=900x900\"\nraw_img <- image_read(sack_url)\n```\n:::\n\nNow, while interactively you can just \"print\" the `magick` object and it will show up in the viewer pane, for this blog-post I'll need to explicitly \"show\" it. I'll call `magick::image_ggplot(<img object>)` to print it throughout the post.\n\n::: {.cell}\n\n```{.r .cell-code}\nimage_ggplot(raw_img)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\nThis looks like a relatively clean image, the only major problems being that it's relatively low-DPI, it has some symbols (team logos), and it has alternating colors along with gridlines (which can mess with the OCR). We can try a \"naive\" OCR as seen below. \n\n::: {.cell}\n\n```{.r .cell-code}\nraw_img %>% \n  image_crop(geometry_area(0, 0, 110, 45)) %>% \n  ocr()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Aaron Donald (DE - LA) 19.0,\\nMyles Garrett (DE - CLE) 16.5\\nTJ. Watt (OLB - PIT) 14.5\\nKhalil Mack (OLB - CHI) 13.0\\nJustin Houston (DE - IND) 12.0\\nEmmanuel Ogbah (DE - MIA) 11.0\\nCarl Lawson (DE - CIN) 10.5\\nBrandon Graham (DE - PHI) 10.0\\nDeMarcus Lawrence (DE - DAL) 10.0\\nYannick Ngakoue (DE - BAL) 10.0,\\nMontez Sweat (DE - WAS) 10.0\\nCarlos’ Dunlap (DE - SEA) 9.0\\nCameron Jordan (DE - NO) 9.0\\nKerry Hyder (DE - SF) 9.0\\nSermierce (OLB -TB) 9.0\\nStephon Tuitt (DE - PIT) 9.0\\n\"\n```\n:::\n:::\n\nUltimately, it does pretty well! But you can see that there are some \"misses\" if we look closely. Let's make it easier on the OCR engine by cleaning up the image for higher contrast.\n\n## Remove the background and grid\n\nWe'll first start by converting the color image to greyscale via `image_quantize()`.\n\n::: {.cell}\n\n```{.r .cell-code}\nraw_img %>% \n  image_quantize(colorspace = \"gray\") %>% \n  image_ggplot()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\nWe can remove the grid by converting \"white\" colors to transparent, and allowing for some \"fuzzy\" approximation of colors that are close to white or \"touching\". There's a lot more to `fuzz` in that it's the \"relative color distance (value between 0 and 100) to be considered similar in the filling algorithm\", but I'm not a color space expert by any means.\n\nBelow we have an example of `fuzz = 0`, `fuzz = 20`, `fuzz = 40`, `fuzz = 60`. Each increase does remove a bit of \"noise\", but is also reducing the quality of the \"signal\".\n\n<details><summary>Code for Combo</summary>\n::: {.cell}\n\n```{.r .cell-code}\nfuzz_fun <- function(fuzz){\n  raw_img %>% \n    image_quantize(colorspace = \"gray\") %>% \n    image_transparent(color = \"white\", fuzz=fuzz) %>% \n    image_background(\"white\") %>% \n    image_crop(geometry_area(0, 150,110, 45))\n}\n\nfuzz_fun(20)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-1.png){width=300}\n:::\n\n```{.r .cell-code}\ncombo_fuzz <- c(\n  fuzz_fun(0),\n  fuzz_fun(20),\n  fuzz_fun(40),\n  fuzz_fun(60)\n) %>% \n  image_append(stack = TRUE) \n```\n:::\n\n</details>\n\n::: {.cell}\n\n```{.r .cell-code}\nimage_ggplot(combo_fuzz)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\nIn practical terms, we are balancing increase `fuzz` to remove unnecessary components (eg grid lines) while leaving the actual characters there. Increasing fuzz will remove more \"noise\" but will eventually start to eat away at the actual \"signal\" as well.\n\n::: {.cell}\n\n```{.r .cell-code}\nno_grid <- raw_img %>% \n  image_quantize(colorspace = \"gray\") %>% \n   image_transparent(color = \"white\", fuzz=20) %>% \n   image_background(\"white\") \n\nimage_ggplot(no_grid)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\nSo we've taken white and converted it to transparent, and then set the image background back to \"white\".\n\nYou can also remove continuous lines with a \"thinning\" method. We can use `image_morphology()` coupled with a rectangular kernel to remove straight horizontal lines for the most part. You can read `Rectangle:20x1` as finding rectangles about 20 pixels wide x 1 pixel high. We couple this with `image_negate()` as otherwise it will focus on the characters.\n\nSo we'll `negate` > `thin` > `negate` to get back to our white background sans grid-lines. While this works pretty well, it's not _always_ necessary for the OCR. I did want to show it as it can be helpful in some situations.\n\n::: {.cell}\n\n```{.r .cell-code}\nno_grid %>% \n  image_negate() %>% \n  image_ggplot()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nno_grid %>%\n  image_negate() %>% # negate\n  image_morphology(method = \"Thinning\", kernel = \"Rectangle:20x1\") %>%\n  image_negate() %>% # back to white\n  image_ggplot()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\nThis worked pretty well! However, remember that we don't always have to do this. We'll also still need to crop the image to remove the team logos as they can't be parsed as text.\n\n## Crop the image\n\n`geometry_area()` is used in various functions to indicate the starting width/heights and then the offset, all in pixels.  \n\n> `geometry_area(width = NULL, height = NULL, x_off = 0, y_off = 0)`  \n\nNote that you're always \"starting\" from the top and left sides, and we're passing the `geometry_area()` to `image_crop` to crop the image itself.\n\n::: {.cell}\n\n```{.r .cell-code}\n# remove the top 20 pixels\nno_grid %>% \n  image_crop(geometry_area(0, 0,110, 45)) %>% \n  image_ggplot()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\nSo this techniques can be used to cut out specific portions of an image, which is another useful technique for tricky columns. For now, let's hope we can use ALL the data together.\n\n::: {.cell}\n\n```{.r .cell-code}\nno_grid_crop <- no_grid %>% \n  image_crop(geometry_area(0, 0,110, 45))\n\nno_grid_crop %>% \n  image_ggplot()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n## Try OCR\n\nWe can try our first OCR now! Note that `image_ocr()` is just calling `tesseract` behind the scenes.\n\n::: {.cell}\n\n```{.r .cell-code}\nno_grid_crop %>% \n  image_ocr()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Aaron Donald (DE - LA) 19.0\\nMyles Garrett (DE - CLE) 16.5\\nT.J. Watt (OLB - PIT) 14.5\\nKhalil Mack (OLB - CHI) 13.0\\nJustin Houston (DE - IND) 12.0\\nEmmanuel Ogbah (DE - MIA) 11.0\\nCarl Lawson (DE - CIN) 10.5\\nBrandon Graham (DE - PHI) 10.0\\nDeMarcus Lawrence (DE - DAL) 10.0\\nYannick Ngakoue (DE - BAL) 10.0\\nMontez Sweat (DE - WAS) 10.0\\nCarlos Dunlap (DE - SEA) 9.0\\nCameron Jordan (DE - NO) 9.0\\nKerry Hyder (DE - SF) 9.0\\nShaquil Barrett (OLB - TB) 9.0\\nStephon Tuitt (DE - PIT) 9.0\\nRomeo Okwara (DE - DET) 9.0\\n\"\n```\n:::\n:::\n\nThis did a great job, but what about this raw text string we ended up with? Also note that `image_ocr()` is just a wrapper around `tesseract::ocr()`.\n\nLet's go into `tesseract` proper to try some robust things out!\n\nI'm going to focus on one numeric \"column\" first to keep things relatively simpler. We'll use `image_crop` to grab the column of interest, then we'll call `tesseract::ocr()` on it. We can provide some options to the engine, namely that we're expecting only spaces, numbers, or a decimal. This will explicitly prevent 5 being converted to S for example. It does really well here!\n\n::: {.cell}\n\n```{.r .cell-code}\nnum_only <- tesseract::tesseract(\n  options = list(tessedit_char_whitelist = c(\".0123456789 \"))\n  )\n\nno_grid %>% \n  image_quantize(colorspace = 'gray') %>% \n  image_threshold() %>% \n  image_crop(geometry_area(100, 0, 600, 40)) %>% \n  ocr(engine = num_only) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"19.0\\n16.5\\n14.5\\n13.0\\n12.0\\n11.0\\n10.5\\n10.0\\n10.0\\n10.0\\n10.0\\n9.0\\n9.0\\n9.0\\n9.0\\n9.0\\n9.0\\n\"\n```\n:::\n:::\n\nBut we have text, numbers, and some symbols like `(`.\n\nSo let's pass those as limitations to the engine, and then we can take the raw text and turn it into a dataframe/tibble.\n\n::: {.cell}\n\n```{.r .cell-code}\ncombo <- tesseract::tesseract(\n    options = list(\n      tessedit_char_whitelist = paste0(\n        c(letters, LETTERS, \" \", \".0123456789 (-)\"), collapse = \"\")\n      )\n  )\n\nraw_text <- no_grid %>%\n  image_quantize(colorspace = \"gray\") %>%\n  image_transparent(\"white\", fuzz = 22) %>%\n  image_background(\"white\") %>%\n  image_threshold() %>%\n  image_crop(geometry_area(0, 0, 110, 45)) %>%  \n  ocr(engine = combo)\n```\n:::\n\n## Make a Tibble\n\n::: {.cell}\n\n```{.r .cell-code}\nraw_text\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Aaron Donald (DE - LA) 19.0\\nMyles Garrett (DE - CLE) 16.5\\nT.J. Watt (OLB - PIT) 14.5\\nKhalil Mack (OLB - CHI) 13.0\\nJustin Houston (DE - IND) 12.0\\nEmmanuel Ogbah (DE - MIA) 11.0\\nCarl Lawson (DE - CIN) 10.5\\nBrandon Graham (DE - PHI) 10.0\\nDeMarcus Lawrence (DE - DAL) 10.0\\nYannick Ngakoue (DE - BAL) 10.0\\nMontez Sweat (DE - WAS) 10.0\\nCarlos Dunlap (DE - SEA) 9.0\\nCameron Jordan (DE - NO) 9.0\\nKerry Hyder (DE - SF) 9.0\\nShaquil Barrett (OLB - TB) 9.0\\nStephon Tuitt (DE - PIT) 9.0\\nRomeo Okwara (DE - DET) 9.0\\n\"\n```\n:::\n:::\n\nThis looks pretty much perfect! We just now need to get it into a dataframe. We can accomplish this by splitting on each new row (`\\n`) and then adding that as a column in a tibble.\n\n::: {.cell}\n\n```{.r .cell-code}\nraw_tibble <- raw_text %>% \n  str_split(pattern = \"\\n\") %>% \n  unlist() %>%\n  tibble(data = .) \n\nraw_tibble\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 18 × 1\n   data                               \n   <chr>                              \n 1 \"Aaron Donald (DE - LA) 19.0\"      \n 2 \"Myles Garrett (DE - CLE) 16.5\"    \n 3 \"T.J. Watt (OLB - PIT) 14.5\"       \n 4 \"Khalil Mack (OLB - CHI) 13.0\"     \n 5 \"Justin Houston (DE - IND) 12.0\"   \n 6 \"Emmanuel Ogbah (DE - MIA) 11.0\"   \n 7 \"Carl Lawson (DE - CIN) 10.5\"      \n 8 \"Brandon Graham (DE - PHI) 10.0\"   \n 9 \"DeMarcus Lawrence (DE - DAL) 10.0\"\n10 \"Yannick Ngakoue (DE - BAL) 10.0\"  \n11 \"Montez Sweat (DE - WAS) 10.0\"     \n12 \"Carlos Dunlap (DE - SEA) 9.0\"     \n13 \"Cameron Jordan (DE - NO) 9.0\"     \n14 \"Kerry Hyder (DE - SF) 9.0\"        \n15 \"Shaquil Barrett (OLB - TB) 9.0\"   \n16 \"Stephon Tuitt (DE - PIT) 9.0\"     \n17 \"Romeo Okwara (DE - DET) 9.0\"      \n18 \"\"                                 \n```\n:::\n:::\n\nNow we have essentially perfect data at this point, we just need to separate out our columns and drop the row without any data.\n\n## Tidy the Tibble\n\nWe'll first drop any rows where the character string is < 2. We can then use `tidyr::separate()` to separate one column into 4 new columns as player, position, team, and sacks. There are multiple separators, which for the example seen `T.J. Watt (OLB - PIT) 14.5` are:  \n\n- `T.J.Watt` then ` (` represented as \"` \\\\(`\"  \n- `OLB` then ` - ` represented as \"` - `\"  \n- `PIT` then `) ` represented as \"`\\\\) `\"  \n- which leaves us with `14.5` at the end  \n\nWe have to \"escape\" the parentheses with `\\\\` so that regex can understand them. The `|` inside the sep arguments tell the regex to separate at a match of a white-space + parentheses OR white-space + dash OR parentheses + white-space.\n\nAs our last step, we'll convert sacks to a double column, and then **BOOM**!\n\n::: {.cell}\n\n```{.r .cell-code}\nraw_tibble %>% \n  filter(str_length(data) >= 2)  %>%\n  separate(\n    data, \n    into = c(\"player\", \"position\", \"team\", \"sacks\"), \n    sep = c(\" \\\\(| - |\\\\) \")\n    ) %>% \n  mutate(sacks = as.double(sacks))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 17 × 4\n   player            position team  sacks\n   <chr>             <chr>    <chr> <dbl>\n 1 Aaron Donald      DE       LA     19  \n 2 Myles Garrett     DE       CLE    16.5\n 3 T.J. Watt         OLB      PIT    14.5\n 4 Khalil Mack       OLB      CHI    13  \n 5 Justin Houston    DE       IND    12  \n 6 Emmanuel Ogbah    DE       MIA    11  \n 7 Carl Lawson       DE       CIN    10.5\n 8 Brandon Graham    DE       PHI    10  \n 9 DeMarcus Lawrence DE       DAL    10  \n10 Yannick Ngakoue   DE       BAL    10  \n11 Montez Sweat      DE       WAS    10  \n12 Carlos Dunlap     DE       SEA     9  \n13 Cameron Jordan    DE       NO      9  \n14 Kerry Hyder       DE       SF      9  \n15 Shaquil Barrett   OLB      TB      9  \n16 Stephon Tuitt     DE       PIT     9  \n17 Romeo Okwara      DE       DET     9  \n```\n:::\n:::\n\n## Write it as a Function\n\nWe can wrap this process into a reusable function, and then call it on our 3 images of interest!\n\n::: {.cell}\n\n```{.r .cell-code}\nscrape_fun <- function(url_in, crop_left, crop_top){\n  raw_img <- image_read(url_in) %>% \n    image_quantize(colorspace = 'gray') %>%\n    image_transparent(\"white\", fuzz=22) %>% \n    image_background(\"white\") %>%\n    image_threshold() %>% \n    image_crop(geometry_area(0, 0, crop_left, crop_top)) \n  \n  image_ocr(raw_img) %>% \n    str_c() %>% \n    str_split(pattern = \"\\n\") %>% \n    unlist() %>%\n    tibble(data = .) %>% \n    filter(str_length(data) >= 2) %>% \n    separate(\n      data, \n      into = c(\"player\", \"position\", \"team\", \"sacks\"), \n      sep = c(\" \\\\(| - |\\\\) \")\n      ) %>% \n    mutate(sacks = as.double(sacks)) %>% \n    mutate(sacks = if_else(sacks >= 20, sacks/10, sacks))\n}\n```\n:::\n\n\nWe can then call our new function! You may notice that I added a `mutate` above which protects against missing decimal places. Trey Hendrickson's decimal place is apparently hard for the parser to \"capture\".\n\n::: {.cell}\n\n```{.r .cell-code}\n# output to tibble\ncr_sacks <- tibble(\n  url_in = c(\n    \"https://pbs.twimg.com/media/ErtmQ1PXYAEUQoY?format=jpg&name=900x900\",\n    \"https://pbs.twimg.com/media/ErtmSLlXMAAvylA?format=jpg&name=900x900\",\n    \"https://pbs.twimg.com/media/ErtmTUGW8AEZ6Cy?format=jpg&name=900x900\"\n    ),\n  crop_left = c(110, 95, 95),\n  crop_top = c(45, 5, 5)\n) %>% \n  pmap_df(scrape_fun)\n\ncr_sacks\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 46 × 4\n   player            position team  sacks\n   <chr>             <chr>    <chr> <dbl>\n 1 Aaron Donald      DE       LA     19  \n 2 Myles Garrett     DE       CLE    16.5\n 3 T.J. Watt         OLB      PIT    14.5\n 4 Khalil Mack       OLB      CHI    13  \n 5 Justin Houston    DE       IND    12  \n 6 Emmanuel Ogbah    DE       MIA    11  \n 7 Carl Lawson       DE       CIN    10.5\n 8 Brandon Graham    DE       PHI    10  \n 9 DeMarcus Lawrence DE       DAL    10  \n10 Yannick Ngakoue   DE       BAL    10  \n# … with 36 more rows\n```\n:::\n:::\n\nWe can plot it just to be safe, and to see if everything \"checks out\"! We get a range we expected, and see that T.J. Watt and Aaron Donald create many more of their own sacks relative to their positions.\n\n::: {.cell .column-column-page-inset}\n\n```{.r .cell-code}\ncr_sacks %>% \n  mutate(position = if_else(position == \"LB\", \"OLB\", position)) %>% \n  ggplot(aes(x = sacks, y = position)) +\n  ggridges::geom_density_ridges(quantile_lines = TRUE, quantiles = 2) +\n  geom_point(\n    data = filter(cr_sacks, player %in% c(\"Aaron Donald\", \"T.J. Watt\")),\n    size = 3\n    ) +\n  ggridges::theme_ridges() +\n  theme(\n    axis.text = element_text(size = 10),\n    axis.title = element_text(size = 14),\n    plot.title = element_text(size = 16),\n    plot.caption = element_text(size = 10),\n    panel.grid.minor = element_blank(),\n    axis.title.x = element_text(hjust = 0)\n    ) +\n  labs(\n    x = \"\\nCreated Sacks\", y = \"\",\n    title = \"T.J. Watt and A. Donald are both outliers amongst their positions\",\n    subtitle = \"Created Sacks by position\",\n    caption = \"Data: ESPN | Plot: @thomas_mock\"\n    )\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nPicking joint bandwidth of 1.05\n```\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-21-1.png){width=1500}\n:::\n:::\n\n\n# Example 2\n\nExample two is from Brian Burke, who was kind enough to share the raw data for NFL playoff leverage for week 17 as a screenshot. At the time, I manually copied these over to a dataframe, but Ben Baldwin asked if there was a \"better\" way. Image OCR (optical character recognition) is a potentially more reproducible way!\n\n<blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">Sorry, no pretty charts for now. But here are the raw numbers. <a href=\"https://t.co/wZ3j9bXzTN\">pic.twitter.com/wZ3j9bXzTN</a></p>&mdash; Brian Burke (@bburkeESPN) <a href=\"https://twitter.com/bburkeESPN/status/1339616433408528384?ref_src=twsrc%5Etfw\">December 17, 2020</a></blockquote> <script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n\nNote that our process is almost identical to the previous example, but there are some considerations as the image is a bit more difficult to work with.\n\nNow, this image is more problematic for two main reasons.  \n\n1. The image itself is _much_ smaller, specifically about 60% smaller than our previous example and of low quality  \n2. The fonts in use are worse (not monospaced and have serifs), and not bold  \n\nThis is going to be **harder** than before.\n\n## Get the raw img\n\n::: {.cell}\n\n```{.r .cell-code}\nburke <- \"https://pbs.twimg.com/media/EpdF4fzW4AEeOvF?format=png&name=small\"\nraw_img <- image_read(burke)\n```\n:::\n\nNow, again while interactively you can just \"print\" the `magick` object and it will show up in the RStudio viewer pane, for this blog-post I'll need to explicitly \"show\" it. I'll call `magick::image_ggplot(<img object>)` to print it throughout the post.\n\n::: {.cell}\n\n```{.r .cell-code}\nimage_ggplot(raw_img)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n:::\n\nThis looks like a relatively clean image, the only major problems as mentioned above are that it's very low-quality along with not ideal fonts, and it cuts off some of the data for team.\n\n## Clean it up\n\nWe can remove the grid by converting \"white\" colors to transparent, and allowing for some \"fuzzy\" approximation of colors that are close to white or \"touching\". There's a lot more to `fuzz` in that it's the \"relative color distance (value between 0 and 100) to be considered similar in the filling algorithm\", but I'm not a color space expert by any means.\n\nIn practical terms, we are balancing increase `fuzz` to remove unnecessary components (eg grid lines) while leaving the actual characters there. Increasing fuzz will remove more \"noise\" but will eventually start to eat away at the actual \"signal\" as well.\n\nBelow we have an example of `fuzz = 0`, `fuzz = 20`, `fuzz = 50`, `fuzz = 70`.\n\nSo we've taken white and converted it to transparent, and then set the image background back to \"white\".\n\n\n::: {.cell}\n\n```{.r .cell-code}\nno_grid <- raw_img %>% \n   image_transparent(color = \"white\", fuzz=20) %>% \n   image_background(\"white\") \n\nimage_ggplot(no_grid)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-24-1.png){width=672}\n:::\n:::\n\nYou can also remove continuous lines with a \"thinning\" method. We can use `image_morphology()` coupled with a rectangular kernel to remove straight horizontal lines for the most part. You can read `Rectangle:20x1` as finding rectangles about 20 pixels wide x 1 pixel high. We couple this with `image_negate()` as otherwise it will focus on the characters.\n\nSo we'll `negate` > `thin` > `negate` to get back to our white background sans grid-lines.\n\n::: {.cell}\n\n```{.r .cell-code}\nno_grid %>% \n  image_negate() %>% \n  image_ggplot()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-25-1.png){width=672}\n:::\n:::\n\n\nWe can apply the thinning morph as seen below, flipping back and forth with `image_negate()`.\n\n::: {.cell}\n\n```{.r .cell-code}\nno_grid %>% \n  image_negate() %>%\n  image_morphology(method = \"Thinning\", kernel = \"Rectangle:20x1\") %>% \n  image_negate() %>% \n  image_ggplot()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-26-1.png){width=672}\n:::\n:::\n\nThis worked pretty well! However, because of the mis-alignment of the column labels and the columns themselves, I'm just going to trim the top off. \n\n## Crop the image\n\n`geometry_area()` is used in various functions to indicate the starting width/heights and then the offset, all in pixels.  \n\n> `geometry_area(width = NULL, height = NULL, x_off = 0, y_off = 0)`  \n\nNote that you're always \"starting\" from the top and left sides, and we're passing the `geometry_area()` to `image_crop` to crop the image itself.\n\n::: {.cell}\n\n```{.r .cell-code}\n# remove the top 20 pixels\nno_grid %>% \n  image_crop(geometry_area(0, 0, 0, 20)) %>% \n  image_ggplot()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-27-1.png){width=672}\n:::\n:::\n\nSo this techniques can be used to cut out specific portions of an image, which is another useful technique for tricky columns. For now, let's hope we can use ALL the data together.\n\n::: {.cell}\n\n```{.r .cell-code}\nno_grid_crop <- no_grid %>% \n  image_crop(geometry_area(0, 0, 0, 20))\n\nno_grid_crop %>% \n  image_ggplot()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-28-1.png){width=672}\n:::\n:::\n\n## Try OCR\n\nWe can try our first OCR now! Note that `image_ocr()` is just calling `tesseract` behind the scenes.\n\n::: {.cell}\n\n```{.r .cell-code}\nno_grid_crop %>% \n  image_ocr()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Bills 100 99.3 07\\nPackers 100 100 0\\nRams 100989 11\\nChiefs 100 100 0\\nSaints 100 100 0\\nSeahawks 100 (97.7 23\\nSteelers 100 100 0\\nBuccaneer 99.5 92.6 69\\nTitans 97.6 787 18.9\\nColts 949 664 028.5,\\nBrowns 946 0 «675 TA\\nRavens 90.1 S18 38.3\\nFootballT 88.6 583 303\\nCardinals 65.7 (25.7 40\\nDolphins 43.7 24 353\\nGiants 413 100313\\nBears 35.3 18 335\\nVikings. 317 430 278\\nRaiders 29.1 45 246\\nEagles 18.3 340-149\\n49ers 145 os 14\\nPatriots 58 0 58\\nCowboys 23 0 23\\nLions 19 0 19\\nPanthers oO. oO O41\\n\"\n```\n:::\n:::\n\nThis did a decent job, but I can already see some \"problems\".\n\nThe Rams row is \"squished\" together, the Browns have some letters instead of numbers, and the Ravens have a \"S\" instead of a 5.\n\nLet's go into `tesseract` proper to try some robust things out!\n\nI'm going to focus on one \"column\" first to keep things relatively simpler. We'll use `image_crop` to grab the column of interest, then we'll call `tesseract::ocr()` on it. We can provide some options to the engine, namely that we're expecting only spaces, numbers, or a decimal. This will explicitly prevent 5 being converted to S for example.\n\n::: {.cell}\n\n```{.r .cell-code}\nnum_only <- tesseract::tesseract(\n  options = list(tessedit_char_whitelist = c(\".0123456789 \"))\n  )\nno_grid %>% \n  image_quantize(colorspace = 'gray') %>% \n  image_threshold() %>% \n  image_crop(geometry_area(80, 0, 80, 20)) %>% \n  ocr(engine = num_only) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"100\\n100\\n100\\n100\\n100\\n100\\n100\\n99.5\\n97.6\\n4.9\\n94.6\\n90.1\\n88.6\\n657\\n48.7\\n41.3\\n35.3\\n317\\n29.1\\n18.3\\n14.5\\n5.8\\n2.3\\n1.9\\n01\\n\"\n```\n:::\n:::\n\nI'm going to \"plot\" the data to show some areas where mistakes were _still_ made. We know that 100 is the max, and that the values are ranked, and thus should be always decreasing. We have at least 5 examples where the data is missing a period which causes it to be scaled improperly (10x larger than reality).\n\n::: {.cell}\n\n```{.r .cell-code}\nocr_col1 <- no_grid %>%\n  image_crop(geometry_area(80, 0, 80, 20)) %>%\n  ocr(engine = num_only) %>%\n  str_split(pattern = \"\\n\") %>%\n  unlist() %>%\n  enframe() %>%\n  mutate(value = as.double(value)) %>%\n  filter(!is.na(value))\n\nocr_col1 %>%\n  mutate(color = case_when(\n    value > 100 ~ \"red\",\n    value > lag(value) ~ \"red\",\n    value > lag(value, n = 3) ~ \"red\",\n    TRUE ~ \"black\"\n  )) %>%\n  ggplot(aes(x = name, y = value, color = color)) +\n  geom_point(size = 3) +\n  scale_color_identity()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-31-1.png){width=672}\n:::\n:::\n\nAgain, due to the VERY low image quality (the original image is 72 DPI and only ~500 pixels high) we're basically stuck with some of these manual steps. Regardless, we've got \"better\" data now that we've added our conversion logic. Those same 5 points now fall \"accurately\" into the appropriate range.\n\n::: {.cell}\n\n```{.r .cell-code}\nocr_col1 %>% \n  mutate(color = case_when(\n    value > 100 ~ \"red\",\n    value > lag(value) ~ \"red\",\n    value > lag(value, n = 3) ~ \"red\",\n    TRUE ~ \"black\"\n  )) %>% \n  mutate(\n    value = if_else(value > 100, value/10, value),\n    value = if_else(name >= 22, value/10, value)\n    ) %>% \n  ggplot(aes(x = name, y = value, color = color)) +\n  geom_point(size = 3) +\n  scale_color_identity()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-32-1.png){width=672}\n:::\n:::\n\nSo we've apparently \"fixed\" this column!\n\n## Create a function\n\nWe'll create a function so that we can split out each column, apply optimal characters or numeric to each and then recombine.\n\n::: {.cell}\n\n```{.r .cell-code}\nimg_ocr_fun <- function(trim_width, trim_start, char_num = TRUE) {\n  \n  num_only <- tesseract::tesseract(\n    options = list(tessedit_char_whitelist = c(\".0123456789 \"))\n  )\n\n  combo <- tesseract::tesseract(\n    options = list(\n      tessedit_char_whitelist = paste0(\n        c(letters, LETTERS, \" \", \".0123456789 \"), collapse = \"\")\n      )\n  )\n\n\n  input_char <- if (isTRUE(char_num)) {\n    num_only\n  } else {\n    combo\n  }\n\n  no_grid %>%\n    image_crop(geometry_area(trim_width, 0, trim_start, 20)) %>%\n    ocr(engine = input_char) %>%\n    str_split(pattern = \"\\n\") %>%\n    unlist() %>%\n    enframe() %>%\n    select(-name) %>%\n    filter(!is.na(value), str_length(value) > 0)\n}\n```\n:::\n\nWe can \"find\" the columns by cropping specific areas. Note that I've \"recombined\" all of them with `image_append()` so that you can see that each section together completes the table.\n\n::: {.cell}\n\n```{.r .cell-code}\nc(\n  no_grid %>%\n    image_crop(geometry_area(80, 0, 0, 20)),\n  no_grid %>%\n    image_crop(geometry_area(50, 0, 80, 20)),\n  no_grid %>%\n    image_crop(geometry_area(50, 0, 140, 20)),\n  no_grid %>%\n    image_crop(geometry_area(50, 0, 210, 20))\n) %>%\n  image_append() %>%\n  image_ggplot()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-34-1.png){width=672}\n:::\n:::\n\n## Apply the function\n\nWe can use `purrr::pmap()` to apply the functions with each of our parameters, and then use `bind_cols` to create our actual dataset.\n\n::: {.cell}\n\n```{.r .cell-code}\nall_ocr <- list(trim_width = c(80, 50, 50, 50),\n     trim_start = c(0, 80, 140, 210),\n     char_num = c(FALSE, TRUE, FALSE, TRUE)) %>% \n  pmap(img_ocr_fun)\n\n# it fails on one row\nall_ocr[[4]] <- append(all_ocr[[4]]$value, 271, after = 10)\n\ndata_df <- all_ocr %>% \n  bind_cols() %>% \n  set_names(nm = \"team\", \"win\", \"lose\", \"leverage\") \n```\n\n::: {.cell-output .cell-output-stderr}\n```\nNew names:\n• `value` -> `value...1`\n• `value` -> `value...2`\n• `value` -> `value...3`\n• `` -> `...4`\n```\n:::\n\n```{.r .cell-code}\ndata_df\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 25 × 4\n   team      win   lose  leverage\n   <chr>     <chr> <chr> <chr>   \n 1 Bills     100   99.3  07      \n 2 Packers   100   100   0       \n 3 Rams      100   98.9  11      \n 4 Chiefs    100   100   0       \n 5 Saints    100   100   0       \n 6 Seahawks  100   977   23      \n 7 Steelers  100   100   0       \n 8 Buccaneer 99.5  92.6  69      \n 9 Titans    97.6  78.7  18.9    \n10 Colts     94.9  66.4  285     \n# … with 15 more rows\n```\n:::\n:::\n\n## Clean it up\n\nWe can convert some of the letters to their proper numeric. I intentionally used characters vs numeric on some columns as it \"guesses\" better in our really low quality image. I then add some logic to convert our numbers if decimal places are missing, and it gets VERY close, but is not perfect.\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_df %>% \n  mutate(across(win:leverage, ~str_replace(tolower(.x), \"s\", \"5\"))) %>% \n  mutate(across(win:leverage, ~str_replace(tolower(.x), \"o|a\", \"0\"))) %>% \n  mutate(across(win:leverage, as.double)) %>% \n  mutate(across(win:leverage, ~if_else(.x > 100, .x/10, .x))) %>% \n  mutate(lose = if_else(lose > win, lose/10, lose)) %>% \n  mutate(leverage = win - lose) %>% \n  print(n = 25)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 25 × 4\n   team         win  lose leverage\n   <chr>      <dbl> <dbl>    <dbl>\n 1 Bills      100    99.3    0.700\n 2 Packers    100   100      0    \n 3 Rams       100    98.9    1.10 \n 4 Chiefs     100   100      0    \n 5 Saints     100   100      0    \n 6 Seahawks   100    97.7    2.30 \n 7 Steelers   100   100      0    \n 8 Buccaneer   99.5  92.6    6.90 \n 9 Titans      97.6  78.7   18.9  \n10 Colts       94.9  66.4   28.5  \n11 Browns      94.6  67.5   27.1  \n12 Ravens      90.1  51.8   38.3  \n13 Football T  88.6  38.3   50.3  \n14 Cardinals   65.7  28.7   37    \n15 Dolphins    48.7  13.4   35.3  \n16 Giants      41.3  10     31.3  \n17 Bears       35.3  18     17.3  \n18 Vikings     31.7   4.3   27.4  \n19 Raiders     29.1   4.5   24.6  \n20 Eagles      18.3   3.4   14.9  \n21 49ers       14.5   5      9.5  \n22 Patriots    58     0     58    \n23 Cowboys     23     0     23    \n24 Lions       19     0     19    \n25 Panthers     1     0      1    \n```\n:::\n:::\n\nIt looks really good, and it really only messed up a few rows, which we could fix manually, but you can see that while these techniques are robust you are still at the mercy of image quality!\n\n:::{.callout-tip collapse=\"true\"}\n## Expand for Session Info\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.0 (2022-04-22)\n os       macOS Monterey 12.2.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       America/Chicago\n date     2022-04-28\n pandoc   2.18 @ /Applications/RStudio.app/Contents/MacOS/quarto/bin/tools/ (via rmarkdown)\n quarto   0.9.294 @ /usr/local/bin/quarto\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version date (UTC) lib source\n dplyr       * 1.0.8   2022-02-08 [1] CRAN (R 4.2.0)\n forcats     * 0.5.1   2021-01-27 [1] CRAN (R 4.2.0)\n ggplot2     * 3.3.5   2021-06-25 [1] CRAN (R 4.2.0)\n magick      * 2.7.3   2021-08-18 [1] CRAN (R 4.2.0)\n purrr       * 0.3.4   2020-04-17 [1] CRAN (R 4.2.0)\n readr       * 2.1.2   2022-01-30 [1] CRAN (R 4.2.0)\n sessioninfo * 1.2.2   2021-12-06 [1] CRAN (R 4.2.0)\n stringr     * 1.4.0   2019-02-10 [1] CRAN (R 4.2.0)\n tesseract   * 5.0.0   2022-01-10 [1] CRAN (R 4.2.0)\n tibble      * 3.1.6   2021-11-07 [1] CRAN (R 4.2.0)\n tidyr       * 1.2.0   2022-02-01 [1] CRAN (R 4.2.0)\n tidyverse   * 1.3.1   2021-04-15 [1] CRAN (R 4.2.0)\n\n [1] /Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/library\n\n──────────────────────────────────────────────────────────────────────────────\n```\n:::\n:::\n\n:::",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}