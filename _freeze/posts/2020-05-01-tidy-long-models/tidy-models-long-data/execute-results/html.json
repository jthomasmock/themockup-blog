{
  "hash": "2012a89a3ab6c3bf725c4c3435652975",
  "result": {
    "markdown": "---\ntitle: \"Flipping tibbles for many models\"\ndescription: |\n  Pivoting data from wide to long to run many models at once\nauthor: Thomas Mock\ndate: 05-01-2020\ncategories:\n  - espnscrapeR\n  - NFL\n  - tidyverse\n  - tidymodels\nimage: preview.png\n---\n\n\n\n# Many Models\n\nThe `tidymodels` package advocates for a nest-map-unnest workflow for running many models at once. While this typically is used for some type of group as seen in the [`tidymodels` docs](https://www.tidymodels.org/learn/statistics/tidy-analysis/#regression-models), we can also do it for running many models at once from a wide dataset.\n\nOur goal is to get all of the measures into a `long` form tibble so that we can fit all of the models at once, and plot it all at once.\n\n## Basic Example\n\nThis basic example is borrowed directly from the [`tidymodels` docs](https://www.tidymodels.org/learn/statistics/tidy-analysis/#regression-models).\n\nFirst you nest the data by a grouping variable to get list-columns of each split data/tibble.\n\n::: {.cell}\n\n```{.r .cell-code}\nmtcars <- as_tibble(mtcars)  # to play nicely with list-cols\n\nnest_mtcars <- mtcars %>%\n  nest(data = c(-am)) \n\nnest_mtcars\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 2\n     am data              \n  <dbl> <list>            \n1     1 <tibble [13 × 10]>\n2     0 <tibble [19 × 10]>\n```\n:::\n:::\n\nNow you can apply a `lm()` call w/ `purrr::map()` to each dataset, and then `broom::tidy()` the model output!\n\n::: {.cell}\n\n```{.r .cell-code}\nnest_mtcars %>% \n  mutate(\n    fit = map(data, ~ lm(wt ~ mpg + qsec + gear, data = .x)),  # S3 list-col\n    tidied = map(fit, tidy)\n  ) %>% \n  unnest(tidied) %>% \n  select(-data, -fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 8 × 6\n     am term        estimate std.error statistic  p.value\n  <dbl> <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1     1 (Intercept)   4.28      3.46      1.24   0.247   \n2     1 mpg          -0.101     0.0294   -3.43   0.00750 \n3     1 qsec          0.0398    0.151     0.264  0.798   \n4     1 gear         -0.0229    0.349    -0.0656 0.949   \n5     0 (Intercept)   4.92      1.40      3.52   0.00309 \n6     0 mpg          -0.192     0.0443   -4.33   0.000591\n7     0 qsec          0.0919    0.0983    0.935  0.365   \n8     0 gear          0.147     0.368     0.398  0.696   \n```\n:::\n:::\n\nNow each of the model metrics for automatic vs manual transmissions (0 vs 1) is easy to work with! We'll use a similar approach (nest-map-unnest) albeit with a slightly different data structure for our following analysis.\n\n# NFL Example\n\nWe'll be performing a similar analysis to what Josh Hermsmeyer's did in his [538 article](https://fivethirtyeight.com/features/why-the-nfl-cant-rely-on-defense/). The raw code for his analysis is available on his [GitHub](https://github.com/friscojosh/defensive-metric-stability). Essentially he evaluated how stable metrics were year-over-year, by comparing:  \n\n- `Metric in Year N`  \n- `Metric in Year N + 1`  \n\nWe're skipping most of the `nflscrapR` aggregation (see the [link](https://github.com/friscojosh/defensive-metric-stability) for full script), the portion we can change a bit to make our lives easier is the repeated modeling.\n\nRather than having to generate a model for every metric one-by-one, we can generate the models for ALL the metrics in the datase at once, while still running the model just for each metric by the following year's metric.\n\n::: {.cell}\n\n```{.r .cell-code}\n### QB Hits model  ------------------------------------------------------------\n\nqb_hits_model <- lm(data = team_defense_joined, qb_hit.y ~ qb_hit.x)\n\nqb_hits_stability <- glance(qb_hits_model) %>%\n   mutate(metric = \"QB Hits\",\n          r.squared = round(r.squared, 3)) %>%\n   select(metric, r.squared)\n```\n:::\n\n# Get the data\n\nSo let's load our libraries and get to modeling!\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse) # all the things\nlibrary(espnscrapeR) # NFL data summaries\nlibrary(broom) # tidy modeling\nlibrary(glue) # nice string creation\nlibrary(ggtext) # for formatted text in ggplot\n```\n:::\n\nFirst we'll get all the data from the 2000-2019 seasons for NFL offenses via `espnscrapeR::scrape_team_stats_nfl()`.\n\n::: {.cell hash='tidy-models-long-data_cache/html/scrape data_a6be9a5a5ac6e069a4d2dbfbe40b631c'}\n\n```{.r .cell-code}\n# Get data from espnscrapeR\nall_off <- 2000:2019 %>% \n  map_dfr(scrape_team_stats_nfl)\n```\n\n::: {.cell-output-stderr}\n```\nScraping passing for offense from 2000!\n```\n:::\n\n::: {.cell-output-stderr}\n```\nScraping passing for offense from 2001!\n```\n:::\n\n::: {.cell-output-stderr}\n```\nScraping passing for offense from 2002!\n```\n:::\n\n::: {.cell-output-stderr}\n```\nScraping passing for offense from 2003!\n```\n:::\n\n::: {.cell-output-stderr}\n```\nScraping passing for offense from 2004!\n```\n:::\n\n::: {.cell-output-stderr}\n```\nScraping passing for offense from 2005!\n```\n:::\n\n::: {.cell-output-stderr}\n```\nScraping passing for offense from 2006!\n```\n:::\n\n::: {.cell-output-stderr}\n```\nScraping passing for offense from 2007!\n```\n:::\n\n::: {.cell-output-stderr}\n```\nScraping passing for offense from 2008!\n```\n:::\n\n::: {.cell-output-stderr}\n```\nScraping passing for offense from 2009!\n```\n:::\n\n::: {.cell-output-stderr}\n```\nScraping passing for offense from 2010!\n```\n:::\n\n::: {.cell-output-stderr}\n```\nScraping passing for offense from 2011!\n```\n:::\n\n::: {.cell-output-stderr}\n```\nScraping passing for offense from 2012!\n```\n:::\n\n::: {.cell-output-stderr}\n```\nScraping passing for offense from 2013!\n```\n:::\n\n::: {.cell-output-stderr}\n```\nScraping passing for offense from 2014!\n```\n:::\n\n::: {.cell-output-stderr}\n```\nScraping passing for offense from 2015!\n```\n:::\n\n::: {.cell-output-stderr}\n```\nScraping passing for offense from 2016!\n```\n:::\n\n::: {.cell-output-stderr}\n```\nScraping passing for offense from 2017!\n```\n:::\n\n::: {.cell-output-stderr}\n```\nScraping passing for offense from 2018!\n```\n:::\n\n::: {.cell-output-stderr}\n```\nScraping passing for offense from 2019!\n```\n:::\n\n```{.r .cell-code}\nglimpse(all_off)\n```\n\n::: {.cell-output-stdout}\n```\nRows: 626\nColumns: 19\n$ season         <int> 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2…\n$ role           <chr> \"OFFENSE\", \"OFFENSE\", \"OFFENSE\", \"OFFENSE\", \"OFFENSE\", …\n$ stat           <chr> \"PASSING\", \"PASSING\", \"PASSING\", \"PASSING\", \"PASSING\", …\n$ team           <chr> \"RedskinsRedskins\", \"BuccaneersBuccaneers\", \"SeahawksSe…\n$ pass_att       <int> 561, 433, 507, 583, 578, 439, 554, 575, 637, 529, 497, …\n$ pass_comp      <int> 343, 237, 308, 366, 311, 217, 316, 331, 352, 311, 298, …\n$ pass_comp_pct  <dbl> 0.611, 0.547, 0.607, 0.628, 0.538, 0.494, 0.570, 0.576,…\n$ yds_att        <dbl> 6.9, 6.5, 6.3, 7.5, 6.1, 6.2, 6.3, 5.9, 6.3, 6.8, 7.2, …\n$ pass_yds       <int> 3892, 2824, 3198, 4400, 3540, 2738, 3478, 3386, 4023, 3…\n$ pass_td        <int> 18, 18, 21, 32, 19, 12, 16, 21, 23, 22, 22, 18, 33, 15,…\n$ int            <int> 21, 13, 21, 10, 30, 10, 24, 15, 29, 13, 15, 15, 18, 17,…\n$ pass_rating    <dbl> 77.0, 76.2, 75.5, 97.0, 61.8, 68.9, 67.4, 75.9, 67.5, 8…\n$ first_downs    <int> 185, 144, 168, 211, 156, 128, 156, 182, 192, 195, 169, …\n$ pass_first_pct <dbl> 0.330, 0.333, 0.331, 0.362, 0.270, 0.292, 0.282, 0.317,…\n$ pass_20plus    <int> 43, 38, 26, 61, 41, 37, 41, 46, 50, 46, 42, 35, 57, 32,…\n$ pass_40plus    <int> 10, 5, 7, 9, 9, 3, 11, 5, 8, 7, 8, 5, 13, 8, 8, 21, 8, …\n$ pass_long      <chr> \"77T\", \"75\", \"71\", \"69T\", \"83T\", \"77T\", \"70T\", \"70T\", \"…\n$ sacks          <int> 32, 38, 46, 25, 53, 43, 35, 45, 20, 28, 39, 48, 35, 28,…\n$ sack_yds       <int> 244, 241, 238, 161, 302, 220, 228, 262, 99, 243, 244, 2…\n```\n:::\n:::\n\n\n## Pivot the data longer\n\nBecause we are looking to run all the models at once, we'll need to take the data structure from wide to longer, so we can `nest()` the datasets by metric and run the model on each metric pair. By `pivot`ing to long format we get our team-level data by season and metric with the corresponding value of each season.\n\n::: {.cell}\n\n```{.r .cell-code}\nlong_off_stats <- all_off %>% \n  select(team, pass_att:sacks, season,-pass_long, -pass_comp) %>% \n  mutate(season2 = season + 1) %>% \n  pivot_longer(\n    cols = c(-team, -season, -season2), \n    names_to = \"metric\", \n    values_to = \"value\")\n\nlong_off_stats\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 7,512 × 5\n   team             season season2 metric            value\n   <chr>             <int>   <dbl> <chr>             <dbl>\n 1 RedskinsRedskins   2000    2001 pass_att        561    \n 2 RedskinsRedskins   2000    2001 pass_comp_pct     0.611\n 3 RedskinsRedskins   2000    2001 yds_att           6.9  \n 4 RedskinsRedskins   2000    2001 pass_yds       3892    \n 5 RedskinsRedskins   2000    2001 pass_td          18    \n 6 RedskinsRedskins   2000    2001 int              21    \n 7 RedskinsRedskins   2000    2001 pass_rating      77    \n 8 RedskinsRedskins   2000    2001 first_downs     185    \n 9 RedskinsRedskins   2000    2001 pass_first_pct    0.33 \n10 RedskinsRedskins   2000    2001 pass_20plus      43    \n# … with 7,502 more rows\n```\n:::\n:::\n\n## Join the data\n\nNext we need to join the data back into itself to get the matched value 1 (year) with value 2 (year + 1). The join renames `value` on the left-hand side (`value.x`) and the right-hand side (`value.y`). Technically we don't need season or season 2 anymore, but I've kept them so we can do a quick visual check on the data. The numbers look good and are aligned properly!\n\n::: {.cell}\n\n```{.r .cell-code}\njoin_years <- long_off_stats %>% \n    inner_join(long_off_stats, by = c(\"season2\" = \"season\", \"team\", \"metric\")) %>% \n    select(everything(), -season2.y)\n\njoin_years\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 7,116 × 6\n   team             season season2 metric          value.x  value.y\n   <chr>             <int>   <dbl> <chr>             <dbl>    <dbl>\n 1 RedskinsRedskins   2000    2001 pass_att        561      432    \n 2 RedskinsRedskins   2000    2001 pass_comp_pct     0.611    0.544\n 3 RedskinsRedskins   2000    2001 yds_att           6.9      6.3  \n 4 RedskinsRedskins   2000    2001 pass_yds       3892     2716    \n 5 RedskinsRedskins   2000    2001 pass_td          18       13    \n 6 RedskinsRedskins   2000    2001 int              21       13    \n 7 RedskinsRedskins   2000    2001 pass_rating      77       71.1  \n 8 RedskinsRedskins   2000    2001 first_downs     185      122    \n 9 RedskinsRedskins   2000    2001 pass_first_pct    0.33     0.282\n10 RedskinsRedskins   2000    2001 pass_20plus      43       31    \n# … with 7,106 more rows\n```\n:::\n:::\n\n## Nest the Data\n\nWe now need to nest the data, leaving `metric` out so that it is used as the group/label data. Now each of the metrics are separated into their own respective nested datasets!\n\n::: {.cell}\n\n```{.r .cell-code}\nnest_off_data <- join_years %>% \n    nest(data = c(-metric))\n\nnest_off_data \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 12 × 2\n   metric         data              \n   <chr>          <list>            \n 1 pass_att       <tibble [593 × 5]>\n 2 pass_comp_pct  <tibble [593 × 5]>\n 3 yds_att        <tibble [593 × 5]>\n 4 pass_yds       <tibble [593 × 5]>\n 5 pass_td        <tibble [593 × 5]>\n 6 int            <tibble [593 × 5]>\n 7 pass_rating    <tibble [593 × 5]>\n 8 first_downs    <tibble [593 × 5]>\n 9 pass_first_pct <tibble [593 × 5]>\n10 pass_20plus    <tibble [593 × 5]>\n11 pass_40plus    <tibble [593 × 5]>\n12 sacks          <tibble [593 × 5]>\n```\n:::\n:::\n\n## Fit the models\n\nNow let's `fit` the models and tidy the outputs with `broom::glance()`. We now have the raw fit and the tidy output as list-column tibbles! We're really just interested in r.squared for this example, so we'll `unnest()` the data in the next step to get that out by metric.\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy_off_models <- nest_off_data %>% \n    mutate(\n      fit = map(data, ~ lm(value.y ~ value.x, data = .x)),\n      tidy_output = map(fit, glance)\n    )\n\ntidy_off_models\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 12 × 4\n   metric         data               fit    tidy_output      \n   <chr>          <list>             <list> <list>           \n 1 pass_att       <tibble [593 × 5]> <lm>   <tibble [1 × 12]>\n 2 pass_comp_pct  <tibble [593 × 5]> <lm>   <tibble [1 × 12]>\n 3 yds_att        <tibble [593 × 5]> <lm>   <tibble [1 × 12]>\n 4 pass_yds       <tibble [593 × 5]> <lm>   <tibble [1 × 12]>\n 5 pass_td        <tibble [593 × 5]> <lm>   <tibble [1 × 12]>\n 6 int            <tibble [593 × 5]> <lm>   <tibble [1 × 12]>\n 7 pass_rating    <tibble [593 × 5]> <lm>   <tibble [1 × 12]>\n 8 first_downs    <tibble [593 × 5]> <lm>   <tibble [1 × 12]>\n 9 pass_first_pct <tibble [593 × 5]> <lm>   <tibble [1 × 12]>\n10 pass_20plus    <tibble [593 × 5]> <lm>   <tibble [1 × 12]>\n11 pass_40plus    <tibble [593 × 5]> <lm>   <tibble [1 × 12]>\n12 sacks          <tibble [593 × 5]> <lm>   <tibble [1 × 12]>\n```\n:::\n:::\n\n## Unnest the model metrics\n\nNow we have a few options - we can use `unnest_wider()` to get ALL the model metrics, but again that's overkill for our example.\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy_off_models %>% \n    unnest_wider(tidy_output)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 12 × 15\n   metric      data     fit   r.squared adj.r.squared   sigma statistic  p.value\n   <chr>       <list>   <lis>     <dbl>         <dbl>   <dbl>     <dbl>    <dbl>\n 1 pass_att    <tibble> <lm>     0.181         0.180  5.36e+1     131.  1.85e-27\n 2 pass_comp_… <tibble> <lm>     0.290         0.289  3.59e-2     242.  5.93e-46\n 3 yds_att     <tibble> <lm>     0.176         0.175  6.65e-1     127.  9.69e-27\n 4 pass_yds    <tibble> <lm>     0.306         0.305  4.93e+2     261.  7.20e-49\n 5 pass_td     <tibble> <lm>     0.180         0.178  6.63e+0     130.  2.77e-27\n 6 int         <tibble> <lm>     0.0623        0.0607 4.81e+0      39.3 7.06e-10\n 7 pass_rating <tibble> <lm>     0.233         0.232  1.04e+1     179.  6.61e-36\n 8 first_downs <tibble> <lm>     0.308         0.307  2.55e+1     263.  3.50e-49\n 9 pass_first… <tibble> <lm>     0.225         0.224  3.31e-2     172.  1.23e-34\n10 pass_20plus <tibble> <lm>     0.133         0.131  9.92e+0      90.3 5.03e-20\n11 pass_40plus <tibble> <lm>     0.0518        0.0502 3.51e+0      32.3 2.10e- 8\n12 sacks       <tibble> <lm>     0.121         0.119  1.01e+1      81.1 2.98e-18\n# … with 7 more variables: df <dbl>, logLik <dbl>, AIC <dbl>, BIC <dbl>,\n#   deviance <dbl>, df.residual <int>, nobs <int>\n```\n:::\n:::\n\nInstead we'll use `tidyr::hoist()` which pulls specific columns from nested data. In this case, we are extracting just the r.squared values for each respective metric and then arranging by r.squared. Full details of `unnest` vs `hoist` can be found at [`tidyr` site](https://tidyr.tidyverse.org/reference/hoist.html).\n\n::: {.cell}\n\n```{.r .cell-code}\noff_lm_output <- tidy_off_models %>% \n    hoist(tidy_output, r.squared = \"r.squared\") %>% \n    arrange(desc(r.squared))\n\noff_lm_output\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 12 × 5\n   metric         data               fit    r.squared tidy_output      \n   <chr>          <list>             <list>     <dbl> <list>           \n 1 first_downs    <tibble [593 × 5]> <lm>      0.308  <tibble [1 × 11]>\n 2 pass_yds       <tibble [593 × 5]> <lm>      0.306  <tibble [1 × 11]>\n 3 pass_comp_pct  <tibble [593 × 5]> <lm>      0.290  <tibble [1 × 11]>\n 4 pass_rating    <tibble [593 × 5]> <lm>      0.233  <tibble [1 × 11]>\n 5 pass_first_pct <tibble [593 × 5]> <lm>      0.225  <tibble [1 × 11]>\n 6 pass_att       <tibble [593 × 5]> <lm>      0.181  <tibble [1 × 11]>\n 7 pass_td        <tibble [593 × 5]> <lm>      0.180  <tibble [1 × 11]>\n 8 yds_att        <tibble [593 × 5]> <lm>      0.176  <tibble [1 × 11]>\n 9 pass_20plus    <tibble [593 × 5]> <lm>      0.133  <tibble [1 × 11]>\n10 sacks          <tibble [593 × 5]> <lm>      0.121  <tibble [1 × 11]>\n11 int            <tibble [593 × 5]> <lm>      0.0623 <tibble [1 × 11]>\n12 pass_40plus    <tibble [593 × 5]> <lm>      0.0518 <tibble [1 × 11]>\n```\n:::\n:::\n\n### Get just the good bits\n\nSo we just want the r.squared and metric values, plus a label we can use for `ggplot` down the road. Boom we have the final output!\n\n\n::: {.cell}\n\n```{.r .cell-code}\noff_stability <- off_lm_output %>% \n  select(metric, r.squared) %>% \n  mutate(metric_label = glue::glue(\"{metric} (R^2 = {round(r.squared, 3)})\"))\n\noff_stability\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 12 × 3\n   metric         r.squared metric_label                \n   <chr>              <dbl> <glue>                      \n 1 first_downs       0.308  first_downs (R^2 = 0.308)   \n 2 pass_yds          0.306  pass_yds (R^2 = 0.306)      \n 3 pass_comp_pct     0.290  pass_comp_pct (R^2 = 0.29)  \n 4 pass_rating       0.233  pass_rating (R^2 = 0.233)   \n 5 pass_first_pct    0.225  pass_first_pct (R^2 = 0.225)\n 6 pass_att          0.181  pass_att (R^2 = 0.181)      \n 7 pass_td           0.180  pass_td (R^2 = 0.18)        \n 8 yds_att           0.176  yds_att (R^2 = 0.176)       \n 9 pass_20plus       0.133  pass_20plus (R^2 = 0.133)   \n10 sacks             0.121  sacks (R^2 = 0.121)         \n11 int               0.0623 int (R^2 = 0.062)           \n12 pass_40plus       0.0518 pass_40plus (R^2 = 0.052)   \n```\n:::\n:::\n\n# TLDR\n\nNow that may have seemed like a lot of code, mainly because we broke down an example. Let's look at it all together now. We rearranged the dataset, nested, ran 9 models, and got our outputs in one pipe with just a few lines of code!\n\n::: {.cell}\n\n```{.r .cell-code}\n(off_stability <- long_off_stats %>% \n    inner_join(long_off_stats, by = c(\"season2\" = \"season\", \"team\", \"metric\")) %>% \n    select(everything(), -season2.y) %>% \n    nest(data = c(-metric)) %>% \n    mutate(\n      fit = map(data, ~ lm(value.y ~ value.x, data = .x)),\n      glanced = map(fit, glance)\n    ) %>% \n    hoist(glanced, r.squared = \"r.squared\") %>% \n    arrange(desc(r.squared)) %>% \n    mutate(metric_label = glue::glue(\"{metric} (R^2 = {round(r.squared, 3)})\")))\n```\n:::\n\n# Plot it\n\nNow there's another advantage to getting data into this longer format!\n\nWe can combine our labels that we generated with `glue` and the long-form data to plot ALL of the raw metrics at once with one `ggplot`. Note I have added an example line in light grey (slope = 1 for perfect fit) and a red-line for the `lm` for each dataset. That's all for this example, but hopefully that opened your eyes to a nest-map-unnest workflow even for relatively simple models!\n\nI'd definitely recommend trying out the rest of the `tidymodels` ecosystem for your more advanced machine learning and statistical analyses. You can learn all about it at the [tidymodels.org site](https://www.tidymodels.org/learn/).\n\n::: {.cell}\n\n```{.r .cell-code}\n(off_plot <- long_off_stats %>% \n    inner_join(long_off_stats, by = c(\"season2\" = \"season\", \"team\", \"metric\")) %>% \n    mutate(metric = factor(metric,\n                           levels = pull(off_stability, metric),\n                           labels = pull(off_stability, metric_label))) %>% \n    ggplot(aes(x = value.x, y = value.y)) +\n    geom_point(color = \"black\", alpha = 0.5) +\n    geom_smooth(method = \"lm\", color = \"#ff2b4f\", se = FALSE) +\n   scale_x_continuous(breaks = scales::pretty_breaks(n = 5)) +\n   scale_y_continuous(breaks = scales::pretty_breaks(n = 5)) +\n   geom_abline(intercept = 0, slope = 1, color = \"grey\", size = 1, alpha = 0.5) +\n    facet_wrap(~metric, scales = \"free\") +\n    labs(x = \"\\nYear Y Metric\", \n         y = \"Year Y + 1 Metric\\n\",\n         title = \"Offense Stats - 2000-2019\",\n         subtitle = \"Linear model fit comparing Year and Year + 1\",\n         caption = \"Plot: @thomas_mock | Data: espnscrapeR\")  +\n    theme_minimal() +\n    theme(strip.background = element_rect(fill = \"black\"),\n          strip.text = element_textbox(face = \"bold\", color = \"white\")))\n\n# optional output\n# ggsave(\"off_stability_plot.png\", off_plot, height = 8, width = 10, dpi = 150)\n```\n:::\n\n:::{.column-body-outset}\n\n::: {.cell}\n::: {.cell-output-display}\n![](off_stability_plot.png){width=500}\n:::\n:::\n\n:::\n\n:::{.callout-tip collapse=\"true\"}\n## Expand for Session Info\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.1.1 (2021-08-10)\n os       macOS Monterey 12.2.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       America/Chicago\n date     2022-04-25\n pandoc   2.18 @ /Applications/RStudio.app/Contents/MacOS/quarto/bin/tools/ (via rmarkdown)\n quarto   0.9.294 @ /usr/local/bin/quarto\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version date (UTC) lib source\n broom       * 0.7.9   2021-07-27 [1] CRAN (R 4.1.0)\n dplyr       * 1.0.8   2022-02-08 [1] CRAN (R 4.1.1)\n espnscrapeR * 0.6.5   2021-10-27 [1] Github (jthomasmock/espnscrapeR@084ce80)\n forcats     * 0.5.1   2021-01-27 [1] CRAN (R 4.1.1)\n ggplot2     * 3.3.5   2021-06-25 [1] CRAN (R 4.1.1)\n ggtext      * 0.1.1   2020-12-17 [1] CRAN (R 4.1.1)\n glue        * 1.6.2   2022-02-24 [1] CRAN (R 4.1.1)\n purrr       * 0.3.4   2020-04-17 [1] CRAN (R 4.1.0)\n readr       * 2.0.2   2021-09-27 [1] CRAN (R 4.1.1)\n sessioninfo * 1.2.2   2021-12-06 [1] CRAN (R 4.1.1)\n stringr     * 1.4.0   2019-02-10 [1] CRAN (R 4.1.1)\n tibble      * 3.1.6   2021-11-07 [1] CRAN (R 4.1.1)\n tidyr       * 1.2.0   2022-02-01 [1] CRAN (R 4.1.1)\n tidyverse   * 1.3.1   2021-04-15 [1] CRAN (R 4.1.0)\n\n [1] /Library/Frameworks/R.framework/Versions/4.1-arm64/Resources/library\n\n──────────────────────────────────────────────────────────────────────────────\n```\n:::\n:::\n\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}